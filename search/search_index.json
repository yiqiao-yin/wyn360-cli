{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"WYN360 CLI","text":"<p>An intelligent AI coding assistant that helps you build projects, generate code, and improve your codebase through natural language conversations.</p> <p> </p> <p>\ud83d\udcda Documentation: https://yiqiao-yin.github.io/wyn360-cli/</p> <p>\ud83d\udd17 GitHub Repository: https://github.com/yiqiao-yin/wyn360-cli</p>"},{"location":"#why-choose-wyn360-cli","title":"Why Choose WYN360 CLI?","text":"<ul> <li>\ud83e\udd16 Interactive AI Assistant - Natural language conversations with Claude</li> <li>\ud83d\udcdd Code Generation - Generate production-ready Python code from descriptions</li> <li>\ud83d\udd0d Project Analysis - Understand and improve existing codebases</li> <li>\u26a1 Multi-Provider Support - Anthropic Claude, AWS Bedrock, Google Gemini</li> <li>\ud83c\udf10 Web Integration - Real-time search and autonomous browsing capabilities</li> <li>\ud83d\udcc4 Document Processing - Read Excel, Word, PDF files with vision support</li> <li>\ud83d\udd12 Enterprise Ready - Secure credential management and session handling</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#1-install","title":"1. Install","text":"<pre><code>pip install wyn360-cli\n</code></pre>"},{"location":"#2-choose-your-ai-provider","title":"2. Choose Your AI Provider","text":"<p>WYN360 CLI supports three AI providers:</p> Anthropic ClaudeAWS BedrockGoogle Gemini (Recommended)OpenAIAuto-Detection <p>Why Claude? Most capable, excellent for complex coding tasks</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=1\nexport ANTHROPIC_API_KEY=your_key_here\nexport ANTHROPIC_MODEL=claude-sonnet-4-20250514\n</code></pre></p> <p>Get API Key: Anthropic Console</p> <p>Available Models: - <code>claude-sonnet-4-20250514</code> - Most capable (default) - <code>claude-3-5-haiku-20241022</code> - Fastest and cheapest - <code>claude-opus-4-1-20250805</code> - Most powerful</p> <p>Why Bedrock? Enterprise AWS integration, compliance features</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=2\nexport AWS_ACCESS_KEY_ID=your_access_key\nexport AWS_SECRET_ACCESS_KEY=your_secret_key\nexport AWS_SESSION_TOKEN=your_session_token\nexport AWS_REGION=us-west-2\nexport ANTHROPIC_MODEL=us.anthropic.claude-sonnet-4-20250514-v1:0\n</code></pre></p> <p>Requirements: Valid AWS account with Bedrock access</p> <p>Why Gemini? ~40x cheaper than Claude, 2M context window, fast performance</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=3\nexport GEMINI_API_KEY=your_key_here\nexport GEMINI_MODEL=gemini-2.5-flash\n</code></pre></p> <p>Get API Key: Google AI Studio</p> <p>Pricing: $0.075 per million input tokens (vs $3.00 for Claude)</p> <p>Why OpenAI? Industry-leading performance, competitive pricing, fast response times</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=4\nexport OPENAI_API_KEY=your_key_here\nexport OPENAI_MODEL=gpt-4o\n</code></pre></p> <p>Get API Key: OpenAI Platform</p> <p>Available Models: - <code>gpt-4o</code> - Latest and most capable (default) - <code>gpt-4</code> - Stable and reliable - <code>gpt-3.5-turbo</code> - Fast and cost-effective</p> <p>Let WYN360 choose automatically based on available credentials:</p> <pre><code># Just set your preferred API key - no CHOOSE_CLIENT needed\nexport GEMINI_API_KEY=your_key_here\n# System automatically detects and uses Gemini\n</code></pre> <p>Priority order: 1. <code>ANTHROPIC_API_KEY</code> \u2192 Use Anthropic 2. AWS credentials \u2192 Use Bedrock 3. <code>GEMINI_API_KEY</code> \u2192 Use Gemini 4. <code>OPENAI_API_KEY</code> \u2192 Use OpenAI</p>"},{"location":"#3-start-chatting","title":"3. Start Chatting","text":"<pre><code>wyn360\n</code></pre> <pre><code>You: Build a Streamlit app for data visualization\n\nWYN360: I'll create a Streamlit app for you...\n[Generates complete code and saves to app.py]\n</code></pre> <p>Get Started \u2192 View Examples \u2192</p>"},{"location":"#core-capabilities","title":"Core Capabilities","text":""},{"location":"#ai-powered-development","title":"\ud83e\udd16 AI-Powered Development","text":"<ul> <li>Natural Language Interface - Describe what you want in plain English</li> <li>Code Generation - From simple scripts to complete applications</li> <li>Smart File Operations - Context-aware file creation and updates</li> <li>Intent Recognition - Understands \"update\" vs \"create new\" automatically</li> </ul>"},{"location":"#advanced-features","title":"\u26a1 Advanced Features","text":"<ul> <li>Real-Time Web Search - Access current information and resources</li> <li>Autonomous Browsing - AI navigates websites and extracts data</li> <li>Document Processing - Read and analyze Excel, Word, PDF files</li> <li>Vision Mode - Process images, charts, and diagrams</li> <li>GitHub Integration - Commit, push, create PRs seamlessly</li> <li>HuggingFace Deployment - Deploy to Spaces with one command</li> </ul>"},{"location":"#developer-experience","title":"\ud83c\udfaf Developer Experience","text":"<ul> <li>Multi-line Input - Shift+Enter for newlines, Enter to submit</li> <li>Streaming Responses - See results as they're generated</li> <li>Session Management - Save/load conversations</li> <li>Token Tracking - Monitor usage and costs</li> <li>Model Switching - Change AI models mid-session</li> </ul>"},{"location":"#recent-updates","title":"Recent Updates","text":""},{"location":"#v0360-google-gemini-integration","title":"v0.3.60 - Google Gemini Integration \ud83c\udd95","text":"<ul> <li>New AI Provider: Google Gemini support with 2M context window</li> <li>Cost Effective: ~40x cheaper than Claude ($0.075/M vs $3.00/M tokens)</li> <li>All Tools Supported: File ops, git, docs, browser automation</li> <li>Auto-Detection: Intelligent provider selection based on available credentials</li> </ul>"},{"location":"#v0352-56-autonomous-browsing","title":"v0.3.52-56 - Autonomous Browsing \ud83d\ude80","text":"<ul> <li>Vision-Powered Navigation: AI \"sees\" and understands web pages</li> <li>Multi-Step Tasks: Complex workflows (search, filter, compare, extract)</li> <li>Authenticated Sessions: Works with saved login credentials</li> <li>Error Resilient: Automatic retry and timeout handling</li> </ul>"},{"location":"#v0330-vision-mode","title":"v0.3.30 - Vision Mode \ud83d\udc41\ufe0f","text":"<ul> <li>Document Images: Process charts, diagrams, screenshots in documents</li> <li>AI-Powered OCR: Extract insights from visual content</li> <li>Cost Transparency: Separate tracking for vision API usage</li> </ul>"},{"location":"#example-workflows","title":"Example Workflows","text":""},{"location":"#starting-a-new-project","title":"Starting a New Project","text":"<pre><code>You: Create a FastAPI app with authentication\n\nWYN360:\n\u2713 Generated main.py with FastAPI setup\n\u2713 Created auth middleware\n\u2713 Added example routes\n\u2713 Provided setup instructions\n</code></pre>"},{"location":"#research-and-analysis","title":"Research and Analysis","text":"<pre><code>You: Find the latest Python web frameworks and compare them\n\nWYN360: [Searches web for current information]\n\n## Popular Python Web Frameworks (2025)\n\n1. **FastAPI** \u2b50 76k stars - Modern, fast, OpenAPI support\n2. **Django** \u2b50 79k stars - Batteries included, ORM, admin\n3. **Flask** \u2b50 67k stars - Lightweight, flexible, minimal\n\n[Provides detailed comparison with current data]\n</code></pre>"},{"location":"#document-processing","title":"Document Processing","text":"<pre><code>You: Analyze quarterly_report.docx with vision mode\n\nWYN360:\n\ud83d\udcca Revenue Chart: Q4 shows 23% growth to $2.5M\n\ud83d\udcd0 Architecture Diagram: 3-tier system (React \u2192 FastAPI \u2192 PostgreSQL)\n\ud83d\udcb0 Vision Cost: $0.06 (2 images processed)\n\n[Full document analysis with image insights]\n</code></pre>"},{"location":"#whats-next","title":"What's Next?","text":"<p>Explore the documentation to learn more about WYN360 CLI's capabilities:</p> <ul> <li>Getting Started - Installation and setup</li> <li>Features - Complete feature overview</li> <li>Usage Examples - Real-world workflows</li> <li>Architecture - Technical deep dive</li> </ul> <p>Current Version: 0.3.64 Last Updated: November 22, 2025</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/","title":"Browser Authentication - Analysis &amp; Recommendations","text":"<p>Date: 2025-11-13 Version: 0.3.41 Status: Phase 4 Complete - Improvement Recommendations</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#executive-summary","title":"Executive Summary","text":"<p>The current browser authentication implementation (Phase 4.1-4.3) successfully provides: - \u2705 Secure credential storage (AES-256-GCM) - \u2705 Session management (TTL-based) - \u2705 Basic form detection - \u2705 CAPTCHA/2FA detection - \u2705 48/48 tests passing</p> <p>However, real-world testing revealed critical limitations when attempting to login to <code>wyn360search.com</code>: - \u274c Form detection failed - \u274c No debugging information available - \u274c No fallback strategies</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#problem-analysis","title":"Problem Analysis","text":""},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#what-went-wrong","title":"What Went Wrong?","text":"<p>User Command: <pre><code>You: can you log in http://wyn360search.com/ for me?\n     My username is 'your_username' and password is 'your_password'\n</code></pre></p> <p>System Response: <pre><code>\u274c Login Form Detection Failed\nCould not detect login form at:\n- http://wyn360search.com/\n- http://wyn360search.com/login\n- http://wyn360search.com/signin\n</code></pre></p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#root-causes","title":"Root Causes","text":""},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#1-limited-form-detection-selectors","title":"1. Limited Form Detection Selectors","text":"<p>Current Implementation: (<code>browser_auth.py:61-114</code>) <pre><code>username_selectors = [\n    'input[type=\"email\"]',\n    'input[type=\"text\"][name*=\"user\"]',\n    'input[name=\"username\"]',\n    'input[id=\"username\"]',\n    # ... 11 total selectors\n]\n</code></pre></p> <p>Issues: - Only covers common patterns - Doesn't handle custom/non-standard forms - No fuzzy matching or AI-based detection - Sequential search (stops at first match, might not be the right one)</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#2-no-dynamic-content-handling","title":"2. No Dynamic Content Handling","text":"<p>Many modern websites use: - React/Vue/Angular - Forms loaded via JavaScript after page load - Shadow DOM - Encapsulated components not accessible via standard selectors - Lazy loading - Forms appear on scroll/interaction - Modal dialogs - Login popup overlays</p> <p>Current Implementation: <pre><code>await self.page.goto(url, timeout=self.timeout)\nform = await self._detect_login_form(self.page)  # Immediate detection\n</code></pre></p> <p>Missing: - Wait for JavaScript to execute - Wait for specific elements to appear - Handle iframes/shadow DOM - Detect and interact with modals</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#3-no-debuggingvisibility","title":"3. No Debugging/Visibility","text":"<p>When form detection fails, users get: <pre><code>\u274c Could not detect login form. Please check the URL.\n</code></pre></p> <p>What's Missing: - What selectors were tried? - What elements were found on the page? - Screenshot of the page at failure point - HTML dump of form-like elements - Console logs/JavaScript errors</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#4-no-fallback-strategies","title":"4. No Fallback Strategies","text":"<p>Current Flow: <pre><code>goto(url) \u2192 detect_form() \u2192 fail\n</code></pre></p> <p>Missing Strategies: - Try common login URLs (<code>/login</code>, <code>/signin</code>, <code>/auth</code>, <code>/account/login</code>) - Look for \"Login\" links on homepage and follow them - Scroll page to trigger lazy-loaded forms - Wait longer for JavaScript frameworks to load - Use LLM to analyze page HTML and suggest selectors</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#5-no-manual-override","title":"5. No Manual Override","text":"<p>Users cannot: - Specify custom selectors - Provide the exact login URL - Skip form detection and use browser interactively - Supply HTML snippets for analysis</p>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#recommended-solutions","title":"Recommended Solutions","text":""},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#phase-44-enhanced-form-detection-priority-high","title":"Phase 4.4: Enhanced Form Detection (Priority: HIGH)","text":""},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#441-intelligent-url-discovery","title":"4.4.1: Intelligent URL Discovery","text":"<pre><code>async def find_login_page(self, base_url: str) -&gt; str:\n    \"\"\"\n    Intelligently find login page by:\n    1. Checking common login URLs\n    2. Following 'Login' links on homepage\n    3. Analyzing page content\n    \"\"\"\n    # Try common patterns\n    common_paths = [\n        '/login', '/signin', '/sign-in', '/auth',\n        '/account/login', '/user/login', '/accounts/signin'\n    ]\n\n    # Try each path\n    for path in common_paths:\n        test_url = urljoin(base_url, path)\n        if await self._has_login_form(test_url):\n            return test_url\n\n    # Search homepage for login links\n    await self.page.goto(base_url)\n    login_links = await self.page.locator('a:has-text(\"log in\"), a:has-text(\"sign in\")').all()\n    for link in login_links:\n        href = await link.get_attribute('href')\n        if href and await self._has_login_form(href):\n            return href\n\n    return base_url  # Fallback to original URL\n</code></pre>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#442-dynamic-content-waiting","title":"4.4.2: Dynamic Content Waiting","text":"<pre><code>async def _wait_for_form_load(self, page: Page, max_wait: int = 10000):\n    \"\"\"Wait for login form to appear dynamically.\"\"\"\n    selectors = [\n        'input[type=\"password\"]',  # Password field is most unique\n        'form[action*=\"login\"]',\n        'div[class*=\"login\"]'\n    ]\n\n    # Wait for ANY selector to appear\n    try:\n        await page.wait_for_selector(\n            ', '.join(selectors),\n            timeout=max_wait,\n            state='visible'\n        )\n    except TimeoutError:\n        pass  # Continue with detection anyway\n</code></pre>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#443-enhanced-form-detection-with-fuzzy-matching","title":"4.4.3: Enhanced Form Detection with Fuzzy Matching","text":"<pre><code>async def _detect_login_form_enhanced(self, page: Page) -&gt; Dict:\n    \"\"\"Enhanced form detection with broader coverage.\"\"\"\n\n    # Wait for dynamic content\n    await self._wait_for_form_load(page)\n\n    # Get ALL input elements\n    all_inputs = await page.locator('input').all()\n\n    username_field = None\n    password_field = None\n\n    for input_elem in all_inputs:\n        input_type = await input_elem.get_attribute('type')\n        input_name = await input_elem.get_attribute('name') or ''\n        input_id = await input_elem.get_attribute('id') or ''\n        input_placeholder = await input_elem.get_attribute('placeholder') or ''\n\n        # Combine all attributes for fuzzy matching\n        combined = f\"{input_type} {input_name} {input_id} {input_placeholder}\".lower()\n\n        # Fuzzy match for username\n        if any(kw in combined for kw in ['user', 'email', 'login', 'account']):\n            if input_type != 'password':\n                username_field = input_elem\n\n        # Exact match for password\n        if input_type == 'password':\n            password_field = input_elem\n\n    return {\n        'username': username_field,\n        'password': password_field,\n        'submit': await self._find_submit_button(page)\n    }\n</code></pre>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#444-debug-mode-with-screenshots","title":"4.4.4: Debug Mode with Screenshots","text":"<pre><code>async def login(self, url: str, username: str, password: str, debug: bool = False):\n    \"\"\"Login with optional debug mode.\"\"\"\n\n    if debug:\n        debug_dir = Path.home() / '.wyn360' / 'debug' / 'browser_auth'\n        debug_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = int(time.time())\n\n    # Navigate\n    await self.page.goto(url)\n\n    if debug:\n        # Save screenshot\n        await self.page.screenshot(\n            path=str(debug_dir / f'{timestamp}_1_initial.png')\n        )\n\n        # Save HTML\n        html_content = await self.page.content()\n        with open(debug_dir / f'{timestamp}_page.html', 'w') as f:\n            f.write(html_content)\n\n    # Detect form\n    form = await self._detect_login_form_enhanced(self.page)\n\n    if not form['username'] or not form['password']:\n        if debug:\n            # Save what we found\n            debug_info = {\n                'url': url,\n                'found_inputs': await self._get_all_inputs_info(self.page),\n                'found_buttons': await self._get_all_buttons_info(self.page)\n            }\n            with open(debug_dir / f'{timestamp}_form_detection.json', 'w') as f:\n                json.dump(debug_info, f, indent=2)\n\n        result['message'] = \"Could not detect login form.\"\n        if debug:\n            result['message'] += f\"\\n\\nDebug files saved to: {debug_dir}\"\n        return result\n\n    # Continue with login...\n</code></pre>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#445-manual-selector-override","title":"4.4.5: Manual Selector Override","text":"<pre><code>async def login_with_selectors(\n    self,\n    url: str,\n    username: str,\n    password: str,\n    username_selector: str,\n    password_selector: str,\n    submit_selector: Optional[str] = None\n) -&gt; Dict:\n    \"\"\"\n    Login using manually specified selectors.\n\n    Usage:\n        login_with_selectors(\n            url=\"http://wyn360search.com/\",\n            username=\"your_username\",\n            password=\"your_password\",\n            username_selector='#user_login',\n            password_selector='#user_pass',\n            submit_selector='#wp-submit'\n        )\n    \"\"\"\n    # Use provided selectors directly\n    await self.page.goto(url)\n    await self.page.fill(username_selector, username)\n    await self.page.fill(password_selector, password)\n\n    if submit_selector:\n        await self.page.click(submit_selector)\n    else:\n        await self.page.press(password_selector, 'Enter')\n\n    # Wait and verify...\n</code></pre>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#phase-45-llm-powered-form-analysis-priority-medium","title":"Phase 4.5: LLM-Powered Form Analysis (Priority: MEDIUM)","text":"<p>Use the Claude API to analyze page HTML when form detection fails:</p> <pre><code>async def _analyze_page_with_llm(self, page: Page) -&gt; Dict:\n    \"\"\"Use LLM to analyze page and suggest selectors.\"\"\"\n\n    html_content = await page.content()\n\n    # Truncate HTML to avoid token limits\n    html_snippet = html_content[:50000]  # ~12k tokens\n\n    prompt = f\"\"\"\n    Analyze this HTML and identify login form elements:\n\n    {html_snippet}\n\n    Return JSON with:\n    {{\n        \"has_login_form\": true/false,\n        \"username_selector\": \"css selector or null\",\n        \"password_selector\": \"css selector or null\",\n        \"submit_selector\": \"css selector or null\",\n        \"confidence\": 0-100,\n        \"reasoning\": \"brief explanation\"\n    }}\n    \"\"\"\n\n    # Call Claude API\n    response = anthropic_client.messages.create(\n        model=\"claude-3-5-sonnet-20241022\",\n        max_tokens=1000,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n\n    analysis = json.loads(response.content[0].text)\n\n    if analysis['confidence'] &gt; 70:\n        return {\n            'username': analysis['username_selector'],\n            'password': analysis['password_selector'],\n            'submit': analysis['submit_selector']\n        }\n\n    return None\n</code></pre>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#phase-46-interactive-browser-mode-priority-low","title":"Phase 4.6: Interactive Browser Mode (Priority: LOW)","text":"<p>Allow users to login manually while system captures session:</p> <pre><code>async def interactive_login(self, url: str) -&gt; Dict:\n    \"\"\"\n    Launch non-headless browser, let user login manually,\n    capture cookies when done.\n    \"\"\"\n\n    print(\"\ud83c\udf10 Opening browser for manual login...\")\n    print(\"\ud83d\udcdd Please login manually, then return here and press ENTER\")\n\n    # Launch visible browser\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=False)\n        page = await browser.new_page()\n\n        await page.goto(url)\n\n        # Wait for user to press Enter\n        input(\"\\n\u2705 Press ENTER after you've logged in successfully: \")\n\n        # Get cookies\n        cookies = await page.context.cookies()\n\n        await browser.close()\n\n        return {\n            'success': True,\n            'message': 'Manual login completed',\n            'cookies': cookies\n        }\n</code></pre>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#implementation-priority","title":"Implementation Priority","text":""},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#immediate-v0342","title":"Immediate (v0.3.42)","text":"<ol> <li>\u2705 Add debug mode with screenshots (<code>debug=True</code> parameter)</li> <li>\u2705 Improve error messages with actionable guidance</li> <li>\u2705 Add dynamic content waiting (5-second wait for forms)</li> <li>\u2705 Try common login URLs automatically</li> </ol>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#short-term-v0343-44","title":"Short-term (v0.3.43-44)","text":"<ol> <li>\u2705 Enhanced form detection with fuzzy matching</li> <li>\u2705 Manual selector override method</li> <li>\u2705 Homepage login link following</li> </ol>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#medium-term-v040","title":"Medium-term (v0.4.0)","text":"<ol> <li>\u23f3 LLM-powered form analysis</li> <li>\u23f3 Interactive browser mode</li> <li>\u23f3 Shadow DOM support</li> </ol>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#testing-strategy","title":"Testing Strategy","text":""},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#test-cases-for-wyn360searchcom","title":"Test Cases for wyn360search.com","text":"<ol> <li>Test with Debug Mode: <pre><code>wyn360 \"login to http://wyn360search.com/ with your_username/your_password --debug\"\n</code></pre></li> </ol> <p>Expected: Screenshots + HTML dump saved to <code>~/.wyn360/debug/browser_auth/</code></p> <ol> <li> <p>Test Manual Selectors: <pre><code>wyn360 \"login to http://wyn360search.com/ with your_username/your_password using selectors #username, #password, #login-button\"\n</code></pre></p> </li> <li> <p>Test Interactive Mode: <pre><code>wyn360 \"help me login to wyn360search.com interactively\"\n</code></pre></p> </li> </ol>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#metrics-for-success","title":"Metrics for Success","text":"Metric Current (v0.3.41) Target (v0.4.0) Login Success Rate ~60% &gt;90% Form Detection Rate ~70% &gt;95% Average Time to Login 15s &lt;10s Debug Info Quality None Comprehensive Manual Override Required N/A &lt;5% of cases"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#user-guidance-immediate","title":"User Guidance (Immediate)","text":"<p>For your current issue with wyn360search.com:</p> <ol> <li>Enable Debug Mode:</li> <li>Ask: \"Login to wyn360search.com with debug mode enabled\"</li> <li> <p>This will save screenshots and HTML</p> </li> <li> <p>Try Manual Login:</p> </li> <li>Visit http://wyn360search.com/ in your browser</li> <li>Inspect the login form (right-click \u2192 Inspect)</li> <li>Find the CSS selectors for username/password fields</li> <li> <p>Use: \"Login with custom selectors #user, #pass, #submit\"</p> </li> <li> <p>Interactive Fallback:</p> </li> <li>Ask: \"Open browser for manual login to wyn360search.com\"</li> <li> <p>Login manually, system captures cookies</p> </li> <li> <p>Temporary Workaround:</p> </li> <li>Login manually in browser</li> <li>Export cookies using browser extension</li> <li>Provide cookies to WYN360 directly</li> </ol>"},{"location":"BROWSER_AUTH_RECOMMENDATIONS/#conclusion","title":"Conclusion","text":"<p>The browser authentication feature is functionally complete (Phase 4.1-4.3) but needs production hardening (Phase 4.4-4.6) to handle diverse real-world websites.</p> <p>Recommendation: Implement Phase 4.4 (Enhanced Form Detection) as the next priority to significantly improve login success rates.</p> <p>Estimated Effort: - Phase 4.4: 8-12 hours (2-3 sessions) - Phase 4.5: 4-6 hours (1-2 sessions) - Phase 4.6: 3-4 hours (1 session)</p> <p>Total: ~20 hours for production-ready browser authentication</p>"},{"location":"ROADMAP_ADD_BEDROCK/","title":"AWS Bedrock Integration Roadmap","text":"<p>Version: 0.3.45 (Target) Date: 2025-11-15 Status: Planning Phase</p>"},{"location":"ROADMAP_ADD_BEDROCK/#executive-summary","title":"Executive Summary","text":"<p>Add AWS Bedrock support to WYN360 CLI, allowing users to authenticate using AWS credentials instead of (or in addition to) direct Anthropic API keys.</p> <p>Current State: - \u2705 Authentication: <code>ANTHROPIC_API_KEY</code> only - \u2705 Client: <code>anthropic.Anthropic</code> - \u2705 Model: <code>AnthropicModel</code> from <code>pydantic_ai.models.anthropic</code></p> <p>Target State: - \u2705 Authentication: <code>ANTHROPIC_API_KEY</code> (default) OR AWS credentials (opt-in) - \u2705 Client: <code>anthropic.Anthropic</code> OR <code>anthropic.AnthropicBedrock</code> - \u2705 Model: <code>AnthropicModel</code> with either client backend - \u2705 Feature flag: <code>CLAUDE_CODE_USE_BEDROCK=1</code> to enable AWS mode</p>"},{"location":"ROADMAP_ADD_BEDROCK/#user-experience","title":"User Experience","text":""},{"location":"ROADMAP_ADD_BEDROCK/#scenario-1-current-behavior-no-changes","title":"Scenario 1: Current Behavior (No Changes)","text":"<pre><code># User sets Anthropic API key (existing behavior)\nexport ANTHROPIC_API_KEY=\"sk-ant-xxxxx\"\nwyn360 \"write a script to analyze data.csv\"\n# \u2705 Works as before - uses Anthropic API directly\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#scenario-2-aws-bedrock-authentication-new","title":"Scenario 2: AWS Bedrock Authentication (New)","text":"<pre><code># User sets AWS credentials + enables Bedrock\nexport AWS_ACCESS_KEY_ID=\"AKIA...\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx...\"\nexport AWS_SESSION_TOKEN=\"xxx...\"  # Optional - for temporary credentials\nexport CLAUDE_CODE_USE_BEDROCK=1\nexport AWS_REGION=\"us-west-2\"  # Optional - defaults to us-east-1\nexport ANTHROPIC_MODEL=\"us.anthropic.claude-sonnet-4-20250514-v1:0\"  # Optional - custom model\n\nwyn360 \"write a script to analyze data.csv\"\n# \u2705 Uses AWS Bedrock instead of Anthropic API\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#scenario-3-missing-credentials-error-handling","title":"Scenario 3: Missing Credentials (Error Handling)","text":"<pre><code># User enables Bedrock but forgets AWS credentials\nexport CLAUDE_CODE_USE_BEDROCK=1\nwyn360 \"hello\"\n\n# \u274c Error message:\n# Error: AWS Bedrock mode enabled but credentials not found.\n#\n# Please set the following environment variables:\n#   - AWS_ACCESS_KEY_ID\n#   - AWS_SECRET_ACCESS_KEY\n#   - AWS_SESSION_TOKEN (optional, for temporary credentials)\n#\n# Or disable Bedrock mode:\n#   unset CLAUDE_CODE_USE_BEDROCK\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#architecture-changes","title":"Architecture Changes","text":""},{"location":"ROADMAP_ADD_BEDROCK/#current-architecture","title":"Current Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 User sets ANTHROPIC_API_KEY             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 WYN360Agent.__init__()                  \u2502\n\u2502  - Creates AnthropicModel               \u2502\n\u2502  - Uses anthropic.Anthropic client      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 API Calls to api.anthropic.com          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#new-architecture-dual-mode","title":"New Architecture (Dual-Mode)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 User sets credentials:                                 \u2502\n\u2502  Option A: ANTHROPIC_API_KEY                           \u2502\n\u2502  Option B: AWS_* + CLAUDE_CODE_USE_BEDROCK=1           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n                 \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 WYN360Agent.__init__()                                 \u2502\n\u2502  - Checks CLAUDE_CODE_USE_BEDROCK environment variable \u2502\n\u2502  - If \"1\": Creates AnthropicBedrock client             \u2502\n\u2502  - If not set: Creates Anthropic client (default)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                \u2502\n         \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Anthropic    \u2502  \u2502 AnthropicBedrock \u2502\n\u2502 Direct API   \u2502  \u2502 AWS Bedrock      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#implementation-plan","title":"Implementation Plan","text":""},{"location":"ROADMAP_ADD_BEDROCK/#phase-1-dependency-updates","title":"Phase 1: Dependency Updates","text":""},{"location":"ROADMAP_ADD_BEDROCK/#11-add-anthropicbedrock-dependency","title":"1.1: Add anthropic[bedrock] Dependency","text":"<p>File: <code>pyproject.toml</code></p> <p>Current: <pre><code>dependencies = [\n    \"anthropic&gt;=0.39.0\",\n    # ... other deps\n]\n</code></pre></p> <p>New: <pre><code>dependencies = [\n    \"anthropic[bedrock]&gt;=0.39.0\",  # Changed: added [bedrock] extra\n    # ... other deps\n]\n</code></pre></p> <p>Note: The <code>anthropic[bedrock]</code> extra includes: - <code>anthropic</code> base package - <code>boto3</code> (AWS SDK for Python) - <code>botocore</code> (AWS core libraries)</p> <p>Commands: <pre><code>poetry add \"anthropic[bedrock]&gt;=0.39.0\"\npoetry lock\npoetry install\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-2-core-authentication-logic","title":"Phase 2: Core Authentication Logic","text":""},{"location":"ROADMAP_ADD_BEDROCK/#21-add-bedrock-detection-helper","title":"2.1: Add Bedrock Detection Helper","text":"<p>File: <code>wyn360_cli/agent.py</code></p> <p>Location: Add near top of file (after imports, around line 40)</p> <p>New Function: <pre><code>def _should_use_bedrock() -&gt; bool:\n    \"\"\"\n    Check if AWS Bedrock mode is enabled via environment variable.\n\n    Returns:\n        True if CLAUDE_CODE_USE_BEDROCK=1, False otherwise\n    \"\"\"\n    return os.getenv('CLAUDE_CODE_USE_BEDROCK', '0') == '1'\n\n\ndef _validate_aws_credentials() -&gt; Tuple[bool, str]:\n    \"\"\"\n    Validate that required AWS credentials are set.\n\n    Returns:\n        Tuple of (is_valid, error_message)\n        - is_valid: True if all required credentials present\n        - error_message: Error message if invalid, empty string if valid\n    \"\"\"\n    required_vars = ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY']\n    missing = [var for var in required_vars if not os.getenv(var)]\n\n    if missing:\n        error_msg = f\"\"\"AWS Bedrock mode enabled but credentials not found.\n\nPlease set the following environment variables:\n  - AWS_ACCESS_KEY_ID\n  - AWS_SECRET_ACCESS_KEY\n  - AWS_SESSION_TOKEN (optional, for temporary credentials)\n\nMissing variables: {', '.join(missing)}\n\nOr disable Bedrock mode:\n  unset CLAUDE_CODE_USE_BEDROCK\n\"\"\"\n        return False, error_msg\n\n    return True, \"\"\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#22-update-wyn360agentinit","title":"2.2: Update WYN360Agent.init()","text":"<p>File: <code>wyn360_cli/agent.py</code></p> <p>Current Code (lines ~66-100): <pre><code>def __init__(\n    self,\n    api_key: str,\n    model_name: str = \"claude-sonnet-4-20250514\",\n    max_history: int = 10\n):\n    self.api_key = api_key\n    self.model_name = model_name\n\n    # Create Anthropic model\n    from pydantic_ai.models.anthropic import AnthropicModel\n    self.model = AnthropicModel(model_name, api_key=api_key)\n\n    # ... rest of init\n</code></pre></p> <p>New Code: <pre><code>def __init__(\n    self,\n    api_key: Optional[str] = None,  # Changed: now optional\n    model_name: str = \"claude-sonnet-4-20250514\",\n    max_history: int = 10,\n    use_bedrock: Optional[bool] = None  # New: explicit override\n):\n    \"\"\"\n    Initialize WYN360 Agent with Anthropic or AWS Bedrock.\n\n    Args:\n        api_key: Anthropic API key (required if not using Bedrock)\n        model_name: Claude model to use\n        max_history: Number of messages to keep in history\n        use_bedrock: Explicitly set Bedrock mode (overrides env var)\n    \"\"\"\n    # Determine authentication mode\n    if use_bedrock is None:\n        use_bedrock = _should_use_bedrock()\n\n    self.use_bedrock = use_bedrock\n    self.model_name = model_name\n\n    # Import required classes\n    from pydantic_ai.models.anthropic import AnthropicModel\n\n    if self.use_bedrock:\n        # AWS Bedrock mode\n        is_valid, error_msg = _validate_aws_credentials()\n        if not is_valid:\n            raise ValueError(error_msg)\n\n        # Create Bedrock client\n        from anthropic import AnthropicBedrock\n\n        # Map model names to Bedrock model IDs\n        bedrock_model_id = self._get_bedrock_model_id(model_name)\n\n        # AnthropicBedrock automatically reads AWS credentials from environment\n        # AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN\n        bedrock_client = AnthropicBedrock()\n\n        # Create model with Bedrock backend\n        self.model = AnthropicModel(\n            bedrock_model_id,\n            http_client=bedrock_client\n        )\n\n        self.api_key = None  # Not used in Bedrock mode\n\n        print(\"\ud83c\udf29\ufe0f  AWS Bedrock mode enabled\")\n        print(f\"\ud83d\udce1 Using model: {bedrock_model_id}\")\n\n    else:\n        # Direct Anthropic API mode (existing behavior)\n        if not api_key:\n            raise ValueError(\n                \"ANTHROPIC_API_KEY is required when not using AWS Bedrock.\\n\"\n                \"Set environment variable: export ANTHROPIC_API_KEY=sk-ant-xxx\\n\"\n                \"Or enable Bedrock mode: export CLAUDE_CODE_USE_BEDROCK=1\"\n            )\n\n        self.api_key = api_key\n        self.model = AnthropicModel(model_name, api_key=api_key)\n\n    # ... rest of existing init code (unchanged)\n    self.max_history = max_history\n    self.conversation_history = []\n    # etc.\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#23-add-bedrock-model-id-mapper","title":"2.3: Add Bedrock Model ID Mapper","text":"<p>File: <code>wyn360_cli/agent.py</code></p> <p>Location: Add as new method in <code>WYN360Agent</code> class</p> <p>New Method: <pre><code>def _get_bedrock_model_id(self, model_name: str) -&gt; str:\n    \"\"\"\n    Map pydantic-ai model names to AWS Bedrock model IDs.\n\n    Args:\n        model_name: Model name from user (e.g., \"claude-sonnet-4-20250514\")\n\n    Returns:\n        Bedrock model ID (e.g., \"anthropic.claude-3-5-sonnet-20241022-v2:0\")\n\n    Reference:\n        https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html\n    \"\"\"\n    # Model mapping: pydantic-ai name \u2192 Bedrock ARN\n    bedrock_models = {\n        # Claude 3.5 Sonnet (latest)\n        \"claude-sonnet-4-20250514\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n        \"claude-3-5-sonnet-20241022\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n        \"claude-3-5-sonnet-20240620\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n\n        # Claude 3 Opus\n        \"claude-3-opus-20240229\": \"anthropic.claude-3-opus-20240229-v1:0\",\n\n        # Claude 3 Sonnet\n        \"claude-3-sonnet-20240229\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n\n        # Claude 3 Haiku\n        \"claude-3-haiku-20240307\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n    }\n\n    # Try exact match first\n    if model_name in bedrock_models:\n        return bedrock_models[model_name]\n\n    # Try partial match (e.g., \"sonnet\" \u2192 latest sonnet)\n    model_lower = model_name.lower()\n    if \"sonnet\" in model_lower:\n        return bedrock_models[\"claude-sonnet-4-20250514\"]  # Default to latest\n    elif \"opus\" in model_lower:\n        return bedrock_models[\"claude-3-opus-20240229\"]\n    elif \"haiku\" in model_lower:\n        return bedrock_models[\"claude-3-haiku-20240307\"]\n\n    # Fallback: use as-is (might be a direct Bedrock ARN)\n    print(f\"\u26a0\ufe0f  Unknown model '{model_name}', using as-is\")\n    return model_name\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-3-cli-integration","title":"Phase 3: CLI Integration","text":""},{"location":"ROADMAP_ADD_BEDROCK/#31-update-main-to-handle-bedrock-mode","title":"3.1: Update main() to Handle Bedrock Mode","text":"<p>File: <code>wyn360_cli/cli.py</code></p> <p>Current Code: <pre><code>def main():\n    api_key = os.getenv('ANTHROPIC_API_KEY')\n    if not api_key:\n        typer.echo(\"Error: ANTHROPIC_API_KEY not set\")\n        raise typer.Exit(code=1)\n\n    agent = WYN360Agent(api_key=api_key)\n    # ...\n</code></pre></p> <p>New Code: <pre><code>def main():\n    \"\"\"Main entry point for WYN360 CLI.\"\"\"\n\n    # Check if Bedrock mode is enabled\n    use_bedrock = os.getenv('CLAUDE_CODE_USE_BEDROCK', '0') == '1'\n\n    if use_bedrock:\n        # AWS Bedrock mode - no API key needed\n        try:\n            agent = WYN360Agent(use_bedrock=True)\n        except ValueError as e:\n            typer.echo(f\"Error: {e}\", err=True)\n            raise typer.Exit(code=1)\n    else:\n        # Direct Anthropic API mode - API key required\n        api_key = os.getenv('ANTHROPIC_API_KEY')\n        if not api_key:\n            typer.echo(\n                \"Error: ANTHROPIC_API_KEY not set\\n\\n\"\n                \"Options:\\n\"\n                \"  1. Set Anthropic API key: export ANTHROPIC_API_KEY=sk-ant-xxx\\n\"\n                \"  2. Use AWS Bedrock: export CLAUDE_CODE_USE_BEDROCK=1\\n\"\n                \"     (requires AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\",\n                err=True\n            )\n            raise typer.Exit(code=1)\n\n        agent = WYN360Agent(api_key=api_key)\n\n    # ... rest of main() unchanged\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-4-model-switching-support","title":"Phase 4: Model Switching Support","text":""},{"location":"ROADMAP_ADD_BEDROCK/#41-update-switch_model-for-bedrock","title":"4.1: Update switch_model() for Bedrock","text":"<p>File: <code>wyn360_cli/agent.py</code></p> <p>Current Code (lines ~3574-3593): <pre><code>async def switch_model(self, ctx: RunContext[None], model_name: str) -&gt; str:\n    # ... validation code ...\n\n    # Create new model instance\n    from pydantic_ai.models.anthropic import AnthropicModel\n    new_model = AnthropicModel(full_model_name)\n\n    # Update agent\n    self.model = new_model\n    self.model_name = full_model_name\n</code></pre></p> <p>New Code: <pre><code>async def switch_model(self, ctx: RunContext[None], model_name: str) -&gt; str:\n    \"\"\"\n    Switch to a different Claude model.\n\n    Works in both Anthropic API and AWS Bedrock modes.\n    \"\"\"\n    # ... existing validation code ...\n\n    # Create new model instance\n    from pydantic_ai.models.anthropic import AnthropicModel\n\n    if self.use_bedrock:\n        # Bedrock mode: map to Bedrock model ID\n        from anthropic import AnthropicBedrock\n\n        bedrock_model_id = self._get_bedrock_model_id(model_name)\n        bedrock_client = AnthropicBedrock()\n\n        new_model = AnthropicModel(\n            bedrock_model_id,\n            http_client=bedrock_client\n        )\n\n        self.model_name = bedrock_model_id\n\n    else:\n        # Direct API mode\n        new_model = AnthropicModel(full_model_name, api_key=self.api_key)\n        self.model_name = full_model_name\n\n    # Update agent with new model\n    self.model = new_model\n\n    # Recreate agent (existing code continues...)\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-5-documentation-updates","title":"Phase 5: Documentation Updates","text":""},{"location":"ROADMAP_ADD_BEDROCK/#51-update-readmemd","title":"5.1: Update README.md","text":"<p>File: <code>README.md</code></p> <p>Add New Section: \"Authentication Methods\"</p> <pre><code>## Authentication Methods\n\nWYN360 supports two authentication methods:\n\n### Method 1: Direct Anthropic API (Default)\n\n```bash\nexport ANTHROPIC_API_KEY=\"sk-ant-xxxxx\"\nwyn360 \"write a script to analyze data.csv\"\n</code></pre> <p>Pros: - Simple setup - Direct access to latest models - Lower latency</p> <p>Cons: - Requires Anthropic API account - May have different pricing than AWS</p>"},{"location":"ROADMAP_ADD_BEDROCK/#method-2-aws-bedrock","title":"Method 2: AWS Bedrock","text":"<pre><code>export AWS_ACCESS_KEY_ID=\"AKIA...\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx...\"\nexport AWS_SESSION_TOKEN=\"xxx...\"  # Optional\nexport CLAUDE_CODE_USE_BEDROCK=1\n\nwyn360 \"write a script to analyze data.csv\"\n</code></pre> <p>Pros: - Use existing AWS credentials - AWS billing and governance - Works with AWS IAM roles/policies - Supports AWS temporary credentials (STS)</p> <p>Cons: - Requires AWS Bedrock access - May have limited model availability - Additional AWS setup required</p>"},{"location":"ROADMAP_ADD_BEDROCK/#switching-between-methods","title":"Switching Between Methods","text":"<p>To switch to Bedrock: <pre><code>export CLAUDE_CODE_USE_BEDROCK=1\n# Also ensure AWS credentials are set\n</code></pre></p> <p>To switch back to Anthropic API: <pre><code>unset CLAUDE_CODE_USE_BEDROCK\n# Or: export CLAUDE_CODE_USE_BEDROCK=0\n</code></pre> <pre><code>---\n\n#### 5.2: Update USE_CASES.md\n\n**File:** `docs/USE_CASES.md`\n\n**Add New Use Case:** \"Use Case 27: AWS Bedrock Authentication\"\n\n```markdown\n## Use Case 27: AWS Bedrock Authentication\n\n### Use Case 27.1: Basic AWS Bedrock Setup\n\n**Scenario:** You have an AWS account with Bedrock access and want to use WYN360 with AWS credentials.\n\n**Setup:**\n```bash\n# Step 1: Set AWS credentials\nexport AWS_ACCESS_KEY_ID=\"your_aws_access_key_id\"\nexport AWS_SECRET_ACCESS_KEY=\"your_aws_secret_access_key\"\n\n# Step 2: Enable Bedrock mode\nexport CLAUDE_CODE_USE_BEDROCK=1\n\n# Step 3: Use WYN360\nwyn360 \"write a Python script to process data.csv\"\n</code></pre></p> <p>Output: <pre><code>\ud83c\udf29\ufe0f  AWS Bedrock mode enabled\n\ud83d\udce1 Using model: anthropic.claude-3-5-sonnet-20241022-v2:0\n\nWYN360: I'll create a Python script to process data.csv...\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#use-case-272-using-aws-iam-roles-ec2ecslambda","title":"Use Case 27.2: Using AWS IAM Roles (EC2/ECS/Lambda)","text":"<p>Scenario: Running WYN360 on AWS infrastructure with IAM roles.</p> <p>Setup: <pre><code># No need to set AWS_ACCESS_KEY_ID or AWS_SECRET_ACCESS_KEY\n# The boto3 SDK automatically uses the instance IAM role\n\n# Just enable Bedrock mode\nexport CLAUDE_CODE_USE_BEDROCK=1\n\nwyn360 \"analyze logs.txt\"\n</code></pre></p> <p>IAM Policy Required: <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"bedrock:InvokeModel\",\n        \"bedrock:InvokeModelWithResponseStream\"\n      ],\n      \"Resource\": \"arn:aws:bedrock:*::foundation-model/anthropic.claude-*\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#use-case-273-using-aws-temporary-credentials-sts","title":"Use Case 27.3: Using AWS Temporary Credentials (STS)","text":"<p>Scenario: Using temporary AWS credentials from <code>aws sts assume-role</code>.</p> <p>Setup: <pre><code># Get temporary credentials\naws sts assume-role \\\n  --role-arn arn:aws:iam::123456789012:role/WYN360Role \\\n  --role-session-name wyn360-session \\\n  --output json &gt; /tmp/aws-creds.json\n\n# Extract and export credentials\nexport AWS_ACCESS_KEY_ID=$(jq -r '.Credentials.AccessKeyId' /tmp/aws-creds.json)\nexport AWS_SECRET_ACCESS_KEY=$(jq -r '.Credentials.SecretAccessKey' /tmp/aws-creds.json)\nexport AWS_SESSION_TOKEN=$(jq -r '.Credentials.SessionToken' /tmp/aws-creds.json)\n\n# Enable Bedrock\nexport CLAUDE_CODE_USE_BEDROCK=1\n\nwyn360 \"help me debug this code\"\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#use-case-274-model-switching-in-bedrock-mode","title":"Use Case 27.4: Model Switching in Bedrock Mode","text":"<p>Scenario: Switching between Claude models while using Bedrock.</p> <p>Commands: <pre><code># Start with default (Sonnet)\nwyn360 \"switch to claude-3-opus-20240229\"\n# \u2705 Now using: anthropic.claude-3-opus-20240229-v1:0\n\nwyn360 \"switch to claude-3-haiku-20240307\"\n# \u2705 Now using: anthropic.claude-3-haiku-20240307-v1:0\n\nwyn360 \"switch to sonnet\"\n# \u2705 Now using: anthropic.claude-3-5-sonnet-20241022-v2:0 (latest)\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#use-case-275-troubleshooting-bedrock-authentication","title":"Use Case 27.5: Troubleshooting Bedrock Authentication","text":"<p>Problem: Missing AWS credentials</p> <pre><code>export CLAUDE_CODE_USE_BEDROCK=1\nwyn360 \"hello\"\n\n# \u274c Error:\n# AWS Bedrock mode enabled but credentials not found.\n#\n# Please set the following environment variables:\n#   - AWS_ACCESS_KEY_ID\n#   - AWS_SECRET_ACCESS_KEY\n#\n# Missing variables: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\n</code></pre> <p>Solution: <pre><code># Option 1: Set credentials\nexport AWS_ACCESS_KEY_ID=\"xxx\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\n\n# Option 2: Use AWS CLI configured credentials\naws configure\n# (Follow prompts to set credentials)\n\n# Option 3: Disable Bedrock mode\nunset CLAUDE_CODE_USE_BEDROCK\nexport ANTHROPIC_API_KEY=\"sk-ant-xxx\"\n</code></pre> <pre><code>---\n\n### Phase 6: Testing Strategy\n\n#### 6.1: Unit Tests\n\n**File:** `tests/test_bedrock.py` (NEW)\n\n```python\n\"\"\"Tests for AWS Bedrock integration.\"\"\"\n\nimport pytest\nimport os\nfrom unittest.mock import Mock, patch, MagicMock\nfrom wyn360_cli.agent import WYN360Agent, _should_use_bedrock, _validate_aws_credentials\n\n\nclass TestBedrockDetection:\n    \"\"\"Test Bedrock mode detection.\"\"\"\n\n    def test_bedrock_disabled_by_default(self):\n        \"\"\"Test that Bedrock is disabled when env var not set.\"\"\"\n        with patch.dict(os.environ, {}, clear=True):\n            assert _should_use_bedrock() is False\n\n    def test_bedrock_enabled_with_1(self):\n        \"\"\"Test that Bedrock is enabled with CLAUDE_CODE_USE_BEDROCK=1.\"\"\"\n        with patch.dict(os.environ, {'CLAUDE_CODE_USE_BEDROCK': '1'}):\n            assert _should_use_bedrock() is True\n\n    def test_bedrock_disabled_with_0(self):\n        \"\"\"Test that Bedrock is disabled with CLAUDE_CODE_USE_BEDROCK=0.\"\"\"\n        with patch.dict(os.environ, {'CLAUDE_CODE_USE_BEDROCK': '0'}):\n            assert _should_use_bedrock() is False\n\n\nclass TestAWSCredentialValidation:\n    \"\"\"Test AWS credential validation.\"\"\"\n\n    def test_valid_credentials(self):\n        \"\"\"Test validation with all required credentials.\"\"\"\n        with patch.dict(os.environ, {\n            'AWS_ACCESS_KEY_ID': 'AKIA...',\n            'AWS_SECRET_ACCESS_KEY': 'secret',\n        }):\n            is_valid, error = _validate_aws_credentials()\n            assert is_valid is True\n            assert error == \"\"\n\n    def test_missing_access_key(self):\n        \"\"\"Test validation with missing access key.\"\"\"\n        with patch.dict(os.environ, {\n            'AWS_SECRET_ACCESS_KEY': 'secret',\n        }, clear=True):\n            is_valid, error = _validate_aws_credentials()\n            assert is_valid is False\n            assert 'AWS_ACCESS_KEY_ID' in error\n\n    def test_missing_secret_key(self):\n        \"\"\"Test validation with missing secret key.\"\"\"\n        with patch.dict(os.environ, {\n            'AWS_ACCESS_KEY_ID': 'AKIA...',\n        }, clear=True):\n            is_valid, error = _validate_aws_credentials()\n            assert is_valid is False\n            assert 'AWS_SECRET_ACCESS_KEY' in error\n\n\nclass TestBedrockAgent:\n    \"\"\"Test WYN360Agent with Bedrock mode.\"\"\"\n\n    @patch('wyn360_cli.agent.AnthropicBedrock')\n    @patch('wyn360_cli.agent.AnthropicModel')\n    def test_bedrock_mode_initialization(self, mock_model, mock_bedrock):\n        \"\"\"Test agent initialization in Bedrock mode.\"\"\"\n        with patch.dict(os.environ, {\n            'AWS_ACCESS_KEY_ID': 'AKIA...',\n            'AWS_SECRET_ACCESS_KEY': 'secret',\n        }):\n            agent = WYN360Agent(use_bedrock=True)\n\n            assert agent.use_bedrock is True\n            assert agent.api_key is None\n            mock_bedrock.assert_called_once()\n\n    def test_bedrock_mode_missing_credentials(self):\n        \"\"\"Test that Bedrock mode raises error with missing credentials.\"\"\"\n        with patch.dict(os.environ, {}, clear=True):\n            with pytest.raises(ValueError, match=\"credentials not found\"):\n                WYN360Agent(use_bedrock=True)\n\n    @patch('wyn360_cli.agent.AnthropicModel')\n    def test_anthropic_mode_initialization(self, mock_model):\n        \"\"\"Test agent initialization in Anthropic API mode.\"\"\"\n        agent = WYN360Agent(api_key=\"sk-ant-xxx\", use_bedrock=False)\n\n        assert agent.use_bedrock is False\n        assert agent.api_key == \"sk-ant-xxx\"\n        mock_model.assert_called_once()\n\n\nclass TestModelMapping:\n    \"\"\"Test Bedrock model ID mapping.\"\"\"\n\n    @patch('wyn360_cli.agent.AnthropicBedrock')\n    @patch('wyn360_cli.agent.AnthropicModel')\n    def test_sonnet_model_mapping(self, mock_model, mock_bedrock):\n        \"\"\"Test that Sonnet model maps to correct Bedrock ID.\"\"\"\n        with patch.dict(os.environ, {\n            'AWS_ACCESS_KEY_ID': 'AKIA...',\n            'AWS_SECRET_ACCESS_KEY': 'secret',\n        }):\n            agent = WYN360Agent(\n                model_name=\"claude-sonnet-4-20250514\",\n                use_bedrock=True\n            )\n\n            expected_id = \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n            # Verify model was created with Bedrock ID\n            mock_model.assert_called()\n            call_args = mock_model.call_args\n            assert expected_id in str(call_args)\n</code></pre></p>"},{"location":"ROADMAP_ADD_BEDROCK/#62-integration-tests","title":"6.2: Integration Tests","text":"<p>File: <code>tests/test_bedrock_integration.py</code> (NEW)</p> <pre><code>\"\"\"Integration tests for Bedrock (requires real AWS credentials).\"\"\"\n\nimport pytest\nimport os\nfrom wyn360_cli.agent import WYN360Agent\n\n\n@pytest.mark.skipif(\n    not os.getenv('AWS_ACCESS_KEY_ID') or not os.getenv('RUN_BEDROCK_TESTS'),\n    reason=\"Requires AWS credentials and RUN_BEDROCK_TESTS=1\"\n)\nclass TestBedrockIntegration:\n    \"\"\"Integration tests with real AWS Bedrock (expensive, skip by default).\"\"\"\n\n    async def test_bedrock_simple_query(self):\n        \"\"\"Test a simple query using real Bedrock credentials.\"\"\"\n        agent = WYN360Agent(use_bedrock=True)\n\n        result = await agent.agent.run(\"Say 'hello' in one word\")\n\n        assert result.data\n        assert len(result.data) &gt; 0\n\n    async def test_bedrock_model_switching(self):\n        \"\"\"Test switching models in Bedrock mode.\"\"\"\n        agent = WYN360Agent(use_bedrock=True)\n\n        # Switch to Haiku\n        from pydantic_ai import RunContext\n        ctx = RunContext(deps=None)\n        result = await agent.switch_model(ctx, \"claude-3-haiku-20240307\")\n\n        assert \"haiku\" in result.lower()\n        assert \"anthropic.claude-3-haiku\" in agent.model_name\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-7-error-handling-edge-cases","title":"Phase 7: Error Handling &amp; Edge Cases","text":""},{"location":"ROADMAP_ADD_BEDROCK/#71-edge-cases-to-handle","title":"7.1: Edge Cases to Handle","text":"<ol> <li>Both API key and Bedrock credentials set</li> <li>Solution: Prioritize <code>CLAUDE_CODE_USE_BEDROCK</code> flag</li> <li> <p>If flag=1, use Bedrock regardless of API key presence</p> </li> <li> <p>Invalid AWS credentials</p> </li> <li> <p>Solution: Let boto3 raise natural error, catch and show friendly message</p> </li> <li> <p>Bedrock model not available in region</p> </li> <li> <p>Solution: Catch error, suggest checking AWS region and model availability</p> </li> <li> <p>AWS session token expiration</p> </li> <li>Solution: boto3 handles automatically, suggest refreshing credentials on auth error</li> </ol>"},{"location":"ROADMAP_ADD_BEDROCK/#72-enhanced-error-messages","title":"7.2: Enhanced Error Messages","text":"<p>File: <code>wyn360_cli/agent.py</code></p> <p>Add to <code>__init__()</code> Bedrock section:</p> <pre><code>try:\n    bedrock_client = AnthropicBedrock()\nexcept Exception as e:\n    raise ValueError(\n        f\"Failed to create AWS Bedrock client: {e}\\n\\n\"\n        \"Common causes:\\n\"\n        \"  - Invalid AWS credentials\\n\"\n        \"  - Bedrock not enabled in your AWS account\\n\"\n        \"  - Incorrect AWS region (check AWS_DEFAULT_REGION)\\n\"\n        \"  - Network connectivity issues\\n\\n\"\n        \"Verify your setup:\\n\"\n        \"  1. Check credentials: aws sts get-caller-identity\\n\"\n        \"  2. Check Bedrock access: aws bedrock list-foundation-models\\n\"\n        \"  3. Ensure region supports Bedrock (us-east-1, us-west-2, etc.)\"\n    )\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-8-version-deployment","title":"Phase 8: Version &amp; Deployment","text":""},{"location":"ROADMAP_ADD_BEDROCK/#81-version-update","title":"8.1: Version Update","text":"<ul> <li>Current: 0.3.44</li> <li>Target: 0.3.45</li> <li>Type: Minor version (new feature)</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#82-changelog-entry","title":"8.2: Changelog Entry","text":"<p>File: <code>docs/USE_CASES.md</code> (Version History section)</p> <pre><code>### v0.3.45\n- \u2728 **NEW FEATURE:** AWS Bedrock authentication support\n- \ud83d\udd10 Use AWS credentials instead of Anthropic API key (opt-in)\n- \ud83c\udf29\ufe0f Enable with `export CLAUDE_CODE_USE_BEDROCK=1`\n- \ud83d\udce6 Added `anthropic[bedrock]` dependency (includes boto3)\n- \ud83d\udee0\ufe0f Automatic model mapping to Bedrock ARNs\n- \ud83d\udcda New Use Case 27: AWS Bedrock Authentication\n- \u2705 Full support for AWS IAM roles and temporary credentials (STS)\n- \ud83e\uddea 26 new unit tests for Bedrock integration\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#file-modification-summary","title":"File Modification Summary","text":""},{"location":"ROADMAP_ADD_BEDROCK/#files-to-modify","title":"Files to Modify","text":"File Changes Lines Changed <code>pyproject.toml</code> Update anthropic dependency ~1 <code>wyn360_cli/agent.py</code> Add Bedrock support ~150 <code>wyn360_cli/cli.py</code> Update credential handling ~20 <code>README.md</code> Add authentication docs ~80 <code>docs/USE_CASES.md</code> Add Use Case 27 ~200 <code>tests/test_bedrock.py</code> New test file ~120 <code>tests/test_bedrock_integration.py</code> New integration tests ~40 <p>Total: ~611 lines of new/modified code</p>"},{"location":"ROADMAP_ADD_BEDROCK/#implementation-checklist","title":"Implementation Checklist","text":""},{"location":"ROADMAP_ADD_BEDROCK/#phase-1-dependencies","title":"Phase 1: Dependencies \u2705","text":"<ul> <li>[ ] Update <code>pyproject.toml</code> with <code>anthropic[bedrock]</code></li> <li>[ ] Run <code>poetry lock</code> and <code>poetry install</code></li> <li>[ ] Verify boto3 is installed</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-2-core-logic","title":"Phase 2: Core Logic \u2705","text":"<ul> <li>[ ] Add <code>_should_use_bedrock()</code> helper</li> <li>[ ] Add <code>_validate_aws_credentials()</code> helper</li> <li>[ ] Add <code>_get_bedrock_model_id()</code> method</li> <li>[ ] Update <code>WYN360Agent.__init__()</code> for dual-mode</li> <li>[ ] Update <code>switch_model()</code> for Bedrock</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-3-cli-integration_1","title":"Phase 3: CLI Integration \u2705","text":"<ul> <li>[ ] Update <code>cli.py</code> main() function</li> <li>[ ] Add improved error messages</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-4-testing","title":"Phase 4: Testing \u2705","text":"<ul> <li>[ ] Create <code>tests/test_bedrock.py</code></li> <li>[ ] Create <code>tests/test_bedrock_integration.py</code></li> <li>[ ] Run all tests: <code>pytest tests/ -v</code></li> <li>[ ] Test with real AWS credentials (manual)</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-5-documentation","title":"Phase 5: Documentation \u2705","text":"<ul> <li>[ ] Update <code>README.md</code> with authentication methods</li> <li>[ ] Add Use Case 27 to <code>docs/USE_CASES.md</code></li> <li>[ ] Update version history in docs</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#phase-6-deployment","title":"Phase 6: Deployment \u2705","text":"<ul> <li>[ ] Update version to 0.3.45</li> <li>[ ] Run <code>poetry publish --build</code></li> <li>[ ] Commit to GitHub</li> <li>[ ] Verify PyPI release</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#testing-plan","title":"Testing Plan","text":""},{"location":"ROADMAP_ADD_BEDROCK/#manual-testing-scenarios","title":"Manual Testing Scenarios","text":""},{"location":"ROADMAP_ADD_BEDROCK/#test-1-anthropic-api-mode-existing-behavior","title":"Test 1: Anthropic API Mode (Existing Behavior)","text":"<pre><code>unset CLAUDE_CODE_USE_BEDROCK\nexport ANTHROPIC_API_KEY=\"sk-ant-xxx\"\nwyn360 \"write a hello world script\"\n# \u2705 Expected: Works as before\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#test-2-bedrock-mode-with-valid-credentials","title":"Test 2: Bedrock Mode with Valid Credentials","text":"<pre><code>export AWS_ACCESS_KEY_ID=\"AKIA...\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\nexport CLAUDE_CODE_USE_BEDROCK=1\nwyn360 \"write a hello world script\"\n# \u2705 Expected: Shows \"AWS Bedrock mode enabled\", generates code\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#test-3-bedrock-mode-with-missing-credentials","title":"Test 3: Bedrock Mode with Missing Credentials","text":"<pre><code>unset AWS_ACCESS_KEY_ID\nunset AWS_SECRET_ACCESS_KEY\nexport CLAUDE_CODE_USE_BEDROCK=1\nwyn360 \"hello\"\n# \u2705 Expected: Clear error message with missing variables\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#test-4-model-switching-in-bedrock","title":"Test 4: Model Switching in Bedrock","text":"<pre><code>export CLAUDE_CODE_USE_BEDROCK=1\n# (AWS credentials set)\nwyn360 \"switch to claude-3-opus-20240229\"\nwyn360 \"what model are you using?\"\n# \u2705 Expected: Confirms using Opus Bedrock ARN\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#test-5-both-credentials-set","title":"Test 5: Both Credentials Set","text":"<pre><code>export ANTHROPIC_API_KEY=\"sk-ant-xxx\"\nexport AWS_ACCESS_KEY_ID=\"AKIA...\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\nexport CLAUDE_CODE_USE_BEDROCK=1\nwyn360 \"hello\"\n# \u2705 Expected: Uses Bedrock (flag takes precedence)\n</code></pre>"},{"location":"ROADMAP_ADD_BEDROCK/#security-considerations","title":"Security Considerations","text":"<ol> <li>Credential Storage:</li> <li>\u2705 No credentials stored in code or config files</li> <li>\u2705 All credentials from environment variables</li> <li> <p>\u2705 AWS credentials follow boto3 best practices</p> </li> <li> <p>AWS IAM Permissions:</p> </li> <li>\u2705 Minimal required permissions documented</li> <li>\u2705 Support for least-privilege IAM policies</li> <li> <p>\u2705 Works with AWS temporary credentials (STS)</p> </li> <li> <p>Error Messages:</p> </li> <li>\u2705 Don't expose full credentials in errors</li> <li>\u2705 Only show presence/absence of variables</li> <li>\u2705 Provide actionable troubleshooting steps</li> </ol>"},{"location":"ROADMAP_ADD_BEDROCK/#cost-considerations","title":"Cost Considerations","text":""},{"location":"ROADMAP_ADD_BEDROCK/#aws-bedrock-pricing-as-of-2024","title":"AWS Bedrock Pricing (as of 2024)","text":"<p>Claude 3.5 Sonnet: - Input: $3.00 per 1M tokens - Output: $15.00 per 1M tokens</p> <p>Claude 3 Opus: - Input: $15.00 per 1M tokens - Output: $75.00 per 1M tokens</p> <p>Claude 3 Haiku: - Input: $0.25 per 1M tokens - Output: $1.25 per 1M tokens</p> <p>Note: Pricing may vary by AWS region. Check AWS Bedrock pricing page.</p>"},{"location":"ROADMAP_ADD_BEDROCK/#rollback-plan","title":"Rollback Plan","text":"<p>If issues arise after deployment:</p> <ol> <li> <p>Emergency rollback: <pre><code>git revert &lt;commit-hash&gt;\ngit push origin main\npoetry publish --build  # Re-publish v0.3.44\n</code></pre></p> </li> <li> <p>User mitigation: <pre><code>pip install wyn360-cli==0.3.44  # Downgrade to previous version\n</code></pre></p> </li> <li> <p>Feature disable:</p> </li> <li>Users can avoid Bedrock by not setting <code>CLAUDE_CODE_USE_BEDROCK</code></li> <li>Existing Anthropic API flow completely unchanged</li> <li>No breaking changes to existing users</li> </ol>"},{"location":"ROADMAP_ADD_BEDROCK/#success-metrics","title":"Success Metrics","text":"<ul> <li>\u2705 All existing tests pass (no regressions)</li> <li>\u2705 26+ new tests added with &gt;90% coverage</li> <li>\u2705 Documentation complete for both auth methods</li> <li>\u2705 Manual testing successful with real AWS credentials</li> <li>\u2705 PyPI deployment successful</li> <li>\u2705 No breaking changes to existing users</li> </ul>"},{"location":"ROADMAP_ADD_BEDROCK/#timeline-estimate","title":"Timeline Estimate","text":"Phase Estimated Time Complexity Phase 1: Dependencies 15 minutes Low Phase 2: Core Logic 2-3 hours High Phase 3: CLI Integration 30 minutes Medium Phase 4: Testing 1-2 hours Medium Phase 5: Documentation 1 hour Low Phase 6: Deployment 30 minutes Low <p>Total: ~5-7 hours</p>"},{"location":"ROADMAP_ADD_BEDROCK/#future-enhancements-out-of-scope-for-v0345","title":"Future Enhancements (Out of Scope for v0.3.45)","text":"<ol> <li>AWS Region Configuration:</li> <li>Allow <code>AWS_DEFAULT_REGION</code> customization</li> <li> <p>Auto-detect optimal region based on latency</p> </li> <li> <p>Cross-Region Inference:</p> </li> <li>Support AWS Bedrock cross-region inference profiles</li> <li> <p>Load balancing across regions</p> </li> <li> <p>Cost Tracking:</p> </li> <li>Estimate and display token costs per session</li> <li> <p>AWS CloudWatch integration for usage monitoring</p> </li> <li> <p>AWS Secrets Manager Integration:</p> </li> <li>Store Anthropic API key in AWS Secrets Manager</li> <li> <p>Automatic rotation support</p> </li> <li> <p>AWS CloudTrail Logging:</p> </li> <li>Audit trail for all Bedrock API calls</li> <li>Compliance and governance features</li> </ol>"},{"location":"ROADMAP_ADD_BEDROCK/#references","title":"References","text":"<ul> <li>Anthropic Bedrock Docs: https://docs.anthropic.com/en/api/claude-on-amazon-bedrock</li> <li>AWS Bedrock User Guide: https://docs.aws.amazon.com/bedrock/latest/userguide/</li> <li>Boto3 Credentials: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html</li> <li>pydantic-ai AnthropicModel: https://ai.pydantic.dev/models/#anthropic</li> </ul> <p>End of Roadmap</p>"},{"location":"ROADMAP_ASK_AI/","title":"WYN360 CLI - Ask AI Documentation Search Feature Roadmap","text":"<p>Status: \ud83d\ude80 Phase 2 Complete - Real Search Index Operational Priority: Enhancement (Documentation UX) Start Date: November 23, 2025 Target Completion: December 2025</p>"},{"location":"ROADMAP_ASK_AI/#executive-summary","title":"\ud83d\udccb Executive Summary","text":"<p>This roadmap outlines the implementation of Ask AI - an intelligent search feature for the WYN360 CLI documentation that enhances the existing search experience with semantic understanding and AI-powered responses.</p>"},{"location":"ROADMAP_ASK_AI/#key-value-proposition","title":"Key Value Proposition","text":"<p>Current State: Users must manually browse through documentation pages to find specific use cases, examples, and configuration details.</p> <p>With Ask AI: Users can ask natural language questions and get: - Semantic search results across all documentation - AI-generated answers with context - Direct links to relevant documentation pages - Intelligent recommendations for next steps</p>"},{"location":"ROADMAP_ASK_AI/#core-principles","title":"Core Principles","text":"<p>\u2705 Non-Invasive: Zero impact on main WYN360 CLI codebase \u2705 Progressive Enhancement: Regular search continues working if AI fails \u2705 Documentation-Focused: Scoped only to GitHub book enhancement \u2705 User-Friendly: Seamless integration with existing MkDocs interface</p>"},{"location":"ROADMAP_ASK_AI/#implementation-phases","title":"\ud83c\udfaf Implementation Phases","text":""},{"location":"ROADMAP_ASK_AI/#phase-1-non-invasive-integration-complete","title":"Phase 1: Non-Invasive Integration \u2705 Complete","text":"<p>Goal: Add AI search UI to existing MkDocs without breaking anything</p>"},{"location":"ROADMAP_ASK_AI/#tasks","title":"Tasks:","text":"<ul> <li>[x] 1.1 Create MkDocs theme overrides structure</li> <li>[x] 1.2 Extend current search interface with \"Ask AI\" button</li> <li>[x] 1.3 Design AI response modal/popup</li> <li>[x] 1.4 Implement basic UI without AI backend</li> <li>[x] 1.5 Test compatibility with existing search</li> <li>[x] 1.6 Ensure mobile responsiveness</li> </ul>"},{"location":"ROADMAP_ASK_AI/#deliverables","title":"Deliverables:","text":"<ul> <li><code>overrides/</code> directory with custom theme</li> <li>Enhanced search UI with Ask AI button</li> <li>CSS styling for AI response components</li> <li>JavaScript skeleton for AI integration</li> </ul>"},{"location":"ROADMAP_ASK_AI/#success-criteria","title":"Success Criteria:","text":"<ul> <li>\u2705 Existing search functionality unchanged</li> <li>\u2705 \"Ask AI\" button appears in search interface</li> <li>\u2705 UI mockup shows expected user experience</li> <li>\u2705 No interference with main documentation</li> <li>\u2705 Documentation builds successfully</li> <li>\u2705 Mobile-responsive design implemented</li> <li>\u2705 Mock AI responses demonstrate functionality</li> </ul>"},{"location":"ROADMAP_ASK_AI/#phase-2-documentation-preprocessing-pipeline-complete","title":"Phase 2: Documentation Preprocessing Pipeline \u2705 Complete","text":"<p>Goal: Create automated system to extract and index documentation content</p>"},{"location":"ROADMAP_ASK_AI/#tasks_1","title":"Tasks:","text":"<ul> <li>[x] 2.1 Create GitHub Action for documentation parsing</li> <li>[x] 2.2 Implement markdown content extraction</li> <li>[x] 2.3 Semantic chunking of documentation sections</li> <li>[x] 2.4 Generate embeddings for content chunks</li> <li>[x] 2.5 Build searchable JSON index</li> <li>[x] 2.6 Deploy index with documentation site</li> </ul>"},{"location":"ROADMAP_ASK_AI/#deliverables_1","title":"Deliverables:","text":"<ul> <li><code>.github/workflows/docs-ai-prep.yml</code> workflow</li> <li><code>scripts/build_search_index.py</code> processing script</li> <li><code>site/assets/search-index.json</code> deployment</li> <li>Automated index updates on doc changes</li> </ul>"},{"location":"ROADMAP_ASK_AI/#success-criteria_1","title":"Success Criteria:","text":"<ul> <li>\u2705 Documentation content extracted into semantic chunks (1,353 chunks from 29 files)</li> <li>\u2705 Embeddings framework ready for semantic search</li> <li>\u2705 Search index builds automatically on doc updates</li> <li>\u2705 Index loads efficiently in browser (0.99 MB, loads &lt; 2s)</li> <li>\u2705 Real semantic search replaces mock responses</li> <li>\u2705 Context-aware answer generation working</li> <li>\u2705 Source attribution with accurate links</li> </ul>"},{"location":"ROADMAP_ASK_AI/#phase-3-client-side-ai-search-mostly-complete","title":"Phase 3: Client-Side AI Search \u2705 Mostly Complete","text":"<p>Goal: Implement semantic search and AI response generation</p>"},{"location":"ROADMAP_ASK_AI/#tasks_2","title":"Tasks:","text":"<ul> <li>[x] 3.1 Load and process search index in browser</li> <li>[x] 3.2 Generate real semantic embeddings with sentence-transformers</li> <li>[x] 3.3 Implement cosine similarity search</li> <li>[x] 3.4 Enable embedding-based semantic search in JavaScript</li> <li>[x] 3.5 Build browser-side similarity calculation</li> <li>[x] 3.6 Format responses with semantic similarity scores</li> <li>[ ] 3.7 Integrate external AI API for enhanced response generation (Future)</li> <li>[x] 3.8 Add comprehensive error handling and fallbacks</li> </ul>"},{"location":"ROADMAP_ASK_AI/#deliverables_2","title":"Deliverables:","text":"<ul> <li>\u2705 <code>docs/js/ai-search.js</code> - Enhanced with real semantic search</li> <li>\u2705 Real embedding generation in build pipeline (384-dimensional vectors)</li> <li>\u2705 Cosine similarity search implementation</li> <li>\u2705 Source attribution with semantic relevance scores</li> <li>\u2705 Graceful error handling and keyword fallback</li> </ul>"},{"location":"ROADMAP_ASK_AI/#success-criteria_2","title":"Success Criteria:","text":"<ul> <li>\u2705 Semantic embeddings generated with sentence-transformers/all-MiniLM-L6-v2</li> <li>\u2705 1,353 documentation chunks with real 384D embeddings (14.86 MB index)</li> <li>\u2705 Browser-based cosine similarity calculation</li> <li>\u2705 Semantic search finds contextually relevant documentation</li> <li>\u2705 Source links navigate to correct doc pages with similarity scores</li> <li>\u2705 Fallback to keyword search when embeddings unavailable</li> </ul>"},{"location":"ROADMAP_ASK_AI/#phase-4-user-experience-optimization-planned","title":"Phase 4: User Experience Optimization \u2728 Planned","text":"<p>Goal: Polish interface and optimize user interactions</p>"},{"location":"ROADMAP_ASK_AI/#tasks_3","title":"Tasks:","text":"<ul> <li>[ ] 4.1 Implement loading states and animations</li> <li>[ ] 4.2 Add result relevance scoring</li> <li>[ ] 4.3 Optimize for mobile devices</li> <li>[ ] 4.4 Add keyboard shortcuts (Ctrl+K enhancement)</li> <li>[ ] 4.5 Implement search result highlighting</li> <li>[ ] 4.6 Add user feedback mechanisms</li> </ul>"},{"location":"ROADMAP_ASK_AI/#deliverables_3","title":"Deliverables:","text":"<ul> <li>Polished UI with smooth interactions</li> <li>Mobile-optimized design</li> <li>Keyboard accessibility features</li> <li>User feedback collection</li> </ul>"},{"location":"ROADMAP_ASK_AI/#success-criteria_3","title":"Success Criteria:","text":"<ul> <li>\u2705 Smooth, responsive user interface</li> <li>\u2705 Excellent mobile experience</li> <li>\u2705 Intuitive keyboard navigation</li> <li>\u2705 Positive user feedback scores</li> </ul>"},{"location":"ROADMAP_ASK_AI/#phase-5-advanced-features-future","title":"Phase 5: Advanced Features \ud83d\ude80 Future","text":"<p>Goal: Add sophisticated AI capabilities</p>"},{"location":"ROADMAP_ASK_AI/#tasks_4","title":"Tasks:","text":"<ul> <li>[ ] 5.1 Context-aware suggestions based on current page</li> <li>[ ] 5.2 Code example generation from documentation</li> <li>[ ] 5.3 Interactive tutorials guided by AI</li> <li>[ ] 5.4 Multi-language support preparation</li> <li>[ ] 5.5 Analytics and usage tracking</li> <li>[ ] 5.6 Performance optimizations</li> </ul>"},{"location":"ROADMAP_ASK_AI/#deliverables_4","title":"Deliverables:","text":"<ul> <li>Context-aware search suggestions</li> <li>AI-generated code examples</li> <li>Interactive tutorial system</li> <li>Usage analytics dashboard</li> </ul>"},{"location":"ROADMAP_ASK_AI/#success-criteria_4","title":"Success Criteria:","text":"<ul> <li>\u2705 Proactive help based on user context</li> <li>\u2705 Accurate code examples generated</li> <li>\u2705 Guided learning experiences</li> <li>\u2705 Data-driven improvements</li> </ul>"},{"location":"ROADMAP_ASK_AI/#technical-architecture","title":"\ud83d\udee0 Technical Architecture","text":""},{"location":"ROADMAP_ASK_AI/#frontend-components","title":"Frontend Components","text":"<pre><code>docs/\n\u251c\u2500\u2500 overrides/          # Custom MkDocs theme\n\u2502   \u251c\u2500\u2500 main.html      # Search interface override\n\u2502   \u2514\u2500\u2500 partials/      # AI search components\n\u251c\u2500\u2500 css/\n\u2502   \u2514\u2500\u2500 ai-search.css  # AI search styling\n\u251c\u2500\u2500 js/\n\u2502   \u2514\u2500\u2500 ai-search.js   # AI search logic\n\u2514\u2500\u2500 assets/\n    \u2514\u2500\u2500 search-index.json  # Pre-built search index\n</code></pre>"},{"location":"ROADMAP_ASK_AI/#build-pipeline","title":"Build Pipeline","text":"<pre><code>GitHub Actions \u2192 Parse Docs \u2192 Generate Embeddings \u2192 Build Index \u2192 Deploy\n</code></pre>"},{"location":"ROADMAP_ASK_AI/#runtime-flow","title":"Runtime Flow","text":"<pre><code>User Query \u2192 Semantic Search \u2192 AI Generation \u2192 Format Response \u2192 Show Results\n</code></pre>"},{"location":"ROADMAP_ASK_AI/#implementation-details","title":"\ud83d\udd27 Implementation Details","text":""},{"location":"ROADMAP_ASK_AI/#search-index-structure","title":"Search Index Structure","text":"<pre><code>{\n  \"version\": \"1.0\",\n  \"chunks\": [\n    {\n      \"id\": \"use-case-1\",\n      \"title\": \"Start New Projects\",\n      \"content\": \"When you're in an empty directory...\",\n      \"url\": \"/usage/use-cases/#use-case-1\",\n      \"section\": \"Usage\",\n      \"tags\": [\"getting-started\", \"projects\"]\n    }\n  ],\n  \"embeddings\": [[0.1, 0.2, ...], ...],\n  \"metadata\": {\n    \"build_date\": \"2025-11-23\",\n    \"total_chunks\": 150\n  }\n}\n</code></pre>"},{"location":"ROADMAP_ASK_AI/#ai-response-format","title":"AI Response Format","text":"<pre><code>{\n  \"answer\": \"To start a new project with WYN360...\",\n  \"confidence\": 0.9,\n  \"sources\": [\n    {\n      \"title\": \"Use Case 1: Start New Projects\",\n      \"url\": \"/usage/use-cases/#use-case-1\",\n      \"snippet\": \"When you're in an empty directory...\",\n      \"relevance\": 0.95\n    }\n  ],\n  \"suggested_actions\": [\"Try the quickstart guide\", \"Check examples\"]\n}\n</code></pre>"},{"location":"ROADMAP_ASK_AI/#success-metrics","title":"\ud83c\udfaf Success Metrics","text":""},{"location":"ROADMAP_ASK_AI/#user-experience","title":"User Experience","text":"<ul> <li>Search query resolution rate &gt; 90%</li> <li>Average time to find information &lt; 30 seconds</li> <li>User satisfaction score &gt; 4.5/5</li> </ul>"},{"location":"ROADMAP_ASK_AI/#technical-performance","title":"Technical Performance","text":"<ul> <li>Search response time &lt; 2 seconds</li> <li>AI response accuracy &gt; 85%</li> <li>Mobile compatibility score &gt; 95%</li> </ul>"},{"location":"ROADMAP_ASK_AI/#adoption","title":"Adoption","text":"<ul> <li>Weekly active AI search users &gt; 50% of total visitors</li> <li>AI search usage growth &gt; 20% month-over-month</li> <li>Reduced support questions about basic usage</li> </ul>"},{"location":"ROADMAP_ASK_AI/#risk-mitigation","title":"\ud83d\udea7 Risk Mitigation","text":""},{"location":"ROADMAP_ASK_AI/#technical-risks","title":"Technical Risks","text":"<ul> <li>AI API failures \u2192 Fallback to regular search</li> <li>Large index size \u2192 Optimize embeddings and lazy loading</li> <li>Search accuracy \u2192 Continuous training data improvement</li> </ul>"},{"location":"ROADMAP_ASK_AI/#user-experience-risks","title":"User Experience Risks","text":"<ul> <li>Slow responses \u2192 Show loading states and partial results</li> <li>Mobile performance \u2192 Progressive loading and caching</li> <li>User adoption \u2192 Clear onboarding and tutorials</li> </ul>"},{"location":"ROADMAP_ASK_AI/#milestones","title":"\ud83d\udcc5 Milestones","text":"Phase Milestone Target Date Status 1 UI Integration Complete Nov 23, 2025 \u2705 Complete 2 Search Index Pipeline Nov 23, 2025 \u2705 Complete 3 Semantic Search Functional Nov 23, 2025 \u2705 Complete 4 UX Optimization Dec 7, 2025 \u23f3 Planned 5 Advanced Features Dec 15, 2025 \u23f3 Planned"},{"location":"ROADMAP_ASK_AI/#team-resources","title":"\ud83e\udd1d Team &amp; Resources","text":"<p>Project Lead: AI Documentation Enhancement Team Technical Lead: Claude Code Assistant Frontend: MkDocs Material Theme Customization Backend: GitHub Actions + Static Site Generation AI/ML: Embedding Generation + Response Systems</p>"},{"location":"ROADMAP_ASK_AI/#references-documentation","title":"\ud83d\udcda References &amp; Documentation","text":"<ul> <li>MkDocs Material: https://squidfunk.github.io/mkdocs-material/</li> <li>Search Architecture: Based on existing MkDocs search with AI enhancement</li> <li>AI Integration: OpenAI/Anthropic APIs for response generation</li> <li>Embedding Models: Sentence-transformers for semantic search</li> </ul> <p>Last Updated: November 23, 2025 Document Version: 1.0 Maintained by: WYN360 CLI Documentation Team Next Review Date: December 1, 2025</p>"},{"location":"ROADMAP_BROWSERUSE/","title":"WYN360-CLI Browser Use Roadmap","text":""},{"location":"ROADMAP_BROWSERUSE/#overview","title":"Overview","text":"<p>This roadmap outlines the implementation of direct website fetching and DOM extraction capabilities for WYN360-CLI. This addresses the limitation where WebSearchTool searches for keywords instead of directly fetching specific URLs provided by users.</p> <p>Problem Statement: When users provide a specific URL like <code>https://github.com/user/repo</code>, the current WebSearchTool searches for keywords and returns top 5 search results, which may not include the exact URL requested.</p> <p>Solution: Implement direct URL fetching using crawl4ai (LLM-optimized web crawler) with smart caching and content management.</p>"},{"location":"ROADMAP_BROWSERUSE/#technical-architecture","title":"Technical Architecture","text":""},{"location":"ROADMAP_BROWSERUSE/#core-technologies","title":"Core Technologies","text":"<ol> <li>crawl4ai - LLM-focused web crawler</li> <li>Built on Playwright for modern browser automation</li> <li>Automatic HTML \u2192 Markdown conversion</li> <li>Async architecture for performance</li> <li> <p>Handles JavaScript-heavy sites</p> </li> <li> <p>Storage Strategy</p> </li> <li>In-memory: Agent conversation context</li> <li>TTL Cache: ~/.wyn360/cache/fetched_sites/</li> <li> <p>Persistent: User-controlled long-term storage</p> </li> <li> <p>Content Management</p> </li> <li>Smart truncation with configurable max tokens</li> <li>Gzip compression for cached files</li> <li>Automatic cleanup with TTL (30 minutes default)</li> </ol>"},{"location":"ROADMAP_BROWSERUSE/#implementation-phases","title":"Implementation Phases","text":""},{"location":"ROADMAP_BROWSERUSE/#phase-1-mvp-basic-website-fetching-v0324","title":"Phase 1: MVP - Basic Website Fetching (v0.3.24)","text":"<p>Goal: Add direct URL fetching capability with in-memory storage</p>"},{"location":"ROADMAP_BROWSERUSE/#tasks","title":"Tasks:","text":"<ul> <li>[x] Research browser automation solutions</li> <li>[x] Create ROADMAP_BROWSERUSE.md</li> <li>[x] Add crawl4ai dependency to pyproject.toml</li> <li>[x] Implement <code>fetch_website(url)</code> tool in agent.py</li> <li>[x] Add URL detection logic in system prompt</li> <li>[x] Implement smart content truncation</li> <li>[x] Store fetched content in agent context (in-memory)</li> <li>[x] Update documentation (README.md, SYSTEM.md, USE_CASES.md)</li> <li>[x] Add error handling for failed fetches</li> <li>[x] Test with various URL types (GitHub, docs, blogs)</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#features","title":"Features:","text":"<pre><code>@tool\nasync def fetch_website(url: str) -&gt; str:\n    \"\"\"\n    Fetch and extract content from a specific URL.\n\n    Args:\n        url: Direct URL to fetch (e.g., https://github.com/user/repo)\n\n    Returns:\n        Markdown-formatted content from the website (truncated if needed)\n    \"\"\"\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#system-prompt-logic","title":"System Prompt Logic:","text":"<pre><code>When user provides direct URL:\n  - \"Read https://example.com\" \u2192 fetch_website()\n  - \"What's on github.com/user/repo\" \u2192 fetch_website()\n\nWhen user asks general question:\n  - \"Find ML repos\" \u2192 WebSearchTool\n  - \"What's the weather?\" \u2192 WebSearchTool\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#configuration","title":"Configuration:","text":"<pre><code># ~/.wyn360/config.yaml\nbrowser_use:\n  max_tokens: 50000  # Max tokens per fetched site (configurable)\n  truncate_strategy: \"smart\"  # smart, head, tail\n</code></pre> <p>Version: v0.3.24 Status: In Progress ETA: Current session</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-2-ttl-based-caching-v0325","title":"Phase 2: TTL-Based Caching (v0.3.25)","text":"<p>Goal: Add persistent caching with automatic cleanup</p>"},{"location":"ROADMAP_BROWSERUSE/#tasks_1","title":"Tasks:","text":"<ul> <li>[x] Create cache directory structure (~/.wyn360/cache/fetched_sites/)</li> <li>[x] Implement TTL-based cache system</li> <li>[x] Add cache key generation (URL hash)</li> <li>[x] Store cached content as gzipped markdown</li> <li>[x] Implement automatic cleanup on cache read</li> <li>[x] Add cache statistics tracking</li> <li>[ ] Implement cache warming (prefetch common URLs) - FUTURE</li> <li>[ ] Add cache hit/miss metrics - FUTURE (basic tracking exists)</li> <li>[x] Update config with cache settings</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#features_1","title":"Features:","text":"<pre><code>class WebsiteCache:\n    \"\"\"TTL-based cache for fetched websites\"\"\"\n\n    def __init__(self, cache_dir: Path, ttl: int = 1800):\n        self.cache_dir = cache_dir\n        self.ttl = ttl  # 30 minutes default\n\n    async def get(self, url: str) -&gt; Optional[str]:\n        \"\"\"Get cached content if not expired\"\"\"\n\n    async def set(self, url: str, content: str):\n        \"\"\"Cache content with TTL\"\"\"\n\n    async def cleanup_expired(self):\n        \"\"\"Remove expired cache entries\"\"\"\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#configuration_1","title":"Configuration:","text":"<pre><code># ~/.wyn360/config.yaml\nbrowser_use:\n  cache:\n    enabled: true\n    ttl: 1800  # 30 minutes (configurable)\n    max_size_mb: 100  # Max total cache size\n    auto_cleanup: true\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#cache-file-format","title":"Cache File Format:","text":"<pre><code>~/.wyn360/cache/fetched_sites/\n  \u251c\u2500\u2500 a3f2c1b9.md.gz  # Gzipped markdown (URL hash)\n  \u251c\u2500\u2500 d8e4b2a1.md.gz\n  \u2514\u2500\u2500 cache_index.json  # Metadata (URL, timestamp, size)\n</code></pre> <p>Version: v0.3.24 (completed in same release as Phase 1) Status: \u2705 Complete (except 2 optional future enhancements) Completed: Current session</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-3-user-controlled-storage-v0326","title":"Phase 3: User-Controlled Storage (v0.3.26)","text":"<p>Goal: Give users control over cache persistence and management</p>"},{"location":"ROADMAP_BROWSERUSE/#tasks_2","title":"Tasks:","text":"<ul> <li>[ ] Implement user prompt for cache preferences - FUTURE</li> <li>[x] Add persistent storage option (cache persists with TTL)</li> <li>[ ] Create <code>/clear-cache</code> CLI command - FUTURE (agent tool exists)</li> <li>[ ] Create <code>/show-cache</code> CLI command - FUTURE (agent tool exists)</li> <li>[ ] Add cache preference persistence - FUTURE</li> <li>[x] Implement selective cache clearing (via agent tool)</li> <li>[ ] Add cache export feature - FUTURE</li> <li>[x] Create cache viewer tool (show_cache_stats agent tool)</li> <li>[x] Implement agent tools: show_cache_stats(), clear_website_cache()</li> <li>[ ] Update CLI with slash commands - FUTURE</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#features_2","title":"Features:","text":"<p>User Prompts: <pre><code>After fetching site:\n\"Would you like me to cache this content?\n- Yes \u2192 Keep for 30 minutes\n- No \u2192 Discard after conversation\n- Always \u2192 Keep until manually cleared\n- Never \u2192 Don't ask again for this session\"\n</code></pre></p> <p>CLI Commands: <pre><code># Show cache statistics\nwyn360 cache stats\n\n# Clear all cache\nwyn360 cache clear\n\n# Clear specific URL\nwyn360 cache clear --url https://example.com\n\n# List cached sites\nwyn360 cache list\n\n# Export cached content\nwyn360 cache export --output cache_backup.tar.gz\n</code></pre></p> <p>Agent Tools: <pre><code>@tool\ndef clear_cache(url: Optional[str] = None):\n    \"\"\"Clear cached website content\"\"\"\n\n@tool\ndef show_cache_stats() -&gt; Dict[str, Any]:\n    \"\"\"Show cache statistics and cached URLs\"\"\"\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#configuration_2","title":"Configuration:","text":"<pre><code># ~/.wyn360/config.yaml\nbrowser_use:\n  cache:\n    user_control: true\n    ask_before_cache: true\n    default_action: \"temp\"  # temp, persist, never\n    persistent_urls:\n      - \"https://docs.python.org/*\"  # Always cache docs\n      - \"https://github.com/*/README.md\"\n</code></pre> <p>Version: v0.3.24 (core features completed) Status: \u26a0\ufe0f Partially Complete Completed: Core agent tools (show_cache_stats, clear_website_cache) implemented Remaining: CLI slash commands, user prompts, cache export (future enhancements)</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-4-authenticated-browsing-v0340","title":"Phase 4: Authenticated Browsing (v0.3.40)","text":"<p>Goal: Enable automated login to websites with secure credential storage</p>"},{"location":"ROADMAP_BROWSERUSE/#tasks_3","title":"Tasks:","text":"<ul> <li>[x] Phase 4.1: Implement secure credential storage</li> <li>[x] Create CredentialManager with AES-256-GCM encryption</li> <li>[x] Implement encrypted vault storage (~/.wyn360/credentials/)</li> <li>[x] Add audit logging (no sensitive data)</li> <li>[x] Write unit tests for credential management (21/21 passing)</li> <li> <p>[x] Set strict file permissions (0600)</p> </li> <li> <p>[x] Phase 4.2: Implement browser authentication</p> </li> <li>[x] Phase 4.2.1: SessionManager for session cookies<ul> <li>[x] Create SessionManager class with TTL-based expiration</li> <li>[x] Implement session save/load/clear operations</li> <li>[x] Add session validation and cleanup</li> <li>[x] Write unit tests (16/16 passing)</li> </ul> </li> <li>[x] Phase 4.2.2: BrowserAuth for automated login<ul> <li>[x] Create BrowserAuth class using Playwright</li> <li>[x] Implement form detection (username, password, submit)</li> <li>[x] Add CAPTCHA detection</li> <li>[x] Add 2FA detection</li> <li>[x] Implement login flow with error handling</li> <li>[x] Write unit tests (11/11 passing)</li> </ul> </li> <li>[x] Phase 4.2.3: Agent integration<ul> <li>[x] Add login_to_website tool to agent</li> <li>[x] Integrate CredentialManager, SessionManager, BrowserAuth</li> <li>[x] Update system prompt with authentication guidelines</li> </ul> </li> <li>[x] Phase 4.2.4: Configuration and documentation<ul> <li>[x] Update .gitignore (.wyn360/ directory)</li> <li>[x] Update .env.example with credential format</li> </ul> </li> <li>[x] Phase 4.2.5: Documentation<ul> <li>[x] Update ROADMAP_BROWSERUSE.md</li> </ul> </li> <li>[x] Phase 4.2.6: Testing<ul> <li>[x] Run all unit tests (27/27 passing)</li> </ul> </li> <li>[x] Phase 4.2.7: Version release<ul> <li>[x] Commit and document changes for v0.3.40</li> </ul> </li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#features_3","title":"Features:","text":"<p>CredentialManager: <pre><code>class CredentialManager:\n    \"\"\"Securely manage login credentials with AES-256-GCM encryption\"\"\"\n\n    def save_credential(self, domain: str, username: str, password: str) -&gt; bool:\n        \"\"\"Encrypt and save credentials\"\"\"\n\n    def get_credential(self, domain: str) -&gt; Optional[Dict[str, str]]:\n        \"\"\"Decrypt and retrieve credentials\"\"\"\n\n    def list_stored_sites(self) -&gt; List[Dict[str, str]]:\n        \"\"\"List sites with stored credentials\"\"\"\n\n    def delete_credential(self, domain: str) -&gt; bool:\n        \"\"\"Remove stored credentials\"\"\"\n</code></pre></p> <p>SessionManager: <pre><code>class SessionManager:\n    \"\"\"Manage authenticated sessions and cookies per website\"\"\"\n\n    def save_session(self, domain: str, cookies: List[Dict], ttl: int = 1800):\n        \"\"\"Save session cookies with TTL (default: 30 minutes)\"\"\"\n\n    def get_session(self, domain: str) -&gt; Optional[Dict]:\n        \"\"\"Retrieve active session if not expired\"\"\"\n\n    def is_session_valid(self, domain: str) -&gt; bool:\n        \"\"\"Check if valid session exists\"\"\"\n\n    def cleanup_expired_sessions(self) -&gt; int:\n        \"\"\"Remove expired sessions\"\"\"\n</code></pre></p> <p>BrowserAuth: <pre><code>class BrowserAuth:\n    \"\"\"Automated browser authentication using Playwright\"\"\"\n\n    async def login(self, url: str, username: str, password: str) -&gt; Dict:\n        \"\"\"\n        Attempt to login to a website\n        Returns: {success, message, cookies, requires_2fa, has_captcha}\n        \"\"\"\n\n    async def verify_session(self, url: str, cookies: List[Dict]) -&gt; bool:\n        \"\"\"Verify if session cookies are still valid\"\"\"\n\n    async def fetch_authenticated_content(self, url: str, cookies: List[Dict]) -&gt; str:\n        \"\"\"Fetch content from authenticated page\"\"\"\n</code></pre></p> <p>Agent Tool: <pre><code>@tool\nasync def login_to_website(\n    url: str,\n    username: str,\n    password: str,\n    save_credentials: bool = True\n) -&gt; str:\n    \"\"\"\n    Login to a website using browser automation.\n\n    - Detects login forms automatically\n    - Handles CAPTCHA detection (notifies user)\n    - Handles 2FA detection (notifies user)\n    - Saves session cookies (30 min TTL)\n    - Optionally encrypts and saves credentials\n    \"\"\"\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#security-features","title":"Security Features:","text":"<ul> <li>Encryption: AES-256-GCM for credential storage</li> <li>Key Management: Per-user encryption key from system entropy</li> <li>File Permissions: 0600 (user read/write only)</li> <li>Session TTL: 30-minute default (configurable)</li> <li>Audit Logging: Access tracking without sensitive data</li> <li>No Plain Text: Credentials only decrypted when needed</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#storage-structure","title":"Storage Structure:","text":"<pre><code>~/.wyn360/\n  \u251c\u2500\u2500 credentials/\n  \u2502   \u251c\u2500\u2500 .keyfile          # Encryption key (0600)\n  \u2502   \u2514\u2500\u2500 vault.enc         # Encrypted credentials\n  \u251c\u2500\u2500 sessions/\n  \u2502   \u251c\u2500\u2500 example_com.session.json\n  \u2502   \u2514\u2500\u2500 github_com.session.json\n  \u2514\u2500\u2500 logs/\n      \u2514\u2500\u2500 auth_audit.log    # Audit log (no sensitive data)\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#usage-example","title":"Usage Example:","text":"<pre><code># Login to website\nresult = await login_to_website(\n    url=\"https://example-site.com/login\",\n    username=\"demo_user\",\n    password=\"SecurePass123!\"\n)\n\n# Subsequent requests use saved session\ncontent = await fetch_website(\"https://example-site.com/profile\")\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#limitations","title":"Limitations:","text":"<ul> <li>CAPTCHA: Requires manual completion (tool detects and notifies)</li> <li>2FA/MFA: Requires manual verification (tool detects and notifies)</li> <li>Complex Auth: OAuth, SAML, etc. may require manual login</li> <li>Headless Mode: Some sites detect headless browsers</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#configuration_3","title":"Configuration:","text":"<pre><code># ~/.wyn360/config.yaml (future enhancement)\nauthentication:\n  session_ttl: 1800  # 30 minutes\n  save_credentials: true\n  headless: true\n  timeout: 30000  # 30 seconds\n</code></pre> <p>Version: v0.3.40 Status: \u2705 Complete Completed: Current session Test Coverage: 27/27 tests passing (SessionManager: 16/16, BrowserAuth: 11/11)</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-43-authenticated-fetch-integration-v0341","title":"Phase 4.3: Authenticated Fetch Integration (v0.3.41)","text":"<p>Goal: Seamlessly integrate authenticated sessions with fetch_website for automatic authenticated browsing</p>"},{"location":"ROADMAP_BROWSERUSE/#tasks_4","title":"Tasks:","text":"<ul> <li>[x] Modify fetch_website_content to accept cookies parameter</li> <li>[x] Update AsyncWebCrawler to inject cookies into browser context</li> <li>[x] Add automatic session detection in agent's fetch_website tool</li> <li>[x] Extract domain from URL and check for saved sessions</li> <li>[x] Pass session cookies to fetch_website_content automatically</li> <li>[x] Add authentication indicator in fetch response</li> <li>[x] Update fetch_website docstring with authentication info</li> <li>[x] Update system prompt with seamless integration details</li> <li>[x] Update ROADMAP_BROWSERUSE.md</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#features_4","title":"Features:","text":"<p>Seamless Authenticated Browsing: - fetch_website automatically detects and uses saved session cookies - No manual cookie management required - Domain-based session matching - Visual indicator (\ud83d\udd10) when fetching authenticated content</p> <p>Implementation: <pre><code># In agent.py fetch_website method\ndomain = urlparse(url).netloc\nsession = self.session_manager.get_session(domain)\nif session:\n    cookies = session['cookies']\n    authenticated = True\n\n# Pass cookies to browser\nsuccess, content = await fetch_website_content(\n    url=url,\n    cookies=cookies  # Automatically injected\n)\n</code></pre></p> <p>User Experience: <pre><code># Step 1: Login once\nlogin_to_website(\n    url=\"https://example-site.com/login\",\n    username=\"demo_user\",\n    password=\"SecurePass123!\"\n)\n\n# Step 2: All subsequent fetches are automatically authenticated!\nfetch_website(\"https://example-site.com/profile\")  # \ud83d\udd10 authenticated\nfetch_website(\"https://example-site.com/dashboard\")  # \ud83d\udd10 authenticated\nfetch_website(\"https://example-site.com/settings\")  # \ud83d\udd10 authenticated\n</code></pre></p> <p>Benefits: - Zero friction authenticated browsing - Session cookies automatically used when available - Clear visual feedback (\ud83d\udd10 indicator) - 30-minute session TTL for security - No manual token/cookie management</p> <p>Technical Changes: - <code>browser_use.py</code>: Added <code>cookies</code> parameter to <code>fetch_website_content</code> - <code>browser_use.py</code>: Modified <code>AsyncWebCrawler</code> initialization with <code>browser_config</code> - <code>agent.py</code>: Added session detection in <code>fetch_website</code> tool - <code>agent.py</code>: Updated system prompt with Phase 4.3 integration details</p> <p>Version: v0.3.41 Status: \u2705 Complete Completed: Current session</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-44-enhanced-form-detection-v0342-0343","title":"Phase 4.4: Enhanced Form Detection (v0.3.42-0.3.43)","text":"<p>Status: \u2705 Complete Priority: HIGH Completed: 2025-11-13 Documentation: v0.3.43</p> <p>Context: Real-world testing revealed form detection limitations. The system failed to login to <code>wyn360search.com</code> due to inability to detect non-standard login forms.</p> <p>Improvements Implemented:</p> <ul> <li>[x] 4.4.1: Intelligent URL Discovery</li> <li>Tries 12 common login URLs (<code>/login</code>, <code>/signin</code>, <code>/auth</code>, <code>/account/login</code>, etc.)</li> <li>Follows \"Login\" links on homepage automatically</li> <li> <p>Validates each URL for login form presence before selecting</p> </li> <li> <p>[x] 4.4.2: Dynamic Content Waiting</p> </li> <li>Waits up to 10 seconds for form elements to appear</li> <li>Handles JavaScript frameworks (React/Vue/Angular)</li> <li>Additional 1-second settle time for dynamic content</li> <li> <p>Continues gracefully if timeout occurs</p> </li> <li> <p>[x] 4.4.3: Enhanced Form Detection with Fuzzy Matching</p> </li> <li>Analyzes ALL input elements on page (not just predefined selectors)</li> <li>Fuzzy matches on 7 attributes: type, name, id, placeholder, class, autocomplete, aria-label</li> <li>Confidence scoring for username field candidates</li> <li> <p>Falls back to traditional detection if enhanced detection succeeds</p> </li> <li> <p>[x] 4.4.4: Debug Mode with Screenshots</p> </li> <li>Environment variable: <code>export WYN360_BROWSER_DEBUG=true</code></li> <li>Saves timestamped screenshots at each step (8 screenshots per login attempt)</li> <li>Dumps full HTML content for analysis</li> <li>Exports detected elements to JSON with confidence scores</li> <li>Stores in <code>~/.wyn360/debug/browser_auth/{timestamp}_*.png|html|json</code></li> <li> <p>Provides clear error messages with debug file locations</p> </li> <li> <p>[x] 4.4.5: Manual Selector Override</p> </li> <li>New agent tool: <code>login_with_manual_selectors()</code></li> <li>Accepts custom CSS selectors for username, password, submit fields</li> <li>Bypasses automatic form detection entirely</li> <li>Example: \"Login with selectors #user, #pass, #submit-btn\"</li> <li>Saves debug screenshots when enabled</li> </ul> <p>Files Modified: - <code>wyn360_cli/browser_auth.py</code>: +300 lines (Phase 4.4 methods) - <code>wyn360_cli/agent.py</code>: +100 lines (new tool + debug support) - <code>pyproject.toml</code>: Version updated to 0.3.42</p> <p>New Methods: - <code>BrowserAuth._find_login_page()</code>: Intelligent URL discovery - <code>BrowserAuth._has_login_form()</code>: Quick form presence check - <code>BrowserAuth._wait_for_form_load()</code>: Dynamic content waiting - <code>BrowserAuth._detect_login_form_enhanced()</code>: Fuzzy matching detection - <code>BrowserAuth._save_debug_screenshot()</code>: Debug screenshot helper - <code>BrowserAuth._save_debug_html()</code>: Debug HTML dump helper - <code>BrowserAuth._save_debug_info()</code>: Debug JSON export helper - <code>BrowserAuth.login_with_selectors()</code>: Manual selector override - <code>Agent.login_with_manual_selectors()</code>: Agent tool for manual login</p> <p>Success Metrics (Expected): - Login success rate: 60% \u2192 90%+ (testing in progress) - Form detection rate: 70% \u2192 95%+ (enhanced detection added) - Average login time: ~15s (with discovery and waiting) - Debug information: Comprehensive (screenshots + HTML + JSON)</p> <p>Usage:</p> <p>Enable debug mode: <pre><code>export WYN360_BROWSER_DEBUG=true\nwyn360 \"login to http://wyn360search.com with your_username/your_password\"\n</code></pre></p> <p>Use manual selectors: <pre><code>wyn360 \"login to http://example.com with user/pass using selectors #username, #password, #submit\"\n</code></pre></p> <p>Next Steps: - Real-world testing with wyn360search.com - Test with diverse website types - Gather metrics on success rates - Consider Phase 4.5 (LLM-powered form analysis) if needed</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-45-llm-powered-form-analysis-v0343-planned","title":"Phase 4.5: LLM-Powered Form Analysis (v0.3.43 - PLANNED)","text":"<p>Status: \ud83d\udccb Planned Priority: MEDIUM Estimated Effort: 4-6 hours</p> <p>Approach: When automatic form detection fails, use Claude API to analyze page HTML and suggest selectors.</p> <p>Implementation:</p> <ul> <li>[ ] 4.5.1: HTML Analysis Tool</li> <li>Extract relevant HTML (forms, inputs, buttons)</li> <li>Truncate to fit in prompt (~50k chars)</li> <li> <p>Call Claude API with analysis task</p> </li> <li> <p>[ ] 4.5.2: Selector Suggestion</p> </li> <li>LLM returns JSON with suggested selectors</li> <li>Include confidence score (0-100)</li> <li>Provide reasoning for suggestions</li> <li> <p>Fall back to manual mode if confidence &lt;70</p> </li> <li> <p>[ ] 4.5.3: Adaptive Learning</p> </li> <li>Cache successful selector patterns per domain</li> <li>Build domain-specific form detection rules</li> <li>Share patterns across users (privacy-safe)</li> </ul> <p>Example: <pre><code>async def _analyze_page_with_llm(self, page: Page) -&gt; Dict:\n    html_content = await page.content()\n    prompt = f\"Analyze this HTML and identify login form elements: {html_content[:50000]}\"\n    # Call Claude API\n    analysis = await claude_analyze(prompt)\n    return analysis['selectors']\n</code></pre></p> <p>Benefits: - Handle truly unique/custom forms - Improve over time with learning - Reduce manual intervention</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-46-interactive-browser-mode-v0344-planned","title":"Phase 4.6: Interactive Browser Mode (v0.3.44 - PLANNED)","text":"<p>Status: \ud83d\udccb Planned Priority: LOW Estimated Effort: 3-4 hours</p> <p>Feature: Launch non-headless browser, let user login manually, capture session cookies when complete.</p> <p>Implementation:</p> <ul> <li>[ ] 4.6.1: Interactive Login Method</li> <li>New method: <code>interactive_login(url)</code></li> <li>Launch browser with <code>headless=False</code></li> <li>Display instructions to user</li> <li>Wait for user confirmation (press ENTER)</li> <li> <p>Capture cookies and close browser</p> </li> <li> <p>[ ] 4.6.2: Session Import/Export</p> </li> <li>Export cookies to JSON file</li> <li>Import cookies from browser extensions</li> <li>Support Chrome/Firefox cookie formats</li> <li>Manual cookie entry via UI</li> </ul> <p>Use Cases: - Complex authentication (OAuth, SAML, SSO) - CAPTCHA/2FA that can't be automated - Sites with strong bot detection - User wants full control</p> <p>Example: <pre><code>You: Help me login to wyn360search.com interactively\n\nWYN360: \ud83c\udf10 Opening browser for manual login...\n        \ud83d\udcdd Please login manually in the browser window\n        \u2705 Press ENTER when you're logged in\n\n[Browser window opens]\n[User logs in manually]\n[User presses ENTER]\n\nWYN360: \u2705 Session captured! You can now fetch authenticated pages.\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#technical-considerations","title":"Technical Considerations","text":""},{"location":"ROADMAP_BROWSERUSE/#1-content-truncation-strategy","title":"1. Content Truncation Strategy","text":"<p>Smart Truncation: - Preserve headers and structure - Keep first N tokens + last M tokens - Summarize middle section if needed</p> <p>Implementation: <pre><code>def smart_truncate(markdown: str, max_tokens: int) -&gt; str:\n    \"\"\"\n    Intelligently truncate markdown content.\n\n    Strategy:\n    1. Keep full content if under max_tokens\n    2. Preserve document structure (headers)\n    3. Keep first 70% and last 30% of tokens\n    4. Add truncation marker\n    \"\"\"\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#2-browser-management","title":"2. Browser Management","text":"<p>Resource Management: - Use browser context pooling - Close browser after each fetch - Implement connection timeout (30s default) - Handle network failures gracefully</p> <p>Memory Usage: - ~50-100MB per browser instance - Close immediately after content extraction - No persistent browser sessions</p>"},{"location":"ROADMAP_BROWSERUSE/#3-security-considerations","title":"3. Security Considerations","text":"<p>URL Validation: - Whitelist allowed protocols (http, https) - Validate URL format before fetching - Implement rate limiting (max 10 fetches/minute) - Block potentially dangerous URLs</p> <p>Content Safety: - Sanitize markdown output - Remove script tags and potentially harmful content - Implement content size limits</p>"},{"location":"ROADMAP_BROWSERUSE/#4-error-handling","title":"4. Error Handling","text":"<p>Common Scenarios: <pre><code># Timeout\nif fetch_time &gt; 30:\n    return \"\u26a0\ufe0f Website took too long to load (timeout: 30s)\"\n\n# 404 / 403 / 500 errors\nif status_code &gt;= 400:\n    return f\"\u274c Failed to fetch: HTTP {status_code}\"\n\n# Network errors\nexcept NetworkError:\n    return \"\u274c Network error: Unable to connect\"\n\n# JavaScript errors\nexcept JavaScriptError:\n    return \"\u26a0\ufe0f Page loaded but JavaScript failed\"\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#performance-metrics","title":"Performance Metrics","text":""},{"location":"ROADMAP_BROWSERUSE/#target-performance","title":"Target Performance:","text":"<ul> <li>Fetch time: &lt; 5 seconds (average)</li> <li>Cache hit rate: &gt; 80% (for repeated URLs)</li> <li>Memory overhead: &lt; 200MB (including browser)</li> <li>Cache size: &lt; 100MB total</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#monitoring","title":"Monitoring:","text":"<pre><code>class BrowserUseMetrics:\n    fetch_count: int\n    cache_hits: int\n    cache_misses: int\n    avg_fetch_time: float\n    total_bytes_fetched: int\n    failed_fetches: int\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#dependencies","title":"Dependencies","text":""},{"location":"ROADMAP_BROWSERUSE/#new-dependencies","title":"New Dependencies:","text":"<pre><code>[tool.poetry.dependencies]\ncrawl4ai = \"^0.7.6\"  # LLM-optimized web crawler\n# Note: crawl4ai includes playwright as dependency\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#browser-binaries","title":"Browser Binaries:","text":"<pre><code># Installed automatically during package installation\nplaywright install chromium\n# Size: ~200MB (Chromium only)\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE/#documentation-updates","title":"Documentation Updates","text":""},{"location":"ROADMAP_BROWSERUSE/#readmemd","title":"README.md:","text":"<ul> <li>Add \"Browser Use\" section</li> <li>Document fetch_website usage</li> <li>Show examples with real URLs</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#systemmd","title":"SYSTEM.md:","text":"<ul> <li>Document Phase 12.1, 12.2, 12.3</li> <li>Add architecture diagram</li> <li>Document cache system</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#use_casesmd","title":"USE_CASES.md:","text":"<ul> <li>Add Use Case 18: \"Direct Website Fetching\"</li> <li>Add examples with GitHub, docs, blogs</li> <li>Document cache management</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#costmd","title":"COST.md:","text":"<ul> <li>Document token usage for fetched content</li> <li>Show cache savings</li> <li>Cost comparison: fetch vs search</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#testing-strategy","title":"Testing Strategy","text":""},{"location":"ROADMAP_BROWSERUSE/#test-cases","title":"Test Cases:","text":"<p>1. Basic URL Fetching: <pre><code># GitHub repository\nurl = \"https://github.com/user/repo\"\ncontent = await fetch_website(url)\nassert \"README\" in content\n\n# Documentation site\nurl = \"https://docs.python.org/3/library/asyncio.html\"\ncontent = await fetch_website(url)\nassert \"asyncio\" in content\n</code></pre></p> <p>2. Cache System: <pre><code># First fetch (miss)\ncontent1 = await fetch_website(url)\nassert cache_stats.misses == 1\n\n# Second fetch (hit)\ncontent2 = await fetch_website(url)\nassert cache_stats.hits == 1\nassert content1 == content2\n</code></pre></p> <p>3. Truncation: <pre><code># Large page\nurl = \"https://example.com/large-page\"\ncontent = await fetch_website(url)\nassert count_tokens(content) &lt;= MAX_TOKENS\nassert \"[Content truncated]\" in content\n</code></pre></p> <p>4. Error Handling: <pre><code># 404 error\ncontent = await fetch_website(\"https://example.com/404\")\nassert \"404\" in content or \"not found\" in content.lower()\n\n# Timeout\ncontent = await fetch_website(\"https://slow-site.com\")\nassert \"timeout\" in content.lower()\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#migration-path","title":"Migration Path","text":""},{"location":"ROADMAP_BROWSERUSE/#for-existing-users","title":"For Existing Users:","text":"<p>Version 0.3.23 \u2192 0.3.24: - New dependency: crawl4ai - Browser binaries installed automatically - No breaking changes to existing features - WebSearchTool remains unchanged</p> <p>Configuration Migration: <pre><code># Automatic migration on first run\nwyn360 migrate-config\n\n# Adds new browser_use section to config\n# Preserves existing settings\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#future-enhancements-post-v0343","title":"Future Enhancements (Post v0.3.43)","text":""},{"location":"ROADMAP_BROWSERUSE/#phase-5-autonomous-vision-based-browser-automation-v0350-0355-option-a","title":"Phase 5: Autonomous Vision-Based Browser Automation (v0.3.50-0.3.55) - OPTION A","text":"<p>Status: \ud83d\udccb Planned (Primary Implementation Path) Priority: HIGH Architecture: Custom pydantic-ai + Anthropic Vision + Playwright Estimated Effort: 2-3 weeks</p> <p>Goal: Enable autonomous multi-step browser task execution using Claude Vision to analyze screenshots and make intelligent navigation decisions.</p> <p>Design Philosophy: - Single Agent Framework: Everything stays within pydantic-ai infrastructure - Unified Billing: All AI decisions (vision + language) through ANTHROPIC_API_KEY - Tight Integration: Seamlessly works with existing WYN360 tools (WebSearch, auth, file tools, etc.) - Full Control: Custom implementation for maximum flexibility and context sharing - Anthropic API Only: Gracefully disabled in Bedrock mode (vision not well-supported)</p> <p>Key Use Cases (Ranked by Priority): 1. Open-Ended Exploration (Priority 1): \"Browse Amazon electronics and tell me what's trending\" 2. Integrated Workflows (Priority 2): \"Search web for best shoe stores, browse top result, find best deal\" 3. Structured Shopping (Priority 3): \"Find the cheapest sneaker with 2-day shipping on Amazon\"</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-51-core-infrastructure-v0352","title":"Phase 5.1: Core Infrastructure (v0.3.52)","text":"<p>Goal: Build foundational browser control and vision analysis infrastructure</p> <p>Status: \u2705 COMPLETE (2025-11-17)</p> <p>Tasks: - [x] 5.1.1: BrowserController Class \u2705   - Create <code>wyn360_cli/browser_controller.py</code>   - Implement Playwright-based browser automation (visible browser by default)   - Browser lifecycle management (launch, navigate, close)   - Action execution (click, type, scroll, navigate, wait)   - Screenshot capture (with quality optimization for vision API)   - Element locator strategies (CSS selectors, XPath, text-based, fuzzy matching)   - Error handling and retry logic   - Resource cleanup and timeout management   - Tests: 17/17 passing (tests/test_browser_controller.py)</p> <ul> <li>[x] 5.1.2: Vision Decision Engine \u2705</li> <li>Create <code>wyn360_cli/vision_engine.py</code></li> <li>Integrate with Anthropic Vision API via pydantic-ai</li> <li>Screenshot analysis prompt engineering</li> <li>Action decision parsing (structured output)</li> <li>Context management (task goal, action history, page state)</li> <li>Confidence scoring for decisions</li> <li>Fallback strategies for low-confidence scenarios</li> <li> <p>Tests: 23/23 passing (tests/test_vision_engine.py)</p> </li> <li> <p>[x] 5.1.3: Action Parser \u2705</p> </li> <li>Parse Claude's natural language decisions into Playwright actions</li> <li>Support action types: click, type, scroll, navigate, extract, complete</li> <li>Handle coordinates, selectors, text targets</li> <li>Validate actions before execution</li> <li>Error recovery suggestions</li> <li>Integrated into: VisionDecisionEngine (_parse_decision, _validate_action methods)</li> </ul> <p>Implementation Details:</p> <pre><code># wyn360_cli/browser_controller.py\nclass BrowserController:\n    \"\"\"\n    Pure browser automation using Playwright (no AI).\n    Responsible for: browser lifecycle, action execution, screenshot capture.\n    \"\"\"\n\n    async def initialize(self, headless: bool = False, viewport_size: tuple = (1024, 768)):\n        \"\"\"Launch browser with optimal settings for vision analysis.\"\"\"\n\n    async def navigate(self, url: str):\n        \"\"\"Navigate to URL with smart waiting.\"\"\"\n\n    async def take_screenshot(self, optimize_for_vision: bool = True) -&gt; bytes:\n        \"\"\"\n        Capture screenshot optimized for Claude Vision.\n        - Resolution: 1024x768 (XGA - optimal for vision API)\n        - Format: PNG\n        - Compression: Balanced for quality vs size\n        \"\"\"\n\n    async def execute_action(self, action: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Execute browser action from parsed decision.\n\n        Actions:\n          - click: {type: 'click', selector: '#btn', text: 'Submit'}\n          - type: {type: 'type', selector: '#search', text: 'sneakers'}\n          - scroll: {type: 'scroll', direction: 'down', amount: 500}\n          - navigate: {type: 'navigate', url: 'https://...'}\n          - extract: {type: 'extract', selector: '.price'}\n          - wait: {type: 'wait', seconds: 2}\n        \"\"\"\n\n    async def find_element(self, strategy: str, value: str) -&gt; Optional[ElementHandle]:\n        \"\"\"\n        Find element using various strategies:\n        - selector: CSS selector\n        - xpath: XPath expression\n        - text: Visible text content\n        - fuzzy: Fuzzy text matching\n        \"\"\"\n\n    async def get_page_state(self) -&gt; Dict[str, Any]:\n        \"\"\"Extract current page metadata (URL, title, loaded state).\"\"\"\n\n    async def cleanup(self):\n        \"\"\"Close browser and cleanup resources.\"\"\"\n\n\n# wyn360_cli/vision_engine.py\nclass VisionDecisionEngine:\n    \"\"\"\n    Uses Anthropic Claude Vision (via pydantic-ai) to analyze screenshots.\n    Responsible for: vision analysis, decision making, action planning.\n    \"\"\"\n\n    def __init__(self, agent: Agent):\n        \"\"\"Initialize with WYN360Agent (pydantic-ai).\"\"\"\n        self.agent = agent\n\n    async def analyze_and_decide(\n        self,\n        screenshot: bytes,\n        goal: str,\n        history: List[Dict],\n        page_state: Dict\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Analyze screenshot and decide next action.\n\n        Returns:\n          {\n            'status': 'continue' | 'complete' | 'stuck',\n            'action': {...},  # Next action to execute\n            'reasoning': str,  # Claude's reasoning\n            'confidence': float,  # 0-100\n            'extracted_data': {...},  # If status='complete'\n          }\n        \"\"\"\n        from pydantic_ai import BinaryContent\n\n        # Build analysis prompt\n        prompt = self._build_analysis_prompt(goal, history, page_state)\n\n        # Call agent with vision (all through pydantic-ai!)\n        result = await self.agent.run(\n            user_prompt=[\n                prompt,\n                BinaryContent(data=screenshot, media_type='image/png'),\n            ]\n        )\n\n        # Parse decision\n        return self._parse_decision(result.data)\n\n    def _build_analysis_prompt(self, goal: str, history: List, state: Dict) -&gt; str:\n        \"\"\"\n        Build comprehensive vision analysis prompt.\n\n        Includes:\n        - Task goal\n        - Current page state\n        - Action history (what we've tried)\n        - Available actions\n        - Success criteria\n        - Instructions for structured output\n        \"\"\"\n\n    def _parse_decision(self, response: Any) -&gt; Dict:\n        \"\"\"Parse Claude's response into structured action.\"\"\"\n</code></pre> <p>Features: - XGA resolution (1024x768) for optimal vision API performance - Visible browser (headless=False) so user can watch - Smart element location (CSS, XPath, text, fuzzy) - Comprehensive error handling - Resource cleanup</p> <p>Dependencies: <pre><code># Already have playwright via crawl4ai, no new deps needed\n</code></pre></p> <p>Version: v0.3.52 Status: \u2705 COMPLETE Completed: 2025-11-17</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-52-task-executor-loop-v0353","title":"Phase 5.2: Task Executor Loop (v0.3.53)","text":"<p>Goal: Implement the core screenshot \u2192 analyze \u2192 decide \u2192 act \u2192 repeat loop</p> <p>Status: \u2705 COMPLETE (2025-11-17)</p> <p>Tasks: - [x] 5.2.1: BrowserTaskExecutor Class \u2705   - Create <code>wyn360_cli/browser_task_executor.py</code>   - Implement main execution loop   - Task state management (goal, progress, history)   - Step limiting (max_steps to prevent infinite loops)   - Success detection (task completion criteria)   - Stuck detection (repeated failed actions)   - Progress reporting to user   - Execution metrics tracking   - Tests: 13/13 passing (tests/test_browser_task_executor.py)</p> <ul> <li>[x] 5.2.2: Loop Orchestration \u2705</li> <li>Initialize browser and vision engine</li> <li>Main loop: screenshot \u2192 analyze \u2192 execute \u2192 validate</li> <li>State persistence across steps</li> <li>Error recovery and retries</li> <li>Graceful degradation</li> <li>User interruption handling</li> <li> <p>Integrated into: BrowserTaskExecutor.execute_task()</p> </li> <li> <p>[x] 5.2.3: Context Management \u2705</p> </li> <li>Track action history (what worked, what didn't)</li> <li>Maintain page state changes</li> <li>Store extracted information</li> <li>Build comprehensive final report</li> <li>Memory-efficient history (avoid token bloat)</li> <li>Integrated into: History tracking in execute_task() loop</li> </ul> <p>Implementation:</p> <pre><code># wyn360_cli/browser_task_executor.py\nclass BrowserTaskExecutor:\n    \"\"\"\n    Orchestrates autonomous browser tasks using vision-based decision making.\n    Coordinates BrowserController (automation) + VisionDecisionEngine (AI).\n    \"\"\"\n\n    def __init__(self, agent: Agent):\n        \"\"\"Initialize with WYN360Agent (pydantic-ai).\"\"\"\n        self.agent = agent\n        self.controller = BrowserController()\n        self.vision_engine = VisionDecisionEngine(agent)\n\n    async def execute_task(\n        self,\n        task: str,\n        url: str,\n        max_steps: int = 20,\n        headless: bool = False\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Execute multi-step browser task autonomously.\n\n        Args:\n          task: Natural language task description\n          url: Starting URL\n          max_steps: Maximum browser actions (default: 20)\n          headless: Run browser in headless mode (default: False for user visibility)\n\n        Returns:\n          {\n            'status': 'success' | 'partial' | 'failed',\n            'result': {...},  # Extracted data\n            'steps_taken': int,\n            'history': [...],  # Action history\n            'reasoning': str,  # Final summary\n          }\n        \"\"\"\n\n        # Initialize\n        await self.controller.initialize(headless=headless)\n        await self.controller.navigate(url)\n\n        history = []\n        stuck_count = 0\n        last_action = None\n\n        try:\n            for step in range(max_steps):\n                # 1. Capture current state\n                screenshot = await self.controller.take_screenshot()\n                page_state = await self.controller.get_page_state()\n\n                # 2. Analyze and decide (ALL AI via pydantic-ai + Anthropic Vision)\n                decision = await self.vision_engine.analyze_and_decide(\n                    screenshot=screenshot,\n                    goal=task,\n                    history=history,\n                    page_state=page_state\n                )\n\n                # 3. Check if task complete\n                if decision['status'] == 'complete':\n                    return {\n                        'status': 'success',\n                        'result': decision['extracted_data'],\n                        'steps_taken': step + 1,\n                        'history': history,\n                        'reasoning': decision['reasoning']\n                    }\n\n                # 4. Check if stuck (repeated failures)\n                if decision['status'] == 'stuck' or decision['action'] == last_action:\n                    stuck_count += 1\n                    if stuck_count &gt;= 3:\n                        return self._handle_stuck_state(task, history, step)\n                else:\n                    stuck_count = 0\n\n                # 5. Execute action\n                action_result = await self.controller.execute_action(decision['action'])\n\n                # 6. Record history\n                history.append({\n                    'step': step + 1,\n                    'action': decision['action'],\n                    'reasoning': decision['reasoning'],\n                    'confidence': decision['confidence'],\n                    'result': action_result,\n                    'page_url': page_state['url']\n                })\n\n                last_action = decision['action']\n\n                # 7. Small delay for page updates\n                await asyncio.sleep(1)\n\n        finally:\n            await self.controller.cleanup()\n\n        # Max steps reached\n        return {\n            'status': 'partial',\n            'result': None,\n            'steps_taken': max_steps,\n            'history': history,\n            'reasoning': f\"Reached maximum steps ({max_steps}) without completion\"\n        }\n\n    def _handle_stuck_state(self, task: str, history: List, step: int) -&gt; Dict:\n        \"\"\"Handle case where agent is stuck/repeating actions.\"\"\"\n        return {\n            'status': 'failed',\n            'result': None,\n            'steps_taken': step,\n            'history': history,\n            'reasoning': \"Agent appears stuck. Last 3 actions failed or repeated.\"\n        }\n</code></pre> <p>Features: - Smart stuck detection (repeated failed actions) - Progress visibility (user can watch browser) - Comprehensive history tracking - Graceful failure handling - Resource cleanup guaranteed (try/finally)</p> <p>Version: v0.3.53 Status: \u2705 COMPLETE Completed: 2025-11-17</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-53-agent-tool-integration-v0354","title":"Phase 5.3: Agent Tool Integration (v0.3.54)","text":"<p>Goal: Add <code>browse_and_find</code> tool to WYN360Agent</p> <p>Tasks: - [x] 5.3.1: New Agent Tool   - Add <code>browse_and_find()</code> tool to <code>wyn360_cli/agent.py</code>   - Integrate BrowserTaskExecutor   - Format results for agent consumption   - Error handling and user-friendly messages   - Bedrock mode check (vision required)</p> <ul> <li>[x] 5.3.2: System Prompt Update</li> <li>Add Phase 5 autonomous browsing section</li> <li>Usage guidelines for the tool</li> <li>Example scenarios</li> <li> <p>Limitations and best practices</p> </li> <li> <p>[x] 5.3.3: Tool Chaining Support</p> </li> <li>Enable seamless use with WebSearchTool</li> <li>Enable use with authenticated browsing (login_to_website)</li> <li>Context sharing across tools</li> <li>Multi-tool workflow examples</li> </ul> <p>Tests: - 14/14 tests passing in <code>tests/test_agent_browse_and_find.py</code>   - TestBrowseAndFindTool: 5 tests (success, partial, failed, bedrock mode, exception)   - TestFormatHelpers: 6 tests (data formatting, action history)   - TestSystemPromptIntegration: 3 tests (prompt validation)</p> <p>Implementation:</p> <pre><code># In wyn360_cli/agent.py (WYN360Agent class)\n\n@self.agent.tool\nasync def browse_and_find(\n    ctx: RunContext[None],\n    task: str,\n    url: str,\n    max_steps: int = 20,\n    headless: bool = False\n) -&gt; str:\n    \"\"\"\n    Autonomously browse a website to complete a multi-step task using vision.\n\n    **How it works:**\n    1. Opens browser (visible by default so you can watch)\n    2. Takes screenshots and analyzes with Claude Vision\n    3. Makes intelligent decisions about what to click/type/navigate\n    4. Continues until task is complete or max_steps reached\n    5. Returns extracted information\n\n    **Examples:**\n    - \"Find the cheapest sneaker with 2-day shipping on Amazon\"\n    - \"Browse electronics section and tell me what's trending\"\n    - \"Search for 'laptop', sort by best rating, get first result's price\"\n    - \"Go to my Amazon wishlist and find the most expensive item\"\n\n    **Args:**\n        task: Natural language description of what to accomplish\n        url: Starting URL (e.g., \"https://amazon.com\")\n        max_steps: Maximum browser actions to attempt (default: 20)\n        headless: Run browser invisibly (default: False - visible)\n\n    **Integration:**\n    - Works seamlessly with login_to_website (uses saved sessions)\n    - Can be chained with WebSearchTool (\"search for X, then browse top result\")\n    - Shares context with main agent\n\n    **IMPORTANT:**\n    - Only works in Anthropic API mode (requires vision capabilities)\n    - Disabled in Bedrock mode\n    - Browser will be visible by default (user can watch the agent work)\n    - Set headless=True to run invisibly\n\n    **Returns:**\n        Extracted information or task result as formatted text\n    \"\"\"\n\n    # Check mode (vision required)\n    if self.use_bedrock:\n        return (\n            \"\u274c Autonomous browsing requires vision capabilities.\\n\\n\"\n            \"This feature uses Claude Vision to analyze screenshots and make \"\n            \"intelligent navigation decisions. Vision capabilities are not \"\n            \"available in AWS Bedrock mode.\\n\\n\"\n            \"Please use Anthropic API mode to access this feature:\\n\"\n            \"  export ANTHROPIC_API_KEY=your_key_here\\n\"\n            \"  unset CLAUDE_CODE_USE_BEDROCK\"\n        )\n\n    try:\n        # Initialize executor\n        executor = BrowserTaskExecutor(self.agent)\n\n        # Execute task\n        result = await executor.execute_task(\n            task=task,\n            url=url,\n            max_steps=max_steps,\n            headless=headless\n        )\n\n        # Format response based on status\n        if result['status'] == 'success':\n            return f\"\"\"\u2705 **Task Completed Successfully!**\n\n**Task:** {task}\n**Steps Taken:** {result['steps_taken']}\n\n**Result:**\n{self._format_extracted_data(result['result'])}\n\n**Summary:**\n{result['reasoning']}\n\n---\n*Powered by Claude Vision + Playwright*\n\"\"\"\n\n        elif result['status'] == 'partial':\n            return f\"\"\"\u26a0\ufe0f **Task Partially Completed**\n\n**Task:** {task}\n**Steps Taken:** {result['steps_taken']} (reached maximum)\n\n**Progress:**\n{self._format_action_history(result['history'])}\n\n**Note:** {result['reasoning']}\n\nYou may want to:\n1. Increase max_steps (currently {max_steps})\n2. Refine the task description\n3. Try a different starting URL\n\"\"\"\n\n        else:  # failed\n            return f\"\"\"\u274c **Task Failed**\n\n**Task:** {task}\n**Steps Attempted:** {result['steps_taken']}\n\n**Issue:** {result['reasoning']}\n\n**Action History:**\n{self._format_action_history(result['history'])}\n\n**Suggestions:**\n- Verify the URL is accessible\n- Check if the task is achievable on this website\n- Try breaking the task into smaller steps\n- Consider using manual selectors if form detection failed\n\"\"\"\n\n    except Exception as e:\n        logger.error(f\"Autonomous browsing error: {e}\")\n        return f\"\u274c Error during autonomous browsing: {str(e)}\"\n\ndef _format_extracted_data(self, data: Dict) -&gt; str:\n    \"\"\"Format extracted data for display.\"\"\"\n    # Pretty-print extracted information\n\ndef _format_action_history(self, history: List[Dict]) -&gt; str:\n    \"\"\"Format action history for display.\"\"\"\n    # Show step-by-step actions taken\n</code></pre> <p>System Prompt Addition:</p> <pre><code>**Phase 5: Autonomous Vision-Based Browsing (Anthropic API Only)**\n\nYou have access to `browse_and_find()` which enables autonomous multi-step browser automation:\n\n**How it works:**\n- Takes screenshots of the browser\n- Analyzes with Claude Vision (you see the page)\n- Decides what to click, type, or navigate\n- Continues until task complete\n\n**Use it for:**\n1. Open-ended exploration: \"Browse Amazon electronics and tell me what's trending\"\n2. Multi-step tasks: \"Find cheapest sneaker with 2-day shipping\"\n3. Integrated workflows: Can chain with WebSearchTool, login_to_website, etc.\n\n**Integration with existing tools:**\n- If user is logged in (via login_to_website), browse_and_find uses saved session\n- Can combine with WebSearchTool: \"search for best shoe stores, browse top result\"\n- Shares context with your main conversation\n\n**Guidelines:**\n- Start URL should be the most relevant page for the task\n- Task description should be clear and specific\n- For complex tasks, break into smaller browse_and_find calls\n- Browser is visible by default (user can watch)\n\n**NOT available in Bedrock mode** (requires vision capabilities)\n</code></pre> <p>Version: v0.3.54 Status: \u2705 COMPLETE Completed: 2025-11-17</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-54-testing-refinement-v0355","title":"Phase 5.4: Testing &amp; Refinement (v0.3.55)","text":"<p>Goal: Comprehensive testing with real-world use cases</p> <p>Tasks: - [x] 5.4.1: Error Handling &amp; Resilience   - Added BrowserConfig for centralized configuration   - Implemented retry logic for failed actions (MAX_RETRIES = 2)   - Added navigation timeout fallback (networkidle \u2192 load)   - Improved error recovery and logging</p> <ul> <li>[x] 5.4.2: Vision Prompt Optimization</li> <li>Enhanced vision prompt with common scenario handling (popups, loading, forms, CAPTCHA)</li> <li>Added confidence scoring guidelines (80-100: high, 50-79: medium, 0-49: low)</li> <li>Improved selector guidance (prefer specific selectors)</li> <li> <p>Added detailed action examples and best practices</p> </li> <li> <p>[x] 5.4.3: Timeout &amp; Retry Mechanisms</p> </li> <li>Configurable timeouts (NAVIGATION_TIMEOUT: 60s, ACTION_TIMEOUT: 10s)</li> <li>Action retry with configurable delay (RETRY_DELAY: 1s)</li> <li>Smart retry logic (don't retry unknown actions)</li> <li> <p>Navigation fallback on timeout</p> </li> <li> <p>[x] 5.4.4: Performance Optimizations</p> </li> <li>Configurable wait times (WAIT_AFTER_NAVIGATION: 1s, WAIT_AFTER_ACTION: 0.5s)</li> <li>Implemented actual vision API integration (replaced mock with BinaryContent)</li> <li>Optimized action execution flow</li> <li>Better error handling reduces unnecessary retries</li> </ul> <p>Tests: - 16/16 new Phase 5.4 integration tests passing in <code>tests/test_phase5_4_refinements.py</code>   - TestBrowserConfigurationPhase54: 3 tests (timeout, retry, performance config)   - TestRetryLogicPhase54: 3 tests (retry on failure, respect retry flag, no retry unknown)   - TestNavigationTimeoutHandlingPhase54: 2 tests (fallback, timeout usage)   - TestVisionPromptImprovementsPhase54: 3 tests (common scenarios, confidence, selectors)   - TestVisionIntegrationPhase54: 2 tests (BinaryContent usage, API error handling)   - TestPerformanceOptimizationsPhase54: 2 tests (wait after action/navigation)   - TestErrorResiliencePhase54: 1 test (recovery from transient errors) - Updated existing tests to use new configurable timeouts - Total Phase 5 tests: 83/83 passing</p> <p>Test Scenarios:</p> <pre><code># Test Case 1: Structured shopping task\nresult = await browse_and_find(\n    task=\"Find the cheapest sneaker with 2-day shipping\",\n    url=\"https://amazon.com\"\n)\n# Expected: Successfully finds and returns cheapest sneaker with Prime\n\n# Test Case 2: Open-ended exploration\nresult = await browse_and_find(\n    task=\"Browse the electronics section and tell me what's trending\",\n    url=\"https://amazon.com\",\n    max_steps=30\n)\n# Expected: Navigates to electronics, analyzes trending items, returns insights\n\n# Test Case 3: Authenticated browsing\nawait login_to_website(\"https://amazon.com/login\", \"user\", \"pass\")\nresult = await browse_and_find(\n    task=\"Find the most expensive item in my wishlist\",\n    url=\"https://amazon.com/wishlist\"\n)\n# Expected: Uses saved session, accesses wishlist, finds most expensive item\n\n# Test Case 4: Multi-tool workflow\nsearch_results = await web_search(\"best online shoe stores\")\ntop_url = extract_top_url(search_results)\nresult = await browse_and_find(\n    task=\"Find the best deal on running shoes\",\n    url=top_url\n)\n# Expected: Seamlessly chains search \u2192 browse, returns best deal\n</code></pre> <p>Key Improvements: - Actual Vision API Integration: Replaced mock implementation with real Claude Vision API calls - Retry Logic: Actions retry up to 2 times on transient failures - Smart Timeouts: Configurable timeouts with fallback strategies - Enhanced Prompts: Better guidance for handling popups, forms, loading states, and CAPTCHAs - Performance: Optimized wait times and error handling</p> <p>Version: v0.3.55 Status: \u2705 COMPLETE Completed: 2025-11-17</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-55-documentation-polish-v0356","title":"Phase 5.5: Documentation &amp; Polish (v0.3.56)","text":"<p>Goal: Comprehensive documentation and user-facing polish</p> <p>Tasks: - [x] 5.5.1: Documentation Updates   - \u2705 Updated README.md with autonomous browsing section (8 features + example)   - \u2705 Updated COST.md with vision API cost analysis (detailed breakdown, examples, optimization tips)   - \u2705 Created AUTONOMOUS_BROWSING.md guide (400+ lines comprehensive guide)</p> <ul> <li>[x] 5.5.2: Code Documentation</li> <li>\u2705 Comprehensive docstrings already in place (from Phase 5.1-5.4)</li> <li>\u2705 Architecture diagram in AUTONOMOUS_BROWSING.md</li> <li>\u2705 4 detailed code examples in AUTONOMOUS_BROWSING.md</li> <li> <p>\u2705 API reference for browse_and_find()</p> </li> <li> <p>[x] 5.5.3: User Experience Polish</p> </li> <li>\u2705 Error messages enhanced in Phase 5.4</li> <li>\u2705 Troubleshooting guide with solutions</li> <li>\u2705 Best practices section with examples</li> <li>\u2705 Configuration guide for optimization</li> </ul> <p>Completed Documentation:</p> <p>docs/AUTONOMOUS_BROWSING.md (NEW - 512 lines): - Overview with architecture diagram - Components breakdown (BrowserController, VisionDecisionEngine, BrowserTaskExecutor, Agent Integration) - Usage examples (basic + programmatic) - 4 detailed examples (structured shopping, exploration, authenticated workflows, multi-tool chaining) - Best practices (5 key guidelines with code examples) - Configuration reference (timeout, retry, performance settings) - Troubleshooting (3 common issues with solutions) - Cost considerations (detailed breakdown, real-world examples, optimization tips) - Limitations (current &amp; future roadmap) - API reference</p> <p>README.md Updates: - Added \"Autonomous Vision-Based Browsing\" section - 8 feature highlights (fully autonomous, vision-powered, multi-step, etc.) - Example usage - Link to AUTONOMOUS_BROWSING.md</p> <p>COST.md Updates: - Added comprehensive \"Autonomous Browsing Costs\" section - Token breakdown per screenshot (~2,500 input, ~300 output) - Cost per screenshot: ~$0.012 - Real-world examples table (8 steps = $0.10, 30 steps = $0.36) - 4 cost optimization strategies with code examples - Updated combined cost formula</p> <p>Tests: All 83 Phase 5 tests passing \u2705</p> <p>Version: v0.3.56 Status: \u2705 COMPLETE Completed: 2025-11-17</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-56-advanced-features-v0357","title":"Phase 5.6: Advanced Features (v0.3.57)","text":"<p>Goal: Add advanced capabilities and optimizations</p> <p>Tasks: - [ ] 5.6.1: Screenshot Optimization   - Intelligent cropping (focus on relevant areas)   - Element highlighting for clarity   - Adaptive resolution based on content   - Caching for repeated views</p> <ul> <li>[ ] 5.6.2: Multi-Page Workflows</li> <li>Support for \"compare across multiple sites\"</li> <li>Parallel browsing (multiple tabs)</li> <li> <p>Cross-site data aggregation</p> </li> <li> <p>[ ] 5.6.3: Learning &amp; Improvement</p> </li> <li>Cache successful navigation patterns per domain</li> <li>Learn common element selectors</li> <li> <p>Optimize prompts based on success rate</p> </li> <li> <p>[ ] 5.6.4: Advanced Error Recovery</p> </li> <li>Automatic backtracking when stuck</li> <li>Alternative path exploration</li> <li>Human-in-the-loop for critical decisions</li> </ul> <p>Version: v0.3.57 Estimated Time: 5-6 days</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-5-summary-option-a","title":"Phase 5 Summary (Option A)","text":"<p>Total Estimated Time: 25-34 days (5-7 weeks)</p> <p>Deliverables: - \u2705 Custom vision-based browser automation - \u2705 Fully integrated with pydantic-ai - \u2705 Seamless tool chaining - \u2705 Authenticated browsing support - \u2705 Anthropic API only (unified billing) - \u2705 Comprehensive documentation - \u2705 Production-ready error handling</p> <p>Architecture Benefits: - Single agent framework (pydantic-ai) - All AI through Anthropic API - Tight integration with existing tools - Full control over behavior - Shared context across tools</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-6-browser-use-package-integration-v0360-0362-option-b","title":"Phase 6: browser-use Package Integration (v0.3.60-0.3.62) - OPTION B","text":"<p>Status: \ud83d\udccb Planned (Alternative/Complementary Path) Priority: MEDIUM Architecture: Hybrid (pydantic-ai + browser-use sub-agent) Estimated Effort: 1-2 weeks</p> <p>Goal: Integrate browser-use package as a specialized sub-agent for structured browser automation tasks, while maintaining pydantic-ai as the main infrastructure.</p> <p>Design Philosophy: - Hybrid Architecture: pydantic-ai as main agent, browser-use as specialized sub-agent - Unified Billing: Both use ANTHROPIC_API_KEY - Use Case Split: Option B for structured tasks, Option A for integrated workflows - Graceful Coexistence: Both options available, user/agent chooses best fit - Minimal Breaking Changes: New tool only, existing code untouched</p> <p>When to Use Option B: - Structured, deterministic browser automation - Battle-tested reliability is critical - Fast development for simple tasks - Don't need integration with other WYN360 tools</p> <p>When to Use Option A: - Integrated workflows (search \u2192 browse \u2192 authenticate) - Open-ended exploration tasks - Need shared context with main agent - Authenticated browsing with existing sessions</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-61-basic-integration-v0360","title":"Phase 6.1: Basic Integration (v0.3.60)","text":"<p>Goal: Add browser-use as an optional specialized tool</p> <p>Tasks: - [ ] 6.1.1: Dependency Management   - Add browser-use to optional dependencies   - Handle graceful degradation if not installed   - Update installation documentation</p> <ul> <li>[ ] 6.1.2: BrowserUseWrapper Class</li> <li>Create <code>wyn360_cli/browser_use_wrapper.py</code></li> <li>Wrap browser-use Agent with WYN360 interface</li> <li>Ensure ANTHROPIC_API_KEY is used</li> <li> <p>Error handling and result formatting</p> </li> <li> <p>[ ] 6.1.3: New Agent Tool</p> </li> <li>Add <code>browse_structured_task()</code> tool</li> <li>Clearly distinguish from <code>browse_and_find()</code> (Option A)</li> <li>Documentation on when to use which</li> </ul> <p>Implementation:</p> <pre><code># wyn360_cli/browser_use_wrapper.py\nfrom typing import Optional\ntry:\n    from browser_use import Agent as BrowserAgent, ChatAnthropic\n    HAS_BROWSER_USE = True\nexcept ImportError:\n    HAS_BROWSER_USE = False\n\nclass BrowserUseWrapper:\n    \"\"\"\n    Wrapper for browser-use package.\n    Provides structured browser automation as a specialized sub-agent.\n    \"\"\"\n\n    def __init__(self, api_key: str):\n        \"\"\"Initialize with Anthropic API key.\"\"\"\n        if not HAS_BROWSER_USE:\n            raise ImportError(\"browser-use not installed. Install with: pip install browser-use\")\n        self.api_key = api_key\n\n    async def execute_task(self, task: str, url: Optional[str] = None) -&gt; Dict:\n        \"\"\"\n        Execute structured browser task using browser-use.\n\n        Args:\n          task: Natural language task (browser-use handles interpretation)\n          url: Optional starting URL (browser-use can navigate if not provided)\n\n        Returns:\n          Browser-use result (formatted for WYN360)\n        \"\"\"\n        # Create browser-use agent (separate from pydantic-ai agent)\n        llm = ChatAnthropic(model='claude-sonnet-4-0')\n\n        # Build task with URL if provided\n        full_task = f\"{task} starting at {url}\" if url else task\n\n        # Create and run browser-use agent\n        browser_agent = BrowserAgent(\n            task=full_task,\n            llm=llm\n        )\n\n        result = await browser_agent.run()\n\n        return {\n            'success': True,\n            'result': result,\n            'source': 'browser-use'\n        }\n\n\n# In wyn360_cli/agent.py\n@self.agent.tool\nasync def browse_structured_task(\n    ctx: RunContext[None],\n    task: str,\n    url: Optional[str] = None\n) -&gt; str:\n    \"\"\"\n    Execute structured browser automation using browser-use package.\n\n    **Best for:**\n    - Simple, deterministic tasks (\"find cheapest X\")\n    - When speed/reliability &gt; integration\n    - Standalone browser tasks (no tool chaining needed)\n\n    **NOT best for:**\n    - Tasks needing authentication (use browse_and_find + login_to_website)\n    - Multi-tool workflows (use browse_and_find)\n    - Open-ended exploration (use browse_and_find)\n\n    **How it differs from browse_and_find:**\n    - browse_structured_task: Uses browser-use (separate sub-agent, optimized for structured tasks)\n    - browse_and_find: Uses custom vision engine (integrated with main agent, better for workflows)\n\n    **Examples:**\n    - \"Find the price of the top-rated laptop on Amazon\"\n    - \"Get the download count for Python package 'requests' from PyPI\"\n    - \"Check the current Bitcoin price on CoinMarketCap\"\n\n    **Args:**\n        task: Natural language task description\n        url: Optional starting URL\n\n    **IMPORTANT:**\n    - Requires browser-use package: pip install browser-use\n    - Uses ANTHROPIC_API_KEY (unified billing)\n    - Runs as separate sub-agent (no context sharing with main agent)\n    - Only works in Anthropic API mode\n\n    **Returns:**\n        Task result as formatted text\n    \"\"\"\n\n    # Check mode\n    if self.use_bedrock:\n        return \"\u274c browser-use integration only available in Anthropic API mode.\"\n\n    # Check if browser-use installed\n    if not HAS_BROWSER_USE:\n        return (\n            \"\u274c browser-use package not installed.\\n\\n\"\n            \"Install with: pip install browser-use\\n\\n\"\n            \"Alternative: Use browse_and_find() which is built-in (Option A)\"\n        )\n\n    try:\n        wrapper = BrowserUseWrapper(self.api_key)\n        result = await wrapper.execute_task(task, url)\n\n        return f\"\"\"\u2705 **Task Completed (via browser-use)**\n\n**Task:** {task}\n\n**Result:**\n{result['result']}\n\n---\n*Powered by browser-use + Anthropic Claude*\n\"\"\"\n\n    except Exception as e:\n        logger.error(f\"browser-use error: {e}\")\n        return f\"\u274c Error: {str(e)}\\n\\nTry using browse_and_find() instead (Option A)\"\n</code></pre> <p>Dependencies:</p> <pre><code># pyproject.toml\n[project.optional-dependencies]\nbrowser-use = [\"browser-use&gt;=0.1.0\"]\n\n# Install with: pip install wyn360-cli[browser-use]\n</code></pre> <p>Version: v0.3.60 Estimated Time: 3-4 days</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-62-smart-tool-selection-v0361","title":"Phase 6.2: Smart Tool Selection (v0.3.61)","text":"<p>Goal: Help agent automatically choose between Option A and Option B</p> <p>Tasks: - [ ] 6.2.1: Decision Logic   - Add guidelines to system prompt   - When to use browse_structured_task vs browse_and_find   - Automatic fallback if one option fails</p> <ul> <li>[ ] 6.2.2: Performance Comparison</li> <li>Benchmark both options on common tasks</li> <li>Document speed/accuracy trade-offs</li> <li>Update recommendations based on data</li> </ul> <p>System Prompt Addition:</p> <pre><code>**Choosing Between Autonomous Browsing Options:**\n\nYou have TWO browser automation tools:\n\n1. **browse_and_find** (Option A - Custom Vision):\n   - Best for: Open-ended exploration, integrated workflows, authenticated browsing\n   - Pros: Tight integration, context sharing, works with login_to_website\n   - Cons: Slower (vision analysis), more API calls\n   - Use when: Task needs tool chaining or exploration\n\n2. **browse_structured_task** (Option B - browser-use):\n   - Best for: Simple structured tasks, standalone automation\n   - Pros: Faster, battle-tested, optimized for structured tasks\n   - Cons: Separate sub-agent, no context sharing, no auth integration\n   - Use when: Task is simple and deterministic\n\n**Decision Guide:**\n- \"Find cheapest X\" \u2192 browse_structured_task (simple, structured)\n- \"Browse and tell me trends\" \u2192 browse_and_find (exploration)\n- \"Search web, then browse result\" \u2192 browse_and_find (multi-tool)\n- \"Login and check my cart\" \u2192 browse_and_find (authentication)\n\n**Fallback Strategy:**\n- Try browse_structured_task first for simple tasks (faster)\n- If it fails or task is complex, use browse_and_find\n- Always prefer browse_and_find for authenticated workflows\n</code></pre> <p>Version: v0.3.61 Estimated Time: 2-3 days</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-63-documentation-comparison-v0362","title":"Phase 6.3: Documentation &amp; Comparison (v0.3.62)","text":"<p>Goal: Comprehensive documentation comparing both options</p> <p>Tasks: - [ ] 6.3.1: Comparison Guide   - Create docs/BROWSER_AUTOMATION_COMPARISON.md   - Side-by-side feature comparison   - Use case decision tree   - Performance benchmarks</p> <ul> <li>[ ] 6.3.2: Migration Path</li> <li>Document how to switch between options</li> <li>Provide migration examples</li> <li>Explain when to use each</li> </ul> <p>Documentation:</p> <p><pre><code># docs/BROWSER_AUTOMATION_COMPARISON.md\n\n## Overview\nWYN360-CLI offers two approaches to autonomous browser automation:\n\n### Option A: Custom Vision-Based (browse_and_find)\n- **Architecture:** pydantic-ai + Anthropic Vision + Playwright\n- **Best for:** Integrated workflows, exploration, authenticated browsing\n- **Status:** Built-in, always available\n\n### Option B: browser-use Integration (browse_structured_task)\n- **Architecture:** browser-use package as sub-agent\n- **Best for:** Simple structured tasks, standalone automation\n- **Status:** Optional, requires browser-use package\n\n## Feature Comparison\n\n| Feature | Option A (Custom) | Option B (browser-use) |\n|---------|-------------------|------------------------|\n| **Integration** | Tight (same agent) | Loose (sub-agent) |\n| **Context Sharing** | \u2705 Yes | \u274c No |\n| **Tool Chaining** | \u2705 Native | \u26a0\ufe0f Manual |\n| **Authentication** | \u2705 Seamless | \u274c Separate |\n| **Open-Ended Tasks** | \u2705 Excellent | \u26a0\ufe0f Limited |\n| **Structured Tasks** | \u2705 Good | \u2705 Excellent |\n| **Speed** | Slower (vision) | Faster (optimized) |\n| **Reliability** | Good | Excellent |\n| **Setup** | Built-in | Requires install |\n| **Billing** | Anthropic API | Anthropic API |\n\n## Use Case Decision Tree\n</code></pre> Is task authenticated? (needs login) \u251c\u2500 YES \u2192 Option A (browse_and_find) \u2514\u2500 NO    \u2502    Does task need other tools? (search, fetch, files)    \u251c\u2500 YES \u2192 Option A (browse_and_find)    \u2514\u2500 NO       \u2502       Is task exploratory? (\"tell me trends\")       \u251c\u2500 YES \u2192 Option A (browse_and_find)       \u2514\u2500 NO          \u2502          Is task structured? (\"find cheapest X\")          \u2514\u2500 YES \u2192 Option B (browse_structured_task) <pre><code>## Performance Benchmarks\n\n| Task Type | Option A | Option B |\n|-----------|----------|----------|\n| Simple extraction | 15-20s | 8-12s |\n| Multi-step navigation | 25-35s | 18-25s |\n| Open exploration | 40-60s | N/A |\n| Authenticated task | 20-30s | N/A |\n\n## Recommendation\n\n**Start with Option A (browse_and_find):**\n- More flexible\n- Better integration\n- Handles all use cases\n\n**Use Option B (browse_structured_task) for:**\n- Speed-critical simple tasks\n- When browser-use is already installed\n- Standalone automation needs\n\n## Migration Examples\n\n### Simple Task (Either Works)\n```python\n# Option A\nresult = browse_and_find(\n    task=\"Find Python download count on PyPI\",\n    url=\"https://pypi.org/project/requests\"\n)\n\n# Option B (faster)\nresult = browse_structured_task(\n    task=\"Get download count for package requests\",\n    url=\"https://pypi.org\"\n)\n</code></pre></p>"},{"location":"ROADMAP_BROWSERUSE/#complex-workflow-option-a-only","title":"Complex Workflow (Option A Only)","text":"<p><pre><code># Search web for stores\nstores = web_search(\"best online shoe stores\")\n\n# Browse top result (needs context from search)\nresult = browse_and_find(\n    task=\"Find best deal on running shoes\",\n    url=extract_url(stores)\n)\n# Option B can't do this - no context sharing\n</code></pre> ```</p> <p>Version: v0.3.62 Estimated Time: 2-3 days</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-6-summary-option-b","title":"Phase 6 Summary (Option B)","text":"<p>Total Estimated Time: 7-10 days (1.5-2 weeks)</p> <p>Deliverables: - \u2705 browser-use package integration - \u2705 Clear separation from Option A - \u2705 Smart tool selection guidelines - \u2705 Comprehensive comparison docs - \u2705 Graceful coexistence with Option A</p> <p>When to Implement: - After Option A is complete and tested - When users request faster structured automation - If browser-use proves significantly more reliable for simple tasks</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-7-advanced-capabilities-v0370","title":"Phase 7: Advanced Capabilities (v0.3.70+)","text":"<p>Status: \ud83d\udccb Planned (Long-term Enhancements) Priority: LOW-MEDIUM</p> <p>Goal: Advanced features that build on Phase 5 &amp; 6 foundations</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-71-multi-site-workflows","title":"Phase 7.1: Multi-Site Workflows","text":"<ul> <li>Parallel browsing across multiple sites</li> <li>Cross-site data aggregation and comparison</li> <li>Site-to-site navigation (\"find on Amazon, compare with eBay\")</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-72-intelligent-caching","title":"Phase 7.2: Intelligent Caching","text":"<ul> <li>Cache successful navigation patterns per domain</li> <li>Learn common element selectors over time</li> <li>Share learned patterns (privacy-safe)</li> <li>Reduce redundant vision API calls</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-73-advanced-error-recovery","title":"Phase 7.3: Advanced Error Recovery","text":"<ul> <li>Automatic backtracking when stuck</li> <li>Alternative path exploration</li> <li>Human-in-the-loop for critical decisions</li> <li>Adaptive retry strategies</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-74-performance-optimizations","title":"Phase 7.4: Performance Optimizations","text":"<ul> <li>Screenshot compression and optimization</li> <li>Intelligent cropping (focus on relevant areas)</li> <li>Adaptive resolution based on content type</li> <li>Vision API call batching</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-75-vector-database-integration","title":"Phase 7.5: Vector Database Integration","text":"<ul> <li>Store browsing history in vector DB</li> <li>Semantic search over visited pages</li> <li>RAG-enhanced browsing decisions</li> <li>Long-term memory across sessions</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-8-production-hardening-v0380","title":"Phase 8: Production Hardening (v0.3.80+)","text":"<p>Status: \ud83d\udccb Planned (Production Readiness) Priority: MEDIUM</p>"},{"location":"ROADMAP_BROWSERUSE/#phase-81-monitoring-metrics","title":"Phase 8.1: Monitoring &amp; Metrics","text":"<ul> <li>Detailed execution metrics (success rate, avg steps, cost per task)</li> <li>Vision API usage tracking</li> <li>Error categorization and logging</li> <li>Performance dashboards</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-82-cost-optimization","title":"Phase 8.2: Cost Optimization","text":"<ul> <li>Vision API call reduction strategies</li> <li>Screenshot caching and reuse</li> <li>Intelligent step limiting</li> <li>Cost alerts and budgets</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-83-security-hardening","title":"Phase 8.3: Security Hardening","text":"<ul> <li>Rate limiting per domain</li> <li>URL validation and filtering</li> <li>Content safety checks</li> <li>Audit logging for all browser actions</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-84-reliability","title":"Phase 8.4: Reliability","text":"<ul> <li>Comprehensive error handling</li> <li>Automatic recovery mechanisms</li> <li>Graceful degradation</li> <li>Circuit breakers for failing sites</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#implementation-timeline","title":"Implementation Timeline","text":""},{"location":"ROADMAP_BROWSERUSE/#option-a-primary-path-implement-first","title":"Option A (Primary Path - Implement First)","text":"Phase Version Duration Dependencies 5.1 - Core Infrastructure v0.3.52 \u2705 COMPLETE (2025-11-17) None 5.2 - Task Executor v0.3.53 \u2705 COMPLETE (2025-11-17) Phase 5.1 5.3 - Agent Integration v0.3.54 3-4 days Phase 5.2 5.4 - Testing v0.3.55 5-7 days Phase 5.3 5.5 - Documentation v0.3.56 3-4 days Phase 5.4 5.6 - Advanced Features v0.3.57 5-6 days Phase 5.5 Total v0.3.52-0.3.57 25-34 days 5-7 weeks"},{"location":"ROADMAP_BROWSERUSE/#option-b-alternative-path-implement-after-option-a","title":"Option B (Alternative Path - Implement After Option A)","text":"Phase Version Duration Dependencies 6.1 - Basic Integration v0.3.60 3-4 days Phase 5 complete 6.2 - Smart Selection v0.3.61 2-3 days Phase 6.1 6.3 - Documentation v0.3.62 2-3 days Phase 6.2 Total v0.3.60-0.3.62 7-10 days 1.5-2 weeks"},{"location":"ROADMAP_BROWSERUSE/#combined-timeline-option-a-option-b","title":"Combined Timeline (Option A \u2192 Option B)","text":"<p>Total: 32-44 days (6.5-9 weeks)</p>"},{"location":"ROADMAP_BROWSERUSE/#success-metrics","title":"Success Metrics","text":""},{"location":"ROADMAP_BROWSERUSE/#option-a-custom-vision-based","title":"Option A (Custom Vision-Based)","text":"<ul> <li>\u2705 Task completion rate &gt;70% for structured tasks</li> <li>\u2705 User satisfaction &gt;80% for open-ended exploration</li> <li>\u2705 Integration success 100% with existing tools (auth, search, files)</li> <li>\u2705 Error recovery &gt;90% graceful handling</li> <li>\u2705 Context sharing works seamlessly</li> <li>\u2705 Vision API costs within acceptable range (&lt;$0.50 per typical task)</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#option-b-browser-use-integration","title":"Option B (browser-use Integration)","text":"<ul> <li>\u2705 Installation success &gt;95%</li> <li>\u2705 Speed improvement &gt;30% vs Option A for simple tasks</li> <li>\u2705 Reliability &gt;90% for structured tasks</li> <li>\u2705 Clear user understanding when to use which option</li> <li>\u2705 Graceful coexistence with Option A (no conflicts)</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#decision-points","title":"Decision Points","text":""},{"location":"ROADMAP_BROWSERUSE/#already-resolved","title":"Already Resolved:","text":"<ol> <li>Which option to implement first? \u2192 Option A (custom vision-based)</li> <li>Should we support both options? \u2192 Yes, complementary strengths</li> <li>Authentication integration? \u2192 Option A only (tight integration required)</li> <li>Single vs multiple agent frameworks? \u2192 Prefer single (pydantic-ai), Option B is specialized sub-agent</li> </ol>"},{"location":"ROADMAP_BROWSERUSE/#to-be-resolved-during-implementation","title":"To Be Resolved During Implementation:","text":"<ol> <li>Optimal max_steps default for different task types</li> <li>Vision prompt templates for best accuracy/cost balance</li> <li>When to automatically choose Option A vs Option B</li> <li>Whether to implement Phase 7 features (long-term)</li> <li>Production hardening priorities (Phase 8)</li> </ol>"},{"location":"ROADMAP_BROWSERUSE/#success-metrics_1","title":"Success Metrics","text":""},{"location":"ROADMAP_BROWSERUSE/#phase-1-success","title":"Phase 1 Success:","text":"<ul> <li>\u2705 Users can fetch specific URLs directly</li> <li>\u2705 Content is LLM-friendly (markdown)</li> <li>\u2705 Smart truncation preserves key information</li> <li>\u2705 No regression in existing features</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-2-success","title":"Phase 2 Success:","text":"<ul> <li>\u2705 Cache hit rate &gt; 80%</li> <li>\u2705 Average fetch time &lt; 3s (with cache)</li> <li>\u2705 Automatic cleanup works reliably</li> <li>\u2705 Cache size stays under 100MB</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#phase-3-success","title":"Phase 3 Success:","text":"<ul> <li>\u2705 Users can manage cache easily</li> <li>\u2705 Preferences persist across sessions</li> <li>\u2705 CLI commands work intuitively</li> <li>\u2705 Export/import works correctly</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#version-history","title":"Version History","text":"Version Phase Status Release Date v0.3.24 Phase 1 \u2705 Complete 2025-01-11 v0.3.24 Phase 2 \u2705 Complete (2 optional items remain) 2025-01-11 v0.3.24 Phase 3 \u26a0\ufe0f Partially Complete (core tools done) 2025-01-11 v0.3.40 Phase 4.1 + 4.2 \u2705 Complete (Auth + Sessions) 2025-11-13 v0.3.41 Phase 4.3 \u2705 Complete (Authenticated Fetch) 2025-11-13 v0.3.42 Phase 4.4 \u2705 Complete (Enhanced Form Detection) 2025-11-13 v0.3.43 Phase 4.4 Docs \u2705 Complete (Use Case 26 + Docs) 2025-11-13 v0.3.44 Phase 4.5 \ud83d\udccb Planned (LLM-Powered Analysis) TBD v0.3.44 Phase 4.6 \ud83d\udccb Planned (Interactive Browser) TBD v0.3.25+ Phase 3 (full) Planned (CLI commands, prompts) TBD v0.3.27+ Phase 5-6 Future TBD"},{"location":"ROADMAP_BROWSERUSE/#questions-decisions","title":"Questions &amp; Decisions","text":""},{"location":"ROADMAP_BROWSERUSE/#resolved","title":"Resolved:","text":"<ol> <li>Which library? \u2192 crawl4ai (LLM-optimized)</li> <li>Storage strategy? \u2192 TTL cache (30 min)</li> <li>Truncation? \u2192 Smart, configurable max tokens</li> <li>Dependencies? \u2192 Acceptable (~200MB for browser)</li> </ol>"},{"location":"ROADMAP_BROWSERUSE/#open","title":"Open:","text":"<ol> <li>Should we support PDF extraction? (Future)</li> <li>Should we integrate with existing vector DBs? (Future)</li> <li>Should we support JavaScript execution? (Already supported via crawl4ai)</li> <li>~~Should we support authentication (login)?~~ \u2192 Resolved: Yes, v0.3.40 (Phase 4)</li> </ol>"},{"location":"ROADMAP_BROWSERUSE/#resources","title":"Resources","text":""},{"location":"ROADMAP_BROWSERUSE/#documentation","title":"Documentation:","text":"<ul> <li>crawl4ai docs: https://docs.crawl4ai.com/</li> <li>Playwright docs: https://playwright.dev/python/</li> <li>HTML to Markdown: https://pypi.org/project/markdownify/</li> </ul>"},{"location":"ROADMAP_BROWSERUSE/#examples","title":"Examples:","text":"<ul> <li>crawl4ai quickstart: https://docs.crawl4ai.com/core/quickstart/</li> <li>Playwright scraping: https://scrapfly.io/blog/posts/web-scraping-with-playwright-and-python</li> </ul> <p>Last Updated: 2025-11-11 Maintained By: WYN360 Development Team</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/","title":"WYN360 CLI - DOM-First Browser Automation Enhancement Roadmap","text":"<p>Status: \ud83d\udea7 In Development Priority: HIGH - Performance &amp; Cost Optimization Start Date: November 24, 2025 Target Completion: December 2025</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#executive-summary","title":"\ud83d\udccb Executive Summary","text":"<p>This roadmap outlines the enhancement of WYN360 CLI's autonomous browser automation capabilities by implementing a DOM-first approach with intelligent fallbacks. The goal is to replace the current expensive and slow vision-based system with a faster, cheaper, and more reliable solution.</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#current-problem","title":"Current Problem","text":"<p>Existing Flow: Screenshot \u2192 Claude Vision API \u2192 JSON Decision \u2192 Playwright Action - Cost Issue: ~$15/1M tokens for vision API calls - Speed Issue: Multiple screenshots per action sequence - Efficiency Issue: Image processing latency</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#enhanced-solution","title":"Enhanced Solution","text":"<p>New Flow: DOM Analysis \u2192 LLM Decision \u2192 Stagehand Fallback \u2192 Vision Fallback \u2192 Playwright Execution - Cost Savings: 80-90% reduction in API costs - Speed Improvement: 44%+ faster execution - Reliability: Self-healing with multiple fallback strategies</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#implementation-strategy","title":"\ud83c\udfaf Implementation Strategy","text":""},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#phase-1-dom-first-analysis-planned","title":"Phase 1: DOM-First Analysis \u2705 Planned","text":"<p>Goal: Extract DOM structure and let LLM make decisions without vision</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#tasks","title":"Tasks:","text":"<ul> <li>[ ] 1.1 Create DOM extraction utility</li> <li>[ ] 1.2 Implement <code>analyze_dom</code> pydantic-ai tool</li> <li>[ ] 1.3 Design DOM-to-action decision logic</li> <li>[ ] 1.4 Add confidence scoring system</li> <li>[ ] 1.5 Integrate with existing browser tools</li> <li>[ ] 1.6 Add token counting for DOM analysis</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-requirements","title":"Technical Requirements:","text":"<ul> <li>Full DOM Structure: Extract complete DOM tree with interactive elements</li> <li>Element Attributes: Include id, class, aria-labels for better LLM decisions</li> <li>Pydantic-AI Integration: New tools that work alongside existing browser capabilities</li> <li>Token Tracking: Count tokens for DOM analysis in slash command breakdown</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#success-criteria","title":"Success Criteria:","text":"<ul> <li>\u2705 DOM extraction covers 90%+ of interactive elements</li> <li>\u2705 LLM can make actionable decisions from DOM data</li> <li>\u2705 Confidence scoring accurately predicts success probability</li> <li>\u2705 Token usage tracked and displayed in <code>/tokens</code> command</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#phase-2-stagehand-fallback-integration-planned","title":"Phase 2: Stagehand Fallback Integration \u23f3 Planned","text":"<p>Goal: Dynamic Stagehand code generation for complex scenarios</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#tasks_1","title":"Tasks:","text":"<ul> <li>[ ] 2.1 Install and configure stagehand-py</li> <li>[ ] 2.2 Create Stagehand code generation system</li> <li>[ ] 2.3 Implement dynamic execution pipeline</li> <li>[ ] 2.4 Add pattern caching mechanism</li> <li>[ ] 2.5 Design fallback trigger logic</li> <li>[ ] 2.6 Add token counting for Stagehand operations</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-requirements_1","title":"Technical Requirements:","text":"<ul> <li>Dynamic Code Generation: Generate Stagehand code on-the-spot based on user query + DOM</li> <li>Execution Pipeline: Safe execution of generated Stagehand code</li> <li>Pattern Caching: Cache successful Stagehand patterns for reuse</li> <li>Fallback Logic: Trigger when DOM confidence score below threshold</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#success-criteria_1","title":"Success Criteria:","text":"<ul> <li>\u2705 Dynamic Stagehand code generation works for complex scenarios</li> <li>\u2705 Pattern caching reduces repeated API calls</li> <li>\u2705 Fallback triggers appropriately based on confidence thresholds</li> <li>\u2705 All operations tracked in token counting system</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#phase-3-vision-fallback-integration-planned","title":"Phase 3: Vision Fallback Integration \u23f3 Planned","text":"<p>Goal: Maintain vision capabilities as final fallback for complex visual tasks</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#tasks_2","title":"Tasks:","text":"<ul> <li>[ ] 3.1 Preserve existing vision-based system</li> <li>[ ] 3.2 Implement transparent tool interface</li> <li>[ ] 3.3 Add intelligent routing between approaches</li> <li>[ ] 3.4 Optimize vision usage for edge cases only</li> <li>[ ] 3.5 Unified error handling across all approaches</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-requirements_2","title":"Technical Requirements:","text":"<ul> <li>Transparent Interface: Same tool interface for DOM \u2192 Stagehand \u2192 Vision</li> <li>Intelligent Routing: Automatic selection of best approach</li> <li>Edge Case Handling: Vision reserved for complex visual understanding</li> <li>Unified Experience: Seamless switching between approaches</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#success-criteria_2","title":"Success Criteria:","text":"<ul> <li>\u2705 All three approaches accessible through same tool interface</li> <li>\u2705 Vision usage reduced to &lt;10% of browser automation tasks</li> <li>\u2705 Seamless user experience regardless of approach used</li> <li>\u2705 Complete token tracking across all approaches</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#phase-4-browser-management-ux-planned","title":"Phase 4: Browser Management &amp; UX \u23f3 Planned","text":"<p>Goal: Enhanced browser control and user experience</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#tasks_3","title":"Tasks:","text":"<ul> <li>[ ] 4.1 Implement <code>--show-browser</code> flag</li> <li>[ ] 4.2 Add headless mode as default</li> <li>[ ] 4.3 Unified Playwright browser instance management</li> <li>[ ] 4.4 Interactive error handling system</li> <li>[ ] 4.5 Update documentation and README</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-requirements_3","title":"Technical Requirements:","text":"<ul> <li>Browser Control: Headless by default, <code>--show-browser</code> flag for debugging</li> <li>Instance Management: Same Playwright browser across all approaches</li> <li>Interactive Errors: When partial success occurs, show error + LLM recommendations</li> <li>User Control: Let user decide next steps after errors</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#success-criteria_3","title":"Success Criteria:","text":"<ul> <li>\u2705 Browser visibility controlled by user preference</li> <li>\u2705 Single browser instance shared across all approaches</li> <li>\u2705 Interactive error recovery with LLM assistance</li> <li>\u2705 Clear documentation for all browser flags</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-architecture","title":"\ud83d\udd27 Technical Architecture","text":""},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#tool-interface-design","title":"Tool Interface Design","text":"<pre><code># New pydantic-ai tools in WYN360Agent:\n\n@tool\nasync def browse_page_intelligently(\n    self,\n    ctx: RunContext[None],\n    url: str,\n    task: str,  # \"login with user@example.com\", \"find product price\"\n    strategy: str = \"auto\"  # \"dom\", \"stagehand\", \"vision\", \"auto\"\n) -&gt; str:\n    \"\"\"\n    Browse webpage intelligently using DOM-first approach with fallbacks\n    \"\"\"\n\n@tool\nasync def extract_page_data(\n    self,\n    ctx: RunContext[None],\n    url: str,\n    schema: dict,  # {\"title\": str, \"price\": float, \"availability\": bool}\n    strategy: str = \"auto\"\n) -&gt; dict:\n    \"\"\"\n    Extract structured data from webpage using best available method\n    \"\"\"\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#decision-flow-logic","title":"Decision Flow Logic","text":"<pre><code>graph TD\n    A[User Request] --&gt; B[Extract DOM]\n    B --&gt; C[Analyze with LLM]\n    C --&gt; D{Confidence &gt; 70%?}\n    D --&gt;|Yes| E[Execute DOM Action]\n    D --&gt;|No| F[Generate Stagehand Code]\n    F --&gt; G[Execute Stagehand]\n    G --&gt; H{Success?}\n    H --&gt;|Yes| I[Return Result]\n    H --&gt;|No| J[Vision Fallback]\n    E --&gt; K{Success?}\n    K --&gt;|Yes| I\n    K --&gt;|No| L[Log Partial Success]\n    L --&gt; M[LLM Error Analysis]\n    M --&gt; N[Interactive User Choice]\n    J --&gt; I</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#token-tracking-enhancement-implemented","title":"Token Tracking Enhancement \u2705 IMPLEMENTED","text":"<pre><code># Enhanced /tokens command breakdown:\n{\n    \"total_tokens\": 15420,\n    \"costs\": {\n        \"total\": \"$0.23\",\n        \"dom_automation\": \"$0.05\",      # \u2705 Implemented\n        \"stagehand_generation\": \"$0.08\", # Phase 2\n        \"vision_fallback\": \"$0.10\"\n    },\n    \"dom_automation\": {                 # \u2705 Implemented\n        \"total_operations\": 12,\n        \"dom_analysis_count\": 8,\n        \"dom_action_count\": 3,\n        \"intelligent_browse_count\": 1,\n        \"total_input_tokens\": 3420,\n        \"total_output_tokens\": 1580,\n        \"total_cost\": \"$0.05\"\n    }\n}\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#integration-points","title":"\ud83c\udfaa Integration Points","text":""},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#existing-browser-tools","title":"Existing Browser Tools","text":"<ul> <li>Keep: <code>login_to_website</code> tool (authentication focus)</li> <li>Replace: Current autonomous browsing loop (vision-based decision making)</li> <li>Extend: Browser session management and error handling</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#pydantic-ai-compatibility","title":"Pydantic-AI Compatibility","text":"<ul> <li>Multi-Model Support: Works with Claude, Bedrock, Gemini</li> <li>Tool Interface: Consistent pydantic-ai tool pattern</li> <li>Context Management: Proper RunContext usage throughout</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#environment-variables","title":"Environment Variables","text":"<pre><code># New browser control flags (to be documented in README.md)\nWYN360_BROWSER_HEADLESS=true          # Default: true\nWYN360_BROWSER_SHOW=false             # Override with --show-browser\nWYN360_DOM_CONFIDENCE_THRESHOLD=0.7   # DOM action confidence threshold\nWYN360_STAGEHAND_CACHE=true           # Enable pattern caching\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#success-metrics","title":"\ud83d\udcca Success Metrics","text":""},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#performance-targets","title":"Performance Targets","text":"<ul> <li>Cost Reduction: 80-90% decrease in browser automation costs</li> <li>Speed Improvement: 44%+ faster than current vision-based approach</li> <li>Success Rate: 95%+ task completion rate across all approaches</li> <li>Reliability: &lt;5% fallback to vision for standard web tasks</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#user-experience-goals","title":"User Experience Goals","text":"<ul> <li>Transparency: Clear indication of which approach is being used</li> <li>Control: User can specify approach or let system choose automatically</li> <li>Recovery: Interactive error handling with LLM-assisted troubleshooting</li> <li>Visibility: Optional browser display for debugging complex scenarios</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#risk-mitigation","title":"\ud83d\udea7 Risk Mitigation","text":""},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-risks","title":"Technical Risks","text":"<ul> <li>DOM Complexity: Some sites have obfuscated/dynamic DOM structures</li> <li>Mitigation: Robust fallback system with Stagehand and vision</li> <li>Stagehand Compatibility: Generated code might not work for all scenarios</li> <li>Mitigation: Pattern learning and caching successful approaches</li> <li>Performance Regression: New system slower than expected</li> <li>Mitigation: Benchmarking against current system, optimization phases</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#user-experience-risks","title":"User Experience Risks","text":"<ul> <li>Learning Curve: Users need to understand new browser flags</li> <li>Mitigation: Clear documentation, sensible defaults</li> <li>Debugging Complexity: Multiple approaches make troubleshooting harder</li> <li>Mitigation: Detailed logging, clear error messages, approach tracing</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#timeline-milestones","title":"\ud83d\udcc5 Timeline &amp; Milestones","text":"Phase Milestone Target Date Dependencies 1 DOM Analysis Complete Dec 1, 2025 Pydantic-AI integration 2 Stagehand Fallback Working Dec 8, 2025 Phase 1 + stagehand-py 3 Vision Integration Complete Dec 15, 2025 Phase 2 + existing vision 4 Browser UX &amp; Documentation Dec 20, 2025 Phase 3 + testing"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#implementation-notes","title":"\ud83d\udcbb Implementation Notes","text":""},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#development-approach","title":"Development Approach","text":"<ul> <li>Incremental: Build each phase on top of previous</li> <li>Backwards Compatible: Existing browser tools continue working</li> <li>Testing: Comprehensive testing with real websites</li> <li>Documentation: Update README.md with new environment variables</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#code-organization","title":"Code Organization","text":"<pre><code>src/wyn360/tools/\n\u251c\u2500\u2500 browser/\n\u2502   \u251c\u2500\u2500 dom_analyzer.py          # Phase 1\n\u2502   \u251c\u2500\u2500 stagehand_generator.py   # Phase 2\n\u2502   \u251c\u2500\u2500 vision_fallback.py       # Phase 3\n\u2502   \u251c\u2500\u2500 browser_manager.py       # Phase 4\n\u2502   \u2514\u2500\u2500 autonomous_browsing.py   # Main coordination\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#progress-tracking","title":"\ud83d\udd04 Progress Tracking","text":"<p>Phase 1 - DOM Analysis: \u2705 COMPLETE (100% Complete) - [x] 1.1 DOM extraction utility - \u2705 Complete with 11 comprehensive tests - [x] 1.2 Browser automation tools - \u2705 Complete with 19 comprehensive tests - [x] 1.3 DOM-to-action decision logic - \u2705 Complete with 25 comprehensive tests - [x] 1.4 Confidence scoring system - \u2705 Complete with 8 integration tests - [x] 1.5 Pydantic-AI agent integration - \u2705 Complete with 9 integration tests - [x] 1.6 Token counting for DOM analysis operations - \u2705 Complete with 12 comprehensive tests</p> <p>Phase 2 - Stagehand Integration: \u2705 COMPLETE (100% Complete) - [x] 2.1 Install and configure stagehand-py \u2705 Complete with dependency management - [x] 2.2 Create Stagehand code generation system \u2705 Complete with 26 comprehensive tests - [x] 2.3 Implement dynamic execution pipeline \u2705 Complete with 21 comprehensive tests - [x] 2.4 Add pattern caching mechanism \u2705 Complete with success rate tracking - [x] 2.5 Design fallback trigger logic \u2705 Complete with 19 comprehensive tests - [x] 2.6 Add token counting for Stagehand operations \u2705 Complete with 11 comprehensive tests</p> <p>Phase 3 - Vision Fallback: \u2705 COMPLETE (100% Complete) - [x] 3.1 Preserve existing vision-based system \u2705 Complete with transparent integration - [x] 3.2 Implement transparent tool interface \u2705 Complete with 18 comprehensive tests - [x] 3.3 Add intelligent routing between approaches \u2705 Complete with 18 comprehensive tests - [x] 3.4 Optimize vision usage for edge cases only \u2705 Complete with 12 comprehensive tests - [x] 3.5 Unified error handling across all approaches \u2705 Complete with 29 comprehensive tests</p> <p>Phase 4 - Browser UX: \u2705 COMPLETE (100% Complete) - [x] 4.1 Implement --show-browser flag \u2705 Complete with environment variable support - [x] 4.2 Add headless mode as default \u2705 Complete with BrowserAuth integration - [x] 4.3 Unified Playwright browser instance management \u2705 Complete with 12 comprehensive tests - [x] 4.4 Interactive error handling system \u2705 Complete with 38 comprehensive tests - [x] 4.5 Update documentation and README \u2705 Complete with comprehensive updates</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#phase-2-implementation-summary","title":"\ud83c\udf89 Phase 2 Implementation Summary","text":"<p>Status: \u2705 COMPLETE - All tasks successfully implemented with comprehensive testing</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#key-achievements","title":"Key Achievements:","text":"<ul> <li>\u2705 Complete Stagehand Integration: Dynamic code generation and execution pipeline</li> <li>\u2705 Pattern Caching System: Smart caching with success rate tracking for performance optimization</li> <li>\u2705 Enhanced Automation Orchestrator: Intelligent routing between DOM, Stagehand, and Vision approaches</li> <li>\u2705 Full Token Tracking: Complete cost tracking for all Stagehand operations</li> <li>\u2705 Comprehensive Testing: 77 total tests across 4 test modules (100% passing)</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-implementation","title":"Technical Implementation:","text":"<ul> <li>6 New Modules: Stagehand generator, integration pipeline, enhanced orchestrator, and tests</li> <li>200+ Functions: Complete implementation with error handling, retries, and fallback logic</li> <li>Token Cost Integration: Full integration with <code>/tokens</code> command displaying Stagehand costs</li> <li>Performance Optimizations: Pattern caching, retry logic, and confidence scoring</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#testing-coverage","title":"Testing Coverage:","text":"<ul> <li>26 tests - Stagehand Code Generator functionality</li> <li>21 tests - Integration pipeline with retry logic and error handling</li> <li>19 tests - Enhanced automation orchestrator with fallback strategies</li> <li>11 tests - Token counting and cost calculation accuracy</li> </ul> <p>Next Phase: Phase 4 - Browser Management &amp; UX (Ready to begin)</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#phase-3-implementation-summary","title":"\ud83c\udf89 Phase 3 Implementation Summary","text":"<p>Status: \u2705 COMPLETE - All tasks successfully implemented with comprehensive testing and optimization</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#key-achievements_1","title":"Key Achievements:","text":"<ul> <li>\u2705 Complete Vision Integration: Seamless integration of existing vision system as intelligent fallback</li> <li>\u2705 Unified Automation Interface: Single entry point for DOM \u2192 Stagehand \u2192 Vision automation pipeline</li> <li>\u2705 Intelligent Routing System: Smart approach selection based on task complexity, confidence, and performance</li> <li>\u2705 Cost &amp; Performance Optimization: Vision usage minimized to &lt;10% through intelligent edge case detection</li> <li>\u2705 Unified Error Handling: Comprehensive error categorization, retry logic, and graceful degradation</li> <li>\u2705 Complete Testing Coverage: 107 total tests across 5 test modules (100% passing)</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-implementation_1","title":"Technical Implementation:","text":"<ul> <li>5 New Modules: Vision fallback integration, unified interface, intelligent routing, vision optimization, and error handling</li> <li>300+ Functions: Complete implementation with cost optimization, performance monitoring, and analytics</li> <li>Transparent Operation: Users interact with single interface regardless of underlying approach</li> <li>Edge Case Intelligence: Sophisticated scoring system to determine when vision is truly needed</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#architecture-delivered","title":"Architecture Delivered:","text":"<pre><code>User Request \u2192 UnifiedAutomationInterface \u2192 EnhancedAutomationOrchestrator\n    \u2193\nIntelligent Routing Decision (DOM \u2192 Stagehand \u2192 Vision)\n    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DOM Analysis\u2502 Stagehand AI\u2502Vision Fallback\u2502\n\u2502(Fast&amp;Cheap) \u2502(AI-Powered) \u2502(Most Capable)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193\nUnified Error Handling \u2192 Consistent Results &amp; Analytics\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#testing-coverage_1","title":"Testing Coverage:","text":"<ul> <li>30 tests - Vision fallback integration with agent injection and Bedrock compatibility</li> <li>18 tests - Unified automation interface with configuration management</li> <li>18 tests - Enhanced orchestrator routing with intelligent decision logic</li> <li>12 tests - Vision optimization with cost-aware and performance-aware routing</li> <li>29 tests - Unified error handling with categorization, retry logic, and analytics</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#performance-optimizations","title":"Performance Optimizations:","text":"<ul> <li>Cost Optimization: Vision usage reduced to true edge cases only through intelligent scoring</li> <li>Performance Routing: Faster approaches prioritized based on task type and confidence</li> <li>Intelligent Fallbacks: Seamless degradation when approaches are unavailable or fail</li> <li>Error Learning: Pattern recognition and adaptive retry strategies</li> </ul> <p>Next Phase: Phase 4 - Browser Management &amp; UX (Enhanced control and user experience)</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#phase-4-implementation-summary","title":"\ud83c\udf89 Phase 4 Implementation Summary","text":"<p>Status: \u2705 COMPLETE - All tasks successfully implemented with comprehensive browser control, UX improvements, and advanced error recovery</p>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#key-achievements_2","title":"Key Achievements:","text":"<ul> <li>\u2705 Show Browser Flag: Complete browser visibility control with <code>--show-browser</code> CLI flag and environment variables</li> <li>\u2705 Unified Browser Management: Singleton browser manager ensuring consistent Playwright instance usage across all automation approaches</li> <li>\u2705 Interactive Error Handling: LLM-assisted error recovery with intelligent recovery options and user choice mechanisms</li> <li>\u2705 Comprehensive Testing: 50 total tests across 2 test modules (100% passing)</li> <li>\u2705 Enhanced UX: Headless by default with optional browser visibility for debugging and troubleshooting</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#technical-implementation_2","title":"Technical Implementation:","text":"<ul> <li>3 New/Enhanced Modules: Enhanced orchestrator with interactive capabilities, unified browser manager, and interactive error handler</li> <li>100+ Functions: Complete browser control implementation with error recovery, resource management, and user interaction</li> <li>Environment Variable Integration: <code>WYN360_BROWSER_SHOW=1</code> support with CLI flag precedence</li> <li>Agent Integration: Full agent injection for LLM-assisted error analysis and recovery suggestions</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#architecture-delivered_1","title":"Architecture Delivered:","text":"<pre><code>Browser Control Layer\n\u251c\u2500\u2500 --show-browser CLI flag\n\u251c\u2500\u2500 WYN360_BROWSER_SHOW env var\n\u251c\u2500\u2500 UnifiedBrowserManager (singleton)\n\u2502   \u251c\u2500\u2500 Shared Playwright instances\n\u2502   \u251c\u2500\u2500 Context &amp; page management\n\u2502   \u2514\u2500\u2500 Resource lifecycle management\n\u2514\u2500\u2500 InteractiveErrorHandler\n    \u251c\u2500\u2500 LLM error analysis\n    \u251c\u2500\u2500 Recovery option generation\n    \u251c\u2500\u2500 User choice mechanisms\n    \u2514\u2500\u2500 Recovery action execution\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#testing-coverage_2","title":"Testing Coverage:","text":"<ul> <li>19 tests - Interactive error handling system with LLM integration, recovery actions, and user choice flows</li> <li>19 tests - Enhanced automation orchestrator with interactive error recovery integration</li> <li>12 tests - Unified browser manager with singleton pattern, resource management, and cleanup</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#user-experience-features","title":"User Experience Features:","text":"<ul> <li>Browser Debugging: <code>--show-browser</code> flag allows users to see automation in action for debugging</li> <li>Intelligent Defaults: Headless mode by default for performance, visual mode on demand</li> <li>Error Recovery: When automation fails, users get LLM analysis and recovery options:</li> <li>Retry same approach</li> <li>Try different approach (DOM \u2192 Stagehand \u2192 Vision)</li> <li>Show browser for debugging</li> <li>Modify task description</li> <li>Manual intervention</li> <li>Abort task</li> <li>Resource Efficiency: Single browser instance shared across all automation approaches</li> </ul>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#error-handling-capabilities","title":"Error Handling Capabilities:","text":"<pre><code># Recovery Actions Available\nRecoveryAction.RETRY_SAME_APPROACH     # Retry with same approach\nRecoveryAction.TRY_DIFFERENT_APPROACH  # Switch to next automation method\nRecoveryAction.MODIFY_TASK             # User-guided task adjustment\nRecoveryAction.SHOW_BROWSER            # Enable browser visibility for debugging\nRecoveryAction.MANUAL_INTERVENTION     # User completes action manually\nRecoveryAction.ABORT_TASK              # Stop automation gracefully\n</code></pre>"},{"location":"ROADMAP_BROWSERUSE_STAGEHAND/#performance-reliability","title":"Performance &amp; Reliability:","text":"<ul> <li>Shared Resources: Single browser instance reduces memory usage and startup time</li> <li>Intelligent Recovery: LLM provides context-aware error analysis and recovery suggestions</li> <li>User Control: Users can choose recovery path based on LLM recommendations</li> <li>Resource Management: Proper cleanup and lifecycle management prevents resource leaks</li> </ul> <p>Project Status: \u2705 ALL PHASES COMPLETE - Full DOM-first browser automation with Stagehand fallback, vision edge cases, and enhanced UX</p> <p>Last Updated: November 24, 2025 Document Version: 2.0 Maintained by: WYN360 CLI Development Team Next Review Date: December 1, 2025</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/","title":"WYN360 CLI - Browser Automation Enhancement with Smolagents-Inspired Architecture","text":"<p>Status: \ud83d\udea7 In Development Priority: HIGH - Reliability &amp; Performance Improvement Start Date: November 25, 2025 Target Completion: December 15, 2025</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#executive-summary","title":"\ud83d\udccb Executive Summary","text":"<p>This roadmap outlines the enhancement of WYN360 CLI's browser automation capabilities by implementing smolagents-inspired architecture patterns. The goal is to reduce timeout errors, improve reliability, and enhance performance while maintaining the existing pydantic-ai framework and single API key approach.</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#current-problem","title":"Current Problem","text":"<p>Existing Issues: - Frequent timeout errors during browser automation - Multiple retry attempts before success - Inconsistent behavior across different websites - Step-by-step tool calls create network overhead</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#enhanced-solution","title":"Enhanced Solution","text":"<p>New Architecture: Code-First Execution + Secure Python Sandbox + Intelligent Error Recovery - Reliability Improvement: 60% reduction in timeout errors - Performance Boost: 30% fewer LLM calls through batch operations - Enhanced Security: Isolated execution environment - Better Recovery: Intelligent error analysis and code regeneration</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#implementation-strategy","title":"\ud83c\udfaf Implementation Strategy","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#design-principles","title":"Design Principles","text":"<ol> <li>Preserve pydantic-ai Framework: All enhancements work within existing agent structure</li> <li>Single API Key: No additional API keys required (use existing Claude/Gemini/AWS)</li> <li>Zero Additional Installation: No Docker, E2B, or external services required</li> <li>Backward Compatibility: Existing browser automation continues to work</li> <li>Progressive Enhancement: Each phase adds capability without breaking previous functionality</li> </ol>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TD\n    A[\"\ud83c\udfaf User Request\"] --&gt; B[\"\ud83d\udcdd Enhanced Code Generator\"]\n    B --&gt; C[\"\ud83d\udd12 Secure Python Sandbox\"]\n    C --&gt; D{Execution Success?}\n    D --&gt;|Yes| E[\"\u2705 Return Results\"]\n    D --&gt;|No| F[\"\ud83e\udde0 Intelligent Error Analysis\"]\n    F --&gt; G[\"\ud83d\udd04 Code Regeneration\"]\n    G --&gt; C\n    F --&gt; H[\"\ud83c\udf9b\ufe0f Fallback to Current System\"]\n    H --&gt; E\n\n    style A fill:#e1f5fe\n    style B fill:#e8f5e8\n    style C fill:#fff3e0\n    style F fill:#fce4ec\n    style E fill:#c8e6c9</code></pre>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#phase-implementation-plan","title":"\ud83d\ude80 Phase Implementation Plan","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#phase-1-enhanced-code-generation-planned","title":"Phase 1: Enhanced Code Generation \u23f3 Planned","text":"<p>Goal: Generate complete automation scripts instead of step-by-step tool calls</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#tasks","title":"Tasks:","text":"<ul> <li>[ ] 1.1 Create enhanced code generation prompts</li> <li>[ ] 1.2 Implement batch automation code generator</li> <li>[ ] 1.3 Add code optimization and validation</li> <li>[ ] 1.4 Integrate with existing pydantic-ai tools</li> <li>[ ] 1.5 Add comprehensive unit tests</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#technical-requirements","title":"Technical Requirements:","text":"<ul> <li>Code-First Approach: Generate complete Python scripts for automation tasks</li> <li>Batch Operations: Handle loops, conditionals, and multi-step workflows in single execution</li> <li>pydantic-ai Integration: Work seamlessly with existing tool decorators</li> <li>Error Prevention: Generate robust code with proper waits and error handling</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#success-criteria","title":"Success Criteria:","text":"<ul> <li>\u2705 Generate complete automation scripts vs multiple tool calls</li> <li>\u2705 Reduce LLM API calls by 30%+ through batching</li> <li>\u2705 Improve execution speed by 25%+</li> <li>\u2705 Maintain full compatibility with existing agent structure</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#files-to-createmodify","title":"Files to Create/Modify:","text":"<ul> <li><code>wyn360_cli/tools/browser/enhanced_code_generator.py</code> - Main code generation logic</li> <li><code>wyn360_cli/tools/browser/code_templates.py</code> - Reusable automation patterns</li> <li><code>tests/test_enhanced_code_generator.py</code> - Comprehensive test suite</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#phase-2-secure-python-sandbox-planned","title":"Phase 2: Secure Python Sandbox \u23f3 Planned","text":"<p>Goal: Execute automation code in isolated Python environment for improved reliability</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#tasks_1","title":"Tasks:","text":"<ul> <li>[ ] 2.1 Design secure Python execution environment</li> <li>[ ] 2.2 Implement restricted globals and imports</li> <li>[ ] 2.3 Add resource management and timeouts</li> <li>[ ] 2.4 Create safe execution wrapper</li> <li>[ ] 2.5 Add comprehensive unit tests</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#technical-requirements_1","title":"Technical Requirements:","text":"<ul> <li>Secure Execution: Restrict dangerous imports and system access</li> <li>Resource Management: Control memory, CPU, and execution time</li> <li>Browser Integration: Maintain connection to Playwright browser instances</li> <li>Error Isolation: Prevent sandbox failures from affecting main process</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#success-criteria_1","title":"Success Criteria:","text":"<ul> <li>\u2705 Execute automation code in isolated environment</li> <li>\u2705 Prevent security vulnerabilities from malicious websites</li> <li>\u2705 Maintain full browser functionality and user experience</li> <li>\u2705 Improve reliability through resource isolation</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#files-to-createmodify_1","title":"Files to Create/Modify:","text":"<ul> <li><code>wyn360_cli/tools/browser/secure_python_sandbox.py</code> - Main sandbox implementation</li> <li><code>wyn360_cli/tools/browser/safe_execution.py</code> - Secure execution wrapper</li> <li><code>tests/test_secure_python_sandbox.py</code> - Security and functionality tests</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#phase-3-intelligent-error-recovery-planned","title":"Phase 3: Intelligent Error Recovery \u23f3 Planned","text":"<p>Goal: Implement adaptive retry logic with code regeneration based on error analysis</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#tasks_2","title":"Tasks:","text":"<ul> <li>[ ] 3.1 Create error analysis and classification system</li> <li>[ ] 3.2 Implement adaptive code regeneration</li> <li>[ ] 3.3 Add intelligent retry strategies</li> <li>[ ] 3.4 Integrate with existing error handling</li> <li>[ ] 3.5 Add comprehensive unit tests</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#technical-requirements_2","title":"Technical Requirements:","text":"<ul> <li>Error Classification: Categorize failures (timeout, element not found, page changes)</li> <li>Adaptive Regeneration: Use existing LLM to analyze errors and improve code</li> <li>Smart Retries: Different strategies for different error types</li> <li>Graceful Degradation: Fall back to current system when needed</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#success-criteria_2","title":"Success Criteria:","text":"<ul> <li>\u2705 Classify and analyze automation failures intelligently</li> <li>\u2705 Generate improved code based on error context</li> <li>\u2705 Achieve 70% better success rate on retry attempts</li> <li>\u2705 Seamlessly integrate with existing error handling</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#files-to-createmodify_2","title":"Files to Create/Modify:","text":"<ul> <li><code>wyn360_cli/tools/browser/intelligent_error_recovery.py</code> - Main recovery logic</li> <li><code>wyn360_cli/tools/browser/error_classification.py</code> - Error analysis system</li> <li><code>tests/test_intelligent_error_recovery.py</code> - Recovery strategy tests</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#technical-architecture","title":"\ud83d\udd27 Technical Architecture","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#enhanced-code-generation-system","title":"Enhanced Code Generation System","text":"<pre><code># Current Approach (Multiple Tool Calls)\n1. analyze_page_dom() -&gt; DOM structure\n2. find_element() -&gt; Element location\n3. click_element() -&gt; Click action\n4. wait_for_change() -&gt; Wait for update\n5. extract_data() -&gt; Get results\n\n# New Approach (Single Code Execution)\nautomation_script = \"\"\"\n# Find and interact with search\nsearch_box = page.locator('input[placeholder*=\"search\"]')\nawait search_box.fill(\"wireless mouse\")\nawait search_box.press(\"Enter\")\n\n# Apply filters and extract results\nawait page.locator('text=\"Under $20\"').click()\nproducts = await page.locator('.product-item').all()\n\nresults = []\nfor product in products:\n    name = await product.locator('.title').inner_text()\n    price = await product.locator('.price').inner_text()\n    results.append({\"name\": name, \"price\": price})\n\"\"\"\n</code></pre>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#secure-python-sandbox-architecture","title":"Secure Python Sandbox Architecture","text":"<pre><code>class SecurePythonSandbox:\n    \"\"\"Execute automation code in restricted Python environment\"\"\"\n\n    def __init__(self):\n        self.safe_globals = {\n            '__builtins__': self._get_safe_builtins(),\n            'playwright': playwright,\n            'asyncio': asyncio,\n            'json': json,\n            're': re,\n            # Only safe, necessary modules\n        }\n\n    async def execute(self, code: str, context: dict) -&gt; dict:\n        \"\"\"Execute automation code safely\"\"\"\n        # Add browser context to safe globals\n        execution_globals = {**self.safe_globals, **context}\n\n        # Execute in separate thread for isolation\n        result = await asyncio.to_thread(\n            self._safe_exec,\n            code,\n            execution_globals\n        )\n\n        return result\n\n    def _safe_exec(self, code: str, globals_dict: dict) -&gt; dict:\n        \"\"\"Execute code with restricted environment\"\"\"\n        local_vars = {}\n        exec(code, globals_dict, local_vars)\n        return local_vars.get('result', {})\n</code></pre>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#intelligent-error-recovery-system","title":"Intelligent Error Recovery System","text":"<pre><code>class IntelligentErrorRecovery:\n    \"\"\"Analyze errors and regenerate improved automation code\"\"\"\n\n    async def analyze_and_recover(self,\n                                 original_code: str,\n                                 error: Exception,\n                                 page_context: dict) -&gt; str:\n        \"\"\"Generate improved code based on error analysis\"\"\"\n\n        error_type = self._classify_error(error)\n\n        if error_type == \"element_not_found\":\n            return await self._regenerate_with_better_selectors(\n                original_code, page_context\n            )\n        elif error_type == \"timeout\":\n            return await self._regenerate_with_waits(original_code)\n        elif error_type == \"page_navigation\":\n            return await self._regenerate_with_navigation_handling(\n                original_code\n            )\n\n        return original_code  # Fallback to original\n</code></pre>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#expected-performance-improvements","title":"\ud83d\udcca Expected Performance Improvements","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#reliability-metrics","title":"Reliability Metrics","text":"Metric Current System Enhanced System Improvement Timeout Errors 25-30% of tasks 8-10% of tasks 60% reduction Success Rate 70-75% 85-90% 20% improvement Retry Attempts 2-3 average 1-2 average 40% reduction Execution Speed Baseline 25-30% faster Batch operations"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#cost-performance","title":"Cost &amp; Performance","text":"Aspect Current Enhanced Benefit LLM API Calls 10-15 per task 7-10 per task 30% reduction Network Overhead High (multiple roundtrips) Low (batch execution) 50% reduction Error Recovery Basic retry Intelligent regeneration 70% better success Security Direct execution Sandboxed execution Isolated environment"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#unit-testing-approach","title":"Unit Testing Approach","text":"<pre><code># Test Structure for Each Phase\ntests/\n\u251c\u2500\u2500 test_enhanced_code_generator.py\n\u2502   \u251c\u2500\u2500 test_code_generation_quality()\n\u2502   \u251c\u2500\u2500 test_batch_operations()\n\u2502   \u251c\u2500\u2500 test_pydantic_ai_integration()\n\u2502   \u2514\u2500\u2500 test_code_optimization()\n\u251c\u2500\u2500 test_secure_python_sandbox.py\n\u2502   \u251c\u2500\u2500 test_secure_execution()\n\u2502   \u251c\u2500\u2500 test_resource_limits()\n\u2502   \u251c\u2500\u2500 test_browser_integration()\n\u2502   \u2514\u2500\u2500 test_error_isolation()\n\u2514\u2500\u2500 test_intelligent_error_recovery.py\n    \u251c\u2500\u2500 test_error_classification()\n    \u251c\u2500\u2500 test_code_regeneration()\n    \u251c\u2500\u2500 test_adaptive_retry()\n    \u2514\u2500\u2500 test_fallback_behavior()\n</code></pre>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#integration-testing","title":"Integration Testing","text":"<ul> <li>End-to-End Automation: Test complete workflows with enhanced system</li> <li>Error Scenario Testing: Simulate various failure conditions</li> <li>Performance Testing: Measure improvements vs current system</li> <li>Compatibility Testing: Ensure existing functionality remains intact</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#progress-tracking","title":"\ud83d\udd04 Progress Tracking","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#phase-1-enhanced-code-generation-complete-100-complete","title":"Phase 1 - Enhanced Code Generation \u2705 COMPLETE (100% Complete)","text":"<ul> <li>[x] 1.1 Enhanced code generation prompts \u2705 Complete with smolagents-inspired patterns</li> <li>[x] 1.2 Batch automation code generator \u2705 Complete with comprehensive automation logic</li> <li>[x] 1.3 Code optimization and validation \u2705 Complete with syntax checking and optimization</li> <li>[x] 1.4 pydantic-ai integration \u2705 Complete with existing framework compatibility</li> <li>[x] 1.5 Unit tests and validation \u2705 Complete with 67 passing tests (37 + 30)</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#phase-2-secure-python-sandbox-complete-100-complete","title":"Phase 2 - Secure Python Sandbox \u2705 COMPLETE (100% Complete)","text":"<ul> <li>[x] 2.1 Secure execution environment design \u2705 Complete with SecurityChecker and AST validation</li> <li>[x] 2.2 Restricted globals implementation \u2705 Complete with safe builtins and controlled imports</li> <li>[x] 2.3 Resource management system \u2705 Complete with ResourceMonitor for timeouts and limits</li> <li>[x] 2.4 Safe execution wrapper \u2705 Complete with SafeExecutionWrapper and async support</li> <li>[x] 2.5 Unit tests and security validation \u2705 Complete with 37 passing tests</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#phase-3-intelligent-error-recovery-complete-100-complete","title":"Phase 3 - Intelligent Error Recovery \u2705 COMPLETE (100% Complete)","text":"<ul> <li>[x] 3.1 Error analysis system \u2705 Complete with ErrorClassifier and pattern matching</li> <li>[x] 3.2 Adaptive code regeneration \u2705 Complete with IntelligentErrorRecovery system</li> <li>[x] 3.3 Intelligent retry strategies \u2705 Complete with strategy selection and learning</li> <li>[x] 3.4 Integration with existing error handling \u2705 Complete with recovery planning</li> <li>[x] 3.5 Unit tests and recovery validation \u2705 Complete with comprehensive test suites</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#project-complete","title":"\ud83c\udf89 PROJECT COMPLETE \ud83c\udf89","text":"<p>All three phases of the smolagents-inspired browser automation enhancement have been successfully implemented:</p> <p>\ud83d\udcc1 Files Created: - <code>wyn360_cli/tools/browser/enhanced_code_generator.py</code> (Phase 1) - <code>wyn360_cli/tools/browser/code_templates.py</code> (Phase 1) - <code>wyn360_cli/tools/browser/secure_python_sandbox.py</code> (Phase 2) - <code>wyn360_cli/tools/browser/safe_execution.py</code> (Phase 2) - <code>wyn360_cli/tools/browser/error_classification.py</code> (Phase 3) - <code>wyn360_cli/tools/browser/intelligent_error_recovery.py</code> (Phase 3)</p> <p>\ud83e\uddea Tests Created: - <code>tests/test_enhanced_code_generator.py</code> (37 tests) - <code>tests/test_code_templates.py</code> (30 tests) - <code>tests/test_secure_python_sandbox.py</code> (37 tests) - <code>tests/test_error_classification.py</code> (33 tests) - <code>tests/test_intelligent_error_recovery.py</code> (comprehensive suite)</p> <p>\ud83d\udcc8 Expected Improvements: - \ud83d\udd50 60% reduction in timeout errors through intelligent code generation - \ud83d\ude80 30% fewer LLM calls via batch operation approach - \ud83d\udd12 Enhanced security through isolated sandbox execution - \ud83e\udde0 Intelligent error recovery with adaptive learning - \u2705 200+ comprehensive unit tests ensuring reliability</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#integration-points","title":"\ud83c\udfaa Integration Points","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#existing-browser-tools-compatibility","title":"Existing Browser Tools Compatibility","text":"<ul> <li>Preserve: All existing pydantic-ai tools continue working</li> <li>Enhance: Add new enhanced execution modes as options</li> <li>Extend: Provide fallback to current system when needed</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#pydantic-ai-framework-integration","title":"pydantic-ai Framework Integration","text":"<ul> <li>Tool Decorators: All enhancements use standard @tool pattern</li> <li>RunContext: Maintain compatibility with existing context management</li> <li>Multi-Model Support: Works with Claude, Gemini, AWS without changes</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#user-experience","title":"User Experience","text":"<ul> <li>CLI Interface: No changes to command-line usage</li> <li>Browser Control: --show-browser flag continues working</li> <li>Configuration: Environment variables remain the same</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#risk-mitigation","title":"\ud83d\udea7 Risk Mitigation","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#technical-risks","title":"Technical Risks","text":"<ul> <li>Code Generation Quality: Extensive testing and validation</li> <li>Sandbox Security: Thorough security review and restricted execution</li> <li>Performance Regression: Benchmarking against current system</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#user-experience-risks","title":"User Experience Risks","text":"<ul> <li>Compatibility Issues: Comprehensive backward compatibility testing</li> <li>Learning Curve: No changes to user interface</li> <li>Debugging Complexity: Enhanced error messages and logging</li> </ul>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#implementation-timeline","title":"\ud83d\udcc5 Implementation Timeline","text":"Phase Milestone Duration Dependencies 1 Enhanced Code Generation 5-7 days pydantic-ai framework 2 Secure Python Sandbox 3-5 days Phase 1 completion 3 Intelligent Error Recovery 4-6 days Phase 2 completion <p>Total Timeline: 12-18 days for complete implementation</p>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#development-notes","title":"\ud83d\udcbb Development Notes","text":""},{"location":"ROADMAP_BROWSER_SMOLAGENT/#code-organization","title":"Code Organization","text":"<pre><code>wyn360_cli/tools/browser/\n\u251c\u2500\u2500 enhanced_code_generator.py     # Phase 1\n\u251c\u2500\u2500 code_templates.py              # Phase 1\n\u251c\u2500\u2500 secure_python_sandbox.py       # Phase 2\n\u251c\u2500\u2500 safe_execution.py              # Phase 2\n\u251c\u2500\u2500 intelligent_error_recovery.py  # Phase 3\n\u2514\u2500\u2500 error_classification.py        # Phase 3\n</code></pre>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#testing-organization","title":"Testing Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 test_enhanced_code_generator.py    # Phase 1 tests\n\u251c\u2500\u2500 test_secure_python_sandbox.py      # Phase 2 tests\n\u2514\u2500\u2500 test_intelligent_error_recovery.py # Phase 3 tests\n</code></pre>"},{"location":"ROADMAP_BROWSER_SMOLAGENT/#integration-strategy","title":"Integration Strategy","text":"<ul> <li>Incremental: Each phase builds on previous work</li> <li>Optional: New features can be enabled/disabled</li> <li>Fallback: Current system always available as backup</li> </ul> <p>Last Updated: November 25, 2025 Document Version: 1.0 Maintained by: WYN360 CLI Development Team Next Review Date: December 1, 2025</p>"},{"location":"ROADMAP_DOCUMENTS/","title":"WYN360 CLI - Document Readers Roadmap","text":"<p>Status: \u2705 Phase 4 Complete - All Core Features Implemented Start Date: January 2025 Target Completion: February 2025</p>"},{"location":"ROADMAP_DOCUMENTS/#overview","title":"\ud83d\udccb Overview","text":"<p>This roadmap outlines the implementation of intelligent document readers for Excel, Word, and PDF files. Unlike simple file reading, these tools implement a chunking + summarization + tagging + retrieval system that allows WYN360 to handle arbitrarily large documents while maintaining intelligent query capabilities.</p>"},{"location":"ROADMAP_DOCUMENTS/#key-innovations","title":"Key Innovations","text":"<ul> <li>\ud83e\udde9 Intelligent Chunking: Documents split into manageable chunks (~1000 tokens)</li> <li>\ud83d\udcdd Auto-Summarization: Each chunk summarized to ~100 tokens using Claude Haiku</li> <li>\ud83c\udff7\ufe0f Tag Generation: 5-8 keywords per chunk for efficient retrieval</li> <li>\ud83d\udd0d Query-Based Retrieval: Match user questions against tags to find relevant sections</li> <li>\ud83d\udcbe Smart Caching: Cache summaries and tags for instant re-access (TTL: 1 hour)</li> <li>\ud83c\udfaf No Breaking Changes: Add-on tools that integrate seamlessly with existing framework</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#design-philosophy","title":"Design Philosophy","text":"<p>Following the <code>fetch_website</code> pattern: - Optional dependencies with graceful fallback - Token-aware processing with configurable limits - Markdown output format for LLM consumption - Full integration with slash commands and token tracking - User-configurable behavior via config.yaml</p>"},{"location":"ROADMAP_DOCUMENTS/#problem-statement","title":"\ud83c\udfaf Problem Statement","text":""},{"location":"ROADMAP_DOCUMENTS/#current-limitations","title":"Current Limitations","text":"<p>Existing <code>read_file</code> tool: - \u2705 Works for plain text files (.txt, .py, .json) - \u274c Cannot handle structured documents (Excel, Word, PDF) - \u274c No support for tables, charts, formulas, images - \u274c Limited by file size (100KB limit) - \u274c No intelligent truncation for large files</p>"},{"location":"ROADMAP_DOCUMENTS/#real-world-scenarios","title":"Real-World Scenarios","text":"<p>Scenario 1: Unstructured Excel Files - User has expense tracking spreadsheet with multiple sheets - Tables don't start at A1 (notes, calculations scattered around) - Each sheet has different purpose and structure - User wants: \"Summarize my Q2 expenses\" or \"What were April gas costs?\"</p> <p>Scenario 2: Research Papers (Word) - 15-page research paper with sections, tables, equations, citations - User wants: \"Summarize the methodology\" or \"What are the conclusions?\" - Need to preserve document structure (headings, sections) - Tables and formulas must be extracted accurately</p> <p>Scenario 3: Large PDFs - 120-page textbook or technical manual - User wants: \"Explain dropout from Chapter 2\" or \"Summarize conclusions\" - Cannot load entire document into context (would be 50K+ tokens) - Need intelligent retrieval of relevant sections</p>"},{"location":"ROADMAP_DOCUMENTS/#smart-truncation-algorithm","title":"\ud83e\udde0 Smart Truncation Algorithm","text":""},{"location":"ROADMAP_DOCUMENTS/#the-problem","title":"The Problem","text":"<p>Traditional truncation (head/tail) doesn't work for documents: - User asks: \"What's in Chapter 5?\" \u2192 If we only keep first/last pages, Chapter 5 is lost - Excel with 20 sheets \u2192 Simple truncation would lose most sheets</p>"},{"location":"ROADMAP_DOCUMENTS/#the-solution-chunking-summarization-retrieval","title":"The Solution: Chunking + Summarization + Retrieval","text":"<pre><code>Document (10,000 tokens)\n    \u2193\nSplit into chunks (1,000 tokens each) = 10 chunks\n    \u2193\nFor each chunk:\n    - Summarize using Claude Haiku \u2192 100 tokens\n    - Generate tags (keywords) \u2192 20 tokens\n    - Store in cache\n    \u2193\nTotal cached: 10 \u00d7 (100 + 20) = 1,200 tokens\n    \u2193\nUser asks question: \"What were April expenses?\"\n    \u2193\nMatch question against tags \u2192 Find chunks with \"April\" tag\n    \u2193\nRetrieve relevant chunk summaries\n    \u2193\nReturn: Summary + original chunk if needed\n</code></pre>"},{"location":"ROADMAP_DOCUMENTS/#example","title":"Example","text":"<p>Excel File: expenses.xlsx (8,450 tokens)</p> <pre><code>Sheet: Q1_Expenses (2,100 tokens)\n\u2192 Chunk 1 (rows 1-30): Summary: \"January expenses $2,100...\"\n                       Tags: [expenses, January, Q1, food, gas]\n\u2192 Chunk 2 (rows 31-60): Summary: \"February expenses $1,800...\"\n                        Tags: [expenses, February, Q1, utilities]\n\u2192 Chunk 3 (rows 61-90): Summary: \"March expenses $1,340...\"\n                        Tags: [expenses, March, Q1, entertainment]\n\nSheet: Q2_Expenses (3,200 tokens)\n\u2192 Chunk 4 (rows 1-35): Summary: \"April expenses $2,400...\"\n                       Tags: [expenses, April, Q2, gas, spike]\n\u2192 ...\n\nUser Query: \"What were April expenses?\"\n\u2192 Tag matching: \"April\" \u2192 Chunk 4\n\u2192 Return: \"April expenses totaled $2,400, with gas showing a spike...\"\n</code></pre>"},{"location":"ROADMAP_DOCUMENTS/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":""},{"location":"ROADMAP_DOCUMENTS/#module-structure","title":"Module Structure","text":"<pre><code>wyn360_cli/\n\u251c\u2500\u2500 document_readers.py          # NEW MODULE\n\u2502   \u251c\u2500\u2500 DocumentChunker          # Chunk documents intelligently\n\u2502   \u251c\u2500\u2500 ChunkSummarizer          # Summarize chunks using Claude\n\u2502   \u251c\u2500\u2500 ChunkCache               # Cache management\n\u2502   \u251c\u2500\u2500 ChunkRetriever           # Query matching &amp; retrieval\n\u2502   \u251c\u2500\u2500 ExcelReader              # Excel-specific reader\n\u2502   \u251c\u2500\u2500 WordReader               # Word-specific reader\n\u2502   \u2514\u2500\u2500 PDFReader                # PDF-specific reader\n\u251c\u2500\u2500 agent.py                     # Register new tools\n\u251c\u2500\u2500 cli.py                       # Add new slash commands\n\u2514\u2500\u2500 config.yaml                  # Add document_reader config\n</code></pre>"},{"location":"ROADMAP_DOCUMENTS/#cache-structure","title":"Cache Structure","text":"<pre><code>~/.wyn360/cache/documents/\n\u251c\u2500\u2500 {file_hash_1}/\n\u2502   \u251c\u2500\u2500 metadata.json           # File info, chunk count, timestamps\n\u2502   \u251c\u2500\u2500 chunks_index.json       # Chunk summaries, tags, positions\n\u2502   \u251c\u2500\u2500 chunk_001.txt           # Original chunk content (optional)\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 {file_hash_2}/\n\u2502   \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"ROADMAP_DOCUMENTS/#data-flow","title":"Data Flow","text":"<pre><code>graph TB\n    User[User: Read expenses.xlsx]\n    Agent[WYN360Agent]\n    Tool[read_excel tool]\n    Cache[ChunkCache]\n    Reader[ExcelReader]\n    Chunker[DocumentChunker]\n    Summarizer[ChunkSummarizer]\n    Claude[Claude Haiku API]\n    Retriever[ChunkRetriever]\n\n    User --&gt; Agent\n    Agent --&gt; Tool\n    Tool --&gt; Cache\n\n    Cache --&gt;|Cache Miss| Reader\n    Reader --&gt; Chunker\n    Chunker --&gt; Summarizer\n    Summarizer --&gt; Claude\n    Claude --&gt; Summarizer\n    Summarizer --&gt; Cache\n    Cache --&gt; Retriever\n\n    Cache --&gt;|Cache Hit| Retriever\n    Retriever --&gt; Agent\n    Agent --&gt; User\n\n    style Cache fill:#e8f5e9\n    style Summarizer fill:#fff9c4\n    style Claude fill:#fff3e0</code></pre>"},{"location":"ROADMAP_DOCUMENTS/#implementation-phases","title":"\ud83d\udcca Implementation Phases","text":""},{"location":"ROADMAP_DOCUMENTS/#phase-1-core-infrastructure-v0326","title":"Phase 1: Core Infrastructure (v0.3.26)","text":"<p>Goal: Build the foundation for all document readers</p>"},{"location":"ROADMAP_DOCUMENTS/#tasks","title":"Tasks:","text":"<ul> <li>[x] Create <code>document_readers.py</code> module \u2705 COMPLETED</li> <li>[x] Implement <code>DocumentChunker</code> class \u2705 COMPLETED</li> <li>[x] <code>chunk_by_tokens()</code> - Split text by token count \u2705</li> <li>[x] <code>chunk_by_structure()</code> - Split by headings/sections \u2705</li> <li>[x] <code>smart_chunk_excel()</code> - Split by sheets + row ranges \u2705</li> <li>[x] Token counting utilities \u2705</li> <li>[x] Implement <code>ChunkSummarizer</code> class \u2705 COMPLETED</li> <li>[x] <code>summarize_chunk()</code> - Call Claude Haiku for summarization \u2705</li> <li>[x] <code>generate_tags()</code> - Extract keywords from chunk \u2705</li> <li>[x] Prompt engineering for good summaries \u2705</li> <li>[x] Token tracking for summarization costs \u2705</li> <li>[x] Implement <code>ChunkCache</code> class \u2705 COMPLETED</li> <li>[x] Cache directory management (<code>~/.wyn360/cache/documents/</code>) \u2705</li> <li>[x] <code>save_chunks()</code> - Write chunks_index.json \u2705</li> <li>[x] <code>load_chunks()</code> - Read cached chunks \u2705</li> <li>[x] <code>get_stats()</code> - Retrieve cache statistics \u2705</li> <li>[x] <code>clear_cache()</code> - Remove old/specific caches \u2705</li> <li>[x] TTL-based expiration (1 hour default) \u2705</li> <li>[x] MD5 file hashing for cache keys \u2705</li> <li>[x] Implement <code>ChunkRetriever</code> class \u2705 COMPLETED</li> <li>[x] <code>match_query()</code> - Simple keyword matching \u2705</li> <li>[x] <code>get_relevant_chunks()</code> - Return top-K chunks \u2705</li> <li>[x] Score chunks by tag overlap \u2705</li> <li>[x] Add new slash commands in <code>cli.py</code>: \u2705 COMPLETED</li> <li>[x] <code>/set_doc_tokens &lt;excel|word|pdf&gt; &lt;tokens&gt;</code> - Set token limits \u2705</li> <li>[x] <code>/clear_doc_cache [file_path]</code> - Clear cache \u2705</li> <li>[x] <code>/doc_cache_stats</code> - Show cache statistics \u2705</li> <li>[x] <code>/set_image_mode &lt;skip|describe|vision&gt;</code> - Image handling \u2705</li> <li>[x] <code>/set_pdf_engine &lt;pymupdf|pdfplumber&gt;</code> - PDF engine selection \u2705</li> <li>[x] Update <code>/tokens</code> command to include document processing costs \u2705 COMPLETED</li> <li>[x] Add configuration section to <code>config.yaml</code>: \u2705 COMPLETED   <pre><code>document_reader:\n  token_limits: {excel: 10000, word: 15000, pdf: 20000}\n  chunking: {enabled: true, chunk_size: 1000, summary_size: 100}\n  cache: {enabled: true, ttl: 3600, max_size_mb: 500}\n</code></pre></li> <li>[x] Unit tests: \u2705 ALL 74 TESTS PASSING</li> <li>[x] <code>test_document_chunker.py</code> - Chunking logic (22 tests) \u2705</li> <li>[x] <code>test_chunk_summarizer.py</code> - Summarization (17 tests, mocked) \u2705</li> <li>[x] <code>test_chunk_cache.py</code> - Cache operations (19 tests) \u2705</li> <li>[x] <code>test_chunk_retriever.py</code> - Query matching (17 tests) \u2705</li> </ul> <p>Success Criteria: - \u2705 Chunking system works with text input - \u2705 Summarization calls Claude Haiku and returns ~100 token summaries - \u2705 Cache saves/loads correctly with TTL enforcement - \u2705 Retriever matches queries to relevant chunks - \u2705 All tests passing - \u2705 No breaking changes to existing tools</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-2-excel-reader-v0327","title":"Phase 2: Excel Reader (v0.3.27)","text":"<p>Goal: Enable intelligent reading of unstructured Excel files</p>"},{"location":"ROADMAP_DOCUMENTS/#tasks_1","title":"Tasks:","text":"<ul> <li>[x] Install optional dependency: <code>openpyxl</code> \u2705 OPTIONAL (graceful fallback)</li> <li>[x] Implement <code>ExcelReader</code> class \u2705 COMPLETED</li> <li>[x] Open .xlsx/.xls files \u2705</li> <li>[x] List all sheets \u2705</li> <li>[x] Detect data regions per sheet (not assuming A1 start) \u2705</li> <li>[x] Handle merged cells \u2705</li> <li>[x] Show evaluated formula values (not formulas) \u2705</li> <li>[x] Convert to markdown tables \u2705</li> <li>[x] Integrate with chunking system: \u2705 COMPLETED</li> <li>[x] Chunk by sheets first \u2705</li> <li>[x] If sheet too large, chunk by row ranges \u2705</li> <li>[x] Each chunk = one sheet or section of sheet \u2705</li> <li>[x] Register <code>read_excel</code> tool in <code>agent.py</code>: \u2705 COMPLETED   <pre><code>@agent.tool\nasync def read_excel(\n    file_path: str,\n    max_tokens: int = 10000,\n    include_sheets: Optional[List[str]] = None,\n    use_chunking: bool = True,\n    regenerate_cache: bool = False,\n    query: Optional[str] = None\n) -&gt; str:\n</code></pre></li> <li>[x] Output format: \u2705 COMPLETED</li> <li>[x] Document header (file, sheets, tokens, chunks) \u2705</li> <li>[x] Per-sheet summaries \u2705</li> <li>[x] Tags for each chunk \u2705</li> <li>[x] Query retrieval support \u2705</li> <li>[x] Error handling: \u2705 COMPLETED</li> <li>[x] File not found \u2705</li> <li>[x] openpyxl not installed \u2192 clear error message \u2705</li> <li>[x] Corrupted Excel files \u2705</li> <li>[ ] Update documentation:</li> <li>[ ] README.md - Add Excel reading example</li> <li>[ ] USE_CASES.md - Add Excel use cases</li> <li>[ ] SYSTEM.md - Document Excel reader architecture</li> <li>[x] Unit tests: \u2705 ALL 14 TESTS PASSING</li> <li>[x] <code>test_excel_reader.py</code> - Excel reading logic \u2705</li> <li>[x] Test multi-sheet files \u2705</li> <li>[x] Test unstructured data (tables not at A1) \u2705</li> <li>[x] Test caching and retrieval \u2705</li> <li>[x] Test with/without openpyxl \u2705</li> </ul> <p>Success Criteria: - \u2705 Can read multi-sheet Excel files - \u2705 Detects data regions regardless of position - \u2705 Shows evaluated formulas (what user sees) - \u2705 Chunking works correctly for large spreadsheets - \u2705 Cache hit/miss works properly - \u2705 Query retrieval finds relevant sheets - \u2705 All tests passing</p> <p>Example Usage: <pre><code>You: Read expenses.xlsx\n\nWYN360:\n\ud83d\udcca Excel File: expenses.xlsx\nSheets: 3 | Chunks: 9 | Cache: \u2713 Generated\n\nSummary:\n- Q1_Expenses: $5,240 total, Jan highest\n- Q2_Expenses: $6,180 total, Apr peak\n- Summary: YTD $11,420, +8% over budget\n\nYou: What were the April expenses?\n\nWYN360: [Retrieves Chunk 5]\nApril expenses totaled $2,400 with breakdown:\n- Food: $680\n- Gas: $590 (15% increase from March)\n- Utilities: $520\n- Entertainment: $320\n- Misc: $290\n</code></pre></p>"},{"location":"ROADMAP_DOCUMENTS/#phase-3-word-reader-v0328","title":"Phase 3: Word Reader (v0.3.28)","text":"<p>Goal: Enable reading of structured Word documents with tables, images, and sections</p>"},{"location":"ROADMAP_DOCUMENTS/#tasks_2","title":"Tasks:","text":"<ul> <li>[x] Install optional dependency: <code>python-docx</code> \u2705 OPTIONAL (graceful fallback)</li> <li>[x] Implement <code>WordReader</code> class \u2705 COMPLETED</li> <li>[x] Open .docx files \u2705</li> <li>[x] Extract document structure: \u2705<ul> <li>[x] Headings (H1, H2, H3) \u2192 <code>#</code>, <code>##</code>, <code>###</code> \u2705</li> <li>[x] Paragraphs \u2192 plain text \u2705</li> <li>[x] Tables \u2192 markdown tables \u2705</li> <li>[x] Lists \u2192 markdown lists \u2705</li> </ul> </li> <li>[x] Handle images: \u2705<ul> <li>[x] Default: \"describe\" mode (extract alt text/captions) \u2705</li> <li>[x] Optional: \"skip\" mode (ignore images) \u2705</li> <li>[x] Optional: \"vision\" mode (use Claude vision API) \u2705</li> </ul> </li> <li>[x] Preserve document hierarchy \u2705</li> <li>[x] Structure-aware chunking: \u2705 COMPLETED</li> <li>[x] Chunk by major sections (H1/H2 boundaries) \u2705</li> <li>[x] Keep tables within chunks (don't split) \u2705</li> <li>[x] Target ~1000 tokens per chunk \u2705</li> <li>[x] Preserve section context in chunk metadata \u2705</li> <li>[x] Register <code>read_word</code> tool in <code>agent.py</code>: \u2705 COMPLETED   <pre><code>@agent.tool\nasync def read_word(\n    file_path: str,\n    max_tokens: int = 15000,\n    use_chunking: bool = True,\n    image_handling: str = \"describe\",\n    regenerate_cache: bool = False,\n    query: Optional[str] = None\n) -&gt; str:\n</code></pre></li> <li>[x] Add <code>/set_image_mode &lt;skip|describe|vision&gt;</code> slash command \u2705 ALREADY IN PHASE 1</li> <li>[x] Image handling implementation: \u2705 COMPLETED</li> <li>[x] \"skip\": Ignore images entirely \u2705</li> <li>[x] \"describe\": Extract alt text, captions, nearby text \u2705</li> <li>[x] \"vision\": Call Claude vision API (warn about costs) \u2705</li> <li>[x] Output format: \u2705 COMPLETED</li> <li>[x] Document header (pages, sections, tokens) \u2705</li> <li>[x] Section-by-section summaries \u2705</li> <li>[x] Tables preserved in markdown \u2705</li> <li>[x] Image handling indicators \u2705</li> <li>[x] Error handling: \u2705 COMPLETED</li> <li>[x] File not found \u2705</li> <li>[x] python-docx not installed \u2705</li> <li>[x] Corrupted Word files \u2705</li> <li>[x] Vision API failures \u2705</li> <li>[ ] Update documentation</li> <li>[x] Unit tests: \u2705 ALL 14 TESTS PASSING</li> <li>[x] <code>test_word_reader.py</code> \u2705</li> <li>[x] Test structured documents \u2705</li> <li>[x] Test table extraction \u2705</li> <li>[x] Test image handling modes \u2705</li> <li>[x] Test chunking by sections \u2705</li> </ul> <p>Success Criteria: - \u2705 Preserves document structure in markdown - \u2705 Tables converted accurately - \u2705 Image handling modes work correctly - \u2705 Structure-aware chunking keeps sections together - \u2705 Query retrieval finds relevant sections - \u2705 All tests passing</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-4-pdf-reader-v0329","title":"Phase 4: PDF Reader (v0.3.29)","text":"<p>Goal: Enable reading of PDFs with page-aware chunking and table detection</p>"},{"location":"ROADMAP_DOCUMENTS/#tasks_3","title":"Tasks:","text":"<ul> <li>[x] Install optional dependencies: \u2705 OPTIONAL (graceful fallback)</li> <li>[x] <code>pymupdf</code> (PyMuPDF) - default, fast, general-purpose \u2705</li> <li>[x] <code>pdfplumber</code> - optional, better for complex tables \u2705</li> <li>[x] Implement <code>PDFReader</code> class \u2705 COMPLETED</li> <li>[x] Open .pdf files \u2705</li> <li>[x] Extract text page by page \u2705</li> <li>[x] Detect tables (preserve structure) \u2705</li> <li>[x] Handle multi-column layouts \u2705</li> <li>[x] Detect sections via font sizes/styles \u2705</li> <li>[x] Extract table of contents if available \u2705</li> <li>[x] Page-aware chunking: \u2705 COMPLETED</li> <li>[x] Chunk by page ranges (3-5 pages per chunk) \u2705</li> <li>[x] Preserve page boundaries \u2705</li> <li>[x] Don't split tables across chunks \u2705</li> <li>[x] Target ~1000 tokens per chunk \u2705</li> <li>[x] Register <code>read_pdf</code> tool in <code>agent.py</code>: \u2705 COMPLETED   <pre><code>@agent.tool\nasync def read_pdf(\n    file_path: str,\n    max_tokens: int = 20000,\n    page_range: Optional[Tuple[int, int]] = None,\n    use_chunking: bool = True,\n    pdf_engine: str = \"pymupdf\",\n    regenerate_cache: bool = False,\n    query: Optional[str] = None\n) -&gt; str:\n</code></pre></li> <li>[x] Add <code>/set_pdf_engine &lt;pymupdf|pdfplumber&gt;</code> slash command \u2705 ALREADY IN PHASE 1</li> <li>[x] PDF engine switching: \u2705 COMPLETED</li> <li>[x] Default: pymupdf (fast, general) \u2705</li> <li>[x] Optional: pdfplumber (complex tables) \u2705</li> <li>[x] Auto-detect table complexity? \u2705</li> <li>[x] Page range support: \u2705 COMPLETED</li> <li>[x] <code>page_range=(10, 25)</code> \u2192 Extract only pages 10-25 \u2705</li> <li>[x] Useful for large documents \u2705</li> <li>[x] Output format: \u2705 COMPLETED</li> <li>[x] Document header (pages, tokens, chunks) \u2705</li> <li>[x] Table of contents summary \u2705</li> <li>[x] Page-by-page or section-by-section summaries \u2705</li> <li>[x] Clear page markers \u2705</li> <li>[x] Error handling: \u2705 COMPLETED</li> <li>[x] File not found \u2705</li> <li>[x] Libraries not installed \u2705</li> <li>[x] Corrupted/password-protected PDFs \u2705</li> <li>[x] Scanned PDFs (no text layer) \u2705</li> <li>[ ] Update documentation</li> <li>[x] Unit tests: \u2705 ALL 18 TESTS PASSING</li> <li>[x] <code>test_pdf_reader.py</code> \u2705</li> <li>[x] Test multi-page PDFs \u2705</li> <li>[x] Test table extraction \u2705</li> <li>[x] Test page range support \u2705</li> <li>[x] Test both PDF engines \u2705</li> </ul> <p>Success Criteria: - \u2705 Handles large PDFs (100+ pages) - \u2705 Tables extracted accurately - \u2705 Page-aware chunking works correctly - \u2705 Page range filtering works - \u2705 Both PDF engines supported - \u2705 Query retrieval finds relevant pages - \u2705 All tests passing</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-5-enhancements-v0330","title":"Phase 5: Enhancements (v0.3.30+)","text":"<p>Goal: Advanced features and optimizations</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-51-vision-mode-for-images-completed-v0330","title":"Phase 5.1: Vision Mode for Images \u2705 COMPLETED (v0.3.30)","text":"<ul> <li>\u2705 Vision Mode Implementation</li> <li>\u2705 ImageProcessor class with Claude Vision API integration</li> <li>\u2705 WordReader image extraction and processing</li> <li>\u2705 PDFReader image extraction (pymupdf &amp; pdfplumber)</li> <li>\u2705 Agent integration with vision token tracking</li> <li>\u2705 Three processing modes: skip, describe, vision</li> <li>\u2705 Cost transparency and separate tracking</li> <li>\u2705 Batch image processing for efficiency</li> <li>\u2705 23 comprehensive tests, all 359 tests passing</li> <li>\u2705 Documentation: ROADMAP_VISION.md, README.md, COST.md</li> </ul> <p>See: ROADMAP_VISION.md for detailed implementation</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-52-semantic-matching-completed-v0331-v0332","title":"Phase 5.2: Semantic Matching \u2705 COMPLETED (v0.3.31-v0.3.32)","text":"<ul> <li>\u2705 Embedding-based Retrieval System</li> <li>\u2705 Replace keyword matching with semantic embeddings</li> <li>\u2705 Integrate sentence-transformers library (all-MiniLM-L6-v2)</li> <li>\u2705 Compute embeddings for chunk summaries and tags</li> <li>\u2705 Cosine similarity for query-chunk matching</li> <li>\u2705 Fallback to keyword matching if embeddings fail</li> <li>\u2705 Significantly better retrieval accuracy</li> <li>\u2705 Embedding cache with chunk cache</li> <li>\u2705 Performance benchmarking vs keyword matching</li> </ul> <p>Status: \u2705 COMPLETE | Tests: test_embedding_model.py, test_excel_embedding_integration.py (passing)</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-53-ocr-support-for-scanned-pdfs-completed-v0333-v0334","title":"Phase 5.3: OCR Support for Scanned PDFs \u2705 COMPLETED (v0.3.33-v0.3.34)","text":"<ul> <li>\u2705 OCR Integration</li> <li>\u2705 Integrate Tesseract OCR (pytesseract)</li> <li>\u2705 Detect scanned vs text-based PDFs (is_scanned_page)</li> <li>\u2705 Extract text from images in PDFs</li> <li>\u2705 Warning about OCR accuracy and costs</li> <li>\u2705 Combine OCR text with Vision API for images</li> <li>\u2705 Language detection and multi-language support (eng, spa, fra, deu, etc.)</li> <li>\u2705 Quality assessment of OCR results (confidence scores)</li> </ul> <p>Status: \u2705 COMPLETE | Tests: test_ocr_processor.py, test_pdf_ocr_integration.py (passing)</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-54-excel-enhancements-partially-completed-v0335","title":"Phase 5.4: Excel Enhancements \ud83d\udfe1 PARTIALLY COMPLETED (v0.3.35)","text":"<ul> <li>\ud83d\udfe1 Advanced Excel Features (3/7 complete)</li> <li>\u2705 Chart/graph extraction and metadata (_extract_charts)</li> <li>[ ] Pivot table detection and summarization</li> <li>\u2705 Formula dependency analysis (_track_formulas)</li> <li>[ ] Cross-sheet reference tracking</li> <li>\u2705 Named ranges support (_extract_named_ranges)</li> <li>[ ] Data validation rules extraction</li> <li>[ ] Conditional formatting descriptions</li> </ul> <p>Status: \ud83d\udfe1 PARTIAL (60% complete) | Tests: test_excel_enhancements.py (passing for implemented features) Remaining: Pivot tables, cross-sheet references, data validation, conditional formatting</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-55-multi-document-queries-completed-v0336-v0337","title":"Phase 5.5: Multi-Document Queries \u2705 COMPLETED (v0.3.36-v0.3.37)","text":"<ul> <li>\u2705 Cross-Document Intelligence</li> <li>\u2705 Query across multiple cached documents (search_all_documents)</li> <li>\u2705 \"Compare expenses.xlsx and budget.xlsx\" (compare_documents)</li> <li>\u2705 Cross-reference information between documents (find_cross_references)</li> <li>\u2705 Unified search across document cache</li> <li>\u2705 Document relationship detection</li> <li>\u2705 Aggregated summaries across documents</li> <li>\u2705 Smart document selection based on query</li> </ul> <p>Status: \u2705 COMPLETE | Tests: test_multi_document_retriever.py (passing)</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-56-performance-optimizations-completed-v0336","title":"Phase 5.6: Performance Optimizations \u2705 COMPLETED (v0.3.36)","text":"<ul> <li>\u2705 Phase 5.6.1: Parallel Chunk Summarization</li> <li>\u2705 Implemented <code>summarize_chunks_parallel()</code> with asyncio.gather()</li> <li>\u2705 Batch processing (batch_size=10) to avoid overwhelming API</li> <li>\u2705 Updated Excel, Word, PDF readers for parallel processing</li> <li>\u2705 Expected impact: 3-5x faster document processing</li> <li>\u2705 6 comprehensive tests, all passing</li> <li>\u2705 Phase 5.6.2: Cache Compression</li> <li>\u2705 Implemented gzip compression for cache files (.json.gz)</li> <li>\u2705 Backward compatibility with uncompressed cache files</li> <li>\u2705 Automatic migration from old to new format</li> <li>\u2705 Expected impact: 50-70% storage reduction</li> <li>\u2705 9 comprehensive tests, all passing</li> <li>\u2705 Phase 5.6.3: LRU Cache Eviction</li> <li>\u2705 Implemented least-recently-used eviction strategy</li> <li>\u2705 Tracks <code>last_accessed</code> timestamp on every cache load</li> <li>\u2705 Evicts least recently used files when cache is full</li> <li>\u2705 Expected impact: Keep hot documents cached longer</li> <li>\u2705 7 comprehensive tests, all passing</li> <li>\ud83d\udccb Remaining Items (Future Work)</li> <li>[ ] Streaming for large files (progressive processing)</li> <li>[ ] Incremental caching (only process changed chunks)</li> <li>[ ] Background cache warming (pre-compute common queries)</li> <li>[ ] Performance monitoring and metrics dashboard</li> </ul> <p>Files Modified: - <code>wyn360_cli/document_readers.py</code>: +183 lines - <code>wyn360_cli/agent.py</code>: +139 lines (3 readers updated) - <code>tests/test_parallel_summarization.py</code>: NEW, 192 lines, 6 tests - <code>tests/test_cache_compression.py</code>: NEW, 472 lines, 9 tests - <code>tests/test_lru_eviction.py</code>: NEW, 364 lines, 7 tests</p> <p>Test Results: 22 new tests, all passing \u2705</p> <p>See: Commit 29135c8 - \"feat: Implement Phase 5.6 Performance Optimizations (v0.3.36)\"</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-57-advanced-chunking-strategies-low-priority-planned","title":"Phase 5.7: Advanced Chunking Strategies (Low Priority) \ud83d\udccb PLANNED","text":"<ul> <li>[ ] Smart Chunking</li> <li>[ ] Adaptive chunk sizes based on content density</li> <li>[ ] Overlap between chunks for context preservation</li> <li>[ ] Hierarchical chunking (sections \u2192 paragraphs \u2192 sentences)</li> <li>[ ] Content-aware boundaries (don't split tables, code blocks)</li> <li>[ ] Configurable chunking strategies per document type</li> <li>[ ] Chunk quality scoring</li> </ul> <p>Estimated Effort: 2 weeks | Version: v0.3.38</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-58-tool-discoverability-improvements-completed-v0338","title":"Phase 5.8: Tool Discoverability Improvements \u2705 COMPLETED (v0.3.38)","text":"<p>Problem: Agent was writing Python scripts to analyze documents instead of using built-in document reading tools (<code>read_excel</code>, <code>read_word</code>, <code>read_pdf</code>).</p> <p>Root Cause Analysis: - \u2705 Tools were properly registered in agent.py - \u2705 Tools had detailed docstrings with features and examples - \u274c System prompt had NO instructions about when to use document tools - \u274c System prompt encouraged \"write code to analyze\" for analysis tasks - \u274c Tool docstrings lacked explicit \"Use this when:\" sections at the top</p> <p>Solution Implemented:</p> <ul> <li>\u2705 Phase 5.8.1: System Prompt Enhancement</li> <li>\u2705 Added \"Document Reading (Phase 13)\" section to system prompt</li> <li>\u2705 Explicit instructions to use read_pdf/read_excel/read_word for document queries</li> <li>\u2705 Clear examples: \"Read report.pdf\" \u2192 read_pdf(\"report.pdf\")</li> <li>\u2705 Guidance on when to write scripts vs. when to use tools</li> <li> <p>\u2705 Prevents agent from defaulting to Python scripts for simple document reading</p> </li> <li> <p>\u2705 Phase 5.8.2: Tool Docstring Improvements</p> </li> <li>\u2705 Added \"Use this tool when:\" section to read_excel() docstring (agent.py:2004)</li> <li>\u2705 Added \"Use this tool when:\" section to read_word() docstring (agent.py:2273)</li> <li>\u2705 Added \"Use this tool when:\" section to read_pdf() docstring (agent.py:2562)</li> <li>\u2705 Each docstring now starts with bold usage guidance and 5-6 concrete examples</li> <li>\u2705 Helps LLM quickly understand tool purpose without reading entire docstring</li> </ul> <p>Files Modified: - <code>wyn360_cli/agent.py</code>: System prompt +28 lines (lines 247-274) - <code>wyn360_cli/agent.py</code>: read_excel docstring +8 lines (lines 2005-2012) - <code>wyn360_cli/agent.py</code>: read_word docstring +8 lines (lines 2274-2281) - <code>wyn360_cli/agent.py</code>: read_pdf docstring +9 lines (lines 2563-2571)</p> <p>Expected Impact: - \u2705 Agent now correctly uses document tools for \"read PDF\" or \"search Excel\" requests - \u2705 Reduced token usage (tools are more efficient than generating/running scripts) - \u2705 Better user experience (instant results from cached documents) - \u2705 Fewer unnecessary file writes (no more temp analysis scripts)</p> <p>Example - Before vs After:</p> <p>Before: <pre><code>User: \"Read report.pdf and find the budget section\"\nAgent: *Writes analyze_pdf.py script with PyMuPDF code*\nAgent: *Executes script to extract text*\n</code></pre></p> <p>After: <pre><code>User: \"Read report.pdf and find the budget section\"\nAgent: read_pdf(\"report.pdf\", query=\"budget\")\nAgent: *Returns cached summary with relevant section*\n</code></pre></p> <p>Version: v0.3.38 | Date: January 2025</p>"},{"location":"ROADMAP_DOCUMENTS/#phase-59-context-retention-fix-critical-bug-fix-completed-v0339","title":"Phase 5.9: Context Retention Fix \ud83d\udd25 CRITICAL BUG FIX \u2705 COMPLETED (v0.3.39)","text":"<p>Problem: Agent was unable to answer follow-up questions about document content even though it had just read the document.</p> <p>User Report: <pre><code>User: \"Can you read this excel file: /content/Premium weekly chore schedule1.xlsm\"\nWYN360: [Successfully reads and summarizes the Excel file]\n\nUser: \"Has John taken out his trash?\"\nWYN360: \"I don't have access to information about John...\"\n</code></pre></p> <p>Root Cause Analysis: - \u2705 Conversation history was being maintained in <code>self.conversation_history</code> - \u274c History was NEVER passed to <code>agent.run()</code> - each message was treated as fresh conversation - \u274c Tool responses (Excel content, PDF summaries, etc.) were lost after first turn - \u274c Agent had no memory of previous interactions</p> <p>Code Investigation: <pre><code># BEFORE (agent.py:2915, 2977):\nresult = await self.agent.run(user_message)  # \u274c No message_history!\n\n# After each run:\nself.conversation_history.append({...})  # \u274c Never used!\n</code></pre></p> <p>Solution Implemented:</p> <ul> <li>\u2705 Phase 5.9.1: Pass Message History to Agent</li> <li>Updated <code>chat()</code> method (agent.py:2910-2913)</li> <li>Updated <code>chat_stream()</code> method (agent.py:2968-2971)</li> <li>Now passes <code>message_history</code> parameter to <code>agent.run()</code></li> <li> <p>Uses pydantic-ai's built-in message history system</p> </li> <li> <p>\u2705 Phase 5.9.2: Store Pydantic-AI Messages</p> </li> <li>Changed <code>conversation_history</code> to store pydantic-ai ModelMessage objects</li> <li>Updated after each run with <code>result.all_messages()</code></li> <li>Includes user messages, tool calls, tool responses, and assistant responses</li> <li> <p>Full conversation context preserved</p> </li> <li> <p>\u2705 Phase 5.9.3: Fix Session Serialization</p> </li> <li>Added import of <code>ModelMessagesTypeAdapter</code> from pydantic-ai</li> <li>Updated <code>save_session()</code> to serialize messages with <code>to_jsonable_python()</code></li> <li>Updated <code>load_session()</code> to deserialize with <code>ModelMessagesTypeAdapter.validate_python()</code></li> <li>Session persistence now works correctly</li> </ul> <p>Files Modified: - <code>wyn360_cli/agent.py</code>:   - Import: Added <code>ModelMessagesTypeAdapter</code> (line 9)   - <code>__init__</code>: Updated conversation_history type hint (line 90)   - <code>chat()</code>: Pass message_history, update with all_messages() (lines 2910-2922)   - <code>chat_stream()</code>: Pass message_history, update with all_messages() (lines 2968-2986)   - <code>get_history()</code>: Updated return type and docstring (lines 3054-3061)   - <code>save_session()</code>: Serialize messages properly (lines 3073-3074)   - <code>load_session()</code>: Deserialize messages properly (lines 3123-3128)   - <code>_track_tokens()</code>: Skip history token estimation (lines 3365-3369)</p> <p>Expected Impact: - \u2705 CRITICAL: Agent now remembers document content across turns - \u2705 CRITICAL: Follow-up questions about Excel/Word/PDF content now work - \u2705 Tool responses (file reads, web searches, etc.) are retained - \u2705 Multi-turn conversations maintain full context - \u2705 Session save/load preserves conversation history correctly</p> <p>Example - Before vs After:</p> <p>Before (BROKEN): <pre><code>User: \"Read report.pdf\"\nAgent: [Reads PDF, summarizes 10 pages]\n\nUser: \"What did it say about the budget?\"\nAgent: \"I don't have access to that information\"  \u274c\n</code></pre></p> <p>After (FIXED): <pre><code>User: \"Read report.pdf\"\nAgent: [Reads PDF, summarizes 10 pages]\n\nUser: \"What did it say about the budget?\"\nAgent: \"Based on the report I just read, the budget section on page 5 mentions...\" \u2705\n</code></pre></p> <p>Impact on All Features: This fix affects ALL agent capabilities, not just documents: - \u2705 Document reading (Excel, Word, PDF) - can now answer follow-ups - \u2705 Web searches - can reference previous search results - \u2705 File operations - remembers what files were created/modified - \u2705 Code generation - can iterate on previously written code - \u2705 GitHub operations - maintains context across multiple git commands</p> <p>Version: v0.3.39 | Date: January 2025</p>"},{"location":"ROADMAP_DOCUMENTS/#technical-specifications","title":"\ud83d\udd27 Technical Specifications","text":""},{"location":"ROADMAP_DOCUMENTS/#token-limits-configurable","title":"Token Limits (Configurable)","text":"Document Type Default Max Tokens Rationale Excel 10,000 Dense tables, multiple sheets Word 15,000 Typical document length PDF 20,000 Longer documents, books"},{"location":"ROADMAP_DOCUMENTS/#chunking-parameters","title":"Chunking Parameters","text":"Parameter Default Range Description <code>chunk_size</code> 1,000 500-2,000 Tokens per chunk <code>summary_size</code> 100 50-200 Target summary length <code>tag_count</code> 8 5-15 Keywords per chunk <code>top_k_chunks</code> 3 1-10 Chunks to retrieve per query"},{"location":"ROADMAP_DOCUMENTS/#cache-settings","title":"Cache Settings","text":"Parameter Default Description <code>ttl</code> 3,600 sec (1 hour) Time to live for cached chunks <code>max_size_mb</code> 500 MB Maximum cache directory size <code>cleanup_threshold</code> 0.9 (90%) Trigger cleanup at 90% full"},{"location":"ROADMAP_DOCUMENTS/#summarization-costs","title":"Summarization Costs","text":"<p>Using Claude Haiku for summaries: - Input: ~1,000 tokens per chunk - Output: ~120 tokens (100 summary + 20 tags) - Cost per chunk: ~$0.0003 (input) + ~$0.0002 (output) = $0.0005 - Example: 100-page PDF (100 chunks) = $0.05</p> <p>Comparison to reading full document: - Full 100-page PDF: ~50,000 tokens - Single Claude Sonnet call: ~$0.15 input - With chunking: $0.05 summarization + multiple smaller queries = more cost-efficient for repeated access</p>"},{"location":"ROADMAP_DOCUMENTS/#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":""},{"location":"ROADMAP_DOCUMENTS/#unit-tests","title":"Unit Tests","text":"<p>Each phase includes comprehensive unit tests:</p> <p>Phase 1 (Core Infrastructure): - <code>test_document_chunker.py</code> - Chunking algorithms - <code>test_chunk_summarizer.py</code> - Summarization (mocked Claude API) - <code>test_chunk_cache.py</code> - Cache operations, TTL, cleanup - <code>test_chunk_retriever.py</code> - Query matching, scoring</p> <p>Phase 2 (Excel): - <code>test_excel_reader.py</code> - Excel reading, multi-sheet, data detection - Test files: structured.xlsx, unstructured.xlsx, formulas.xlsx</p> <p>Phase 3 (Word): - <code>test_word_reader.py</code> - Structure extraction, tables, images - Test files: simple.docx, complex.docx, with_tables.docx</p> <p>Phase 4 (PDF): - <code>test_pdf_reader.py</code> - Page extraction, tables, both engines - Test files: text.pdf, tables.pdf, scanned.pdf</p>"},{"location":"ROADMAP_DOCUMENTS/#integration-tests","title":"Integration Tests","text":"<ul> <li>Test full workflow: read \u2192 chunk \u2192 summarize \u2192 cache \u2192 query \u2192 retrieve</li> <li>Test with real files (not just mocked)</li> <li>Test cache hit/miss scenarios</li> <li>Test token tracking integration</li> <li>Test slash command functionality</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#performance-tests","title":"Performance Tests","text":"<ul> <li>Large file handling (100+ pages)</li> <li>Cache performance (10,000+ chunks)</li> <li>Summarization speed (parallel vs sequential)</li> <li>Memory usage for large documents</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#documentation-plan","title":"\ud83d\udcda Documentation Plan","text":""},{"location":"ROADMAP_DOCUMENTS/#readmemd-updates","title":"README.md Updates","text":"<p>Add section: \ud83d\udcc4 Document Reading <pre><code>### Reading Excel, Word, and PDF Files\n\nWYN360 can intelligently read and analyze structured documents:\n\nYou: Read expenses.xlsx\nYou: Summarize research_paper.docx\nYou: What's in Chapter 5 of textbook.pdf?\n</code></pre></p>"},{"location":"ROADMAP_DOCUMENTS/#use_casesmd","title":"USE_CASES.md","text":"<p>Add new use cases: - Use Case 15: Expense Report Analysis (Excel) - Use Case 16: Research Paper Summarization (Word) - Use Case 17: Textbook Navigation (PDF)</p>"},{"location":"ROADMAP_DOCUMENTS/#systemmd","title":"SYSTEM.md","text":"<p>Add architecture section: - Document Readers Layer   - Chunking architecture diagram   - Summarization flow   - Cache structure   - Tool descriptions</p>"},{"location":"ROADMAP_DOCUMENTS/#new-documentation","title":"New Documentation","text":"<ul> <li>DOCUMENT_READERS.md - Detailed user guide</li> <li>Supported formats</li> <li>Configuration options</li> <li>Slash commands</li> <li>Best practices</li> <li>Troubleshooting</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#success-metrics","title":"\u2705 Success Metrics","text":""},{"location":"ROADMAP_DOCUMENTS/#technical-metrics","title":"Technical Metrics","text":"<ul> <li>Test Coverage: &gt;90% for all document reader modules</li> <li>Performance:</li> <li>Excel (10 sheets): &lt;10 seconds</li> <li>Word (50 pages): &lt;15 seconds</li> <li>PDF (100 pages): &lt;30 seconds</li> <li>Cache Hit Rate: &gt;90% for repeated reads within TTL</li> <li>Memory Usage: &lt;500MB for largest supported document</li> <li>Token Efficiency: Chunked reading uses &lt;20% tokens of full read</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#user-experience-metrics","title":"User Experience Metrics","text":"<ul> <li>Query Accuracy: Top-3 chunks relevant in &gt;80% of queries</li> <li>Summary Quality: User validation (captures key information)</li> <li>Error Handling: Clear error messages for all failure modes</li> <li>No Breaking Changes: All existing tools work unchanged</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#adoption-metrics-post-release","title":"Adoption Metrics (Post-Release)","text":"<ul> <li>Usage of document tools vs traditional read_file</li> <li>Cache hit rates in production</li> <li>User feedback on summary quality</li> <li>Feature requests and bug reports</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#maintenance-updates","title":"\ud83d\udd04 Maintenance &amp; Updates","text":""},{"location":"ROADMAP_DOCUMENTS/#ongoing-maintenance","title":"Ongoing Maintenance","text":"<ul> <li>Monitor cache disk usage</li> <li>Update dependencies (openpyxl, python-docx, pymupdf)</li> <li>Improve summarization prompts based on feedback</li> <li>Add support for new file formats (e.g., .odt, .pages)</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#version-history","title":"Version History","text":"Version Phase Status Features Release Date v0.3.26 Phase 1 \u2705 Complete Core infrastructure Jan 2025 v0.3.27 Phase 2 \u2705 Complete Excel reader Jan 2025 v0.3.28 Phase 3 \u2705 Complete Word reader Jan 2025 v0.3.29 Phase 4 \u2705 Complete PDF reader Jan 2025 v0.3.30 Phase 5.1 \u2705 Complete Vision mode for images Jan 2025 v0.3.31 Phase 5.2 \u2705 Complete Semantic matching Jan 2025 v0.3.32 Phase 5.3 \u2705 Complete OCR support Jan 2025 v0.3.33 Phase 5.4 \u2705 Complete Excel enhancements Jan 2025 v0.3.34 Phase 5.5 \u2705 Complete Multi-document queries Jan 2025 v0.3.35 Phase 5.7 \u2705 Complete Advanced chunking Jan 2025 v0.3.36 Phase 5.6 \u2705 Complete Performance optimizations Jan 2025 v0.3.37 Docs \u2705 Complete Documentation updates Jan 2025 v0.3.38 Phase 5.8 \u2705 Complete Tool discoverability improvements Jan 2025 v0.3.39 Phase 5.9 \u2705 Complete Context retention fix (CRITICAL) Jan 2025 v0.3.40+ Future \ud83d\udca1 Planned Additional features TBD"},{"location":"ROADMAP_DOCUMENTS/#related-roadmaps","title":"\ud83e\udd1d Related Roadmaps","text":"<ul> <li>ROADMAP.md - Main feature roadmap</li> <li>ROADMAP_BROWSERUSE.md - Browser use / website fetching</li> </ul>"},{"location":"ROADMAP_DOCUMENTS/#feedback-support","title":"\ud83d\udcde Feedback &amp; Support","text":"<ul> <li>GitHub Issues: https://github.com/yiqiao-yin/wyn360-cli/issues</li> <li>Feature Requests: Tag with <code>enhancement</code> and <code>document-readers</code></li> <li>Bug Reports: Tag with <code>bug</code> and <code>document-readers</code></li> </ul> <p>Last Updated: January 12, 2025 Maintained by: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/","title":"Google Gemini Integration Roadmap","text":"<p>Version: 0.3.60+ Status: In Progress Started: November 19, 2025</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#objective","title":"\ud83c\udfaf Objective","text":"<p>Integrate Google Gemini models as an alternative AI provider alongside Anthropic Claude, giving users more flexibility in model selection while maintaining full feature parity with existing functionality.</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>[x] Research pydantic-ai Gemini support - CONFIRMED \u2705</li> <li>[x] Verify tool calling compatibility - CONFIRMED \u2705</li> <li>[x] Verify web search capabilities - CONFIRMED \u2705</li> <li>[x] Verify vision/multimodal support - CONFIRMED \u2705</li> <li>[x] Get Gemini API key for testing - CONFIRMED \u2705</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#implementation-phases","title":"\ud83d\ude80 Implementation Phases","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#phase-1-basic-integration-completed","title":"Phase 1: Basic Integration \u2705 COMPLETED","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#11-environment-dependencies-completed","title":"1.1 Environment &amp; Dependencies \u2705 COMPLETED","text":"<ul> <li>[x] Add <code>GEMINI_API_KEY</code> environment variable support</li> <li>[x] Update <code>pyproject.toml</code> to add <code>google-genai</code> dependency</li> <li>[x] Run <code>poetry install</code> to install new dependency</li> <li>[x] Add API key to <code>.env</code> file (for testing, not committed)</li> <li>[x] Update <code>.gitignore</code> to ensure <code>.env</code> is excluded</li> </ul> <p>Files modified: - <code>pyproject.toml</code> - Added <code>google-genai&gt;=1.0.0</code> - <code>.env</code> - Added GEMINI_API_KEY, CHOOSE_CLIENT, GEMINI_MODEL - <code>.gitignore</code> - Verified (already excludes .env)</p> <p>Tests: - [x] Verify <code>google-genai</code> package installs correctly - \u2705 PASSED - [x] Verify environment variable loads properly - \u2705 PASSED</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#12-model-configuration-completed","title":"1.2 Model Configuration \u2705 COMPLETED","text":"<ul> <li>[x] Add Gemini model definitions to agent configuration</li> <li>[x] Support Generative Language API (GoogleModel)</li> <li>[x] Add model selection logic in <code>agent.py</code></li> <li>[x] Update model initialization to handle Gemini models</li> <li>[x] Implemented <code>CHOOSE_CLIENT</code> environment variable (1=Anthropic, 2=Bedrock, 3=Gemini)</li> </ul> <p>Supported Models: - <code>gemini-2.5-pro</code> (recommended for complex tasks) - <code>gemini-2.5-flash</code> (recommended for fast tasks, default) - <code>gemini-2.0-flash</code> (alternative)</p> <p>Files modified: - <code>wyn360_cli/agent.py</code> - Added GoogleModel, _get_client_choice(), _validate_gemini_credentials()</p> <p>Tests: - [x] Test Gemini model initialization - \u2705 PASSED - [x] Test model selection with CHOOSE_CLIENT=3 - \u2705 PASSED - [x] Test API connection with real Gemini API - \u2705 PASSED (math, code generation)</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#13-cli-integration-completed","title":"1.3 CLI Integration \u2705 COMPLETED","text":"<ul> <li>[x] Implemented <code>CHOOSE_CLIENT</code> environment variable instead of flags</li> <li>[x] Auto-detection of provider based on API keys</li> <li>[x] Update CLI to show correct provider in banner</li> <li>[x] Update credential validation for all providers</li> </ul> <p>Files modified: - <code>wyn360_cli/cli.py</code> - Updated credential validation, provider display</p> <p>Tests: - [x] Test CHOOSE_CLIENT parsing - \u2705 PASSED - [x] Test model selection via env var - \u2705 PASSED - [x] Test auto-detection priority (Anthropic &gt; Gemini &gt; Bedrock) - \u2705 PASSED</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#14-cost-tracking-partially-completed","title":"1.4 Cost Tracking \u23f3 PARTIALLY COMPLETED","text":"<ul> <li>[x] Add Gemini pricing information (documented)</li> <li>[ ] Update token cost calculations for Gemini models (needs implementation)</li> <li>[ ] Update <code>/tokens</code> command to show Gemini costs (needs implementation)</li> </ul> <p>Gemini Pricing (as of Nov 2025): - Gemini 2.5 Pro: $1.25/M input, $10.00/M output - Gemini 2.5 Flash: $0.075/M input, $0.30/M output - Gemini 2.0 Flash: $0.10/M input, $0.40/M output</p> <p>Files to modify: - <code>wyn360_cli/agent.py</code> (cost tracking) - TODO - <code>wyn360_cli/cli.py</code> (<code>/tokens</code> command) - TODO</p> <p>Tests: - [ ] Test token cost calculation for Gemini models - [ ] Test <code>/tokens</code> command shows correct pricing</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#phase-2-feature-parity-in-progress","title":"Phase 2: Feature Parity \u23f3 IN PROGRESS","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#21-toolfunction-calling-verified","title":"2.1 Tool/Function Calling \u2705 VERIFIED","text":"<ul> <li>[x] Verify all existing tools work with Gemini - \u2705 TESTED with real API</li> <li>[x] All tools registered successfully (30+ tools)</li> <li>[x] File operations confirmed available</li> <li>[x] Code execution confirmed available</li> <li>[x] Git operations confirmed available</li> <li>[x] HuggingFace tools confirmed available</li> <li>[x] GitHub tools confirmed available</li> <li>[x] Document readers (Excel, Word, PDF) confirmed available</li> <li>[x] Browser tools confirmed available</li> </ul> <p>Files verified: - <code>wyn360_cli/agent.py</code> (all tool definitions) - \u2705 ALL COMPATIBLE</p> <p>Tests: - [x] Test basic chat with Gemini - \u2705 PASSED (math question) - [x] Test code generation with Gemini - \u2705 PASSED (Python function) - [x] Verify error handling works correctly - \u2705 PASSED</p> <p>Note: All tools work with Gemini! No compatibility issues found.</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#22-web-search-integration-disabled-temporary","title":"2.2 Web Search Integration \u26a0\ufe0f DISABLED (TEMPORARY)","text":"<ul> <li>[x] Discovered Gemini limitation: Cannot use builtin_tools + custom tools simultaneously</li> <li>[x] Disabled WebSearchTool for Gemini to prevent errors</li> <li>[ ] TODO: Implement Google Search as custom tool for Gemini (Phase 3)</li> </ul> <p>Current Status: - WebSearchTool (builtin) disabled for Gemini - All other tools work perfectly - Web search available for Anthropic API mode only</p> <p>Files modified: - <code>wyn360_cli/agent.py</code> - Disabled builtin_tools for Gemini</p> <p>Reason: - pydantic-ai limitation: Gemini doesn't support mixing builtin_tools and custom function tools - Error: \"Google does not support function tools and built-in tools at the same time\"</p> <p>Future Plan: - Implement web search as custom tool using Google Search API directly - This will enable web search for Gemini in future update</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#23-visionmultimodal-support","title":"2.3 Vision/Multimodal Support \u23f3","text":"<ul> <li>[ ] Test image processing with Gemini</li> <li>[ ] Test PDF document reading with vision mode</li> <li>[ ] Test Word document image descriptions</li> <li>[ ] Leverage Gemini's enhanced capabilities (object detection, segmentation)</li> <li>[ ] Test multi-image processing (up to 3,600 images)</li> </ul> <p>Files to verify: - <code>wyn360_cli/document_readers.py</code> (vision mode)</p> <p>Tests: - [ ] Test image description with Gemini - [ ] Test PDF with images using Gemini - [ ] Test Word documents with images using Gemini - [ ] Compare quality with Anthropic vision - [ ] Test up to 10 images in one request</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#24-streaming-responses","title":"2.4 Streaming Responses \u23f3","text":"<ul> <li>[ ] Verify text streaming works with Gemini</li> <li>[ ] Handle structured output (non-streaming) appropriately</li> <li>[ ] Update streaming logic to handle Gemini responses</li> </ul> <p>Files to verify: - <code>wyn360_cli/agent.py</code> (<code>chat_stream</code> method) - <code>wyn360_cli/cli.py</code> (streaming display)</p> <p>Tests: - [ ] Test text streaming with Gemini - [ ] Test structured output handling - [ ] Verify no regression with Anthropic streaming</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#25-document-reading","title":"2.5 Document Reading \u23f3","text":"<ul> <li>[ ] Test Excel reading with Gemini</li> <li>[ ] Test Word reading with Gemini</li> <li>[ ] Test PDF reading with Gemini</li> <li>[ ] Leverage Gemini's 2M context window for larger documents</li> <li>[ ] Test documents up to 1,000 pages (Gemini limit)</li> </ul> <p>Files to verify: - <code>wyn360_cli/document_readers.py</code></p> <p>Tests: - [ ] Test all document types with Gemini - [ ] Test large documents (&gt;100 pages) - [ ] Compare chunking behavior with Anthropic</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#phase-3-enhancements-planned","title":"Phase 3: Enhancements \ud83d\udccb PLANNED","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#31-extended-context-window","title":"3.1 Extended Context Window \u23f3","text":"<ul> <li>[ ] Leverage Gemini 2.5's 2M token context window</li> <li>[ ] Update document reading limits for Gemini</li> <li>[ ] Add warning when approaching context limits</li> </ul> <p>Files to modify: - <code>wyn360_cli/agent.py</code> - <code>wyn360_cli/document_readers.py</code></p> <p>Tests: - [ ] Test with very large documents - [ ] Test context limit warnings</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#32-video-audio-processing-new","title":"3.2 Video &amp; Audio Processing (NEW) \u23f3","text":"<ul> <li>[ ] Add video file reading capability</li> <li>[ ] Add audio file reading capability</li> <li>[ ] Create <code>read_video</code> tool</li> <li>[ ] Create <code>read_audio</code> tool</li> <li>[ ] Add tests for multimedia processing</li> </ul> <p>Supported Formats: - Video: MP4, MOV, AVI, etc. - Audio: MP3, WAV, FLAC, etc.</p> <p>Files to create/modify: - <code>wyn360_cli/agent.py</code> (new tools) - <code>wyn360_cli/multimedia_readers.py</code> (new file)</p> <p>Tests: - [ ] Test video processing - [ ] Test audio processing - [ ] Test audio transcription</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#33-vertex-ai-support-optional","title":"3.3 Vertex AI Support (Optional) \u23f3","text":"<ul> <li>[ ] Add Vertex AI authentication support</li> <li>[ ] Support Application Default Credentials</li> <li>[ ] Support service account JSON files</li> <li>[ ] Add region/location customization</li> <li>[ ] Add provisioned throughput options</li> </ul> <p>Files to modify: - <code>wyn360_cli/agent.py</code> - <code>wyn360_cli/cli.py</code></p> <p>Tests: - [ ] Test Vertex AI authentication - [ ] Test regional endpoints</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#phase-4-documentation-testing-planned","title":"Phase 4: Documentation &amp; Testing \ud83d\udccb PLANNED","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#41-documentation-updates","title":"4.1 Documentation Updates \u23f3","text":"<ul> <li>[ ] Update README.md with Gemini setup instructions</li> <li>[ ] Add Gemini examples to USE_CASES.md</li> <li>[ ] Update COST.md with Gemini pricing</li> <li>[ ] Update SYSTEM.md with architecture changes</li> <li>[ ] Create GEMINI_GUIDE.md with detailed Gemini-specific features</li> </ul> <p>Files to update: - <code>README.md</code> - <code>docs/USE_CASES.md</code> - <code>docs/COST.md</code> - <code>docs/SYSTEM.md</code> - <code>docs/GEMINI_GUIDE.md</code> (new)</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#42-comprehensive-testing","title":"4.2 Comprehensive Testing \u23f3","text":"<ul> <li>[ ] Run all existing unit tests with Gemini</li> <li>[ ] Add Gemini-specific test cases</li> <li>[ ] Test edge cases (API errors, rate limits, etc.)</li> <li>[ ] Test model switching (Anthropic \u2194 Gemini)</li> <li>[ ] Integration tests with real API</li> </ul> <p>Test Files: - <code>tests/test_agent.py</code> (update) - <code>tests/test_cli.py</code> (update) - <code>tests/test_gemini.py</code> (new) - <code>tests/test_gemini_tools.py</code> (new)</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#43-error-handling","title":"4.3 Error Handling \u23f3","text":"<ul> <li>[ ] Handle Gemini API errors gracefully</li> <li>[ ] Handle rate limiting</li> <li>[ ] Handle invalid API keys</li> <li>[ ] Handle model availability issues</li> <li>[ ] Add helpful error messages for users</li> </ul> <p>Files to modify: - <code>wyn360_cli/agent.py</code></p> <p>Tests: - [ ] Test error scenarios - [ ] Test rate limit handling - [ ] Test invalid API key</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#phase-5-deployment-planned","title":"Phase 5: Deployment \ud83d\udccb PLANNED","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#51-version-update","title":"5.1 Version Update \u23f3","text":"<ul> <li>[ ] Update version to 0.3.60 in <code>pyproject.toml</code></li> <li>[ ] Update version in <code>wyn360_cli/__init__.py</code></li> <li>[ ] Update version in README.md footer</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#52-build-publish","title":"5.2 Build &amp; Publish \u23f3","text":"<ul> <li>[ ] Run <code>poetry install</code> to verify dependencies</li> <li>[ ] Run all tests: <code>WYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v</code></li> <li>[ ] Build package: <code>poetry build</code></li> <li>[ ] Publish to PyPI: <code>poetry publish</code></li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#53-git-commit-push","title":"5.3 Git Commit &amp; Push \u23f3","text":"<ul> <li>[ ] Commit changes with detailed message</li> <li>[ ] Push to GitHub</li> <li>[ ] Create release notes</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#progress-tracking","title":"\ud83d\udcca Progress Tracking","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#overall-progress-0-complete","title":"Overall Progress: 0% Complete","text":"<ul> <li>Phase 1: Basic Integration - 0% (0/14 tasks)</li> <li>Phase 2: Feature Parity - 0% (0/17 tasks)</li> <li>Phase 3: Enhancements - 0% (0/11 tasks)</li> <li>Phase 4: Documentation - 0% (0/9 tasks)</li> <li>Phase 5: Deployment - 0% (0/5 tasks)</li> </ul> <p>Total Tasks: 56 Completed: 0 In Progress: 0 Remaining: 56</p>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#environment-variables","title":"\ud83d\udd11 Environment Variables","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#new-variables-added","title":"New Variables Added:","text":"Variable Description Default Example <code>GEMINI_API_KEY</code> Google Gemini API key (Generative Language API) None <code>AIzaSy...</code> <code>GOOGLE_API_KEY</code> Alternative name for Gemini API key None <code>AIzaSy...</code> <code>USE_GEMINI</code> Enable Gemini instead of Anthropic <code>0</code> <code>1</code> <code>GEMINI_MODEL</code> Specific Gemini model to use <code>gemini-2.5-flash</code> <code>gemini-2.5-pro</code>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#setup-example","title":"Setup Example:","text":"<pre><code># .env file\nGEMINI_API_KEY=your_key_here\nUSE_GEMINI=1\nGEMINI_MODEL=gemini-2.5-flash\n</code></pre>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#testing-plan","title":"\ud83e\uddea Testing Plan","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#unit-tests-tests-folder","title":"Unit Tests (tests/ folder):","text":"<ol> <li>test_gemini.py - Basic Gemini integration</li> <li>Test model initialization</li> <li>Test API key loading</li> <li>Test model selection</li> <li> <p>Test error handling</p> </li> <li> <p>test_gemini_tools.py - Tool compatibility</p> </li> <li>Test all file operations with Gemini</li> <li>Test code execution with Gemini</li> <li>Test git operations with Gemini</li> <li> <p>Test document reading with Gemini</p> </li> <li> <p>test_gemini_vision.py - Vision/multimodal</p> </li> <li>Test image processing</li> <li>Test PDF with images</li> <li> <p>Test multi-image handling</p> </li> <li> <p>test_gemini_search.py - Web search</p> </li> <li>Test Google Search Grounding</li> <li>Test grounding metadata</li> <li>Test source citations</li> </ol>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#integration-tests","title":"Integration Tests:","text":"<ul> <li>[ ] End-to-end workflow with Gemini</li> <li>[ ] Model switching during session</li> <li>[ ] Real API calls with test key</li> <li>[ ] Performance comparison with Anthropic</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#success-criteria","title":"\ud83d\udcc8 Success Criteria","text":""},{"location":"ROADMAP_GEMINI_INTEGRATION/#must-have-phase-1-2","title":"Must Have (Phase 1-2):","text":"<ul> <li>\u2705 Users can switch to Gemini with <code>--use-gemini</code> flag or environment variable</li> <li>\u2705 All existing tools work with Gemini without modification</li> <li>\u2705 Web search works with Google Search Grounding</li> <li>\u2705 Vision mode works with Gemini</li> <li>\u2705 Streaming responses work correctly</li> <li>\u2705 Cost tracking shows accurate Gemini pricing</li> <li>\u2705 All existing tests pass with Gemini</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#nice-to-have-phase-3","title":"Nice to Have (Phase 3):","text":"<ul> <li>\u2705 Video and audio processing capabilities</li> <li>\u2705 Vertex AI support for enterprise users</li> <li>\u2705 Leverage 2M token context window</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#documentation","title":"Documentation:","text":"<ul> <li>\u2705 Clear setup instructions in README</li> <li>\u2705 Examples of Gemini usage</li> <li>\u2705 Pricing comparison with Anthropic</li> <li>\u2705 Feature comparison guide</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#known-limitations","title":"\ud83d\udea8 Known Limitations","text":"<ol> <li>Structured Output Streaming: Gemini doesn't support streaming structured outputs (returns full output at once)</li> <li>Web Search Pricing: Google Search Grounding costs $35/1K queries (separate from model pricing)</li> <li>License Requirement: Must display source links when using Google Search Grounding</li> <li>Paid Tier: Google Search Grounding only available on paid tier</li> <li>Regional Availability: Some features may have regional limitations</li> </ol>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#notes","title":"\ud83d\udcdd Notes","text":"<ul> <li>Keep <code>.env</code> file excluded from git to protect API keys</li> <li>Test with provided API key before deploying</li> <li>Maintain backward compatibility with Anthropic</li> <li>Default to Anthropic if no Gemini configuration</li> <li>Add helpful error messages for common setup issues</li> </ul>"},{"location":"ROADMAP_GEMINI_INTEGRATION/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<ol> <li>\u2705 Create this roadmap document</li> <li>\u23f3 Add dependencies to <code>pyproject.toml</code></li> <li>\u23f3 Implement basic model initialization</li> <li>\u23f3 Test with real API key</li> <li>\u23f3 Add unit tests progressively</li> </ol> <p>Last Updated: November 19, 2025 Target Completion: Phase 1-2 by end of week Version Target: 0.3.60</p>"},{"location":"ROADMAP_GIT_BOOK/","title":"GitHub Book Implementation Roadmap","text":""},{"location":"ROADMAP_GIT_BOOK/#executive-summary","title":"Executive Summary","text":"<p>\u2705 FEASIBLE AND SAFE: Adding MkDocs-based GitHub Pages documentation is completely compatible with the existing PyPI package structure and will not interfere with package development or publication.</p>"},{"location":"ROADMAP_GIT_BOOK/#analysis-pypi-package-safety","title":"Analysis: PyPI Package Safety","text":""},{"location":"ROADMAP_GIT_BOOK/#current-package-structure-protected","title":"Current Package Structure \u2705 PROTECTED","text":"<pre><code>wyn360-cli/\n\u251c\u2500\u2500 pyproject.toml          # \u2705 Package metadata - UNTOUCHED\n\u251c\u2500\u2500 wyn360_cli/             # \u2705 Source code - UNTOUCHED\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 cli.py\n\u2502   \u251c\u2500\u2500 agent.py\n\u2502   \u2514\u2500\u2500 [other modules]\n\u251c\u2500\u2500 tests/                  # \u2705 Test suite - UNTOUCHED\n\u251c\u2500\u2500 README.md              # \u2705 PyPI description - UNTOUCHED\n\u251c\u2500\u2500 LICENSE               # \u2705 License file - UNTOUCHED\n\u2514\u2500\u2500 docs/                 # \u2705 Current docs - WILL ENHANCE\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#what-changes-for-github-book","title":"What Changes for GitHub Book","text":"<pre><code>+ mkdocs.yml                # NEW: MkDocs configuration\n+ docs/index.md            # NEW: Homepage (extracted from README)\n+ docs/getting-started/     # NEW: Organized documentation structure\n+ docs/features/\n+ docs/usage/\n+ docs/architecture/\n+ docs/development/\n+ .github/workflows/docs.yml # NEW: Auto-deploy to gh-pages branch\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#what-never-changes","title":"What NEVER Changes","text":"<ul> <li><code>pyproject.toml</code> package configuration</li> <li><code>wyn360_cli/</code> source code structure</li> <li>Package build/publish process (<code>poetry build &amp;&amp; poetry publish</code>)</li> <li>PyPI package functionality</li> <li>Existing development workflow</li> </ul>"},{"location":"ROADMAP_GIT_BOOK/#implementation-plan","title":"Implementation Plan","text":""},{"location":"ROADMAP_GIT_BOOK/#phase-1-setup-mkdocs-no-risk","title":"Phase 1: Setup MkDocs (No Risk)","text":"<p>Estimated Time: 30 minutes Risk Level: Zero - only adds dev dependencies</p> <pre><code># Add MkDocs as development dependency (doesn't affect package)\npoetry add --group dev mkdocs mkdocs-material mkdocstrings[python]\n\n# Create MkDocs configuration\n# This file is ignored by PyPI package building\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#phase-2-content-organization-no-risk","title":"Phase 2: Content Organization (No Risk)","text":"<p>Estimated Time: 1-2 hours Risk Level: Zero - only reorganizes docs</p> <ol> <li>Preserve existing docs: Keep all current <code>.md</code> files</li> <li>Create organized structure:    <pre><code>docs/\n\u251c\u2500\u2500 index.md                    # NEW: Homepage from README\n\u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 installation.md         # NEW: From README\n\u2502   \u251c\u2500\u2500 quickstart.md          # NEW: From README\n\u2502   \u2514\u2500\u2500 configuration.md       # NEW: From README\n\u251c\u2500\u2500 features/\n\u2502   \u251c\u2500\u2500 overview.md            # NEW: From README\n\u2502   \u251c\u2500\u2500 web-search.md          # NEW: Extract from README\n\u2502   \u251c\u2500\u2500 browser-use.md         # NEW: Extract from README\n\u2502   \u251c\u2500\u2500 vision-mode.md         # NEW: Extract from README\n\u2502   \u251c\u2500\u2500 github.md              # NEW: Extract from README\n\u2502   \u2514\u2500\u2500 huggingface.md         # NEW: Extract from README\n\u251c\u2500\u2500 usage/\n\u2502   \u251c\u2500\u2500 use-cases.md           # MOVE: docs/USE_CASES.md\n\u2502   \u251c\u2500\u2500 commands.md            # NEW: From README\n\u2502   \u2514\u2500\u2500 cost.md                # MOVE: docs/COST.md\n\u251c\u2500\u2500 architecture/\n\u2502   \u251c\u2500\u2500 system.md              # MOVE: docs/SYSTEM.md\n\u2502   \u2514\u2500\u2500 autonomous-browsing.md # MOVE: docs/AUTONOMOUS_BROWSING.md\n\u2514\u2500\u2500 development/\n    \u251c\u2500\u2500 contributing.md        # NEW: From README\n    \u251c\u2500\u2500 testing.md             # NEW: From README\n    \u2514\u2500\u2500 roadmap.md             # MOVE: docs/ROADMAP.md\n</code></pre></li> </ol>"},{"location":"ROADMAP_GIT_BOOK/#phase-3-github-actions-no-risk","title":"Phase 3: GitHub Actions (No Risk)","text":"<p>Estimated Time: 20 minutes Risk Level: Zero - creates separate deployment branch</p> <pre><code># .github/workflows/docs.yml\nname: Deploy Documentation\non:\n  push:\n    branches: [ main ]\n  workflow_dispatch:\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.10'\n      - name: Install Poetry\n        uses: snok/install-poetry@v1\n      - name: Install dependencies\n        run: poetry install --with dev\n      - name: Deploy docs\n        run: poetry run mkdocs gh-deploy --force\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#phase-4-test-and-verify-no-risk","title":"Phase 4: Test and Verify (No Risk)","text":"<p>Estimated Time: 15 minutes</p> <pre><code># Test locally (doesn't affect package)\npoetry run mkdocs serve\n\n# Verify package still builds correctly\npoetry build\n# \u2705 Should work exactly as before\n\n# Deploy docs (creates gh-pages branch)\npoetry run mkdocs gh-deploy\n# \u2705 Documentation live at: https://yiqiao-yin.github.io/wyn360-cli/\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#dual-workflow-independence","title":"Dual Workflow Independence","text":""},{"location":"ROADMAP_GIT_BOOK/#pypi-package-development-unchanged","title":"PyPI Package Development (Unchanged)","text":"<pre><code># 1. Develop new features\ngit checkout -b feature/new-awesome-feature\n# Edit wyn360_cli/ source code\n\n# 2. Test package\npoetry run pytest tests/ -v\n\n# 3. Update version\n# Edit pyproject.toml: version = \"0.3.61\"\n# Edit wyn360_cli/__init__.py: __version__ = \"0.3.61\"\n\n# 4. Build and publish to PyPI (UNCHANGED)\npoetry build\npoetry publish\n\n# 5. Push to main\ngit push origin main\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#documentation-updates-new-independent","title":"Documentation Updates (New, Independent)","text":"<pre><code># 1. Update docs\n# Edit docs/features/new-feature.md\n\n# 2. Test docs locally\npoetry run mkdocs serve\n\n# 3. Deploy docs (automatic via GitHub Actions)\ngit push origin main\n# \u2705 Docs auto-deploy to https://yiqiao-yin.github.io/wyn360-cli/\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#technical-implementation-details","title":"Technical Implementation Details","text":""},{"location":"ROADMAP_GIT_BOOK/#mkdocs-configuration-mkdocsyml","title":"MkDocs Configuration (<code>mkdocs.yml</code>)","text":"<pre><code>site_name: WYN360 CLI Documentation\nsite_description: An intelligent AI coding assistant CLI tool powered by Anthropic Claude\nsite_author: Yiqiao Yin\nrepo_url: https://github.com/yiqiao-yin/wyn360-cli\nrepo_name: yiqiao-yin/wyn360-cli\nsite_url: https://yiqiao-yin.github.io/wyn360-cli/\n\ntheme:\n  name: material\n  palette:\n    - scheme: default\n      primary: indigo\n      accent: indigo\n      toggle:\n        icon: material/brightness-7\n        name: Switch to dark mode\n    - scheme: slate\n      primary: indigo\n      accent: indigo\n      toggle:\n        icon: material/brightness-4\n        name: Switch to light mode\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - navigation.top\n    - search.highlight\n    - content.code.copy\n    - navigation.footer\n\nplugins:\n  - search\n  - mkdocstrings:\n      handlers:\n        python:\n          paths: [wyn360_cli]\n\nnav:\n  - Home: index.md\n  - Getting Started:\n      - Installation: getting-started/installation.md\n      - Quick Start: getting-started/quickstart.md\n      - Configuration: getting-started/configuration.md\n  - Features:\n      - Overview: features/overview.md\n      - Web Search: features/web-search.md\n      - Browser Use: features/browser-use.md\n      - Vision Mode: features/vision-mode.md\n      - GitHub Integration: features/github.md\n      - HuggingFace: features/huggingface.md\n  - Usage:\n      - Use Cases: usage/use-cases.md\n      - Commands: usage/commands.md\n      - Cost Management: usage/cost.md\n  - Architecture:\n      - System Design: architecture/system.md\n      - Autonomous Browsing: architecture/autonomous-browsing.md\n  - Development:\n      - Contributing: development/contributing.md\n      - Testing: development/testing.md\n      - Roadmap: development/roadmap.md\n\nmarkdown_extensions:\n  - admonition\n  - codehilite\n  - pymdownx.highlight:\n      anchor_linenums: true\n  - pymdownx.inlinehilite\n  - pymdownx.snippets\n  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_code_format\n  - pymdownx.tabbed:\n      alternate_style: true\n  - toc:\n      permalink: true\n  - attr_list\n  - md_in_html\n</code></pre>"},{"location":"ROADMAP_GIT_BOOK/#content-extraction-strategy","title":"Content Extraction Strategy","text":"<p>From README.md to docs/index.md: <pre><code># WYN360 CLI\n\nAn intelligent AI coding assistant that helps you build projects, generate code, and improve your codebase through natural language conversations.\n\n## Why Choose WYN360 CLI?\n\n- \ud83e\udd16 **Interactive AI Assistant** - Natural language conversations with Claude\n- \ud83d\udcdd **Code Generation** - Generate production-ready Python code\n- \ud83d\udd0d **Project Analysis** - Understand and improve existing codebases\n- \u26a1 **Multi-Provider Support** - Anthropic, AWS Bedrock, Google Gemini\n\n## Quick Start\n\n```bash\npip install wyn360-cli\nexport ANTHROPIC_API_KEY=your_key_here\nwyn360\n</code></pre></p> <p>Get Started \u2192 View on GitHub \u2192 <pre><code>**Content Distribution:**\n- **README sections \u2192 Dedicated pages**: Extract complex sections into focused pages\n- **Existing docs \u2192 Organized structure**: Move and categorize current documentation\n- **Cross-references**: Link between related content\n- **Navigation**: Logical flow from basic to advanced topics\n\n## Risk Assessment\n\n### Zero Risk Factors \u2705\n1. **Package Structure**: Completely untouched\n2. **Build Process**: Uses same `poetry build` command\n3. **PyPI Publishing**: Uses same `poetry publish` command\n4. **Source Code**: No changes to `wyn360_cli/` directory\n5. **Dependencies**: MkDocs added to dev group only\n6. **Git Branches**: `gh-pages` is separate and isolated\n\n### Additional Benefits \u2705\n1. **Professional Documentation Site**: Modern, searchable interface\n2. **SEO Optimized**: Better discoverability for your project\n3. **API Documentation**: Auto-generated from docstrings with mkdocstrings\n4. **Mobile Friendly**: Responsive Material Design\n5. **Dark/Light Mode**: User preference support\n6. **Version History**: Git-based documentation versioning\n\n## Implementation Verification Checklist\n\n### Before Implementation\n- [x] Verify `poetry build` works correctly\n- [x] Verify `poetry publish` works correctly\n- [x] Note current PyPI package structure\n- [x] Backup current docs folder\n\n### During Implementation\n- [x] Add MkDocs dependencies to dev group only\n- [x] Create `mkdocs.yml` configuration\n- [x] Reorganize documentation content\n- [x] Test local documentation build\n- [x] Verify package build still works\n\n### After Implementation\n- [x] Confirm PyPI package functionality unchanged\n- [ ] Verify documentation site deployed correctly (pending GitHub Pages setup)\n- [x] Test both workflows independently\n- [x] Update development documentation\n\n## \u2705 IMPLEMENTATION COMPLETED\n\n**Date:** November 21, 2025\n**Status:** \u2705 **SUCCESSFULLY IMPLEMENTED**\n**Time Taken:** ~2.5 hours\n\n### What Was Implemented\n\n#### Phase 1: MkDocs Setup \u2705\n- **Duration:** 30 minutes\n- **Status:** Complete\n- Added MkDocs dependencies to Poetry dev group:\n  - mkdocs ^1.6.1\n  - mkdocs-material ^9.7.0\n  - mkdocstrings[python] ^0.30.1\n- Created `mkdocs.yml` configuration with Material theme\n- Configured navigation structure, plugins, and markdown extensions\n\n#### Phase 2: Content Organization \u2705\n- **Duration:** 1.5 hours\n- **Status:** Complete\n- Created organized directory structure:\n  ```\n  docs/\n  \u251c\u2500\u2500 index.md (new homepage from README)\n  \u251c\u2500\u2500 getting-started/\n  \u2502   \u251c\u2500\u2500 installation.md (new, detailed)\n  \u2502   \u251c\u2500\u2500 quickstart.md (new, comprehensive)\n  \u2502   \u2514\u2500\u2500 configuration.md (new, complete)\n  \u251c\u2500\u2500 features/\n  \u2502   \u251c\u2500\u2500 overview.md (new, feature comparison)\n  \u2502   \u251c\u2500\u2500 web-search.md (new)\n  \u2502   \u251c\u2500\u2500 browser-use.md (new)\n  \u2502   \u251c\u2500\u2500 vision-mode.md (new)\n  \u2502   \u251c\u2500\u2500 github.md (new)\n  \u2502   \u2514\u2500\u2500 huggingface.md (new)\n  \u251c\u2500\u2500 usage/\n  \u2502   \u251c\u2500\u2500 use-cases.md (moved from docs/USE_CASES.md)\n  \u2502   \u251c\u2500\u2500 commands.md (new, complete reference)\n  \u2502   \u2514\u2500\u2500 cost.md (moved from docs/COST.md)\n  \u251c\u2500\u2500 architecture/\n  \u2502   \u251c\u2500\u2500 system.md (moved from docs/SYSTEM.md)\n  \u2502   \u2514\u2500\u2500 autonomous-browsing.md (moved from docs/AUTONOMOUS_BROWSING.md)\n  \u2514\u2500\u2500 development/\n      \u251c\u2500\u2500 contributing.md (new, comprehensive)\n      \u251c\u2500\u2500 testing.md (new, detailed guide)\n      \u2514\u2500\u2500 roadmap.md (moved from docs/ROADMAP.md)\n  ```\n\n#### Phase 3: GitHub Actions \u2705\n- **Duration:** 20 minutes\n- **Status:** Complete\n- Created `.github/workflows/docs.yml` for automatic deployment\n- Configured Poetry, Python 3.10, and dependency caching\n- Set up GitHub Pages deployment with proper permissions\n\n#### Phase 4: Testing &amp; Verification \u2705\n- **Duration:** 15 minutes\n- **Status:** Complete\n- \u2705 MkDocs build successful: `poetry run mkdocs build --clean`\n- \u2705 Package build verified: `poetry build` works correctly\n- \u2705 CLI functionality confirmed: `poetry run wyn360 --help` works\n- \u2705 PyPI package structure unchanged\n- \u2705 Development workflow unaffected\n\n### Verification Results\n\n**PyPI Package Integrity:** \u2705 CONFIRMED\n```bash\n$ poetry build\nBuilding wyn360-cli (0.3.60)\nBuilding sdist\n  - Built wyn360_cli-0.3.60.tar.gz\nBuilding wheel\n  - Built wyn360_cli-0.3.60-py3-none-any.whl\n</code></pre></p> <p>CLI Functionality: \u2705 CONFIRMED <pre><code>$ poetry run wyn360 --help\nUsage: wyn360 [OPTIONS]\nWYN360 - An intelligent AI coding assistant CLI tool.\n[Full help output working correctly]\n</code></pre></p> <p>Documentation Build: \u2705 CONFIRMED <pre><code>$ poetry run mkdocs build --clean\nINFO - Building documentation to directory: /site\nINFO - Documentation built in 1.97 seconds\n</code></pre></p> <p>Dependencies Added: \u2705 CONFIRMED - All MkDocs dependencies added to <code>[dependency-groups] dev</code> only - No impact on production package dependencies - Poetry lock file updated correctly</p>"},{"location":"ROADMAP_GIT_BOOK/#next-steps-for-deployment","title":"Next Steps for Deployment","text":"<p>To activate GitHub Pages: 1. Push changes to main branch 2. Go to repository Settings \u2192 Pages 3. Set source to \"GitHub Actions\" 4. Documentation will be live at: <code>https://yiqiao-yin.github.io/wyn360-cli/</code></p> <p>To test locally: <pre><code>poetry run mkdocs serve\n# Visit http://127.0.0.1:8000\n</code></pre></p> <p>To deploy manually (if needed): <pre><code>poetry run mkdocs gh-deploy\n</code></pre></p>"},{"location":"ROADMAP_GIT_BOOK/#files-createdmodified","title":"Files Created/Modified","text":"<p>New Files: - <code>mkdocs.yml</code> - MkDocs configuration - <code>.github/workflows/docs.yml</code> - GitHub Actions workflow - <code>docs/index.md</code> - Homepage - <code>docs/getting-started/</code> - 3 comprehensive getting started pages - <code>docs/features/</code> - 6 feature-specific pages - <code>docs/usage/commands.md</code> - Complete command reference - <code>docs/development/contributing.md</code> - Contribution guide - <code>docs/development/testing.md</code> - Testing documentation</p> <p>Moved Files: - <code>docs/USE_CASES.md</code> \u2192 <code>docs/usage/use-cases.md</code> - <code>docs/COST.md</code> \u2192 <code>docs/usage/cost.md</code> - <code>docs/SYSTEM.md</code> \u2192 <code>docs/architecture/system.md</code> - <code>docs/AUTONOMOUS_BROWSING.md</code> \u2192 <code>docs/architecture/autonomous-browsing.md</code> - <code>docs/ROADMAP.md</code> \u2192 <code>docs/development/roadmap.md</code></p> <p>Modified Files: - <code>pyproject.toml</code> - Added MkDocs dev dependencies - <code>poetry.lock</code> - Updated with new dependencies</p> <p>Zero Risk Confirmed: - No changes to <code>wyn360_cli/</code> source code - No changes to package build process - No changes to PyPI publishing workflow - All MkDocs additions are development-only - GitHub Pages uses separate <code>gh-pages</code> branch</p>"},{"location":"ROADMAP_GIT_BOOK/#expected-outcomes","title":"Expected Outcomes","text":""},{"location":"ROADMAP_GIT_BOOK/#documentation-site","title":"Documentation Site","text":"<ul> <li>URL: <code>https://yiqiao-yin.github.io/wyn360-cli/</code></li> <li>Features: Professional, searchable documentation</li> <li>Content: All existing docs + new organized structure</li> <li>Maintenance: Automatic updates via GitHub Actions</li> </ul>"},{"location":"ROADMAP_GIT_BOOK/#package-development","title":"Package Development","text":"<ul> <li>Process: Completely unchanged</li> <li>Publishing: Same commands, same results</li> <li>Testing: Same test suite, same commands</li> <li>Development: Same workflow, no interference</li> </ul>"},{"location":"ROADMAP_GIT_BOOK/#conclusion","title":"Conclusion","text":"<p>This implementation adds significant value (professional documentation website) with zero risk to the existing package infrastructure. The two systems operate independently:</p> <ol> <li>PyPI Package: Continues normal development/publish cycle</li> <li>GitHub Pages: Provides enhanced documentation experience</li> </ol> <p>Both workflows can be maintained simultaneously by the same development team using familiar tools and processes.</p> <p>Sources: - MkDocs - Python Poetry Template - Installation - Material for MkDocs - GitHub Pages - Arduino - Deploy MkDocs Poetry Workflow - \ud83d\ude80 GitHub Pages + MkDocs Complete Guide 2025 - Documentation with MkDocs - cookiecutter-poetry - \ud83e\udde9 Automated Documentation using MkDocs and Python - Starting a Static Website Project with MkDocs - COMP423 Spring 2025</p> <p>Recommendation: \u2705 PROCEED WITH IMPLEMENTATION - This is a low-risk, high-value addition that follows 2025 best practices for Python project documentation.</p>"},{"location":"ROADMAP_OCR/","title":"WYN360 CLI - OCR Support Implementation Roadmap","text":"<p>Status: \u2705 Phase 5.3 - COMPLETED (v0.3.32) Priority: Medium Target Version: v0.3.32 Completion Date: January 2025</p>"},{"location":"ROADMAP_OCR/#executive-summary","title":"\ud83d\udccb Executive Summary","text":"<p>This roadmap outlines the implementation of OCR Support for scanned PDFs - enabling text extraction from image-based PDF documents. This is a medium-priority enhancement in Phase 5.3.</p>"},{"location":"ROADMAP_OCR/#key-value-proposition","title":"Key Value Proposition","text":"<p>Current State: Scanned PDFs (images of pages) cannot be read. Text extraction only works on text-based PDFs.</p> <p>With OCR: Scanned PDFs are automatically detected and processed with OCR to extract text, making them searchable and analyzable.</p>"},{"location":"ROADMAP_OCR/#business-impact","title":"Business Impact","text":"<ul> <li>Scanned document support - Process legacy documents, forms, receipts</li> <li>Universal PDF handling - Works with any PDF regardless of type</li> <li>Cost awareness - Clear warnings about OCR processing time</li> <li>Quality assessment - Confidence scores for OCR results</li> </ul>"},{"location":"ROADMAP_OCR/#implementation-plan-overview","title":"\ud83c\udfaf Implementation Plan Overview","text":""},{"location":"ROADMAP_OCR/#phase-531-ocr-infrastructure-v0333","title":"Phase 5.3.1: OCR Infrastructure (v0.3.33)","text":"<ul> <li>Add Tesseract OCR dependency (or pytesseract wrapper)</li> <li>Create OCRProcessor class for text extraction</li> <li>Implement scanned PDF detection logic</li> <li>Basic text extraction from images</li> </ul>"},{"location":"ROADMAP_OCR/#phase-532-integration-with-pdfreader-v0333","title":"Phase 5.3.2: Integration with PDFReader (v0.3.33)","text":"<ul> <li>Update PDFReader to detect scanned pages</li> <li>Process scanned pages with OCR</li> <li>Combine OCR text with existing text (hybrid PDFs)</li> <li>Add OCR confidence scores to chunks</li> </ul>"},{"location":"ROADMAP_OCR/#phase-533-quality-optimization-v0334","title":"Phase 5.3.3: Quality &amp; Optimization (v0.3.34)","text":"<ul> <li>Language detection (English, Spanish, etc.)</li> <li>OCR preprocessing (deskew, denoise)</li> <li>Quality assessment and warnings</li> <li>Performance optimization for large scans</li> </ul>"},{"location":"ROADMAP_OCR/#phase-534-testing-documentation-v0334","title":"Phase 5.3.4: Testing &amp; Documentation (v0.3.34)","text":"<ul> <li>Comprehensive OCR tests</li> <li>Documentation and examples</li> <li>Cost/performance benchmarks</li> </ul>"},{"location":"ROADMAP_OCR/#detailed-implementation","title":"\ud83d\udd27 Detailed Implementation","text":""},{"location":"ROADMAP_OCR/#phase-531-ocr-infrastructure","title":"Phase 5.3.1: OCR Infrastructure","text":"<p>Dependencies: <pre><code>dependencies = [\n    # ... existing ...\n    \"pytesseract&gt;=0.3.10\",  # Python wrapper for Tesseract\n    \"pdf2image&gt;=1.16.0\",    # Convert PDF pages to images\n    \"Pillow&gt;=10.0.0\",       # Image processing (already present)\n]\n</code></pre></p> <p>OCRProcessor Class: <pre><code>class OCRProcessor:\n    \"\"\"Extract text from images using Tesseract OCR.\"\"\"\n\n    def __init__(self, language: str = \"eng\"):\n        \"\"\"\n        Initialize OCR processor.\n\n        Args:\n            language: Tesseract language code (eng, spa, fra, etc.)\n        \"\"\"\n        self.language = language\n        self._check_tesseract()\n\n    def _check_tesseract(self):\n        \"\"\"Verify Tesseract is installed.\"\"\"\n        try:\n            import pytesseract\n            pytesseract.get_tesseract_version()\n        except Exception:\n            raise RuntimeError(\n                \"Tesseract OCR not installed. \"\n                \"Install: apt-get install tesseract-ocr (Linux) \"\n                \"or brew install tesseract (Mac)\"\n            )\n\n    def extract_text(\n        self,\n        image: Image.Image,\n        preprocess: bool = True\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Extract text from image using OCR.\n\n        Args:\n            image: PIL Image object\n            preprocess: Apply preprocessing (deskew, denoise)\n\n        Returns:\n            {\n                \"text\": str,\n                \"confidence\": float (0-100),\n                \"word_count\": int\n            }\n        \"\"\"\n        import pytesseract\n\n        if preprocess:\n            image = self._preprocess_image(image)\n\n        # Extract text with confidence\n        data = pytesseract.image_to_data(\n            image,\n            lang=self.language,\n            output_type=pytesseract.Output.DICT\n        )\n\n        # Calculate average confidence\n        confidences = [c for c in data['conf'] if c != -1]\n        avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n\n        # Extract text\n        text = pytesseract.image_to_string(image, lang=self.language)\n\n        return {\n            \"text\": text.strip(),\n            \"confidence\": avg_confidence,\n            \"word_count\": len(text.split())\n        }\n\n    def _preprocess_image(self, image: Image.Image) -&gt; Image.Image:\n        \"\"\"Preprocess image for better OCR results.\"\"\"\n        # Convert to grayscale\n        image = image.convert('L')\n\n        # Increase contrast\n        from PIL import ImageEnhance\n        enhancer = ImageEnhance.Contrast(image)\n        image = enhancer.enhance(2.0)\n\n        return image\n\n    def is_scanned_page(\n        self,\n        page_image: Image.Image,\n        text_from_pdf: str\n    ) -&gt; bool:\n        \"\"\"\n        Detect if PDF page is scanned (image-based).\n\n        Args:\n            page_image: Page rendered as image\n            text_from_pdf: Text extracted directly from PDF\n\n        Returns:\n            True if page appears to be scanned\n        \"\"\"\n        # If PDF has very little text but page has visual content, likely scanned\n        if len(text_from_pdf.strip()) &lt; 10:\n            # Try quick OCR to see if there's text\n            result = self.extract_text(page_image, preprocess=False)\n            return result[\"word_count\"] &gt; 20\n\n        return False\n</code></pre></p> <p>Scanned PDF Detection Logic: <pre><code># In PDFReader._read_with_pymupdf()\n\nasync def _read_with_pymupdf(self, page_range: Optional[Tuple[int, int]] = None):\n    \"\"\"Read PDF with PyMuPDF, detecting and processing scanned pages.\"\"\"\n\n    ocr_processor = None\n    if self.enable_ocr:  # NEW parameter\n        try:\n            ocr_processor = OCRProcessor()\n        except RuntimeError:\n            # Tesseract not installed, skip OCR\n            pass\n\n    for page_num in range(start_page, end_page):\n        page = doc[page_num]\n\n        # Extract text normally\n        text = page.get_text()\n\n        # Check if page is scanned\n        if ocr_processor and len(text.strip()) &lt; 50:\n            # Render page as image\n            pix = page.get_pixmap(dpi=300)\n            image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n\n            # Check if truly scanned\n            if ocr_processor.is_scanned_page(image, text):\n                # Extract text with OCR\n                ocr_result = ocr_processor.extract_text(image)\n                text = ocr_result[\"text\"]\n\n                # Add OCR metadata\n                page_data[\"ocr_used\"] = True\n                page_data[\"ocr_confidence\"] = ocr_result[\"confidence\"]\n\n        # ... rest of processing ...\n</code></pre></p>"},{"location":"ROADMAP_OCR/#phase-532-integration-with-pdfreader","title":"Phase 5.3.2: Integration with PDFReader","text":"<p>Update PDFReader.init(): <pre><code>def __init__(\n    self,\n    file_path: str,\n    chunk_size: int = 1000,\n    engine: str = \"pymupdf\",\n    pages_per_chunk: int = 3,\n    image_handling: str = \"skip\",\n    enable_ocr: bool = False,  # NEW PARAMETER\n    ocr_language: str = \"eng\"  # NEW PARAMETER\n):\n    \"\"\"\n    Initialize PDF reader.\n\n    Args:\n        enable_ocr: Enable OCR for scanned PDFs\n        ocr_language: Tesseract language code\n    \"\"\"\n    # ... existing init ...\n    self.enable_ocr = enable_ocr\n    self.ocr_language = ocr_language\n</code></pre></p> <p>Combine OCR with Vision Mode:</p> <p>For hybrid PDFs with both text and images: - Extract text normally - Extract images with Vision API (if enabled) - Use OCR for scanned pages - Combine all sources into coherent content</p>"},{"location":"ROADMAP_OCR/#phase-533-quality-optimization","title":"Phase 5.3.3: Quality &amp; Optimization","text":"<p>Language Detection: <pre><code>def detect_language(self, image: Image.Image) -&gt; str:\n    \"\"\"\n    Detect language of text in image.\n\n    Returns:\n        Tesseract language code (eng, spa, fra, etc.)\n    \"\"\"\n    import pytesseract\n    from langdetect import detect\n\n    # Quick OCR in English\n    text = pytesseract.image_to_string(image, lang=\"eng\")\n\n    # Detect language\n    try:\n        lang_code = detect(text)\n        # Map to Tesseract codes\n        lang_map = {\"en\": \"eng\", \"es\": \"spa\", \"fr\": \"fra\", \"de\": \"deu\"}\n        return lang_map.get(lang_code, \"eng\")\n    except:\n        return \"eng\"\n</code></pre></p> <p>Quality Assessment: <pre><code>def assess_ocr_quality(self, ocr_result: Dict) -&gt; str:\n    \"\"\"\n    Assess OCR quality and provide user feedback.\n\n    Returns:\n        Quality rating: \"excellent\", \"good\", \"fair\", \"poor\"\n    \"\"\"\n    confidence = ocr_result[\"confidence\"]\n\n    if confidence &gt; 90:\n        return \"excellent\"\n    elif confidence &gt; 75:\n        return \"good\"\n    elif confidence &gt; 60:\n        return \"fair\"\n    else:\n        return \"poor\"\n</code></pre></p>"},{"location":"ROADMAP_OCR/#phase-534-testing-documentation","title":"Phase 5.3.4: Testing &amp; Documentation","text":"<p>Tests: - <code>test_ocr_processor.py</code> (15 tests)   - OCR text extraction   - Confidence scoring   - Scanned page detection   - Preprocessing effects   - Language detection   - Error handling (Tesseract not installed)</p> <ul> <li><code>test_pdf_ocr_integration.py</code> (10 tests)</li> <li>Scanned PDF reading</li> <li>Hybrid PDF handling</li> <li>OCR + Vision mode combined</li> <li>Performance with large scans</li> </ul> <p>Documentation: - Update README.md with OCR examples - Add OCR costs and performance notes to COST.md - Document Tesseract installation instructions</p>"},{"location":"ROADMAP_OCR/#cost-analysis","title":"\ud83d\udcb0 Cost Analysis","text":""},{"location":"ROADMAP_OCR/#computational-costs","title":"Computational Costs","text":"<p>OCR Processing: - Speed: ~1-2 seconds per page (300 DPI) - Memory: ~50MB per page during processing - No API costs (runs locally)</p> <p>Storage: - No additional cache size (OCR text replaces non-existent text)</p> <p>Performance Impact: - 10-page scanned PDF: ~10-20 seconds additional processing - Acceptable for occasional use, not real-time</p>"},{"location":"ROADMAP_OCR/#success-criteria","title":"\u2705 Success Criteria","text":""},{"location":"ROADMAP_OCR/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>\u2705 Detect scanned PDF pages accurately</li> <li>\u2705 Extract text from scanned pages with &gt;75% accuracy</li> <li>\u2705 Handle hybrid PDFs (mix of text and scanned pages)</li> <li>\u2705 Provide confidence scores and quality warnings</li> <li>\u2705 Language detection for multi-lingual documents</li> </ul>"},{"location":"ROADMAP_OCR/#quality-requirements","title":"Quality Requirements","text":"<ul> <li>\u2705 OCR accuracy &gt;80% on clear scans</li> <li>\u2705 Processing time &lt;2s per page</li> <li>\u2705 Graceful fallback if Tesseract not installed</li> <li>\u2705 All existing tests continue to pass</li> </ul>"},{"location":"ROADMAP_OCR/#implementation-timeline","title":"\ud83d\uddd3\ufe0f Implementation Timeline","text":""},{"location":"ROADMAP_OCR/#week-1-ocr-infrastructure-531","title":"Week 1: OCR Infrastructure (5.3.1)","text":"<ul> <li>Days 1-2: Add dependencies, create OCRProcessor</li> <li>Days 3-4: Implement scanned page detection</li> <li>Day 5: Basic OCR testing</li> </ul>"},{"location":"ROADMAP_OCR/#week-2-integration-532-533","title":"Week 2: Integration (5.3.2-5.3.3)","text":"<ul> <li>Days 1-2: Integrate with PDFReader</li> <li>Days 3-4: Quality improvements and language detection</li> <li>Day 5: Performance optimization</li> </ul>"},{"location":"ROADMAP_OCR/#week-3-testing-documentation-534","title":"Week 3: Testing &amp; Documentation (5.3.4)","text":"<ul> <li>Days 1-2: Comprehensive testing</li> <li>Days 3-4: Documentation updates</li> <li>Day 5: Release prep</li> </ul> <p>Total: 3 weeks</p> <p>Last Updated: January 2026 Document Version: 1.0 Maintained by: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"ROADMAP_OCR/#implementation-summary-v0332","title":"\u2705 Implementation Summary (v0.3.32)","text":""},{"location":"ROADMAP_OCR/#completed-features","title":"Completed Features","text":"<p>Phase 5.3.1: OCR Infrastructure \u2713 - Added dependencies: pytesseract, pdf2image, Pillow - Created OCRProcessor class with text extraction and confidence scoring - Scanned page detection (is_scanned_page) - Quality assessment (assess_quality) - Image preprocessing for better OCR results - 15 OCRProcessor unit tests passing</p> <p>Phase 5.3.2: PDFReader Integration \u2713 - enable_ocr and ocr_language parameters in PDFReader.init - OCR integration in _read_with_pymupdf - OCR integration in _read_with_pdfplumber - OCR metadata added to page data (ocr_used, ocr_confidence) - Automatic scanned page detection - Graceful fallback when Tesseract not installed - 8 PDF OCR integration tests passing</p>"},{"location":"ROADMAP_OCR/#test-results","title":"Test Results","text":"<ul> <li>387 tests passing (all document reader integrations)</li> <li>15 OCRProcessor tests (all core functionality)</li> <li>8 PDF OCR integration tests (initialization, pymupdf, pdfplumber, hybrid PDFs)</li> </ul>"},{"location":"ROADMAP_OCR/#files-modifiedcreated","title":"Files Modified/Created","text":"<ul> <li><code>pyproject.toml</code>: Added OCR dependencies</li> <li><code>wyn360_cli/document_readers.py</code> (+176 lines): OCRProcessor class and PDFReader integration</li> <li><code>tests/test_ocr_processor.py</code> (NEW, 275 lines): OCRProcessor unit tests</li> <li><code>tests/test_pdf_ocr_integration.py</code> (NEW, 331 lines): PDFReader OCR integration tests</li> </ul>"},{"location":"ROADMAP_OCR/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Automatic scanned PDF page detection</li> <li>\u2705 OCR text extraction with confidence scoring  </li> <li>\u2705 Support for both pymupdf and pdfplumber engines</li> <li>\u2705 Hybrid PDF support (mixed text and scanned pages)</li> <li>\u2705 Quality assessment (excellent/good/fair/poor)</li> <li>\u2705 Image preprocessing for accuracy</li> <li>\u2705 Graceful fallback when Tesseract unavailable</li> </ul>"},{"location":"ROADMAP_OCR/#performance","title":"Performance","text":"<ul> <li>Speed: ~1-2 seconds per page (300 DPI)</li> <li>Memory: ~50MB per page during processing</li> <li>No API costs: Runs locally with Tesseract</li> </ul>"},{"location":"ROADMAP_OCR/#next-steps","title":"Next Steps","text":"<ul> <li>Phase 5.4: Excel Enhancements (Charts, Pivot Tables, Formula Analysis)</li> <li>Phase 5.5: Multi-Document Queries</li> <li>Performance optimizations (Phase 5.6)</li> </ul> <p>Last Updated: January 2025 Implementation: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/","title":"Phase 5 Enhancements - Implementation Summary","text":"<p>This document provides a high-level summary of all Phase 5 enhancements with links to detailed implementation plans.</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#phase-51-vision-mode-for-images-completed-v0330","title":"Phase 5.1: Vision Mode for Images \u2705 COMPLETED (v0.3.30)","text":"<p>Status: \u2705 Implementation Complete Documentation: ROADMAP_VISION.md</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#key-features-delivered","title":"Key Features Delivered","text":"<ul> <li>\ud83d\uddbc\ufe0f ImageProcessor class with Claude Vision API</li> <li>\ud83d\udcca Chart, diagram, screenshot recognition</li> <li>\ud83d\udcb0 Separate vision cost tracking</li> <li>\ud83c\udfaf Three modes: skip, describe, vision</li> <li>\u26a1 Batch processing</li> <li>\ud83d\udccb 23 comprehensive tests, 359 total tests passing</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#phase-52-semantic-matching-completed-v0331","title":"Phase 5.2: Semantic Matching \u2705 COMPLETED (v0.3.31)","text":"<p>Status: \u2705 Implementation Complete Priority: High Duration: Completed Documentation: ROADMAP_SEMANTIC.md</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#overview","title":"Overview","text":"<p>Replace keyword-based chunk retrieval with embedding-based semantic search for significantly better retrieval accuracy.</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#key-features","title":"Key Features","text":"<ul> <li>\ud83e\udde0 sentence-transformers integration (all-MiniLM-L6-v2)</li> <li>\ud83d\udcca Compute embeddings for all chunks during summarization</li> <li>\ud83d\udd0d Cosine similarity for query-chunk matching</li> <li>\u26a1 Fallback to keyword matching if embeddings fail</li> <li>\ud83d\udcbe Cache embeddings alongside chunks</li> <li>\ud83d\udcc8 Performance benchmarking</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#implementation-phases","title":"Implementation Phases","text":"<ol> <li>5.2.1: Setup and Dependencies - Add embedding library, create EmbeddingModel class</li> <li>5.2.2: Chunk Embedding Generation - Compute embeddings during summarization</li> <li>5.2.3: Semantic Query Matching - Update query_chunks() with cosine similarity</li> <li>5.2.4: Cache Integration - Store embeddings with chunks</li> <li>5.2.5: Performance Benchmarking - Measure improvement vs keyword matching</li> </ol>"},{"location":"ROADMAP_PHASE5_SUMMARY/#success-metrics","title":"Success Metrics","text":"<ul> <li>\u2705 +30-50% improvement in retrieval accuracy</li> <li>\u2705 Query latency &lt; 50ms additional overhead</li> <li>\u2705 Memory usage &lt; 200MB additional</li> <li>\u2705 All existing tests pass + 15 new tests</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#phase-53-ocr-support-for-scanned-pdfs-completed-v0332","title":"Phase 5.3: OCR Support for Scanned PDFs \u2705 COMPLETED (v0.3.32)","text":"<p>Status: \u2705 Implementation Complete Priority: Medium Duration: Completed Documentation: ROADMAP_OCR.md</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#overview_1","title":"Overview","text":"<p>Enable text extraction from scanned PDFs using Tesseract OCR, making image-based documents searchable and analyzable.</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#key-features_1","title":"Key Features","text":"<ul> <li>\ud83d\udd0d Tesseract OCR integration (pytesseract wrapper)</li> <li>\ud83d\udcc4 Automatic scanned page detection</li> <li>\ud83c\udf0d Multi-language support (English, Spanish, French, etc.)</li> <li>\ud83d\udcca OCR confidence scoring and quality assessment</li> <li>\ud83d\uddbc\ufe0f Combines with Vision API for images</li> <li>\u26a1 Image preprocessing (deskew, denoise)</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#implementation-phases_1","title":"Implementation Phases","text":"<ol> <li>5.3.1: OCR Infrastructure - Add Tesseract, create OCRProcessor class</li> <li>5.3.2: PDFReader Integration - Detect and process scanned pages</li> <li>5.3.3: Quality &amp; Optimization - Language detection, preprocessing</li> <li>5.3.4: Testing &amp; Documentation - Comprehensive tests and docs</li> </ol>"},{"location":"ROADMAP_PHASE5_SUMMARY/#success-metrics_1","title":"Success Metrics","text":"<ul> <li>\u2705 &gt;80% OCR accuracy on clear scans</li> <li>\u2705 &lt;2s processing time per page</li> <li>\u2705 Accurate scanned page detection</li> <li>\u2705 Graceful fallback if Tesseract not installed</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#phase-54-excel-enhancements-completed-v0333","title":"Phase 5.4: Excel Enhancements \u2705 COMPLETED (v0.3.33)","text":"<p>Status: \u2705 Implementation Complete Priority: Medium Duration: Completed</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#overview_2","title":"Overview","text":"<p>Advanced Excel features beyond basic table reading - charts, named ranges, and formula tracking.</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#key-features-delivered_1","title":"Key Features Delivered","text":"<ul> <li>\ud83d\udcca Chart/Graph Extraction \u2705</li> <li>Extract chart metadata from Excel sheets</li> <li>Chart type, title, anchor position, series count</li> <li> <p>Opt-in via <code>extract_charts=True</code> parameter</p> </li> <li> <p>\ud83d\udcdb Named Ranges \u2705</p> </li> <li>Extract named ranges and their cell references</li> <li>Workbook-scoped named ranges</li> <li> <p>Opt-in via <code>extract_named_ranges=True</code> parameter</p> </li> <li> <p>\ud83e\uddee Formula Tracking \u2705</p> </li> <li>Track all formula cells in sheets</li> <li>Cell coordinates, formulas, sheet names</li> <li>Opt-in via <code>track_formulas=True</code> parameter</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#implementation-details","title":"Implementation Details","text":"<ol> <li>5.4.1: Chart Extraction - <code>_extract_charts()</code> method extracts chart metadata</li> <li>5.4.2: Named Ranges - <code>_extract_named_ranges()</code> method processes workbook.defined_names</li> <li>5.4.3: Formula Tracking - <code>_track_formulas()</code> method identifies formula cells</li> <li>5.4.4: Testing &amp; Documentation - 15 comprehensive tests, all passing</li> </ol>"},{"location":"ROADMAP_PHASE5_SUMMARY/#test-results","title":"Test Results","text":"<ul> <li>\u2705 15 new enhancement tests (chart extraction, named ranges, formulas)</li> <li>\u2705 14 existing Excel tests still passing</li> <li>\u2705 29 total Excel tests passing</li> <li>\u2705 All features backward compatible (opt-in via flags)</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#success-metrics_2","title":"Success Metrics","text":"<ul> <li>\u2705 Extract and describe charts from Excel files</li> <li>\u2705 Extract named ranges with cell references</li> <li>\u2705 Track all formula cells in workbooks</li> <li>\u2705 Handle complex workbooks with backward compatibility</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#phase-55-multi-document-queries-completed-v0334","title":"Phase 5.5: Multi-Document Queries \u2705 COMPLETED (v0.3.34)","text":"<p>Status: \u2705 Implementation Complete Priority: Low Duration: Completed</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#overview_3","title":"Overview","text":"<p>Query across multiple cached documents simultaneously, enabling cross-document analysis and comparison.</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#key-features_2","title":"Key Features","text":"<ul> <li>\ud83d\udd0d Unified Search</li> <li>Search across all cached documents at once</li> <li>Rank results by relevance across documents</li> <li> <p>Show which document each result came from</p> </li> <li> <p>\ud83d\udcca Document Comparison</p> </li> <li>\"Compare expenses.xlsx and budget.xlsx\"</li> <li>\"What changed between Q1_report.docx and Q2_report.docx?\"</li> <li> <p>Side-by-side comparison summaries</p> </li> <li> <p>\ud83d\udd17 Cross-Reference Detection</p> </li> <li>Identify when multiple documents mention same entities</li> <li>Link related information across documents</li> <li> <p>Build document relationship graph</p> </li> <li> <p>\ud83d\udce6 Aggregated Summaries</p> </li> <li>Summarize findings across multiple documents</li> <li>Extract common themes and patterns</li> <li> <p>Generate cross-document insights</p> </li> <li> <p>\ud83c\udfaf Smart Document Selection</p> </li> <li>Automatically select relevant documents for query</li> <li>\"Find all documents mentioning 'machine learning'\"</li> <li>Don't require user to specify which documents</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#implementation-summary","title":"Implementation Summary","text":"<p>MultiDocumentRetriever Class (~ 230 lines) - Added to <code>wyn360_cli/document_readers.py</code> at line 1560 - Integrates with existing ChunkCache and ChunkRetriever - 4 core methods for multi-document operations</p> <p>Key Methods: 1. <code>search_all_documents(query, top_k)</code> - Unified search across all cached documents 2. <code>compare_documents(file1, file2, aspect)</code> - Side-by-side document comparison 3. <code>find_cross_references(entity, min_mentions)</code> - Cross-document entity search 4. <code>list_cached_documents()</code> - List all cached documents with metadata</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#test-results_1","title":"Test Results","text":"<ul> <li>\u2705 12 comprehensive tests (all passing)</li> <li>\u2705 Tests cover: initialization, search, comparison, cross-references</li> <li>\u2705 Handles empty cache, missing documents, single and multiple documents</li> <li>\u2705 Works with both semantic and keyword matching</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#files-modified","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/document_readers.py</code>: +230 lines (MultiDocumentRetriever class)</li> <li><code>tests/test_multi_document_retriever.py</code>: NEW, 515 lines, 12 tests</li> <li><code>pyproject.toml</code>: version 0.3.33 \u2192 0.3.34</li> <li><code>docs/ROADMAP_PHASE5_SUMMARY.md</code>: Updated Phase 5.5 status</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#success-metrics-achieved","title":"Success Metrics Achieved","text":"<ul> <li>\u2705 Query across multiple cached documents efficiently</li> <li>\u2705 Accurate document comparison with metadata and diff metrics</li> <li>\u2705 Cross-reference detection across documents</li> <li>\u2705 Seamless integration with existing caching system</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#phase-56-performance-optimizations-ongoing","title":"Phase 5.6: Performance Optimizations \ud83d\udd04 ONGOING","text":"<p>Status: \ud83d\udccb High-Level Plan Priority: Ongoing Duration: Incremental improvements</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#overview_4","title":"Overview","text":"<p>Continuous performance improvements to reduce latency, memory usage, and processing time.</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#key-features_3","title":"Key Features","text":""},{"location":"ROADMAP_PHASE5_SUMMARY/#1-parallel-chunk-summarization","title":"1. Parallel Chunk Summarization","text":"<ul> <li>Current: Chunks summarized sequentially (1 by 1)</li> <li>Target: Parallel summarization using async/await</li> <li>Benefit: ~3-5x faster for large documents <pre><code># Current\nfor chunk in chunks:\n    summary = await summarize_chunk(chunk)\n\n# Optimized\nsummaries = await asyncio.gather(*[\n    summarize_chunk(chunk) for chunk in chunks\n])\n</code></pre></li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#2-streaming-for-large-files","title":"2. Streaming for Large Files","text":"<ul> <li>Current: Load entire file into memory</li> <li>Target: Stream and process incrementally</li> <li>Benefit: Handle GB-sized files without OOM</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#3-incremental-caching","title":"3. Incremental Caching","text":"<ul> <li>Current: Re-process entire document on any change</li> <li>Target: Only process changed pages/chunks</li> <li>Benefit: ~10x faster for updates to large docs</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#4-background-cache-warming","title":"4. Background Cache Warming","text":"<ul> <li>Current: Cache populated on-demand</li> <li>Target: Pre-compute summaries for frequently accessed docs</li> <li>Benefit: Instant results for common queries</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#5-compression-for-cached-data","title":"5. Compression for Cached Data","text":"<ul> <li>Current: JSON cached as plaintext</li> <li>Target: gzip compression for cache files</li> <li>Benefit: ~50-70% storage reduction</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#6-lru-cache-eviction","title":"6. LRU Cache Eviction","text":"<ul> <li>Current: Delete oldest files when cache full</li> <li>Target: Least-recently-used eviction strategy</li> <li>Benefit: Keep hot documents cached longer</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#7-performance-monitoring","title":"7. Performance Monitoring","text":"<ul> <li>Feature: Built-in profiling and metrics</li> <li>Metrics: Processing time, cache hit rate, token usage</li> <li>Benefit: Identify bottlenecks, optimize hot paths</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#implementation-approach","title":"Implementation Approach","text":"<ul> <li>Incremental improvements in each version</li> <li>Benchmark before/after each optimization</li> <li>No single \"performance release\" - ongoing effort</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#success-metrics_3","title":"Success Metrics","text":"<ul> <li>\u2705 50% reduction in document processing time</li> <li>\u2705 70% cache storage reduction with compression</li> <li>\u2705 Handle 100+ page documents without OOM</li> <li>\u2705 90%+ cache hit rate on repeated queries</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#phase-57-advanced-chunking-strategies-completed-v0335","title":"Phase 5.7: Advanced Chunking Strategies \u2705 COMPLETED (v0.3.35)","text":"<p>Status: \u2705 Implementation Complete Priority: Low Duration: Completed</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#overview_5","title":"Overview","text":"<p>Enhanced DocumentChunker with adaptive sizes, overlapping chunks, content-aware boundaries, and quality scoring.</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#key-features-delivered_2","title":"Key Features Delivered","text":""},{"location":"ROADMAP_PHASE5_SUMMARY/#1-adaptive-chunk-sizes","title":"1. Adaptive Chunk Sizes \u2705","text":"<ul> <li>\u2705 <code>_calculate_adaptive_size()</code> method analyzes content density</li> <li>\u2705 Dense content (tables, lists, code): smaller chunks (~500 tokens)</li> <li>\u2705 Sparse content (prose): larger chunks (~1500 tokens)</li> <li>\u2705 Opt-in via <code>adaptive_sizing=True</code> parameter</li> <li>\u2705 8 comprehensive tests, all passing</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#2-overlapping-chunks","title":"2. Overlapping Chunks \u2705","text":"<ul> <li>\u2705 <code>_chunk_with_overlap()</code> method creates overlapping chunks</li> <li>\u2705 Configurable overlap via <code>overlap_tokens</code> parameter</li> <li>\u2705 Preserves context across chunk boundaries</li> <li>\u2705 Example: chunk1: 0-1000, chunk2: 800-1800 (200 token overlap)</li> <li>\u2705 11 comprehensive tests, all passing</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#3-content-aware-boundaries","title":"3. Content-Aware Boundaries \u2705","text":"<ul> <li>\u2705 <code>_detect_content_blocks()</code> identifies tables, code blocks, lists</li> <li>\u2705 <code>_chunk_respecting_blocks()</code> avoids splitting semantic units</li> <li>\u2705 Detects and preserves:</li> <li>Markdown tables (| ... |)</li> <li>Code blocks (```)</li> <li>Lists (-, *, 1.)</li> <li>\u2705 Opt-in via <code>content_aware=True</code> parameter</li> <li>\u2705 14 comprehensive tests, all passing</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#4-chunk-quality-scoring","title":"4. Chunk Quality Scoring \u2705","text":"<ul> <li>\u2705 <code>score_chunk_quality()</code> scores chunks 0.0-1.0</li> <li>\u2705 Evaluates coherence, completeness, independence</li> <li>\u2705 <code>_apply_quality_filtering()</code> filters low-quality chunks</li> <li>\u2705 Opt-in via <code>quality_threshold</code> parameter (0.0-1.0)</li> <li>\u2705 17 comprehensive tests, all passing</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#implementation-summary_1","title":"Implementation Summary","text":"<p>DocumentChunker Class Enhancements (~450 lines added) - Modified <code>__init__()</code> to add 4 optional parameters - Added 6 new methods for advanced chunking - 100% backward compatible (all new features opt-in)</p> <p>New Parameters: <pre><code>DocumentChunker(\n    chunk_size=1000,           # Default\n    adaptive_sizing=False,      # Phase 5.7.1\n    overlap_tokens=0,           # Phase 5.7.2\n    content_aware=False,        # Phase 5.7.3\n    quality_threshold=0.0       # Phase 5.7.4\n)\n</code></pre></p> <p>New Methods: 1. <code>_calculate_adaptive_size(text)</code> - Calculate adaptive chunk size 2. <code>_chunk_with_overlap(text, target_chars)</code> - Create overlapping chunks 3. <code>_detect_content_blocks(text)</code> - Detect tables, code, lists 4. <code>_chunk_respecting_blocks(text, target_chars)</code> - Chunk respecting blocks 5. <code>score_chunk_quality(chunk)</code> - Score chunk quality (0.0-1.0) 6. <code>_apply_quality_filtering(chunks)</code> - Filter low-quality chunks</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#test-results_2","title":"Test Results","text":"<ul> <li>\u2705 50 new tests (8 adaptive + 11 overlap + 14 content-aware + 17 quality)</li> <li>\u2705 All 50 tests passing</li> <li>\u2705 100% backward compatibility (existing 437 tests still passing)</li> <li>\u2705 Integration tests verify all features work together</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#files-modified_1","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/document_readers.py</code>: DocumentChunker class enhanced (~450 lines added)</li> <li><code>tests/test_adaptive_chunking.py</code>: NEW, 213 lines, 8 tests</li> <li><code>tests/test_overlapping_chunks.py</code>: NEW, 222 lines, 11 tests</li> <li><code>tests/test_content_aware_chunking.py</code>: NEW, 303 lines, 14 tests</li> <li><code>tests/test_quality_scoring.py</code>: NEW, 309 lines, 17 tests</li> <li><code>pyproject.toml</code>: version 0.3.34 \u2192 0.3.35</li> <li><code>docs/ROADMAP_PHASE5_SUMMARY.md</code>: Updated Phase 5.7 status</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#success-metrics-achieved_1","title":"Success Metrics Achieved","text":"<ul> <li>\u2705 Adaptive sizing adjusts to content density</li> <li>\u2705 Overlapping chunks preserve context across boundaries</li> <li>\u2705 No split tables/code blocks/lists (content-aware)</li> <li>\u2705 Quality scoring identifies coherent, complete chunks</li> <li>\u2705 All features work together (integration tested)</li> <li>\u2705 100% backward compatible (opt-in only)</li> </ul>"},{"location":"ROADMAP_PHASE5_SUMMARY/#overall-phase-5-timeline","title":"\ud83d\udcca Overall Phase 5 Timeline","text":"Phase Priority Duration Version Status 5.1 Vision Mode High 3 weeks v0.3.30 \u2705 COMPLETE 5.2 Semantic Matching High 3 weeks v0.3.31 \u2705 COMPLETE 5.3 OCR Support Medium 3 weeks v0.3.32 \u2705 COMPLETE 5.4 Excel Enhancements Medium 2 weeks v0.3.33 \u2705 COMPLETE 5.5 Multi-Doc Queries Low 3 weeks v0.3.34 \u2705 COMPLETE 5.6 Performance Opts Ongoing Incremental Various \ud83d\udd04 ONGOING 5.7 Advanced Chunking Low Completed v0.3.35 \u2705 COMPLETE <p>Total Duration: 16 weeks completed</p>"},{"location":"ROADMAP_PHASE5_SUMMARY/#implementation-progress","title":"\ud83c\udfaf Implementation Progress","text":"<p>Given priorities and dependencies:</p> <ol> <li>\u2705 Phase 5.1 (COMPLETED v0.3.30) - Vision Mode</li> <li>\u2705 Phase 5.2 (COMPLETED v0.3.31) - Semantic Matching \u2192 Immediate value, no dependencies</li> <li>\u2705 Phase 5.3 (COMPLETED v0.3.32) - OCR Support \u2192 Complements Vision Mode</li> <li>\u2705 Phase 5.4 (COMPLETED v0.3.33) - Excel Enhancements \u2192 Charts, named ranges, formulas</li> <li>\u2705 Phase 5.5 (COMPLETED v0.3.34) - Multi-Document Queries \u2192 Cross-document search and comparison</li> <li>\u2705 Phase 5.7 (COMPLETED v0.3.35) - Advanced Chunking \u2192 Adaptive sizing, overlapping chunks, content-aware, quality scoring</li> <li>\ud83d\udd04 Phase 5.6 (ONGOING) - Performance optimizations alongside other work</li> </ol>"},{"location":"ROADMAP_PHASE5_SUMMARY/#documentation-index","title":"\ud83d\udcda Documentation Index","text":"<ul> <li>ROADMAP_DOCUMENTS.md - Main document readers roadmap</li> <li>ROADMAP_VISION.md - Phase 5.1 detailed plan (\u2705 IMPLEMENTED)</li> <li>ROADMAP_SEMANTIC.md - Phase 5.2 detailed plan</li> <li>ROADMAP_OCR.md - Phase 5.3 detailed plan</li> <li>ROADMAP_PHASE5_SUMMARY.md - This document</li> </ul> <p>Last Updated: January 2026 Document Version: 1.0 Maintained by: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"ROADMAP_SEMANTIC/","title":"WYN360 CLI - Semantic Matching Implementation Roadmap","text":"<p>Status: \u2705 Phase 5.2 - COMPLETED (v0.3.31) Priority: High Target Version: v0.3.31 Completion Date: January 2025</p>"},{"location":"ROADMAP_SEMANTIC/#executive-summary","title":"\ud83d\udccb Executive Summary","text":"<p>This roadmap outlines the implementation of Semantic Matching - a feature that replaces keyword-based chunk retrieval with embedding-based semantic search. This is the highest priority enhancement in Phase 5.2 of the Document Readers feature set.</p>"},{"location":"ROADMAP_SEMANTIC/#key-value-proposition","title":"Key Value Proposition","text":"<p>Current State: Chunk retrieval uses simple keyword matching on tags, which can miss relevant chunks if exact keywords don't match. Query: \"machine learning algorithms\" might miss chunks tagged with \"ML\", \"neural networks\", \"deep learning\".</p> <p>With Semantic Matching: Chunks are matched using semantic embeddings, understanding meaning rather than exact keywords. Queries like \"machine learning algorithms\" will match chunks about \"neural networks\", \"deep learning\", \"AI models\" even without exact keyword overlap.</p>"},{"location":"ROADMAP_SEMANTIC/#business-impact","title":"Business Impact","text":"<ul> <li>Better retrieval accuracy - Find relevant chunks even with different wording</li> <li>Natural language queries - Users can ask questions naturally without keyword engineering</li> <li>Cross-lingual potential - Embeddings can work across languages (future enhancement)</li> <li>Improved user experience - More relevant results, fewer \"no results found\"</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#goals-and-non-goals","title":"\ud83c\udfaf Goals and Non-Goals","text":""},{"location":"ROADMAP_SEMANTIC/#goals","title":"Goals","text":"<ol> <li>\u2705 Replace keyword matching with semantic embeddings</li> <li>\u2705 Integrate lightweight embedding model (sentence-transformers)</li> <li>\u2705 Compute embeddings for chunk summaries and tags</li> <li>\u2705 Use cosine similarity for query-chunk matching</li> <li>\u2705 Cache embeddings alongside chunks</li> <li>\u2705 Fallback to keyword matching if embeddings fail</li> <li>\u2705 Performance benchmarking vs keyword matching</li> <li>\u2705 Maintain backward compatibility</li> </ol>"},{"location":"ROADMAP_SEMANTIC/#non-goals","title":"Non-Goals","text":"<ol> <li>\u274c Training custom embedding models (use pre-trained)</li> <li>\u274c Vector databases (use in-memory numpy arrays for now)</li> <li>\u274c Re-ranking with cross-encoders (saved for future)</li> <li>\u274c Multi-lingual support (English only for v1)</li> <li>\u274c Query expansion or reformulation</li> </ol>"},{"location":"ROADMAP_SEMANTIC/#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":""},{"location":"ROADMAP_SEMANTIC/#component-diagram","title":"Component Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    WYN360 Agent                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502  read_word() / read_pdf() / read_excel()           \u2502     \u2502\n\u2502  \u2502  - Creates chunks with summaries and tags          \u2502     \u2502\n\u2502  \u2502  - NEW: Compute embeddings for chunks              \u2502     \u2502\n\u2502  \u2502  - Cache chunks + embeddings together              \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                   \u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502  Query Processing (with query string)              \u2502     \u2502\n\u2502  \u2502  - NEW: Compute query embedding                    \u2502     \u2502\n\u2502  \u2502  - NEW: Semantic similarity search                 \u2502     \u2502\n\u2502  \u2502  - Fallback: Keyword matching if embeddings fail   \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 EmbeddingModel  \u2502      \u2502  ChunkCache     \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502      \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502 \u2502 sentence  \u2502   \u2502      \u2502  \u2502 chunks +  \u2502  \u2502\n\u2502 \u2502 transform \u2502   \u2502      \u2502  \u2502 embeddings\u2502  \u2502\n\u2502 \u2502 ers       \u2502   \u2502      \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502      \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502      \u2502  \u2502 metadata  \u2502  \u2502\n\u2502 \u2502 cosine    \u2502   \u2502      \u2502  \u2502           \u2502  \u2502\n\u2502 \u2502 similarity\u2502   \u2502      \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ROADMAP_SEMANTIC/#data-flow","title":"Data Flow","text":"<pre><code>User: \"What are the key findings about neural networks?\"\n  \u2193\nAgent: compute_embedding(query)\n  \u2193\nEmbeddingModel: encode(\"What are the key findings about neural networks?\")\n  \u2193\nAgent: load cached chunks with embeddings\n  \u2193\nAgent: compute cosine_similarity(query_embedding, chunk_embeddings)\n  \u2193\nAgent: rank chunks by similarity score\n  \u2193\nAgent: retrieve top_k chunks (e.g., top 3)\n  \u2193\nAgent: pass chunks to LLM for answer generation\n  \u2193\nUser: receives answer based on most semantically relevant chunks\n</code></pre>"},{"location":"ROADMAP_SEMANTIC/#current-implementation-analysis","title":"\ud83d\udcca Current Implementation Analysis","text":""},{"location":"ROADMAP_SEMANTIC/#existing-keyword-matching-document_readerspy","title":"Existing Keyword Matching (document_readers.py)","text":"<p>Location: <code>ChunkSummarizer.query_chunks()</code> (lines ~830-900)</p> <p>Current Logic: <pre><code>def query_chunks(self, chunks: List[Dict], query: str, top_k: int = 3):\n    \"\"\"Find most relevant chunks using keyword matching.\"\"\"\n    query_terms = set(query.lower().split())\n\n    scores = []\n    for chunk in chunks:\n        # Simple keyword matching on tags\n        chunk_tags = set(tag.lower() for tag in chunk.get(\"tags\", []))\n        overlap = len(query_terms &amp; chunk_tags)\n        scores.append(overlap)\n\n    # Return top_k chunks by keyword overlap\n    # ...\n</code></pre></p> <p>Limitations: - Misses semantic relationships (\"ML\" vs \"machine learning\") - No understanding of synonyms or related concepts - Binary matching (keyword present or not) - Poor performance on natural language queries</p>"},{"location":"ROADMAP_SEMANTIC/#detailed-implementation-plan","title":"\ud83d\udd27 Detailed Implementation Plan","text":""},{"location":"ROADMAP_SEMANTIC/#phase-521-setup-and-dependencies-v0331","title":"Phase 5.2.1: Setup and Dependencies (v0.3.31)","text":"<p>Goal: Add embedding library and basic infrastructure</p>"},{"location":"ROADMAP_SEMANTIC/#implementation-steps","title":"Implementation Steps","text":"<p>Step 1: Add Dependencies to pyproject.toml</p> <pre><code>dependencies = [\n    # ... existing dependencies ...\n    \"sentence-transformers&gt;=2.2.0\",\n    \"torch&gt;=2.0.0\",  # Required by sentence-transformers\n    \"numpy&gt;=1.24.0\",  # For cosine similarity\n]\n</code></pre> <p>Step 2: Create EmbeddingModel Class</p> <p>Location: <code>wyn360_cli/document_readers.py</code> (new class)</p> <pre><code>class EmbeddingModel:\n    \"\"\"\n    Wrapper for sentence-transformers embedding model.\n\n    Uses a lightweight model for fast inference:\n    - all-MiniLM-L6-v2 (22MB, 384 dimensions)\n    - Fast inference (~0.01s per sentence)\n    - Good quality for semantic search\n    \"\"\"\n\n    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n        \"\"\"\n        Initialize embedding model.\n\n        Args:\n            model_name: HuggingFace model name\n        \"\"\"\n        self.model_name = model_name\n        self.model = None\n        self._initialized = False\n\n    def _lazy_load(self):\n        \"\"\"Lazy load model on first use.\"\"\"\n        if not self._initialized:\n            try:\n                from sentence_transformers import SentenceTransformer\n                self.model = SentenceTransformer(self.model_name)\n                self._initialized = True\n            except ImportError:\n                raise ImportError(\n                    \"sentence-transformers not installed. \"\n                    \"Install with: pip install sentence-transformers\"\n                )\n\n    def encode(self, texts: Union[str, List[str]]) -&gt; np.ndarray:\n        \"\"\"\n        Encode text(s) into embeddings.\n\n        Args:\n            texts: Single text or list of texts\n\n        Returns:\n            Embeddings as numpy array (n_texts, embedding_dim)\n        \"\"\"\n        self._lazy_load()\n\n        if isinstance(texts, str):\n            texts = [texts]\n\n        embeddings = self.model.encode(texts, convert_to_numpy=True)\n        return embeddings\n\n    def compute_similarity(\n        self,\n        query_embedding: np.ndarray,\n        chunk_embeddings: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Compute cosine similarity between query and chunks.\n\n        Args:\n            query_embedding: Query embedding (1, embedding_dim)\n            chunk_embeddings: Chunk embeddings (n_chunks, embedding_dim)\n\n        Returns:\n            Similarity scores (n_chunks,)\n        \"\"\"\n        # Normalize embeddings\n        query_norm = query_embedding / np.linalg.norm(query_embedding)\n        chunk_norms = chunk_embeddings / np.linalg.norm(\n            chunk_embeddings, axis=1, keepdims=True\n        )\n\n        # Cosine similarity\n        similarities = np.dot(chunk_norms, query_norm.T).flatten()\n        return similarities\n</code></pre>"},{"location":"ROADMAP_SEMANTIC/#files-modified","title":"Files Modified","text":"<ul> <li><code>pyproject.toml</code> - Add dependencies</li> <li><code>wyn360_cli/document_readers.py</code> - Add EmbeddingModel class (~150 lines)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#tests-required","title":"Tests Required","text":"<ul> <li><code>test_embedding_model.py</code>:</li> <li><code>test_model_initialization()</code> - Lazy loading</li> <li><code>test_encode_single_text()</code> - Single text encoding</li> <li><code>test_encode_multiple_texts()</code> - Batch encoding</li> <li><code>test_compute_similarity()</code> - Cosine similarity</li> <li><code>test_model_not_installed()</code> - ImportError handling</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#phase-522-chunk-embedding-generation-v0331","title":"Phase 5.2.2: Chunk Embedding Generation (v0.3.31)","text":"<p>Goal: Compute embeddings for chunks during summarization</p>"},{"location":"ROADMAP_SEMANTIC/#implementation-steps_1","title":"Implementation Steps","text":"<p>Step 1: Update ChunkSummarizer to Compute Embeddings</p> <p>Location: <code>wyn360_cli/document_readers.py</code> (modify ChunkSummarizer)</p> <pre><code>class ChunkSummarizer:\n    \"\"\"Summarize chunks with LLM and generate embeddings.\"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        model: str = \"claude-3-5-haiku-20241022\",\n        enable_embeddings: bool = True  # NEW PARAMETER\n    ):\n        # ... existing initialization ...\n        self.enable_embeddings = enable_embeddings\n        self.embedding_model = None\n\n        if self.enable_embeddings:\n            try:\n                self.embedding_model = EmbeddingModel()\n            except ImportError:\n                # Fallback to keyword matching\n                self.enable_embeddings = False\n\n    async def summarize_chunks(\n        self,\n        chunks: List[Dict[str, Any]]\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Summarize chunks and compute embeddings.\n\n        Returns:\n            List of chunks with summaries, tags, and embeddings\n        \"\"\"\n        # ... existing summarization logic ...\n\n        # NEW: Compute embeddings after summarization\n        if self.enable_embeddings and self.embedding_model:\n            # Combine summary and tags for embedding\n            texts_to_embed = []\n            for chunk in summarized_chunks:\n                summary = chunk[\"summary\"]\n                tags = \", \".join(chunk[\"tags\"])\n                combined_text = f\"{summary} | {tags}\"\n                texts_to_embed.append(combined_text)\n\n            # Batch encode all chunks\n            embeddings = self.embedding_model.encode(texts_to_embed)\n\n            # Add embeddings to chunks\n            for chunk, embedding in zip(summarized_chunks, embeddings):\n                chunk[\"embedding\"] = embedding.tolist()  # Convert to list for JSON\n\n        return summarized_chunks\n</code></pre>"},{"location":"ROADMAP_SEMANTIC/#files-modified_1","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/document_readers.py</code> - Update ChunkSummarizer (~50 lines)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#tests-required_1","title":"Tests Required","text":"<ul> <li><code>test_chunk_summarizer.py</code> (update existing):</li> <li><code>test_summarize_chunks_with_embeddings()</code> - Embeddings added</li> <li><code>test_summarize_chunks_without_embeddings()</code> - Fallback</li> <li><code>test_embedding_format()</code> - Verify embedding shape</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#phase-523-semantic-query-matching-v0332","title":"Phase 5.2.3: Semantic Query Matching (v0.3.32)","text":"<p>Goal: Replace keyword matching with semantic search</p>"},{"location":"ROADMAP_SEMANTIC/#implementation-steps_2","title":"Implementation Steps","text":"<p>Step 1: Update query_chunks() Method</p> <p>Location: <code>wyn360_cli/document_readers.py</code> (modify ChunkSummarizer)</p> <pre><code>def query_chunks(\n    self,\n    chunks: List[Dict[str, Any]],\n    query: str,\n    top_k: int = 3,\n    similarity_threshold: float = 0.3  # NEW PARAMETER\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Find most relevant chunks using semantic similarity.\n\n    Args:\n        chunks: List of chunks with embeddings\n        query: User query\n        top_k: Number of chunks to return\n        similarity_threshold: Minimum similarity score (0-1)\n\n    Returns:\n        Top-k most relevant chunks\n    \"\"\"\n    if not chunks:\n        return []\n\n    # Check if embeddings are available\n    has_embeddings = all(\"embedding\" in chunk for chunk in chunks)\n\n    if has_embeddings and self.enable_embeddings and self.embedding_model:\n        # SEMANTIC MATCHING\n        # Encode query\n        query_embedding = self.embedding_model.encode(query)\n\n        # Extract chunk embeddings\n        chunk_embeddings = np.array([\n            chunk[\"embedding\"] for chunk in chunks\n        ])\n\n        # Compute similarities\n        similarities = self.embedding_model.compute_similarity(\n            query_embedding, chunk_embeddings\n        )\n\n        # Filter by threshold and rank\n        scored_chunks = [\n            (chunk, score)\n            for chunk, score in zip(chunks, similarities)\n            if score &gt;= similarity_threshold\n        ]\n        scored_chunks.sort(key=lambda x: x[1], reverse=True)\n\n        # Return top_k\n        top_chunks = [chunk for chunk, score in scored_chunks[:top_k]]\n\n        # Add similarity scores to chunks (for debugging)\n        for chunk, (_, score) in zip(top_chunks, scored_chunks[:top_k]):\n            chunk[\"similarity_score\"] = float(score)\n\n        return top_chunks\n\n    else:\n        # FALLBACK: KEYWORD MATCHING\n        query_terms = set(query.lower().split())\n\n        scores = []\n        for chunk in chunks:\n            chunk_tags = set(tag.lower() for tag in chunk.get(\"tags\", []))\n            overlap = len(query_terms &amp; chunk_tags)\n            scores.append((chunk, overlap))\n\n        # Sort by overlap and return top_k\n        scores.sort(key=lambda x: x[1], reverse=True)\n        return [chunk for chunk, _ in scores[:top_k]]\n</code></pre> <p>Step 2: Update Agent to Use Semantic Matching</p> <p>Location: <code>wyn360_cli/agent.py</code> (no changes needed!)</p> <p>The agent already calls <code>query_chunks()</code>, so semantic matching will be automatic.</p>"},{"location":"ROADMAP_SEMANTIC/#files-modified_2","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/document_readers.py</code> - Update query_chunks() (~80 lines)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#tests-required_2","title":"Tests Required","text":"<ul> <li><code>test_semantic_matching.py</code> (NEW):</li> <li><code>test_semantic_query_basic()</code> - Simple semantic match</li> <li><code>test_semantic_query_synonyms()</code> - \"ML\" matches \"machine learning\"</li> <li><code>test_semantic_query_concepts()</code> - Related concepts match</li> <li><code>test_keyword_fallback()</code> - Falls back without embeddings</li> <li><code>test_similarity_threshold()</code> - Filters low-similarity chunks</li> <li><code>test_empty_query()</code> - Handle empty queries</li> <li><code>test_top_k_limit()</code> - Respects top_k parameter</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#phase-524-cache-integration-v0332","title":"Phase 5.2.4: Cache Integration (v0.3.32)","text":"<p>Goal: Cache embeddings alongside chunks</p>"},{"location":"ROADMAP_SEMANTIC/#implementation-steps_3","title":"Implementation Steps","text":"<p>Step 1: Update ChunkCache to Store Embeddings</p> <p>Location: <code>wyn360_cli/document_readers.py</code> (modify ChunkCache)</p> <p>No changes needed! Embeddings are already part of chunk dictionaries, so they'll be automatically cached with chunks.</p> <p>Step 2: Verify Cache Size Impact</p> <p>Embeddings add ~1.5KB per chunk (384 floats \u00d7 4 bytes): - Before: ~500 bytes per chunk (summary + tags) - After: ~2KB per chunk (summary + tags + embedding) - Impact: ~4x cache size increase</p> <p>This is acceptable given the performance benefits.</p>"},{"location":"ROADMAP_SEMANTIC/#files-modified_3","title":"Files Modified","text":"<ul> <li>None (embeddings already cached)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#tests-required_3","title":"Tests Required","text":"<ul> <li><code>test_chunk_cache.py</code> (update existing):</li> <li><code>test_cache_with_embeddings()</code> - Embeddings persist</li> <li><code>test_cache_size_with_embeddings()</code> - Verify size increase</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#phase-525-performance-benchmarking-v0332","title":"Phase 5.2.5: Performance Benchmarking (v0.3.32)","text":"<p>Goal: Measure improvement over keyword matching</p>"},{"location":"ROADMAP_SEMANTIC/#implementation-steps_4","title":"Implementation Steps","text":"<p>Step 1: Create Benchmark Script</p> <p>Location: <code>tests/benchmark_semantic_matching.py</code> (NEW)</p> <pre><code>\"\"\"\nBenchmark semantic matching vs keyword matching.\n\nTests:\n1. Retrieval accuracy (manual evaluation on test queries)\n2. Query latency (time to retrieve chunks)\n3. Memory usage (with/without embeddings)\n4. Cache size impact\n\"\"\"\n\nimport time\nimport pytest\nfrom wyn360_cli.document_readers import ChunkSummarizer, EmbeddingModel\n\n\ndef test_retrieval_accuracy():\n    \"\"\"Compare semantic vs keyword matching on test queries.\"\"\"\n    # Test queries with expected results\n    test_cases = [\n        {\n            \"query\": \"machine learning algorithms\",\n            \"expected_tags\": [\"ML\", \"neural networks\", \"deep learning\"],\n            \"unexpected_tags\": [\"database\", \"frontend\"],\n        },\n        {\n            \"query\": \"financial performance metrics\",\n            \"expected_tags\": [\"revenue\", \"profit\", \"earnings\"],\n            \"unexpected_tags\": [\"marketing\", \"HR\"],\n        },\n    ]\n\n    # ... benchmark logic ...\n\n\ndef test_query_latency():\n    \"\"\"Measure query time for semantic vs keyword.\"\"\"\n    # ... timing benchmarks ...\n\n\ndef test_memory_usage():\n    \"\"\"Measure memory usage with embeddings.\"\"\"\n    # ... memory profiling ...\n</code></pre> <p>Step 2: Run Benchmarks and Document Results</p> <p>Add benchmark results to ROADMAP_SEMANTIC.md.</p>"},{"location":"ROADMAP_SEMANTIC/#files-modified_4","title":"Files Modified","text":"<ul> <li><code>tests/benchmark_semantic_matching.py</code> (NEW, ~200 lines)</li> <li><code>docs/ROADMAP_SEMANTIC.md</code> - Add benchmark results</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#tests-required_4","title":"Tests Required","text":"<ul> <li>Benchmark scripts (not pytest tests)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#cost-analysis","title":"\ud83d\udcb0 Cost Analysis","text":""},{"location":"ROADMAP_SEMANTIC/#computational-costs","title":"Computational Costs","text":"<p>Embedding Model: - Model: all-MiniLM-L6-v2 (22MB download) - Inference: ~0.01s per sentence (CPU) - Memory: ~100MB loaded in memory</p> <p>Per-Document Costs: - 10-page document \u2192 ~20 chunks - Embedding time: ~0.2s (20 chunks \u00d7 0.01s) - Storage: ~40KB (20 chunks \u00d7 2KB)</p> <p>No API Costs: Embeddings computed locally, no additional API charges!</p>"},{"location":"ROADMAP_SEMANTIC/#performance-impact","title":"Performance Impact","text":"<p>Pros: - Better retrieval accuracy (estimated +30-50% relevance) - Natural language queries work better - No ongoing API costs</p> <p>Cons: - Initial embedding time (~0.2s per document) - Increased cache size (~4x) - Requires torch/transformers libraries (~500MB)</p>"},{"location":"ROADMAP_SEMANTIC/#success-criteria","title":"\u2705 Success Criteria","text":""},{"location":"ROADMAP_SEMANTIC/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>\u2705 Semantic matching replaces keyword matching</li> <li>\u2705 Embeddings computed for all chunks</li> <li>\u2705 Query-chunk similarity computed correctly</li> <li>\u2705 Fallback to keyword matching if embeddings fail</li> <li>\u2705 All existing tests continue to pass</li> <li>\u2705 New semantic matching tests pass</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#quality-requirements","title":"Quality Requirements","text":"<ul> <li>\u2705 Retrieval accuracy improves by 30%+ (benchmark)</li> <li>\u2705 Query latency &lt; 50ms (acceptable overhead)</li> <li>\u2705 Memory usage &lt; 200MB additional</li> <li>\u2705 Cache size increase &lt; 5x</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#documentation-requirements","title":"Documentation Requirements","text":"<ul> <li>\u2705 ROADMAP_SEMANTIC.md with implementation details</li> <li>\u2705 Benchmark results documented</li> <li>\u2705 README.md updated with semantic matching info</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#implementation-timeline","title":"\ud83d\uddd3\ufe0f Implementation Timeline","text":""},{"location":"ROADMAP_SEMANTIC/#week-1-infrastructure-phase-521-522","title":"Week 1: Infrastructure (Phase 5.2.1-5.2.2)","text":"<ul> <li>Days 1-2: Add dependencies, create EmbeddingModel class</li> <li>Days 3-4: Update ChunkSummarizer to compute embeddings</li> <li>Day 5: Testing embedding generation</li> </ul> <p>Deliverable: Chunks have embeddings</p>"},{"location":"ROADMAP_SEMANTIC/#week-2-semantic-matching-phase-523-524","title":"Week 2: Semantic Matching (Phase 5.2.3-5.2.4)","text":"<ul> <li>Days 1-2: Update query_chunks() with semantic matching</li> <li>Days 3-4: Integration testing with agent</li> <li>Day 5: Cache integration and testing</li> </ul> <p>Deliverable: Semantic matching working end-to-end</p>"},{"location":"ROADMAP_SEMANTIC/#week-3-benchmarking-polish-phase-525","title":"Week 3: Benchmarking &amp; Polish (Phase 5.2.5)","text":"<ul> <li>Days 1-2: Performance benchmarking</li> <li>Days 3-4: Documentation updates</li> <li>Day 5: Code review and release</li> </ul> <p>Deliverable: Production-ready semantic matching</p>"},{"location":"ROADMAP_SEMANTIC/#total-estimate-3-weeks-15-development-days","title":"Total Estimate: 3 weeks (15 development days)","text":""},{"location":"ROADMAP_SEMANTIC/#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":""},{"location":"ROADMAP_SEMANTIC/#unit-tests-15-new-tests","title":"Unit Tests (~15 new tests)","text":"<p>EmbeddingModel (5 tests): - Model initialization and lazy loading - Single and batch text encoding - Cosine similarity computation - Error handling (model not installed) - Edge cases (empty texts, special characters)</p> <p>ChunkSummarizer (5 tests): - Embedding generation during summarization - Fallback when embeddings disabled - Embedding format and shape validation - Cache integration with embeddings - Performance with large chunk counts</p> <p>Semantic Matching (5 tests): - Basic semantic query matching - Synonym and concept matching - Similarity threshold filtering - Keyword fallback when no embeddings - Top-k ranking correctness</p>"},{"location":"ROADMAP_SEMANTIC/#integration-tests-3-tests","title":"Integration Tests (~3 tests)","text":"<ul> <li>End-to-end document reading with semantic queries</li> <li>Cache persistence with embeddings</li> <li>Fallback behavior when model unavailable</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#benchmark-tests-3-scripts","title":"Benchmark Tests (~3 scripts)","text":"<ul> <li>Retrieval accuracy comparison</li> <li>Query latency measurement</li> <li>Memory usage profiling</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#risk-mitigation","title":"\ud83d\udd12 Risk Mitigation","text":""},{"location":"ROADMAP_SEMANTIC/#technical-risks","title":"Technical Risks","text":"Risk Probability Impact Mitigation Model download slow/fails Medium High Bundle model with package, provide fallback Embeddings too slow Low Medium Use lightweight model, benchmark early Memory usage too high Low Medium Lazy load model, optimize embedding storage Poor retrieval accuracy Low High Benchmark vs keyword matching, tune threshold"},{"location":"ROADMAP_SEMANTIC/#user-experience-risks","title":"User Experience Risks","text":"Risk Probability Impact Mitigation Breaking changes Low High Maintain keyword fallback, comprehensive testing Unexpected dependencies Medium Medium Clear documentation, optional dependency Cache size explosion Low Medium Monitor cache sizes, add cleanup logic"},{"location":"ROADMAP_SEMANTIC/#references","title":"\ud83d\udcda References","text":""},{"location":"ROADMAP_SEMANTIC/#libraries","title":"Libraries","text":"<ul> <li>sentence-transformers - Embedding models</li> <li>all-MiniLM-L6-v2 - Model choice</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#related-files","title":"Related Files","text":"<ul> <li><code>wyn360_cli/document_readers.py</code> - Core implementation</li> <li><code>wyn360_cli/agent.py</code> - Agent integration</li> <li><code>docs/ROADMAP_DOCUMENTS.md</code> - Parent roadmap</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#next-steps","title":"\ud83c\udfaf Next Steps","text":""},{"location":"ROADMAP_SEMANTIC/#immediate-actions","title":"Immediate Actions","text":"<ol> <li>\u2705 Create this roadmap document</li> <li>\u23f3 User review and approval of plan</li> <li>\u23f3 Begin Week 1: Infrastructure setup</li> <li>\u23f3 Daily progress updates</li> <li>\u23f3 Continuous testing as features are added</li> </ol>"},{"location":"ROADMAP_SEMANTIC/#decision-points","title":"Decision Points","text":"<p>Before starting implementation, confirm: - \u2705 sentence-transformers dependency acceptable (~500MB) - \u2705 Cache size increase acceptable (~4x) - \u2705 3-week timeline acceptable - \u2705 Approach aligns with project goals</p> <p>Last Updated: January 2026 Document Version: 1.0 Maintained by: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"ROADMAP_SEMANTIC/#implementation-summary-v0331","title":"\u2705 Implementation Summary (v0.3.31)","text":""},{"location":"ROADMAP_SEMANTIC/#completed-features","title":"Completed Features","text":"<p>Phase 5.2.1: EmbeddingModel Class \u2713 - Implemented EmbeddingModel with support for local (sentence-transformers) and Claude (placeholder) - Security whitelist: all-MiniLM-L6-v2, all-mpnet-base-v2, paraphrase-MiniLM-L6-v2, multi-qa-MiniLM-L6-cos-v1 - Lazy loading for performance - encode() and compute_similarity() methods - 10/17 tests passing (core validation tests)</p> <p>Phase 5.2.2: Chunk Embedding Generation \u2713 - ChunkSummarizer.add_embeddings_to_chunks() method - Embeddings generated from summary + tags - Batch processing for efficiency - JSON-serializable embeddings (List[float]) - Integrated with ExcelReader, WordReader, PDFReader - ChunkMetadata.embedding field added</p> <p>Phase 5.2.3: Semantic Query Matching \u2713 - ChunkRetriever._semantic_match() method - Cosine similarity-based ranking - Automatic fallback to keyword matching - similarity_threshold parameter (default: 0.3) - Integrated with all document readers in agent.py</p>"},{"location":"ROADMAP_SEMANTIC/#test-results","title":"Test Results","text":"<ul> <li>379 tests passing (all document reader integrations)</li> <li>10 Excel integration tests created and passing</li> <li>7 embedding model tests have mocking issues (non-blocking)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#files-modified_5","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/document_readers.py</code> (+368 lines): EmbeddingModel, ChunkSummarizer, ChunkRetriever updates</li> <li><code>wyn360_cli/agent.py</code> (+84 lines): Integration with all document readers</li> <li><code>tests/test_embedding_model.py</code> (NEW, 284 lines): Unit tests</li> <li><code>tests/test_excel_embedding_integration.py</code> (NEW, 236 lines): Integration tests</li> <li><code>pyproject.toml</code>: Added dependencies (sentence-transformers, torch, numpy)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#performance-impact_1","title":"Performance Impact","text":"<ul> <li>No API costs: Embeddings computed locally</li> <li>Memory: ~200MB for model (all-MiniLM-L6-v2)</li> <li>Latency: ~50ms per batch of chunks</li> <li>Cache storage: +1.5KB per chunk (384-dim embeddings)</li> </ul>"},{"location":"ROADMAP_SEMANTIC/#next-steps_1","title":"Next Steps","text":"<ul> <li>Phase 5.3: OCR Support for Scanned PDFs</li> <li>Phase 5.4: Excel Enhancements (Charts, Pivot Tables)</li> <li>Performance optimizations (Phase 5.6)</li> </ul> <p>Last Updated: January 2025 Implementation: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"ROADMAP_VISION/","title":"WYN360 CLI - Vision Mode Implementation Roadmap","text":"<p>Status: \u2705 Phase 5.1 - Implementation Complete (Documentation in Progress) Priority: High (Phase 5.1) Start Date: November 2025 Completion Date: January 2026</p>"},{"location":"ROADMAP_VISION/#executive-summary","title":"\ud83d\udccb Executive Summary","text":"<p>This roadmap outlines the implementation of Vision Mode - a feature that enables intelligent image processing in Word and PDF documents using Claude's Vision API. This is the highest priority enhancement in Phase 5 of the Document Readers feature set.</p>"},{"location":"ROADMAP_VISION/#key-value-proposition","title":"Key Value Proposition","text":"<p>Current State: Documents with images show only placeholders like <code>[Image]</code> or are completely skipped, losing valuable information from charts, diagrams, and visual content.</p> <p>With Vision Mode: Images are automatically sent to Claude Vision API for intelligent description, extracting insights from: - \ud83d\udcca Charts and graphs (data visualizations) - \ud83d\udcd0 Diagrams and flowcharts (process flows, architectures) - \ud83d\udda5\ufe0f Screenshots (UI mockups, interfaces) - \ud83d\udcf7 Photos and illustrations (visual documentation)</p>"},{"location":"ROADMAP_VISION/#business-impact","title":"Business Impact","text":"<ul> <li>Better comprehension of visual-heavy documents (reports, presentations, technical docs)</li> <li>Accessibility for users who can't see images</li> <li>Searchability - image content becomes text-searchable through summaries</li> <li>Cost transparency - separate tracking of vision API costs vs. text processing</li> </ul>"},{"location":"ROADMAP_VISION/#goals-and-non-goals","title":"\ud83c\udfaf Goals and Non-Goals","text":""},{"location":"ROADMAP_VISION/#goals","title":"Goals","text":"<ol> <li>\u2705 Extract images from Word (.docx) and PDF documents</li> <li>\u2705 Send images to Claude Vision API for intelligent description</li> <li>\u2705 Support three image handling modes:</li> <li><code>skip</code> - Ignore images (current default, no API calls)</li> <li><code>describe</code> - Extract alt text/captions only (no API calls)</li> <li><code>vision</code> - Full Vision API processing (requires API calls, costs money)</li> <li>\u2705 Track vision API costs separately from text summarization</li> <li>\u2705 Provide clear cost warnings to users before processing</li> <li>\u2705 Support batch processing for efficiency</li> <li>\u2705 Integrate seamlessly with existing chunking/caching system</li> <li>\u2705 Maintain backward compatibility (no breaking changes)</li> </ol>"},{"location":"ROADMAP_VISION/#non-goals","title":"Non-Goals","text":"<ol> <li>\u274c OCR for scanned PDFs (saved for Phase 5.2)</li> <li>\u274c Image editing or manipulation</li> <li>\u274c Video or animation processing</li> <li>\u274c Chart data extraction (just descriptions)</li> <li>\u274c Local image processing (all processing via Claude Vision API)</li> </ol>"},{"location":"ROADMAP_VISION/#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":""},{"location":"ROADMAP_VISION/#component-diagram","title":"Component Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    WYN360 Agent                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502  read_word() / read_pdf()                          \u2502     \u2502\n\u2502  \u2502  - Check image_handling_mode                       \u2502     \u2502\n\u2502  \u2502  - Warn user about costs if vision mode           \u2502     \u2502\n\u2502  \u2502  - Track vision tokens separately                 \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  WordReader     \u2502      \u2502  PDFReader      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502      \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Extract   \u2502  \u2502      \u2502  \u2502 Extract   \u2502  \u2502\n\u2502  \u2502 images    \u2502  \u2502      \u2502  \u2502 images    \u2502  \u2502\n\u2502  \u2502 from docx \u2502  \u2502      \u2502  \u2502 from PDF  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2502      \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                        \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502 ImageProcessor   \u2502\n         \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n         \u2502 \u2502 Vision API   \u2502 \u2502\n         \u2502 \u2502 Integration  \u2502 \u2502\n         \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n         \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n         \u2502 \u2502 Image Format \u2502 \u2502\n         \u2502 \u2502 Detection    \u2502 \u2502\n         \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n         \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n         \u2502 \u2502 Type         \u2502 \u2502\n         \u2502 \u2502 Detection    \u2502 \u2502\n         \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502 Claude Vision    \u2502\n         \u2502 API              \u2502\n         \u2502 (Sonnet 4.5)     \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ROADMAP_VISION/#data-flow","title":"Data Flow","text":"<pre><code>User: \"Read presentation.docx with vision mode\"\n  \u2193\nAgent: check image_handling_mode = \"vision\"\n  \u2193\nAgent: Warn user about vision API costs\n  \u2193\nWordReader: read document\n  \u2193\nWordReader: extract_images() \u2192 List[ImageData]\n  \u2193\nImageProcessor: describe_images_batch()\n  \u2193\nClaude Vision API: process each image\n  \u2193\nImageProcessor: return descriptions\n  \u2193\nWordReader: insert descriptions into markdown\n  \u2193\nChunkSummarizer: summarize chunks (including image descriptions)\n  \u2193\nChunkCache: cache results\n  \u2193\nAgent: format output, track costs\n  \u2193\nUser: receives document with image descriptions\n</code></pre>"},{"location":"ROADMAP_VISION/#current-implementation-status","title":"\ud83d\udcca Current Implementation Status","text":""},{"location":"ROADMAP_VISION/#completed-lines-122-349-in-document_readerspy","title":"\u2705 Completed (Lines 122-349 in document_readers.py)","text":"<p>ImageProcessor Class: - \u2705 Vision API integration (line 157-243) - \u2705 Image format detection (line 272-293) - \u2705 Context-aware prompts (line 295-319) - \u2705 Image type detection (line 321-334) - \u2705 Markdown formatting (line 336-349) - \u2705 Batch processing support (line 245-270) - \u2705 Error handling with fallbacks - \u2705 Token tracking</p> <p>Dependencies Added: - \u2705 <code>base64</code> - Image encoding - \u2705 <code>io</code> - BytesIO for image handling - \u2705 <code>PIL/Pillow</code> - Optional, for format detection (HAS_PIL flag)</p> <p>Phase 5.1.1 - WordReader Enhancement: - \u2705 <code>_extract_images()</code> method (lines 1633-1679) - \u2705 <code>_process_images_with_vision()</code> method (lines 1681-1720) - \u2705 Updated <code>read()</code> to async with vision support (line 1428) - \u2705 5 new tests added to test_word_reader.py - \u2705 All 336 tests passing</p> <p>Phase 5.1.2 - PDFReader Enhancement: - \u2705 Added <code>image_handling</code> parameter to PDFReader.init() - \u2705 Updated <code>read()</code> to async with image_processor parameter - \u2705 <code>_extract_images_pymupdf()</code> method (lines 2137-2177) - \u2705 <code>_extract_images_pdfplumber()</code> method (lines 2179-2216) - \u2705 <code>_process_images_with_vision()</code> method (lines 2218-2260) - \u2705 Updated <code>_read_with_pymupdf()</code> to async with image extraction - \u2705 Updated <code>_read_with_pdfplumber()</code> to async with image extraction - \u2705 All 8 PDFReader tests updated to async - \u2705 All 336 tests passing</p> <p>Phase 5.1.3 - Agent Integration (v0.3.30): - \u2705 Added vision token tracking fields to Agent.init() (lines 99-102) - \u2705 Added ImageProcessor import to agent.py - \u2705 Created track_vision_processing() method (lines 2931-2942) - \u2705 Updated read_word() to use ImageProcessor when vision mode enabled (lines 2284-2301) - \u2705 Updated read_pdf() with image_handling parameter (line 2421) - \u2705 Updated read_pdf() to use ImageProcessor (lines 2553-2570) - \u2705 Updated get_token_stats() to calculate and return vision costs (lines 3001-3035) - \u2705 Updated /tokens command in cli.py to display vision API stats (lines 274-284) - \u2705 All existing tests continue to pass</p> <p>Phase 5.1.4 - Testing (v0.3.30): - \u2705 Created test_image_processor.py with 23 comprehensive tests - \u2705 Tests cover format detection (PNG, JPEG, GIF, WebP, unknown) - \u2705 Tests cover image type detection (chart, diagram, screenshot, photo, other) - \u2705 Tests cover prompt building with/without context - \u2705 Tests cover markdown formatting for all image types - \u2705 Tests cover Vision API integration (success, error handling, batch processing) - \u2705 All 359 tests passing (336 existing + 23 new)</p>"},{"location":"ROADMAP_VISION/#remaining-work","title":"\ud83d\udea7 Remaining Work","text":"<ol> <li>Phase 5.1.5 - Documentation (~50 lines) - IN PROGRESS</li> <li>Update README.md with vision mode examples</li> <li>Update COST.md with vision pricing</li> <li>Update ROADMAP_DOCUMENTS.md with Phase 5.1 completion</li> <li>Add cost calculator examples</li> <li>Update USE_CASES.md</li> <li>Update version numbers to 0.3.30</li> </ol>"},{"location":"ROADMAP_VISION/#detailed-implementation-plan","title":"\ud83d\udd27 Detailed Implementation Plan","text":""},{"location":"ROADMAP_VISION/#phase-511-wordreader-image-extraction-v0330","title":"Phase 5.1.1: WordReader Image Extraction (v0.3.30)","text":"<p>Goal: Extract images from Word documents and integrate with vision mode</p>"},{"location":"ROADMAP_VISION/#implementation-steps","title":"Implementation Steps","text":"<p>Step 1: Add Image Extraction Method to WordReader</p> <p>Location: <code>wyn360_cli/document_readers.py</code> (after line 1327, in WordReader class)</p> <pre><code>def _extract_images(self, doc) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Extract all images from Word document.\n\n    Returns:\n        List of image dicts with {\n            \"data\": bytes,\n            \"format\": \"png\"|\"jpeg\"|\"gif\",\n            \"context\": {\"section\": \"...\", \"index\": N}\n        }\n    \"\"\"\n    images = []\n\n    # Method 1: Inline shapes (document.inline_shapes)\n    for idx, shape in enumerate(doc.inline_shapes):\n        try:\n            # Get image bytes\n            image_bytes = shape._inline.graphic.graphicData.pic.blipFill.blip.embed\n            image_part = doc.part.related_parts[image_bytes]\n            image_data = image_part.blob\n\n            # Detect format from content type\n            content_type = image_part.content_type  # 'image/png', 'image/jpeg', etc.\n            image_format = content_type.split('/')[-1] if '/' in content_type else 'png'\n\n            images.append({\n                \"data\": image_data,\n                \"format\": image_format,\n                \"context\": {\n                    \"doc_type\": \"word\",\n                    \"index\": idx,\n                    \"shape_type\": \"inline\"\n                }\n            })\n        except Exception as e:\n            # Skip images that can't be extracted\n            continue\n\n    return images\n</code></pre> <p>Step 2: Integrate Vision Processing in _extract_sections()</p> <p>Modify <code>_extract_sections()</code> to detect images and process them if vision mode enabled:</p> <pre><code># In _extract_sections(), after line 1289 (paragraph processing)\n# Add image detection:\n\n# Check for images in paragraph\nif para.runs:\n    for run in para.runs:\n        if run._element.xpath('.//w:drawing'):\n            # Image found in paragraph\n            if current_section:\n                current_section[\"has_images\"] = True\n</code></pre> <p>Step 3: Add Vision Processing Method</p> <pre><code>async def _process_images_with_vision(\n    self,\n    images: List[Dict[str, Any]],\n    image_processor: 'ImageProcessor',\n    section_context: Dict[str, Any]\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Process images with vision API.\n\n    Args:\n        images: List of image data dicts\n        image_processor: ImageProcessor instance\n        section_context: Context about current section\n\n    Returns:\n        List of image description dicts\n    \"\"\"\n    if not images:\n        return []\n\n    # Add section context to each image\n    for img in images:\n        img[\"context\"].update(section_context)\n\n    # Batch process images\n    descriptions = await image_processor.describe_images_batch(images)\n\n    return descriptions\n</code></pre> <p>Step 4: Update read() Method Signature</p> <pre><code>async def read(self, image_processor: Optional['ImageProcessor'] = None) -&gt; Dict[str, Any]:\n    \"\"\"\n    Read Word file and return structured data.\n\n    Args:\n        image_processor: Optional ImageProcessor for vision mode\n\n    Returns:\n        {\n            \"sections\": [...],\n            \"images\": [...],  # NEW: list of image descriptions if vision mode\n            \"vision_tokens_used\": 0  # NEW: tokens used for vision API\n        }\n    \"\"\"\n</code></pre>"},{"location":"ROADMAP_VISION/#files-modified","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/document_readers.py</code> - WordReader class (~150 new lines)</li> </ul>"},{"location":"ROADMAP_VISION/#tests-required","title":"Tests Required","text":"<ul> <li><code>test_word_reader.py</code>:</li> <li><code>test_extract_images_from_docx()</code> - Mock docx with images</li> <li><code>test_image_extraction_with_vision_mode()</code> - Mock ImageProcessor</li> <li><code>test_image_extraction_skip_mode()</code> - Verify images skipped</li> <li><code>test_image_extraction_describe_mode()</code> - Extract alt text only</li> <li><code>test_image_context_preserved()</code> - Verify section context</li> </ul>"},{"location":"ROADMAP_VISION/#phase-512-pdfreader-image-extraction-v0331","title":"Phase 5.1.2: PDFReader Image Extraction (v0.3.31)","text":"<p>Goal: Extract images from PDF documents</p>"},{"location":"ROADMAP_VISION/#implementation-steps_1","title":"Implementation Steps","text":"<p>Step 1: Add Image Extraction for PyMuPDF</p> <p>Location: <code>wyn360_cli/document_readers.py</code> (in PDFReader class)</p> <pre><code>def _extract_images_pymupdf(self, page, page_num: int) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Extract images from PDF page using PyMuPDF.\n\n    Args:\n        page: PyMuPDF page object\n        page_num: Page number (1-indexed)\n\n    Returns:\n        List of image dicts\n    \"\"\"\n    images = []\n\n    try:\n        image_list = page.get_images(full=True)\n\n        for img_index, img in enumerate(image_list):\n            xref = img[0]  # image xref\n            base_image = page.parent.extract_image(xref)\n\n            image_data = base_image[\"image\"]\n            image_ext = base_image[\"ext\"]  # png, jpeg, etc.\n\n            images.append({\n                \"data\": image_data,\n                \"format\": image_ext,\n                \"context\": {\n                    \"doc_type\": \"pdf\",\n                    \"page_number\": page_num,\n                    \"index\": img_index\n                }\n            })\n    except Exception as e:\n        # Skip if image extraction fails\n        pass\n\n    return images\n</code></pre> <p>Step 2: Add Image Extraction for pdfplumber</p> <pre><code>def _extract_images_pdfplumber(self, page, page_num: int) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Extract images from PDF page using pdfplumber.\n\n    Note: pdfplumber doesn't have direct image extraction,\n    so we'll need to work with page.images metadata\n    \"\"\"\n    images = []\n\n    try:\n        # pdfplumber provides image objects but not raw data directly\n        # We'll need to use page.to_image() and crop\n        page_images = page.images\n\n        for idx, img_info in enumerate(page_images):\n            # This is a simplified approach\n            # Full implementation would require cropping page image\n            images.append({\n                \"data\": None,  # Would need cropping logic\n                \"format\": \"png\",\n                \"context\": {\n                    \"doc_type\": \"pdf\",\n                    \"page_number\": page_num,\n                    \"index\": idx,\n                    \"note\": \"pdfplumber image extraction limited\"\n                }\n            })\n    except Exception:\n        pass\n\n    return images\n</code></pre> <p>Step 3: Update read() Methods</p> <p>Modify <code>_read_with_pymupdf()</code> and <code>_read_with_pdfplumber()</code> to: - Extract images from each page - Store images with page data - Track image count</p>"},{"location":"ROADMAP_VISION/#files-modified_1","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/document_readers.py</code> - PDFReader class (~200 new lines)</li> </ul>"},{"location":"ROADMAP_VISION/#tests-required_1","title":"Tests Required","text":"<ul> <li><code>test_pdf_reader.py</code>:</li> <li><code>test_extract_images_pymupdf()</code> - Mock pymupdf image extraction</li> <li><code>test_extract_images_pdfplumber()</code> - Mock pdfplumber</li> <li><code>test_image_extraction_with_vision()</code> - End-to-end vision mode</li> <li><code>test_image_context_in_pdf()</code> - Verify page context</li> <li><code>test_pdf_without_images()</code> - Handle PDFs with no images</li> </ul>"},{"location":"ROADMAP_VISION/#phase-513-agent-integration-v0332","title":"Phase 5.1.3: Agent Integration (v0.3.32)","text":"<p>Goal: Integrate vision mode into agent tools</p>"},{"location":"ROADMAP_VISION/#implementation-steps_2","title":"Implementation Steps","text":"<p>Step 1: Update Agent Initialization</p> <p>Location: <code>wyn360_cli/agent.py</code> (around line 100-110)</p> <pre><code># Add to __init__\nself.vision_tokens_used = 0  # Track vision API tokens separately\nself.vision_enabled = False  # Can be toggled\n</code></pre> <p>Step 2: Update read_word() Method</p> <p>Location: <code>wyn360_cli/agent.py</code> (around line 2178)</p> <pre><code>async def read_word(\n    self,\n    ctx: RunContext[None],\n    file_path: str,\n    max_tokens: Optional[int] = None,\n    use_chunking: bool = True,\n    image_handling: Optional[str] = None,\n    regenerate_cache: bool = False,\n    query: Optional[str] = None\n) -&gt; str:\n    \"\"\"...\"\"\"\n\n    # Get image_handling mode\n    if image_handling is None:\n        image_handling = self.image_handling_mode\n\n    # Warn user about vision costs\n    if image_handling == \"vision\":\n        # Count estimated cost\n        response = \"\u26a0\ufe0f **Vision Mode Enabled**\\n\\n\"\n        response += \"This will use Claude Vision API to process images.\\n\"\n        response += \"**Estimated cost:** ~$0.01-0.05 per image\\n\"\n        response += \"Do you want to proceed?\\n\\n\"\n        # In actual implementation, might want user confirmation\n\n    # Create ImageProcessor if vision mode\n    image_processor = None\n    if image_handling == \"vision\":\n        from .document_readers import ImageProcessor\n        image_processor = ImageProcessor(\n            api_key=self.api_key,\n            model=\"claude-3-5-sonnet-20241022\"\n        )\n\n    # Pass image_processor to reader\n    reader = WordReader(\n        file_path=str(file_path_obj),\n        chunk_size=1000,\n        image_handling=image_handling\n    )\n\n    # Read with vision processing\n    result = await reader.read(image_processor=image_processor)\n\n    # Track vision tokens\n    if \"vision_tokens_used\" in result:\n        self.vision_tokens_used += result[\"vision_tokens_used\"]\n\n    # ... rest of method\n</code></pre> <p>Step 3: Update read_pdf() Similarly</p> <p>Step 4: Update /tokens Command</p> <p>Location: <code>wyn360_cli/cli.py</code> (tokens command)</p> <pre><code># Add vision tokens to display\nif agent.vision_tokens_used &gt; 0:\n    console.print(f\"Vision API Tokens: {agent.vision_tokens_used:,}\")\n    # Calculate vision cost (different pricing)\n    # Sonnet 4.5 vision: ~$3/MTok input, ~$15/MTok output\n</code></pre>"},{"location":"ROADMAP_VISION/#files-modified_2","title":"Files Modified","text":"<ul> <li><code>wyn360_cli/agent.py</code> - read_word(), read_pdf() methods (~100 lines)</li> <li><code>wyn360_cli/cli.py</code> - /tokens command (~20 lines)</li> </ul>"},{"location":"ROADMAP_VISION/#phase-514-testing-v0333","title":"Phase 5.1.4: Testing (v0.3.33)","text":"<p>Goal: Comprehensive test coverage</p>"},{"location":"ROADMAP_VISION/#test-files-to-createupdate","title":"Test Files to Create/Update","text":"<p>1. test_image_processor.py (NEW)</p> <p>20 tests covering: - Image format detection - Vision API calls (mocked) - Error handling - Batch processing - Context prompt building - Image type detection - Markdown formatting - Cost tracking</p> <p>2. test_word_reader.py (UPDATE)</p> <p>Add 5 tests: - Image extraction from docx - Vision mode integration - Skip/describe/vision modes - Image context preservation - Error handling for corrupted images</p> <p>3. test_pdf_reader.py (UPDATE)</p> <p>Add 5 tests: - Image extraction from PDF (pymupdf) - Image extraction from PDF (pdfplumber) - Vision mode end-to-end - Page context in images - PDFs without images</p> <p>4. Integration Tests (NEW)</p> <p>Test complete workflows: - Read Word doc with vision mode - Read PDF with vision mode - Cost tracking accuracy - Cache with vision descriptions - Query retrieval with image content</p>"},{"location":"ROADMAP_VISION/#total-test-count","title":"Total Test Count","text":"<ul> <li>Current: 120 tests</li> <li>New: ~30 tests</li> <li>Total: ~150 tests</li> </ul>"},{"location":"ROADMAP_VISION/#phase-515-documentation-v0334","title":"Phase 5.1.5: Documentation (v0.3.34)","text":"<p>Goal: Complete user-facing documentation</p>"},{"location":"ROADMAP_VISION/#documents-to-update","title":"Documents to Update","text":"<p>1. README.md</p> <p>Add section: Vision Mode for Images</p> <pre><code>### \ud83d\uddbc\ufe0f Vision Mode for Images\n\nWYN360 can intelligently describe images in Word and PDF documents using Claude Vision API.\n\n#### Usage\n\nwyn360 read presentation.docx --image-mode vision\n\n\n#### Image Handling Modes\n\n- **skip** (default): Ignore images entirely\n- **describe**: Extract alt text and captions only (no API calls)\n- **vision**: Use Claude Vision API for intelligent descriptions (costs apply)\n\n#### Cost Considerations\n\nVision mode uses Claude's Vision API with the following pricing:\n- ~$0.01-0.05 per image\n- Separate from text processing costs\n- Track costs with `/tokens` command\n\n#### Example Output\n\n\ud83d\udcca **[Image 1]:** A bar chart showing quarterly revenue growth from Q1 to Q4,\nwith Q4 showing the highest revenue at approximately $2.5M.\n\n\ud83d\udcd0 **[Image 2]:** System architecture diagram depicting three layers: frontend\n(React), API layer (FastAPI), and database (PostgreSQL).\n</code></pre> <p>2. ROADMAP_DOCUMENTS.md</p> <p>Update Phase 5.1 status: - Mark all tasks as completed - Add \"IMPLEMENTED\" badges - Update version history table</p> <p>3. USE_CASES.md</p> <p>Add new use case:</p> <pre><code>### Use Case 18: Analyzing Presentation with Charts\n\n**Scenario:** User needs to understand a PowerPoint presentation converted to Word with multiple charts.\n\n**Commands:**\nwyn360 read quarterly_report.docx --image-mode vision\n\n**Output:** Full document summary with intelligent descriptions of all charts, graphs, and diagrams.\n\n**Value:** Extract insights from visual data without manually describing each chart.\n</code></pre> <p>4. COST.md (NEW or UPDATE)</p> <p>Create cost guide:</p> <pre><code>### Vision API Costs\n\n#### Pricing\n- Input tokens (image + text): $3.00 per million tokens\n- Output tokens (descriptions): $15.00 per million tokens\n\n#### Typical Costs\n- Simple chart: ~$0.01 (300 input tokens, 100 output tokens)\n- Complex diagram: ~$0.03 (500 input tokens, 200 output tokens)\n- Photo: ~$0.02 (400 input tokens, 150 output tokens)\n\n#### Example: 20-Page Report\n- 10 images average\n- Total cost: ~$0.10-0.30\n- Plus text summarization: ~$0.05\n- **Total: ~$0.15-0.35**\n\n#### Cost Control\n- Use `skip` mode for documents without important images\n- Use `describe` mode for simple images with alt text\n- Reserve `vision` mode for critical visual content\n</code></pre>"},{"location":"ROADMAP_VISION/#cost-analysis","title":"\ud83d\udcb0 Cost Analysis","text":""},{"location":"ROADMAP_VISION/#vision-api-pricing-claude-sonnet-45","title":"Vision API Pricing (Claude Sonnet 4.5)","text":"Component Price per MTok Typical Usage Cost per Image Input (image + text) $3.00 300-500 tokens $0.0009-0.0015 Output (description) $15.00 100-200 tokens $0.0015-0.0030 Total per image - - $0.01-0.05"},{"location":"ROADMAP_VISION/#example-scenarios","title":"Example Scenarios","text":"<p>Scenario 1: Research Paper (15 pages, 5 diagrams) - Text summarization: ~$0.02 (Haiku) - Vision processing: ~$0.05 (5 diagrams) - Total: ~$0.07</p> <p>Scenario 2: Financial Report (50 pages, 20 charts) - Text summarization: ~$0.08 (Haiku) - Vision processing: ~$0.20-0.40 (20 charts) - Total: ~$0.28-0.48</p> <p>Scenario 3: Presentation (30 slides, 30 images) - Text summarization: ~$0.05 (Haiku) - Vision processing: ~$0.30-0.60 (30 images) - Total: ~$0.35-0.65</p>"},{"location":"ROADMAP_VISION/#cost-mitigation-strategies","title":"Cost Mitigation Strategies","text":"<ol> <li>Smart Defaults: Default to <code>skip</code> mode, require explicit <code>--vision</code> flag</li> <li>User Warnings: Show estimated cost before processing</li> <li>Batch Limits: Limit to 50 images per document by default</li> <li>Caching: Cache vision results for 1 hour (same as text)</li> <li>Selective Processing: Allow users to specify image indices to process</li> </ol>"},{"location":"ROADMAP_VISION/#success-criteria","title":"\u2705 Success Criteria","text":""},{"location":"ROADMAP_VISION/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>\u2705 Extract images from Word documents with 95%+ success rate</li> <li>\u2705 Extract images from PDFs (PyMuPDF) with 90%+ success rate</li> <li>\u2705 Vision API calls return descriptions within 3 seconds per image</li> <li>\u2705 Support skip/describe/vision modes seamlessly</li> <li>\u2705 Zero breaking changes to existing API</li> <li>\u2705 All existing tests continue to pass</li> <li>\u2705 New features have 90%+ test coverage</li> </ul>"},{"location":"ROADMAP_VISION/#quality-requirements","title":"Quality Requirements","text":"<ul> <li>\u2705 Image descriptions are accurate and concise (100-300 tokens)</li> <li>\u2705 Cost tracking is accurate to within 1%</li> <li>\u2705 Error handling gracefully handles corrupted images</li> <li>\u2705 Performance: process 10-image document in &lt;30 seconds</li> <li>\u2705 Memory: handle documents with 50+ images without OOM</li> </ul>"},{"location":"ROADMAP_VISION/#documentation-requirements","title":"Documentation Requirements","text":"<ul> <li>\u2705 README.md updated with vision mode examples</li> <li>\u2705 Cost guide with clear pricing examples</li> <li>\u2705 USE_CASES.md with vision mode scenarios</li> <li>\u2705 All slash commands documented</li> <li>\u2705 API reference updated</li> </ul>"},{"location":"ROADMAP_VISION/#implementation-timeline","title":"\ud83d\uddd3\ufe0f Implementation Timeline","text":""},{"location":"ROADMAP_VISION/#sprint-1-core-image-extraction-week-1","title":"Sprint 1: Core Image Extraction (Week 1)","text":"<ul> <li>Days 1-2: WordReader image extraction</li> <li>Days 3-4: PDFReader image extraction (PyMuPDF)</li> <li>Day 5: Testing image extraction</li> </ul> <p>Deliverable: Images can be extracted from both Word and PDF</p>"},{"location":"ROADMAP_VISION/#sprint-2-vision-api-integration-week-2","title":"Sprint 2: Vision API Integration (Week 2)","text":"<ul> <li>Days 1-2: Agent integration (read_word, read_pdf)</li> <li>Days 3-4: Cost tracking and warnings</li> <li>Day 5: Integration testing</li> </ul> <p>Deliverable: Vision mode working end-to-end</p>"},{"location":"ROADMAP_VISION/#sprint-3-testing-documentation-week-3","title":"Sprint 3: Testing &amp; Documentation (Week 3)","text":"<ul> <li>Days 1-2: Comprehensive unit tests</li> <li>Days 3-4: Documentation updates</li> <li>Day 5: Code review and polish</li> </ul> <p>Deliverable: Production-ready vision mode</p>"},{"location":"ROADMAP_VISION/#total-estimate-3-weeks-15-development-days","title":"Total Estimate: 3 weeks (15 development days)","text":""},{"location":"ROADMAP_VISION/#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":""},{"location":"ROADMAP_VISION/#unit-tests-30-new-tests","title":"Unit Tests (~30 new tests)","text":"<p>ImageProcessor (20 tests): - Format detection (4 tests) - Vision API calls (4 tests) - Error handling (4 tests) - Batch processing (3 tests) - Type detection (3 tests) - Markdown formatting (2 tests)</p> <p>WordReader (5 tests): - Image extraction - Vision mode integration - Skip/describe/vision modes - Context preservation - Error handling</p> <p>PDFReader (5 tests): - PyMuPDF image extraction - pdfplumber image extraction - Vision mode end-to-end - Page context - No images handling</p>"},{"location":"ROADMAP_VISION/#integration-tests-5-tests","title":"Integration Tests (~5 tests)","text":"<ul> <li>End-to-end Word document with vision</li> <li>End-to-end PDF with vision</li> <li>Cost tracking validation</li> <li>Cache with vision results</li> <li>Query retrieval with image content</li> </ul>"},{"location":"ROADMAP_VISION/#performance-tests","title":"Performance Tests","text":"<ul> <li>Large document (50+ images) processing time</li> <li>Memory usage with many images</li> <li>Concurrent vision API calls</li> <li>Cache hit rate with vision mode</li> </ul>"},{"location":"ROADMAP_VISION/#risk-mitigation","title":"\ud83d\udd12 Risk Mitigation","text":""},{"location":"ROADMAP_VISION/#technical-risks","title":"Technical Risks","text":"Risk Probability Impact Mitigation Vision API rate limits Medium High Implement retry logic, batch throttling Large image handling Medium Medium Resize images before sending, set size limits Cost overruns High High Clear warnings, user confirmation, batch limits python-docx image extraction failures Medium Medium Graceful fallbacks, error handling PyMuPDF vs pdfplumber incompatibility Low Medium Test both engines, document limitations"},{"location":"ROADMAP_VISION/#user-experience-risks","title":"User Experience Risks","text":"Risk Probability Impact Mitigation Unexpected high costs High High Prominent cost warnings, require explicit --vision flag Slow processing Medium Medium Progress indicators, async processing Inaccurate descriptions Low Medium Include confidence scores, allow user feedback Breaking changes Low High Comprehensive backward compatibility testing"},{"location":"ROADMAP_VISION/#references","title":"\ud83d\udcda References","text":""},{"location":"ROADMAP_VISION/#api-documentation","title":"API Documentation","text":"<ul> <li>Claude Vision API</li> <li>python-docx</li> <li>PyMuPDF</li> <li>pdfplumber</li> </ul>"},{"location":"ROADMAP_VISION/#related-files","title":"Related Files","text":"<ul> <li><code>wyn360_cli/document_readers.py</code> - Core implementation</li> <li><code>wyn360_cli/agent.py</code> - Agent integration</li> <li><code>docs/ROADMAP_DOCUMENTS.md</code> - Parent roadmap</li> <li><code>docs/USE_CASES.md</code> - Use cases</li> </ul>"},{"location":"ROADMAP_VISION/#next-steps","title":"\ud83c\udfaf Next Steps","text":""},{"location":"ROADMAP_VISION/#immediate-actions-to-begin-implementation","title":"Immediate Actions (To Begin Implementation)","text":"<ol> <li>\u2705 Create this roadmap document</li> <li>\u23f3 User review and approval of plan</li> <li>\u23f3 Begin Sprint 1: WordReader image extraction</li> <li>\u23f3 Daily standup updates on progress</li> <li>\u23f3 Continuous testing as features are added</li> </ol>"},{"location":"ROADMAP_VISION/#decision-points","title":"Decision Points","text":"<p>Before starting implementation, confirm: - \u2705 Cost structure acceptable to users - \u2705 Vision API access available - \u2705 Three-week timeline acceptable - \u2705 Approach aligns with project goals</p>"},{"location":"ROADMAP_VISION/#feedback-questions","title":"\ud83d\udcde Feedback &amp; Questions","text":"<p>Questions? Concerns? Suggestions?</p> <p>This is a comprehensive plan designed to implement vision mode without breaking existing functionality. The implementation is broken into logical phases, each with clear deliverables and test requirements.</p> <p>Key Design Decisions: 1. Default to skip mode - Avoid surprise costs 2. Separate cost tracking - Transparency on vision vs text costs 3. Three image modes - Flexibility for different use cases 4. Batch processing - Efficiency for multi-image documents 5. Cache vision results - Avoid re-processing same images</p> <p>Last Updated: November 2025 Document Version: 1.0 Maintained by: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"architecture/autonomous-browsing/","title":"Intelligent Browser Automation Architecture","text":"<p>Current Implementation (v0.3.78)</p> <p>WYN360-CLI features a sophisticated browser automation system that uses a DOM-first approach with intelligent fallback strategies. The system combines fast DOM analysis, AI-powered Stagehand automation, and vision-based fallbacks to provide reliable web interaction capabilities while maintaining cost efficiency and performance.</p>"},{"location":"architecture/autonomous-browsing/#overview","title":"Overview","text":"<p>The intelligent browser automation enables Claude to: - Analyze web page structure using fast DOM extraction - Execute precise automation using DOM selectors when possible - Fallback to Stagehand AI automation for complex scenarios - Adapt using vision-based approaches for dynamic content - Optimize cost and performance through intelligent approach selection</p> <p>This creates a layered automation system that achieves high success rates while minimizing costs through intelligent approach selection.</p>"},{"location":"architecture/autonomous-browsing/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[\"User Request\"] --&gt; B[\"DOM Analysis\"]\n    B --&gt; C{\"Confidence Score\"}\n    C --&gt;|\"High (&gt;0.7)\"| D[\"DOM Automation\"]\n    C --&gt;|\"Medium (0.4-0.7)\"| E[\"Stagehand AI\"]\n    C --&gt;|\"Low (&lt;0.4)\"| F[\"Vision Fallback\"]\n\n    D --&gt; G{Success?}\n    E --&gt; G\n    F --&gt; G\n\n    G --&gt;|Yes| H[\"Return Results\"]\n    G --&gt;|No| I[\"Try Next Approach\"]\n    I --&gt; J{\"More Approaches?\"}\n    J --&gt;|Yes| K[\"Increase Fallback Level\"]\n    K --&gt; E\n    J --&gt;|No| L[\"Report Failure\"]\n\n    style A fill:#e1f5fe\n    style B fill:#e8f5e8\n    style D fill:#c8e6c9\n    style E fill:#fff3e0\n    style F fill:#fce4ec\n    style H fill:#c8e6c9</code></pre>"},{"location":"architecture/autonomous-browsing/#cost-performance-optimization","title":"Cost &amp; Performance Optimization","text":""},{"location":"architecture/autonomous-browsing/#performance-comparison","title":"Performance Comparison","text":"Approach Cost per Task Speed Reliability Use Cases DOM Automation ~$0.001-0.01 \u26a1 1-3s 95% on static sites Forms, clicks, simple navigation Stagehand AI ~$0.05-0.15 \ud83d\ude80 5-15s 85% on dynamic sites Complex workflows, modern SPAs Vision Fallback ~$0.20-0.50 \ud83d\udc0c 20-60s 75% on any site Visual elements, CAPTCHAs"},{"location":"architecture/autonomous-browsing/#intelligent-approach-selection","title":"Intelligent Approach Selection","text":"<p>The system automatically selects the optimal approach based on: - DOM Confidence Score - Calculated from element accessibility - Page Complexity - Number of interactive elements and dynamic content - Task Requirements - Specific actions needed (forms vs navigation) - Historical Success - Learning from previous attempts</p>"},{"location":"architecture/autonomous-browsing/#components","title":"Components","text":""},{"location":"architecture/autonomous-browsing/#1-dom-analyzer","title":"1. DOM Analyzer","text":"<p>Fast webpage structure analysis for automation planning.</p> <p>Features: - Interactive element detection and accessibility scoring - Form analysis with field identification - Navigation structure mapping - Confidence score calculation for automation success</p> <p>File: <code>wyn360_cli/tools/browser/dom_analyzer.py</code></p>"},{"location":"architecture/autonomous-browsing/#2-browser-manager","title":"2. Browser Manager","text":"<p>Centralized browser lifecycle and session management.</p> <p>Features: - Playwright browser instance management - Session persistence and cookie handling - Resource cleanup and memory management - Concurrent session support</p> <p>File: <code>wyn360_cli/tools/browser/browser_manager.py</code></p>"},{"location":"architecture/autonomous-browsing/#3-unified-automation-interface","title":"3. Unified Automation Interface","text":"<p>High-level orchestration layer for approach selection and execution.</p> <p>Features: - Automatic approach selection based on confidence scores - Intelligent fallback progression (DOM \u2192 Stagehand \u2192 Vision) - Performance monitoring and cost optimization - Error handling and retry logic</p> <p>File: <code>wyn360_cli/tools/browser/unified_automation_interface.py</code></p>"},{"location":"architecture/autonomous-browsing/#4-stagehand-integration","title":"4. Stagehand Integration","text":"<p>AI-powered automation for complex web interactions.</p> <p>Features: - Natural language to web action conversion - Dynamic element handling and adaptation - Modern SPA and JavaScript-heavy site support - Context-aware automation planning</p> <p>File: <code>wyn360_cli/tools/browser/stagehand_integration.py</code></p>"},{"location":"architecture/autonomous-browsing/#5-vision-fallback-integration","title":"5. Vision Fallback Integration","text":"<p>Visual analysis and interaction for complex scenarios.</p> <p>Features: - Screenshot-based element detection - Visual similarity matching - CAPTCHA and dynamic content handling - Accessibility-independent interaction</p> <p>File: <code>wyn360_cli/tools/browser/vision_fallback_integration.py</code></p>"},{"location":"architecture/autonomous-browsing/#6-enhanced-automation-orchestrator","title":"6. Enhanced Automation Orchestrator","text":"<p>Coordination layer managing multiple automation approaches.</p> <p>Features: - Multi-approach coordination and selection - Performance monitoring and analytics - Error classification and recovery strategies - Learning from success/failure patterns</p> <p>File: <code>wyn360_cli/tools/browser/enhanced_automation_orchestrator.py</code></p>"},{"location":"architecture/autonomous-browsing/#browser-control-features","title":"Browser Control Features","text":""},{"location":"architecture/autonomous-browsing/#show-browser-flag","title":"Show Browser Flag","text":"<p>Control browser visibility for debugging and development:</p> <pre><code># Show browser window during automation\nwyn360 --show-browser\n\n# Environment variable option\nexport WYN360_BROWSER_SHOW=1\nwyn360\n</code></pre>"},{"location":"architecture/autonomous-browsing/#headless-mode-default","title":"Headless Mode (Default)","text":"<ul> <li>Default: Browser runs invisibly for performance</li> <li>Debugging: Use <code>--show-browser</code> to watch automation</li> <li>Development: Visual feedback for troubleshooting</li> </ul>"},{"location":"architecture/autonomous-browsing/#available-functions","title":"Available Functions","text":""},{"location":"architecture/autonomous-browsing/#analyze_page_dom","title":"analyze_page_dom()","text":"<p>Analyze webpage DOM structure for intelligent automation planning.</p> <pre><code>async def analyze_page_dom(\n    ctx: RunContext[None],\n    url: str,\n    task_description: Optional[str] = None,\n    confidence_threshold: float = 0.7,\n    show_browser: Optional[bool] = None\n) -&gt; str:\n    \"\"\"\n    Analyze webpage DOM structure for automation planning.\n\n    Args:\n        url: Website URL to analyze\n        task_description: Optional description of intended task\n        confidence_threshold: Minimum confidence for DOM approach (0.0-1.0)\n        show_browser: Whether to show browser window for debugging\n\n    Returns:\n        Structured analysis with confidence scores and recommendations\n    \"\"\"\n</code></pre>"},{"location":"architecture/autonomous-browsing/#intelligent_browse","title":"intelligent_browse()","text":"<p>Main intelligent browsing function with DOM-first approach and fallbacks.</p> <pre><code>async def intelligent_browse(\n    ctx: RunContext[None],\n    task: str,\n    url: str,\n    max_steps: int = 15,\n    confidence_threshold: float = 0.7,\n    show_browser: Optional[bool] = None\n) -&gt; str:\n    \"\"\"\n    Intelligently browse website using DOM-first approach with fallbacks.\n\n    Args:\n        task: Natural language description of what to accomplish\n        url: Starting URL for the browsing session\n        max_steps: Maximum number of automation steps\n        confidence_threshold: Minimum confidence for DOM approach\n        show_browser: Override default browser visibility\n\n    Returns:\n        Formatted result with actions taken and data extracted\n    \"\"\"\n</code></pre>"},{"location":"architecture/autonomous-browsing/#browse_and_find","title":"browse_and_find()","text":"<p>Simplified browsing function for basic navigation and data extraction.</p> <pre><code>async def browse_and_find(\n    ctx: RunContext[None],\n    url: str,\n    task: str,\n    max_attempts: int = 3,\n    show_browser: Optional[bool] = None\n) -&gt; str:\n    \"\"\"\n    Browse website and find specific information or complete tasks.\n\n    Args:\n        url: Target website URL\n        task: Description of what to find or accomplish\n        max_attempts: Number of retry attempts if initial approach fails\n        show_browser: Whether to show browser window\n\n    Returns:\n        Results of the browsing task with approach used\n    \"\"\"\n</code></pre>"},{"location":"architecture/autonomous-browsing/#login_to_website","title":"login_to_website()","text":"<p>Automated website authentication with form detection.</p> <pre><code>async def login_to_website(\n    ctx: RunContext[None],\n    url: str,\n    username: str,\n    password: str,\n    save_credentials: bool = False,\n    show_browser: Optional[bool] = None\n) -&gt; str:\n    \"\"\"\n    Automatically login to websites with form detection.\n\n    Args:\n        url: Login page URL\n        username: Username or email for login\n        password: Password for login\n        save_credentials: Whether to save encrypted credentials\n        show_browser: Whether to show browser window\n\n    Returns:\n        Login result and session status\n    \"\"\"\n</code></pre>"},{"location":"architecture/autonomous-browsing/#fetch_website","title":"fetch_website()","text":"<p>Simple page content fetching and analysis.</p> <pre><code>async def fetch_website(\n    ctx: RunContext[None],\n    url: str,\n    max_tokens: int = 50000,\n    show_browser: Optional[bool] = None\n) -&gt; str:\n    \"\"\"\n    Fetch and analyze website content.\n\n    Args:\n        url: Website URL to fetch\n        max_tokens: Maximum content tokens to return\n        show_browser: Whether to show browser window\n\n    Returns:\n        Formatted website content and metadata\n    \"\"\"\n</code></pre>"},{"location":"architecture/autonomous-browsing/#usage-examples","title":"Usage Examples","text":""},{"location":"architecture/autonomous-browsing/#example-1-e-commerce-product-search-dom-first","title":"Example 1: E-commerce Product Search (DOM-First)","text":"<p>Task: Search for products with specific criteria</p> <pre><code>You: \"Browse to Amazon and find wireless headphones under $50 with good reviews\"\n\nSystem:\n\ud83d\udd0d **DOM Analysis:** High confidence (0.9) - Well-structured search forms\n\u26a1 **DOM Automation Selected** - Fast and cost-effective\n\u2705 **Success** - Found 12 products matching criteria\n\ud83d\udcb0 **Cost:** $0.02 | \u23f1\ufe0f **Time:** 4 seconds\n</code></pre>"},{"location":"architecture/autonomous-browsing/#example-2-complex-web-app-stagehand-ai","title":"Example 2: Complex Web App (Stagehand AI)","text":"<p>Task: Navigate modern SPA with dynamic content</p> <pre><code>You: \"Login to my GitHub account and create a new repository named 'test-project'\"\n\nSystem:\n\ud83d\udd0d **DOM Analysis:** Medium confidence (0.6) - Dynamic login flow\n\ud83e\udd16 **Stagehand AI Selected** - Better for complex workflows\n\u2705 **Success** - Repository created successfully\n\ud83d\udcb0 **Cost:** $0.12 | \u23f1\ufe0f **Time:** 18 seconds\n</code></pre>"},{"location":"architecture/autonomous-browsing/#example-3-fallback-progression","title":"Example 3: Fallback Progression","text":"<p>Task: Handle site with unusual interface</p> <pre><code>You: \"Complete the contact form on this custom website\"\n\nSystem:\n\ud83d\udd0d **DOM Analysis:** Low confidence (0.3) - Unusual form structure\n\ud83d\udc41\ufe0f **Vision Fallback Selected** - Visual element detection needed\n\u2705 **Success** - Form submitted using visual navigation\n\ud83d\udcb0 **Cost:** $0.35 | \u23f1\ufe0f **Time:** 45 seconds\n</code></pre>"},{"location":"architecture/autonomous-browsing/#example-4-intelligent-approach-learning","title":"Example 4: Intelligent Approach Learning","text":"<p>Task: Repeated automation on familiar site</p> <pre><code>You: \"Check my Gmail inbox for new messages\"\n\nSystem:\n\ud83e\udde0 **Historical Analysis:** Previous DOM success on Gmail (0.95 confidence)\n\u26a1 **DOM Automation Selected** - Learned pattern applied\n\u2705 **Success** - 5 new messages found\n\ud83d\udcb0 **Cost:** $0.01 | \u23f1\ufe0f **Time:** 2 seconds\n</code></pre>"},{"location":"architecture/autonomous-browsing/#configuration","title":"Configuration","text":""},{"location":"architecture/autonomous-browsing/#browser-control","title":"Browser Control","text":"<pre><code># Environment variables for browser behavior\nexport WYN360_BROWSER_SHOW=1              # Show browser window\nexport WYN360_DOM_CONFIDENCE_THRESHOLD=0.7   # DOM approach threshold\nexport WYN360_MAX_AUTOMATION_STEPS=15        # Maximum steps per session\nexport WYN360_AUTOMATION_TIMEOUT=300         # Total timeout in seconds\n</code></pre>"},{"location":"architecture/autonomous-browsing/#approach-selection","title":"Approach Selection","text":"<pre><code># Fine-tune approach selection in agent configuration\nautomation_config = {\n    \"dom_confidence_threshold\": 0.7,\n    \"enable_stagehand_fallback\": True,\n    \"enable_vision_fallback\": True,\n    \"max_retries_per_approach\": 2,\n    \"total_timeout_seconds\": 300\n}\n</code></pre>"},{"location":"architecture/autonomous-browsing/#cost-controls","title":"Cost Controls","text":"<pre><code># Budget-aware automation settings\ncost_limits = {\n    \"max_cost_per_task\": 0.50,        # Stop if exceeding 50\u00a2\n    \"prefer_dom_approach\": True,      # Favor fast DOM when possible\n    \"track_spending\": True,           # Real-time cost tracking\n    \"enable_approach_learning\": True  # Learn from success patterns\n}\n</code></pre>"},{"location":"architecture/autonomous-browsing/#advanced-features","title":"Advanced Features","text":""},{"location":"architecture/autonomous-browsing/#token-counting-cost-tracking","title":"Token Counting &amp; Cost Tracking","text":"<p>Enhanced <code>/tokens</code> command shows detailed breakdown:</p> <pre><code>{\n    \"total_tokens\": 6420,\n    \"costs\": {\n        \"total\": \"$0.18\",\n        \"dom_automation\": \"$0.03\",\n        \"stagehand_ai\": \"$0.12\",\n        \"vision_fallback\": \"$0.03\"\n    },\n    \"browser_automation\": {\n        \"total_operations\": 12,\n        \"dom_approach_count\": 8,\n        \"stagehand_count\": 3,\n        \"vision_count\": 1,\n        \"average_success_rate\": 0.92\n    },\n    \"approach_distribution\": {\n        \"dom_automation\": 65,\n        \"stagehand_ai\": 25,\n        \"vision_fallback\": 10\n    }\n}\n</code></pre>"},{"location":"architecture/autonomous-browsing/#confidence-score-analytics","title":"Confidence Score Analytics","text":"<pre><code># Approach effectiveness tracking\nconfidence_analytics = {\n    \"dom_average_confidence\": 0.82,\n    \"dom_success_rate\": 0.94,\n    \"stagehand_success_rate\": 0.87,\n    \"vision_success_rate\": 0.78,\n    \"overall_success_rate\": 0.91\n}\n</code></pre>"},{"location":"architecture/autonomous-browsing/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Real-time performance metrics\nperformance_stats = {\n    \"average_dom_speed\": \"2.3s\",\n    \"average_stagehand_speed\": \"12.1s\",\n    \"average_vision_speed\": \"34.7s\",\n    \"cost_per_successful_task\": \"$0.08\",\n    \"approach_selection_accuracy\": 0.89\n}\n</code></pre>"},{"location":"architecture/autonomous-browsing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/autonomous-browsing/#dom-analysis-issues","title":"DOM Analysis Issues","text":"<p>Symptom: Low confidence scores on seemingly simple sites</p> <p>Solutions: 1. Check page complexity: Sites with heavy JavaScript may need Stagehand 2. Verify element accessibility: Ensure proper form labels and IDs 3. Enable browser visibility: <code>wyn360 --show-browser</code> to debug 4. Lower confidence threshold: Allow DOM approach on borderline cases</p>"},{"location":"architecture/autonomous-browsing/#stagehand-integration-problems","title":"Stagehand Integration Problems","text":"<p>Symptom: Stagehand automation fails or times out</p> <p>Solutions: 1. Check API connectivity: Verify Stagehand service availability 2. Simplify task description: Break complex tasks into smaller steps 3. Enable browser visibility: Watch automation for debugging 4. Try vision fallback: Force fallback for problematic sites</p>"},{"location":"architecture/autonomous-browsing/#vision-fallback-issues","title":"Vision Fallback Issues","text":"<p>Symptom: Vision approach fails to find elements</p> <p>Solutions: 1. Check screenshot quality: Ensure browser window is properly sized 2. Verify element visibility: Target elements must be in viewport 3. Simplify visual targets: Focus on clearly visible elements 4. Enable browser visibility: See what the vision system sees</p>"},{"location":"architecture/autonomous-browsing/#performance-concerns","title":"Performance Concerns","text":"<p>Symptom: Automation is slower than expected</p> <p>Solutions: 1. Check approach selection: Ensure DOM approach is being used when possible 2. Monitor confidence scores: Investigate why DOM confidence is low 3. Optimize task descriptions: Be specific about automation goals 4. Enable learning: Let system learn patterns for repeated tasks</p>"},{"location":"architecture/autonomous-browsing/#best-practices","title":"Best Practices","text":""},{"location":"architecture/autonomous-browsing/#1-optimize-for-dom-first-success","title":"1. Optimize for DOM-First Success","text":"<ul> <li>Use websites with proper semantic HTML</li> <li>Target sites with good accessibility practices</li> <li>Provide clear, specific task descriptions</li> <li>Enable approach learning for repeated tasks</li> </ul>"},{"location":"architecture/autonomous-browsing/#2-leverage-intelligent-fallbacks","title":"2. Leverage Intelligent Fallbacks","text":"<ul> <li>Let the system automatically select the best approach</li> <li>Don't force specific automation methods unless needed</li> <li>Monitor success rates to understand site complexity</li> <li>Use browser visibility for debugging complex sites</li> </ul>"},{"location":"architecture/autonomous-browsing/#3-use-browser-visibility-strategically","title":"3. Use Browser Visibility Strategically","text":"<pre><code># Development and debugging\nwyn360 --show-browser\n\n# Production and scripts\nwyn360  # headless mode for performance\n</code></pre>"},{"location":"architecture/autonomous-browsing/#4-monitor-performance-costs","title":"4. Monitor Performance &amp; Costs","text":"<ul> <li>Check <code>/tokens</code> regularly for approach distribution</li> <li>Monitor confidence scores to understand automation challenges</li> <li>Enable learning to improve future performance</li> <li>Set appropriate confidence thresholds for your use cases</li> </ul>"},{"location":"architecture/autonomous-browsing/#real-world-performance","title":"Real-World Performance","text":""},{"location":"architecture/autonomous-browsing/#approach-distribution-typical-usage","title":"Approach Distribution (Typical Usage)","text":"<ul> <li>DOM Automation: 65-75% of tasks</li> <li>Stagehand AI: 20-30% of tasks</li> <li>Vision Fallback: 5-15% of tasks</li> </ul>"},{"location":"architecture/autonomous-browsing/#success-rates-by-site-type","title":"Success Rates by Site Type","text":"<ul> <li>Static Sites (news, blogs): 95% DOM success</li> <li>E-commerce (Amazon, eBay): 85% DOM success</li> <li>Modern SPAs (GitHub, Gmail): 60% DOM, 30% Stagehand</li> <li>Custom/Complex Sites: 40% DOM, 35% Stagehand, 25% Vision</li> </ul>"},{"location":"architecture/autonomous-browsing/#cost-distribution","title":"Cost Distribution","text":"<ul> <li>Average cost per task: $0.08</li> <li>DOM-heavy workloads: $0.02-0.05 per task</li> <li>Stagehand-heavy workloads: $0.10-0.20 per task</li> <li>Vision-heavy workloads: $0.25-0.50 per task</li> </ul>"},{"location":"architecture/autonomous-browsing/#future-enhancements","title":"Future Enhancements","text":""},{"location":"architecture/autonomous-browsing/#planned-improvements","title":"Planned Improvements","text":"<ul> <li>Multi-tab workflow coordination - Handle complex cross-page workflows</li> <li>Advanced pattern learning - Improve automation from usage patterns</li> <li>Real-time confidence tuning - Dynamic threshold adjustment</li> <li>Site-specific optimization - Custom approaches for popular sites</li> <li>Performance analytics dashboard - Real-time monitoring and insights</li> </ul>"},{"location":"architecture/autonomous-browsing/#support","title":"Support","text":"<ul> <li>Documentation: Complete guides in <code>/docs</code></li> <li>Examples: Real-world use cases in <code>USE_CASES.md</code></li> <li>Issues: Report bugs on GitHub</li> <li>Community: Discussions for questions and feedback</li> </ul> <p>Generated with WYN360-CLI v0.3.78 Intelligent Browser Automation with DOM-First Architecture</p>"},{"location":"architecture/system/","title":"WYN360 CLI - System Architecture","text":"<p>This document provides a detailed overview of the WYN360 CLI system architecture, including all components, layers, and data flows.</p> <p>Version: 0.3.41 Last Updated: November 2025</p>"},{"location":"architecture/system/#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<p>WYN360 CLI is built on a modular, layered architecture that separates concerns and enables flexible extensibility.</p> <p>Executive version:</p> <pre><code>graph TB\n    subgraph \"User Interface\"\n        CLI[CLI Interface]\n        Input[User Input]\n        Output[Console Output]\n    end\n\n    subgraph \"Core Agent\"\n        Agent[WYN360Agent]\n        Model[Claude API]\n        Tools[Tool System]\n    end\n\n    subgraph \"Essential Tools\"\n        Files[File Operations&lt;br/&gt;read, write, list]\n        Commands[Shell Commands&lt;br/&gt;execute with confirmation]\n        Git[Git Operations&lt;br/&gt;status, diff, commit]\n        Web[Web Tools&lt;br/&gt;search, fetch, browse]\n    end\n\n    subgraph \"Advanced Features\"\n        GitHub[GitHub Integration&lt;br/&gt;auth, PR, branches]\n        Auth[Website Authentication&lt;br/&gt;login automation]\n        Config[Configuration&lt;br/&gt;user + project settings]\n    end\n\n    Input --&gt; CLI\n    CLI --&gt; Agent\n    Agent --&gt; Model\n    Agent --&gt; Tools\n    Tools --&gt; Files\n    Tools --&gt; Commands\n    Tools --&gt; Git\n    Tools --&gt; Web\n    Tools --&gt; GitHub\n    Tools --&gt; Auth\n    Config --&gt; Agent\n    Model --&gt; Output\n    CLI --&gt; Output\n\n    style Agent fill:#e1f5ff\n    style Model fill:#fff3e0\n    style CLI fill:#f3e5f5</code></pre> <p>Here's a detailed version:</p> <pre><code>graph TB\n    subgraph \"User Interface Layer\"\n        CLI[CLI Interface&lt;br/&gt;click + prompt-toolkit]\n        Input[User Input&lt;br/&gt;Multi-line support&lt;br/&gt;Shift+Enter]\n        Output[Rich Console Output&lt;br/&gt;Word-by-word streaming&lt;br/&gt;Markdown rendering]\n        SlashCmd[Slash Commands&lt;br/&gt;/clear /history /save&lt;br/&gt;/load /tokens /model /config]\n    end\n\n    subgraph \"Configuration Layer\"\n        UserConfig[User Config&lt;br/&gt;~/.wyn360/config.yaml&lt;br/&gt;Default model, instructions]\n        ProjectConfig[Project Config&lt;br/&gt;.wyn360.yaml&lt;br/&gt;Project-specific context]\n        ConfigMerge[Config Merger&lt;br/&gt;Combines user + project settings]\n    end\n\n    subgraph \"Agent Layer\"\n        Agent[WYN360Agent&lt;br/&gt;pydantic-ai framework]\n        ModelSwitch[Model Switcher&lt;br/&gt;haiku/sonnet/opus]\n        Model[Anthropic Claude&lt;br/&gt;claude-sonnet-4 - default]\n        Prompt[System Prompt&lt;br/&gt;Intent recognition&lt;br/&gt;Context awareness]\n        History[Conversation History&lt;br/&gt;Context persistence&lt;br/&gt;Token tracking]\n    end\n\n    subgraph \"Core Tools Layer\"\n        ReadFile[read_file&lt;br/&gt;Read file contents&lt;br/&gt;Size limits]\n        WriteFile[write_file&lt;br/&gt;Create/update files&lt;br/&gt;Overwrite protection]\n        ListFiles[list_files&lt;br/&gt;Scan directory&lt;br/&gt;Categorize by type]\n        ProjectInfo[get_project_info&lt;br/&gt;Project summary&lt;br/&gt;File counts]\n        ExecCmd[execute_command&lt;br/&gt;Run shell commands&lt;br/&gt;User confirmation&lt;br/&gt;Timeout protection]\n    end\n\n    subgraph \"Extended Tools Layer (Phase 2)\"\n        GitStatus[git_status&lt;br/&gt;Show git status]\n        GitDiff[git_diff&lt;br/&gt;Show changes]\n        GitLog[git_log&lt;br/&gt;Commit history]\n        GitBranch[git_branch&lt;br/&gt;List branches]\n        SearchFiles[search_files&lt;br/&gt;Pattern search&lt;br/&gt;File type filtering]\n        DeleteFile[delete_file&lt;br/&gt;Delete files safely]\n        MoveFile[move_file&lt;br/&gt;Move/rename files]\n        CreateDir[create_directory&lt;br/&gt;Create nested dirs]\n    end\n\n    subgraph \"Builtin Tools Layer (Phase 11.1)\"\n        WebSearch[web_search&lt;br/&gt;Real-time web search&lt;br/&gt;Weather, URLs, current info&lt;br/&gt;$10 per 1K searches]\n    end\n\n    subgraph \"Browser Use Tools Layer (Phase 12)\"\n        FetchWebsite[fetch_website&lt;br/&gt;Direct URL fetching&lt;br/&gt;crawl4ai integration&lt;br/&gt;Smart truncation]\n        ShowCacheStats[show_cache_stats&lt;br/&gt;View cache statistics&lt;br/&gt;Cached URLs list]\n        ClearCache[clear_website_cache&lt;br/&gt;Clear specific URL&lt;br/&gt;or all cache]\n    end\n\n    subgraph \"GitHub Integration Tools (Phase 8.1)\"\n        CheckGHAuth[check_gh_authentication&lt;br/&gt;Check GitHub auth status]\n        AuthGH[authenticate_gh&lt;br/&gt;Authenticate with token]\n        GHCommit[gh_commit_changes&lt;br/&gt;Commit and push changes]\n        GHCreatePR[gh_create_pr&lt;br/&gt;Create pull request]\n        GHCreateBranch[gh_create_branch&lt;br/&gt;Create new branch]\n        GHCheckoutBranch[gh_checkout_branch&lt;br/&gt;Switch branch]\n        GHMergeBranch[gh_merge_branch&lt;br/&gt;Merge branches]\n    end\n\n    subgraph \"Authentication Tools (Phase 4)\"\n        LoginWebsite[login_to_website&lt;br/&gt;Automated browser login&lt;br/&gt;Form detection&lt;br/&gt;CAPTCHA/2FA detection]\n        CredManager[CredentialManager&lt;br/&gt;AES-256-GCM encryption&lt;br/&gt;Secure credential storage]\n        SessionManager[SessionManager&lt;br/&gt;Session cookies&lt;br/&gt;30-min TTL]\n        BrowserAuth[BrowserAuth&lt;br/&gt;Playwright automation&lt;br/&gt;Form detection]\n    end\n\n    subgraph \"Utility Layer\"\n        FileOps[File Operations&lt;br/&gt;Safe read/write&lt;br/&gt;Backup handling]\n        Scanner[Directory Scanner&lt;br/&gt;Categorize files&lt;br/&gt;Ignore patterns]\n        CmdExec[Command Executor&lt;br/&gt;subprocess + timeout&lt;br/&gt;Output capture]\n        CodeExt[Code Extractor&lt;br/&gt;Parse markdown blocks&lt;br/&gt;Language detection]\n        TokenTrack[Token Tracker&lt;br/&gt;Cost estimation&lt;br/&gt;Usage statistics]\n        SessionMgr[Session Manager&lt;br/&gt;Save/Load JSON&lt;br/&gt;History persistence]\n    end\n\n    subgraph \"Data Storage\"\n        SessionFiles[Session Files&lt;br/&gt;JSON format&lt;br/&gt;Conversation + tokens]\n        ConfigFiles[Config Files&lt;br/&gt;YAML format&lt;br/&gt;User preferences]\n    end\n\n    Input --&gt; CLI\n    SlashCmd --&gt; CLI\n    CLI --&gt; ConfigMerge\n    UserConfig --&gt; ConfigMerge\n    ProjectConfig --&gt; ConfigMerge\n    ConfigMerge --&gt; Agent\n    CLI --&gt; Agent\n    Agent --&gt; ModelSwitch\n    ModelSwitch --&gt; Model\n    Agent --&gt; Prompt\n    Agent --&gt; History\n\n    Agent --&gt; ReadFile\n    Agent --&gt; WriteFile\n    Agent --&gt; ListFiles\n    Agent --&gt; ProjectInfo\n    Agent --&gt; ExecCmd\n    Agent --&gt; GitStatus\n    Agent --&gt; GitDiff\n    Agent --&gt; GitLog\n    Agent --&gt; GitBranch\n    Agent --&gt; SearchFiles\n    Agent --&gt; DeleteFile\n    Agent --&gt; MoveFile\n    Agent --&gt; CreateDir\n    Agent --&gt; WebSearch\n    Agent --&gt; FetchWebsite\n    Agent --&gt; ShowCacheStats\n    Agent --&gt; ClearCache\n    Agent --&gt; CheckGHAuth\n    Agent --&gt; AuthGH\n    Agent --&gt; GHCommit\n    Agent --&gt; GHCreatePR\n    Agent --&gt; GHCreateBranch\n    Agent --&gt; GHCheckoutBranch\n    Agent --&gt; GHMergeBranch\n    Agent --&gt; LoginWebsite\n    LoginWebsite --&gt; BrowserAuth\n    LoginWebsite --&gt; CredManager\n    LoginWebsite --&gt; SessionManager\n    FetchWebsite --&gt; SessionManager\n\n    ReadFile --&gt; FileOps\n    WriteFile --&gt; FileOps\n    ListFiles --&gt; Scanner\n    ProjectInfo --&gt; Scanner\n    ExecCmd --&gt; CmdExec\n    GitStatus --&gt; CmdExec\n    GitDiff --&gt; CmdExec\n    GitLog --&gt; CmdExec\n    GitBranch --&gt; CmdExec\n    SearchFiles --&gt; FileOps\n    DeleteFile --&gt; FileOps\n    MoveFile --&gt; FileOps\n    CreateDir --&gt; FileOps\n    CheckGHAuth --&gt; CmdExec\n    AuthGH --&gt; CmdExec\n    GHCommit --&gt; CmdExec\n    GHCreatePR --&gt; CmdExec\n    GHCreateBranch --&gt; CmdExec\n    GHCheckoutBranch --&gt; CmdExec\n    GHMergeBranch --&gt; CmdExec\n\n    WriteFile --&gt; CodeExt\n    History --&gt; TokenTrack\n    History --&gt; SessionMgr\n    SessionMgr --&gt; SessionFiles\n    ConfigMerge --&gt; ConfigFiles\n\n    Model --&gt; Output\n    CLI --&gt; Output\n\n    style Agent fill:#e1f5ff\n    style Model fill:#fff3e0\n    style CLI fill:#f3e5f5\n    style ExecCmd fill:#ffebee\n    style History fill:#e8f5e9\n    style ConfigMerge fill:#fff9c4</code></pre>"},{"location":"architecture/system/#component-descriptions","title":"\ud83d\udce6 Component Descriptions","text":""},{"location":"architecture/system/#user-interface-layer","title":"User Interface Layer","text":"<p>CLI Interface - Built with <code>click</code> for argument parsing - Uses <code>prompt-toolkit</code> for advanced input handling - Supports multi-line input with Shift+Enter - Rich console output with markdown rendering</p> <p>Slash Commands - <code>/clear</code> - Clear conversation history and reset token counters - <code>/history</code> - Display conversation history in table format - <code>/save &lt;file&gt;</code> - Save current session to JSON file - <code>/load &lt;file&gt;</code> - Load session from JSON file - <code>/tokens</code> - Show detailed token usage statistics and costs - <code>/model [name]</code> - Show current model or switch models - <code>/config</code> - Show current configuration settings - <code>/help</code> - Display help message with all commands</p> <p>Output Display - Word-by-word streaming simulation for better UX - Syntax highlighting for code blocks - Progress indicators (spinners) during processing - Confirmation messages for command execution</p>"},{"location":"architecture/system/#configuration-layer","title":"Configuration Layer","text":"<p>User Configuration (<code>~/.wyn360/config.yaml</code>) - Default model selection - Custom system instructions - Preferences and settings - Applies globally across all projects</p> <p>Project Configuration (<code>.wyn360.yaml</code>) - Project-specific instructions - Technology stack context - Custom commands - Overrides user config for project</p> <p>Config Merger - Loads both user and project configs - Merges settings with project taking precedence - Combines custom instructions from both sources</p>"},{"location":"architecture/system/#agent-layer","title":"Agent Layer","text":"<p>WYN360Agent - Core orchestrator using <code>pydantic-ai</code> framework - Manages tool calling and execution - Handles conversation flow and context - Error handling and retry logic</p> <p>Model Switcher - Dynamic model selection during session - Supports Haiku, Sonnet, and Opus models - Cost-aware model recommendations - Preserves conversation history across switches</p> <p>Anthropic Claude Models - Haiku: Fast, cheap for simple tasks ($0.25/$1.25 per M tokens) - Sonnet (default): Balanced capability ($3.00/$15.00 per M tokens) - Opus: Most capable for complex tasks ($15.00/$75.00 per M tokens)</p> <p>Conversation History - Maintains context across multiple interactions - Tracks all user messages and assistant responses - Sent with each API request for continuity - Can be cleared with <code>/clear</code> command</p> <p>Token Tracking - Estimates token usage for input and output - Calculates costs based on current model - Cumulative tracking across session - Displayed with <code>/tokens</code> command</p>"},{"location":"architecture/system/#core-tools-layer-phase-1","title":"Core Tools Layer (Phase 1)","text":"<p>read_file - Reads file contents safely - Enforces size limits - Returns error for non-existent files - Used for understanding existing code</p> <p>write_file - Creates new files or updates existing ones - Overwrite protection (requires explicit flag) - Validates content size (100KB limit) - Creates parent directories automatically</p> <p>list_files - Scans directory and lists files - Categorizes by type (Python, text, config, data, other) - Respects .gitignore patterns - Returns structured summary</p> <p>get_project_info - Provides project overview - File counts by category - Technology detection - Identifies blank projects</p> <p>execute_command - Runs shell commands safely - User confirmation prompt with clear feedback - Timeout protection (5 min default) - Captures stdout, stderr, and exit code - Environment variable support</p>"},{"location":"architecture/system/#extended-tools-layer-phase-2","title":"Extended Tools Layer (Phase 2)","text":"<p>Git Operations - <code>git_status</code> - Show working tree status - <code>git_diff</code> - View changes (all or specific file) - <code>git_log</code> - Display commit history - <code>git_branch</code> - List all branches</p> <p>Code Search - <code>search_files</code> - Pattern matching across files - Supports regex patterns - File type filtering (.py, .txt, etc.) - Line number reporting - Smart truncation (first 100 matches)</p> <p>File Management - <code>delete_file</code> - Delete files with safety checks - <code>move_file</code> - Move/rename files with directory creation - <code>create_directory</code> - Create nested directory structures</p>"},{"location":"architecture/system/#builtin-tools-layer-phase-111","title":"Builtin Tools Layer (Phase 11.1)","text":"<p>Web Search (pydantic-ai WebSearchTool) - Real-time internet search using Claude's native web_search_20250305 tool - Integrated via pydantic-ai's <code>builtin_tools</code> parameter - Configured with <code>max_uses=5</code> to control costs</p> <p>Use Cases: 1. Weather Queries    - User asks: \"What's the weather in [location]?\"    - Asks for location if not provided    - Searches and displays current weather with source</p> <ol> <li>Website Reading</li> <li>User provides URL: \"Read https://example.com\"</li> <li>Fetches and summarizes website content</li> <li> <p>Displays key points with proper citations</p> </li> <li> <p>Current Information</p> </li> <li>Latest documentation and package updates</li> <li>Recent news and events</li> <li>Real-time data and trends</li> <li>Examples: \"What's new in Python 3.13?\", \"Latest React features\"</li> </ol> <p>Cost Structure: - $10.00 per 1,000 searches - Plus standard token costs for input/output - Limited to 5 searches per session by default</p> <p>Integration: - Separate from custom @tool decorated functions - Works alongside 19 existing custom tools - No conflicts with file operations or git tools - Invoked automatically by Claude when needed for current information</p>"},{"location":"architecture/system/#github-integration-tools-phase-81","title":"GitHub Integration Tools (Phase 8.1)","text":"<p>Authentication Tools - <code>check_gh_authentication</code> - Check GitHub CLI authentication status   - Checks GH_TOKEN or GITHUB_TOKEN environment variables   - Auto-authenticates if token found   - Returns username if authenticated</p> <ul> <li><code>authenticate_gh(token)</code> - Authenticate with GitHub token</li> <li>Validates token format (ghp_ or github_pat_)</li> <li>Stores token in environment</li> <li>Uses gh CLI login command</li> <li>Required scopes: repo, workflow</li> </ul> <p>Repository Operations - <code>gh_commit_changes(message, push)</code> - Commit and push changes   - Stages all changes with 'git add -A'   - Commits with provided message   - Optionally pushes to remote (default: True)   - Checks for git repo and remote configuration</p> <ul> <li><code>gh_create_pr(title, body, base_branch)</code> - Create pull request</li> <li>Creates PR using gh CLI</li> <li>Validates not on base branch (e.g., main)</li> <li>Returns PR URL on success</li> <li>Handles existing PR detection</li> </ul> <p>Branch Management - <code>gh_create_branch(branch_name, checkout)</code> - Create new branch   - Validates branch name (no spaces)   - Optionally switches to new branch (default: True)   - Checks for existing branch with same name</p> <ul> <li><code>gh_checkout_branch(branch_name)</code> - Switch to existing branch</li> <li>Checks for uncommitted changes</li> <li>Returns error if branch doesn't exist</li> <li> <p>Safe branch switching with status checks</p> </li> <li> <p><code>gh_merge_branch(source_branch, target_branch)</code> - Merge branches</p> </li> <li>Merges source into target (default: current branch)</li> <li>Checks for uncommitted changes</li> <li>Detects and reports merge conflicts</li> <li>Supports fast-forward and 3-way merges</li> </ul> <p>Common Workflows:</p> <ol> <li> <p>Commit and Push: <pre><code>User: \"Commit these changes\"\n\u2192 check_gh_authentication() \u2192 gh_commit_changes(\"message\", push=True)\n</code></pre></p> </li> <li> <p>Create Feature Branch: <pre><code>User: \"Create branch feature/auth\"\n\u2192 gh_create_branch(\"feature/auth\", checkout=True)\n</code></pre></p> </li> <li> <p>Open Pull Request: <pre><code>User: \"Create PR for my changes\"\n\u2192 check_gh_authentication() \u2192 gh_create_pr(\"title\", \"body\", \"main\")\n</code></pre></p> </li> <li> <p>Merge Feature: <pre><code>User: \"Merge feature/auth into main\"\n\u2192 gh_merge_branch(\"feature/auth\", \"main\")\n</code></pre></p> </li> </ol> <p>Integration Notes: - All tools use execute_command_safe with user confirmation - GitHub CLI (gh) must be installed on system - Uses existing git repository in current directory - Authentication persists across session - Follows same pattern as HuggingFace integration</p>"},{"location":"architecture/system/#browser-use-tools-layer-phase-12","title":"Browser Use Tools Layer (Phase 12)","text":"<p>Overview: Direct website fetching with crawl4ai-powered scraping, TTL-based caching, and smart content truncation.</p>"},{"location":"architecture/system/#where-and-how-crawl4ai-is-used","title":"Where and How crawl4ai is Used","text":"<p>crawl4ai is an LLM-optimized async web crawler built on top of Playwright that extracts web content and converts it to markdown. It is used exclusively in the <code>fetch_website</code> tool.</p> <p>Location: <code>wyn360_cli/browser_use.py</code></p> <p>Integration Points: 1. Import (browser_use.py:22-26):    <pre><code>try:\n    from crawl4ai import AsyncWebCrawler\n    HAS_CRAWL4AI = True\nexcept ImportError:\n    HAS_CRAWL4AI = False\n    AsyncWebCrawler = None\n</code></pre></p> <ol> <li>Usage (browser_use.py:420-421):    <pre><code>async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url)\n</code></pre></li> </ol> <p>What crawl4ai Does: - Launches headless Chromium browser via Playwright - Executes JavaScript to render dynamic content - Extracts full DOM including JS-generated content - Converts HTML to clean markdown format - Returns structured result with success status</p> <p>Playwright Dependency: - crawl4ai requires Playwright browser binaries (~200MB) - One-time installation: <code>playwright install chromium</code> - Validated before use via <code>check_playwright_installed()</code> (browser_use.py:29-82) - Auto-installation is prevented with <code>PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD='1'</code> (browser_use.py:417)</p> <p>Browser Use Architecture:</p> <pre><code>graph TB\n    subgraph \"User Request\"\n        UserInput[\"User: Read https://example.com\"]\n    end\n\n    subgraph \"Agent Layer\"\n        Agent[WYN360Agent]\n        ToolCall[Tool Selection:&lt;br/&gt;fetch_website]\n    end\n\n    subgraph \"Browser Use Module (browser_use.py)\"\n        Validate[URL Validation&lt;br/&gt;is_valid_url]\n        PlaywrightCheck[Playwright Check&lt;br/&gt;check_playwright_installed]\n        CacheCheck[Cache Lookup&lt;br/&gt;WebsiteCache.get]\n        Fetch[Web Fetching&lt;br/&gt;crawl4ai.AsyncWebCrawler]\n        Truncate[Smart Truncation&lt;br/&gt;smart_truncate]\n        CacheStore[Cache Storage&lt;br/&gt;WebsiteCache.set]\n    end\n\n    subgraph \"External Dependencies\"\n        Playwright[Playwright&lt;br/&gt;Headless Chromium]\n        Website[Target Website&lt;br/&gt;example.com]\n    end\n\n    subgraph \"Storage\"\n        CacheDir[\"~/.wyn360/cache/fetched_sites/&lt;br/&gt;- *.md.gz files&lt;br/&gt;- cache_index.json\"]\n    end\n\n    UserInput --&gt; Agent\n    Agent --&gt; ToolCall\n    ToolCall --&gt; Validate\n    Validate --&gt; PlaywrightCheck\n    PlaywrightCheck --&gt; CacheCheck\n    CacheCheck --&gt;|Cache Miss| Fetch\n    CacheCheck --&gt;|Cache Hit| Truncate\n    Fetch --&gt; Playwright\n    Playwright --&gt; Website\n    Website --&gt; Playwright\n    Playwright --&gt; Fetch\n    Fetch --&gt; CacheStore\n    CacheStore --&gt; CacheDir\n    Fetch --&gt; Truncate\n    Truncate --&gt; Agent\n    Agent --&gt; UserInput\n\n    style Fetch fill:#e1f5ff\n    style Playwright fill:#fff3e0\n    style CacheCheck fill:#e8f5e9\n    style Truncate fill:#fff9c4</code></pre>"},{"location":"architecture/system/#fetch_website-tool-details","title":"fetch_website Tool Details","text":"<p>Function: <code>fetch_website(url, max_tokens, truncate_strategy)</code> Location: <code>wyn360_cli/agent.py</code> (tool registration), <code>wyn360_cli/browser_use.py</code> (implementation)</p> <p>Parameters: - <code>url</code>: Target URL to fetch (must be http:// or https://) - <code>max_tokens</code>: Maximum tokens to return (default: 50,000) - <code>truncate_strategy</code>: \"smart\" | \"head\" | \"tail\" (default: \"smart\")</p> <p>Execution Flow:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant Tool as fetch_website\n    participant Cache as WebsiteCache\n    participant Crawl as crawl4ai\n    participant Web as Website\n\n    User-&gt;&gt;Agent: \"Read https://example.com\"\n    Agent-&gt;&gt;Tool: fetch_website(url)\n\n    Tool-&gt;&gt;Tool: 1. Validate URL format\n    Tool-&gt;&gt;Tool: 2. Check Playwright installed\n\n    Tool-&gt;&gt;Cache: get(url)\n\n    alt Cache Hit (&lt; 30min old)\n        Cache--&gt;&gt;Tool: Cached markdown\n        Tool-&gt;&gt;Tool: 3b. Skip fetch\n    else Cache Miss or Expired\n        Tool-&gt;&gt;Crawl: AsyncWebCrawler().arun(url)\n        Crawl-&gt;&gt;Web: HTTP request + JS execution\n        Web--&gt;&gt;Crawl: HTML content\n        Crawl-&gt;&gt;Crawl: Convert HTML \u2192 Markdown\n        Crawl--&gt;&gt;Tool: markdown content\n        Tool-&gt;&gt;Cache: set(url, content)\n        Cache-&gt;&gt;Cache: Save as .md.gz with TTL\n    end\n\n    Tool-&gt;&gt;Tool: 4. Smart truncate if &gt; max_tokens\n    Tool--&gt;&gt;Agent: Truncated markdown\n    Agent--&gt;&gt;User: Display formatted content</code></pre>"},{"location":"architecture/system/#websitecache-implementation","title":"WebsiteCache Implementation","text":"<p>Class: <code>WebsiteCache</code> Location: <code>browser_use.py:85-270</code></p> <p>Architecture:</p> <pre><code>graph LR\n    subgraph \"Cache Structure\"\n        Index[cache_index.json&lt;br/&gt;Metadata]\n        Files[*.md.gz files&lt;br/&gt;Compressed content]\n    end\n\n    subgraph \"Cache Operations\"\n        Get[get - Retrieve]\n        Set[set - Store]\n        Clear[clear - Delete]\n        Stats[get_stats - Info]\n        Cleanup[cleanup_expired]\n    end\n\n    subgraph \"Cache Logic\"\n        TTL[TTL Check&lt;br/&gt;30min default]\n        Size[Size Check&lt;br/&gt;100MB max]\n        Hash[MD5 Hash&lt;br/&gt;URL \u2192 cache key]\n        Gzip[Gzip Compression&lt;br/&gt;~70% reduction]\n    end\n\n    Get --&gt; TTL\n    Get --&gt; Hash\n    Get --&gt; Files\n\n    Set --&gt; Hash\n    Set --&gt; Size\n    Set --&gt; Gzip\n    Set --&gt; Files\n    Set --&gt; Index\n\n    Clear --&gt; Hash\n    Clear --&gt; Files\n    Clear --&gt; Index\n\n    Stats --&gt; Index\n    Cleanup --&gt; TTL\n    Cleanup --&gt; Files\n\n    style TTL fill:#e8f5e9\n    style Gzip fill:#fff9c4\n    style Hash fill:#e1f5ff</code></pre> <p>Cache Features: - TTL-Based Expiration: 30 minutes (configurable) - Automatic Cleanup: Removes expired entries on access - Size Management: Max 100MB, auto-removes oldest entries - Compression: Gzip reduces storage by ~70% - MD5 Hashing: URL \u2192 unique cache key - JSON Index: Metadata tracking (url, timestamp, size)</p> <p>Cache Location: <code>~/.wyn360/cache/fetched_sites/</code></p> <p>Files: - <code>cache_index.json</code> - Metadata index - <code>&lt;md5_hash&gt;.md.gz</code> - Compressed markdown content</p>"},{"location":"architecture/system/#show_cache_stats-tool","title":"show_cache_stats Tool","text":"<p>Function: Display cache statistics and cached URLs Location: <code>wyn360_cli/agent.py</code></p> <p>Returns: - Total cached entries - Total cache size (MB) - List of cached URLs with age - Expired entry count</p> <p>Example Output: <pre><code>\ud83d\udcca Website Cache Statistics\n\nTotal Entries: 3\nCache Size: 2.45 MB\nExpired Entries: 0\n\nCached URLs:\n- \u2713 5m old: https://github.com/yiqiao-yin/deepspeed-course\n- \u2713 12m old: https://python.org/downloads\n- \u2713 25m old: https://docs.anthropic.com\n</code></pre></p>"},{"location":"architecture/system/#clear_website_cache-tool","title":"clear_website_cache Tool","text":"<p>Function: Clear specific URL or entire cache Location: <code>wyn360_cli/agent.py</code></p> <p>Parameters: - <code>url</code>: Optional - specific URL to clear, or None for all</p> <p>Behavior: - If <code>url</code> provided: Removes single cache entry - If <code>url</code> is None: Clears entire cache - Updates index and deletes .md.gz files</p>"},{"location":"architecture/system/#web-search-vs-fetch-website-comparison","title":"Web Search vs Fetch Website Comparison","text":"<pre><code>graph TB\n    subgraph \"User Intent\"\n        Intent1[\"Find information about X\"]\n        Intent2[\"Read specific URL\"]\n    end\n\n    subgraph \"web_search (Phase 11.1)\"\n        WS1[Builtin WebSearchTool]\n        WS2[Claude's web_search_20250305]\n        WS3[Searches web for keywords]\n        WS4[Returns top 5 results]\n        WS5[Summarizes findings]\n        WS6[Cost: $10 per 1K searches]\n    end\n\n    subgraph \"fetch_website (Phase 12)\"\n        FW1[Custom Tool + crawl4ai]\n        FW2[Fetches specific URL]\n        FW3[Extracts full page content]\n        FW4[Converts HTML \u2192 Markdown]\n        FW5[Smart truncation]\n        FW6[30-minute caching]\n        FW7[Cost: API tokens only]\n    end\n\n    Intent1 --&gt; WS1\n    WS1 --&gt; WS2\n    WS2 --&gt; WS3\n    WS3 --&gt; WS4\n    WS4 --&gt; WS5\n    WS5 --&gt; WS6\n\n    Intent2 --&gt; FW1\n    FW1 --&gt; FW2\n    FW2 --&gt; FW3\n    FW3 --&gt; FW4\n    FW4 --&gt; FW5\n    FW5 --&gt; FW6\n    FW6 --&gt; FW7\n\n    style WS2 fill:#fff3e0\n    style FW1 fill:#e1f5ff</code></pre> <p>Key Differences:</p> Feature web_search fetch_website Purpose Find/search for information Read specific webpage Input Search query/keywords Exact URL Output Top 5 search results Full page markdown Technology Claude native tool crawl4ai + Playwright Caching None (real-time) 30-minute TTL cache Cost $10 per 1K searches Standard API tokens Max Uses 5 per session Unlimited Use Cases Weather, news, find resources GitHub repos, docs, specific pages <p>Example Comparison:</p> <pre><code># web_search Example\nUser: \"Find Python async tutorials\"\n\u2192 Searches web for \"python async tutorials\"\n\u2192 Returns: Top 5 articles with summaries\n\u2192 Best for: Discovery and exploration\n\n# fetch_website Example\nUser: \"Read https://docs.python.org/3/library/asyncio.html\"\n\u2192 Fetches exact URL\n\u2192 Returns: Full page content as markdown\n\u2192 Best for: Deep reading of known pages\n</code></pre>"},{"location":"architecture/system/#utility-layer","title":"Utility Layer","text":"<p>File Operations - Safe file reading with encoding detection - Safe file writing with backup handling - Directory creation with parent path support - Error handling for permissions and I/O issues</p> <p>Directory Scanner - Recursive file traversal - File categorization by extension - Ignore pattern support (.gitignore, pycache, etc.) - Efficient for large codebases</p> <p>Command Executor - Subprocess management with timeout - Output streaming and capture - Working directory support - Environment variable injection - Exit code handling</p> <p>Code Extractor - Parses markdown code blocks - Language detection from fence markers - Multiple block extraction - Used for auto-saving generated code</p> <p>Token Tracker - Estimates tokens using char count heuristic - Tracks input and output separately - Calculates costs based on model pricing - Cumulative session tracking - Per-message breakdown</p> <p>Session Manager - Saves conversations to JSON format - Includes conversation history and token stats - Loads previous sessions - Preserves context across sessions</p>"},{"location":"architecture/system/#data-storage","title":"Data Storage","text":"<p>Session Files (JSON) - Conversation history (user + assistant messages) - Token usage statistics (input, output, cost) - Timestamp and metadata - Can be loaded to resume sessions</p> <p>Config Files (YAML) - User preferences in <code>~/.wyn360/config.yaml</code> - Project settings in <code>.wyn360.yaml</code> - Model selection, custom instructions, etc.</p>"},{"location":"architecture/system/#data-flow-examples","title":"\ud83d\udd04 Data Flow Examples","text":""},{"location":"architecture/system/#simple-file-read","title":"Simple File Read","text":"<pre><code>User: \"Show me app.py\"\n  \u2192 CLI \u2192 Agent \u2192 read_file tool\n  \u2192 FileOps reads file\n  \u2192 Content returned to Model\n  \u2192 Model generates response\n  \u2192 Output displayed word-by-word\n</code></pre>"},{"location":"architecture/system/#command-execution-with-confirmation","title":"Command Execution with Confirmation","text":"<pre><code>User: \"Run the tests\"\n  \u2192 CLI \u2192 Agent \u2192 execute_command tool\n  \u2192 Confirmation prompt displayed\n  \u2192 User presses 'y' + Enter\n  \u2192 \"\u2713 Confirmed. Executing command...\" displayed\n  \u2192 CmdExec runs command with timeout\n  \u2192 Output captured (stdout + stderr)\n  \u2192 Results returned to Model\n  \u2192 Model summarizes results\n  \u2192 Output displayed word-by-word\n</code></pre>"},{"location":"architecture/system/#multi-tool-workflow","title":"Multi-Tool Workflow","text":"<pre><code>User: \"Create a FastAPI app\"\n  \u2192 CLI \u2192 Agent \u2192 Model analyzes request\n  \u2192 Model calls write_file(\"app.py\", code)\n  \u2192 FileOps writes file\n  \u2192 Model calls write_file(\"requirements.txt\", deps)\n  \u2192 FileOps writes file\n  \u2192 Model generates response explaining what was created\n  \u2192 Output displayed word-by-word\n  \u2192 Conversation + tokens saved to history\n</code></pre>"},{"location":"architecture/system/#model-switch-mid-session","title":"Model Switch Mid-Session","text":"<pre><code>User: \"/model haiku\"\n  \u2192 CLI \u2192 SlashCmd handler\n  \u2192 Agent \u2192 ModelSwitch\n  \u2192 New model instantiated (claude-3-5-haiku)\n  \u2192 Conversation history preserved\n  \u2192 Confirmation message displayed\n</code></pre>"},{"location":"architecture/system/#session-saveload","title":"Session Save/Load","text":"<pre><code>User: \"/save my_session.json\"\n  \u2192 CLI \u2192 SlashCmd handler\n  \u2192 SessionMgr serializes conversation + tokens\n  \u2192 JSON file written\n  \u2192 Confirmation message\n\nLater...\nUser: \"/load my_session.json\"\n  \u2192 CLI \u2192 SlashCmd handler\n  \u2192 SessionMgr reads JSON file\n  \u2192 Conversation history restored\n  \u2192 Token counters restored\n  \u2192 Confirmation message\n</code></pre>"},{"location":"architecture/system/#website-fetching-with-cache","title":"Website Fetching with Cache","text":"<pre><code>User: \"Read https://github.com/user/repo\"\n  \u2192 CLI \u2192 Agent \u2192 fetch_website tool\n  \u2192 Validate URL format (http/https)\n  \u2192 Check Playwright installation (browser binaries)\n  \u2192 WebsiteCache checks for cached content\n\n  If Cache Hit (&lt; 30min):\n    \u2192 Return cached markdown (instant)\n    \u2192 Skip web fetch\n\n  If Cache Miss:\n    \u2192 crawl4ai launches headless Chromium\n    \u2192 Executes JavaScript on target page\n    \u2192 Extracts full DOM content\n    \u2192 Converts HTML \u2192 Markdown\n    \u2192 WebsiteCache stores compressed .md.gz\n    \u2192 Updates cache_index.json\n\n  \u2192 smart_truncate if content &gt; 50K tokens\n    \u2192 Keep first 70% + last 30%\n    \u2192 Preserve headers and structure\n  \u2192 Model receives markdown content\n  \u2192 Model generates summary/response\n  \u2192 Output displayed word-by-word\n</code></pre>"},{"location":"architecture/system/#web-search-vs-website-fetch","title":"Web Search vs Website Fetch","text":"<pre><code>Scenario 1: \"What's the weather in Boston?\"\n  \u2192 Agent recognizes weather query\n  \u2192 Calls web_search (builtin tool)\n  \u2192 Claude's native search returns current weather\n  \u2192 Cost: 1 search ($0.01)\n  \u2192 No caching\n\nScenario 2: \"Read https://docs.python.org/3/library/asyncio.html\"\n  \u2192 Agent recognizes specific URL\n  \u2192 Calls fetch_website (custom tool)\n  \u2192 crawl4ai fetches full page content\n  \u2192 Caches for 30 minutes\n  \u2192 Cost: Only API tokens (~5K tokens input)\n  \u2192 Subsequent requests use cache (free)\n</code></pre>"},{"location":"architecture/system/#key-features-by-phase","title":"\ud83d\ude80 Key Features by Phase","text":""},{"location":"architecture/system/#phase-1-context-management-v028","title":"Phase 1: Context Management (v0.2.8)","text":"<ul> <li>\u2705 Conversation history persistence</li> <li>\u2705 Token tracking and cost monitoring</li> <li>\u2705 Session save/load functionality</li> <li>\u2705 Slash commands (/clear, /history, /save, /load, /tokens, /help)</li> </ul>"},{"location":"architecture/system/#phase-2-additional-tools-v029","title":"Phase 2: Additional Tools (v0.2.9)","text":"<ul> <li>\u2705 Git operations (status, diff, log, branch)</li> <li>\u2705 Code search across files with pattern matching</li> <li>\u2705 File management (delete, move, create dirs)</li> <li>\u2705 8 new tools for enhanced project management</li> </ul>"},{"location":"architecture/system/#phase-3-model-selection-v030","title":"Phase 3: Model Selection (v0.3.0)","text":"<ul> <li>\u2705 Dynamic model switching (haiku/sonnet/opus)</li> <li>\u2705 Model information display with pricing</li> <li>\u2705 /model command for mid-session changes</li> <li>\u2705 Cost-aware recommendations</li> </ul>"},{"location":"architecture/system/#phase-4-configuration-v031","title":"Phase 4: Configuration (v0.3.1)","text":"<ul> <li>\u2705 User configuration file (~/.wyn360/config.yaml)</li> <li>\u2705 Project configuration file (.wyn360.yaml)</li> <li>\u2705 Custom instructions and project context</li> <li>\u2705 /config command to view settings</li> </ul>"},{"location":"architecture/system/#phase-5-streaming-responses-v032-v0315","title":"Phase 5: Streaming Responses (v0.3.2-v0.3.15)","text":"<ul> <li>\u2705 Word-by-word output simulation for smooth UX</li> <li>\u2705 Real-time feedback and progress visibility</li> <li>\u2705 Immediate command execution confirmation (v0.3.14)</li> <li>\u2705 No text duplication (fixed in v0.3.13)</li> </ul>"},{"location":"architecture/system/#phase-81-github-integration-v0322","title":"Phase 8.1: GitHub Integration (v0.3.22)","text":"<ul> <li>\u2705 GitHub authentication with token management (GH_TOKEN/GITHUB_TOKEN)</li> <li>\u2705 Commit and push changes directly from CLI</li> <li>\u2705 Create pull requests with title, body, and base branch</li> <li>\u2705 Branch management: create, checkout, merge branches</li> <li>\u2705 Auto-authentication from environment variables</li> <li>\u2705 Integration with GitHub CLI (gh) for seamless operations</li> <li>\u2705 7 new tools for complete GitHub workflow management</li> </ul>"},{"location":"architecture/system/#phase-111-web-search-v0321-enhanced-v0323","title":"Phase 11.1: Web Search (v0.3.21, Enhanced v0.3.23)","text":"<ul> <li>\u2705 Real-time web search using Claude's native web_search_20250305 tool</li> <li>\u2705 Weather queries with location handling</li> <li>\u2705 Website content fetching and summarization</li> <li>\u2705 Current information retrieval (docs, news, trends)</li> <li>\u2705 Resource finding - GitHub repos, libraries, tutorials (v0.3.23)</li> <li>\u2705 Cost-controlled with 5 searches per session max</li> <li>\u2705 Integrated via pydantic-ai's WebSearchTool builtin</li> <li>\u2705 Upgraded to pydantic-ai 1.13.0 for improved stability (v0.3.23)</li> <li>\u2705 Enhanced system prompt with clearer intent examples (v0.3.23)</li> </ul>"},{"location":"architecture/system/#phase-12-browser-use-direct-website-fetching-v0324-v0325","title":"Phase 12: Browser Use / Direct Website Fetching (v0.3.24-v0.3.25)","text":"<p>Phase 12.1: Basic Website Fetching (v0.3.24) - \u2705 Direct URL fetching using crawl4ai (LLM-optimized web crawler) - \u2705 Full DOM extraction with JavaScript execution support - \u2705 Automatic HTML \u2192 Markdown conversion for LLM consumption - \u2705 Smart truncation preserving document structure - \u2705 Configurable max tokens (default: 50,000) - \u2705 URL validation and error handling - \u2705 Integration with agent tool system</p> <p>Phase 12.2: TTL-Based Caching (v0.3.24) - \u2705 Automatic caching with 30-minute TTL (configurable) - \u2705 Gzip compression for efficient storage - \u2705 Cache directory: <code>~/.wyn360/cache/fetched_sites/</code> - \u2705 Automatic cleanup of expired entries - \u2705 Size-based cache management (max 100MB) - \u2705 Cache hit/miss tracking - \u2705 JSON index for metadata management</p> <p>Phase 12.3: User-Controlled Cache Management (v0.3.24) - \u2705 <code>show_cache_stats</code> - View cache statistics and cached URLs - \u2705 <code>clear_website_cache</code> - Clear specific URL or all cache - \u2705 Cache age tracking and expiration display - \u2705 User-friendly cache information - \u2705 Integration with agent conversation flow</p> <p>Phase 12.4: Playwright Installation Validation (v0.3.25) - \u2705 Pre-flight Playwright installation check via <code>check_playwright_installed()</code> - \u2705 Prevents unwanted auto-installation during execution - \u2705 Clear error messages with installation instructions - \u2705 Environment variable <code>PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD='1'</code> to block auto-install - \u2705 Validates both Playwright CLI and browser binaries (~/.cache/ms-playwright/) - \u2705 24 comprehensive unit tests for all browser use functionality - \u2705 Test coverage: URL validation, caching, truncation, Playwright checks, fetch operations</p> <p>Technical Architecture: - crawl4ai: Playwright-based async web crawler (optional dependency) - Playwright: Headless Chromium browser (~200MB, one-time install) - browser_use.py: Core fetching, caching, truncation, and validation logic - WebsiteCache: TTL-based cache with automatic cleanup - Smart Truncation: Preserves headers, keeps first 70% + last 30% - Token Estimation: ~4 chars per token for truncation decisions - Installation Check: Subprocess validation before crawl4ai usage</p> <p>Configuration (config.yaml): <pre><code>browser_use:\n  max_tokens: 50000  # Configurable per user\n  truncate_strategy: \"smart\"  # smart, head, tail\n  cache:\n    enabled: true\n    ttl: 1800  # 30 minutes\n    max_size_mb: 100\n</code></pre></p> <p>Key Differentiators from WebSearchTool: - WebSearchTool: Searches for keywords \u2192 Returns top 5 results - fetch_website: Fetches specific URL \u2192 Returns full page content - Use Case Split: Search (find things) vs Fetch (get specific pages)</p>"},{"location":"architecture/system/#phase-4-authenticated-browsing-v0340-v0341","title":"Phase 4: Authenticated Browsing (v0.3.40-v0.3.41)","text":"<p>Phase 4.1: Secure Credential Storage (v0.3.40) - \u2705 CredentialManager with AES-256-GCM encryption - \u2705 Per-user encryption key from system entropy - \u2705 Encrypted credential vault (~/.wyn360/credentials/vault.enc) - \u2705 File permissions: 0600 (user read/write only) - \u2705 Audit logging without sensitive data - \u2705 21/21 unit tests passing</p> <p>Phase 4.2: Browser Authentication &amp; Session Management (v0.3.40) - \u2705 SessionManager with TTL-based session cookies (30 min default) - \u2705 BrowserAuth using Playwright for automated login - \u2705 Automatic form detection (username, password, submit) - \u2705 CAPTCHA detection (notifies user) - \u2705 2FA/MFA detection (notifies user) - \u2705 Session persistence and automatic expiration - \u2705 27/27 unit tests passing (SessionManager: 16, BrowserAuth: 11)</p> <p>Phase 4.3: Authenticated Fetch Integration (v0.3.41) - \u2705 Seamless integration of sessions with fetch_website - \u2705 Automatic session detection and cookie injection - \u2705 Domain-based session matching - \u2705 Visual authentication indicator (\ud83d\udd10) - \u2705 Zero-friction authenticated browsing</p> <p>What Happens When User Says \"Login to this website\":</p> <pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant BrowserAuth\n    participant CredentialManager\n    participant SessionManager\n    participant Playwright\n\n    User-&gt;&gt;Agent: \"Login to https://site.com with user/pass\"\n    Agent-&gt;&gt;BrowserAuth: login(url, username, password)\n    BrowserAuth-&gt;&gt;Playwright: Launch browser (headless)\n    Playwright-&gt;&gt;BrowserAuth: Browser ready\n    BrowserAuth-&gt;&gt;Playwright: Navigate to URL\n    BrowserAuth-&gt;&gt;Playwright: Detect login form elements\n    BrowserAuth-&gt;&gt;Playwright: Fill username field\n    BrowserAuth-&gt;&gt;Playwright: Fill password field\n    BrowserAuth-&gt;&gt;Playwright: Click submit button\n    BrowserAuth-&gt;&gt;Playwright: Wait for navigation\n\n    alt CAPTCHA Detected\n        BrowserAuth--&gt;&gt;User: \u26a0\ufe0f CAPTCHA detected, manual completion required\n    else 2FA Detected\n        BrowserAuth--&gt;&gt;User: \ud83d\udd10 2FA detected, manual verification required\n    else Login Failed\n        BrowserAuth--&gt;&gt;User: \u274c Login failed (incorrect credentials)\n    else Login Success\n        BrowserAuth-&gt;&gt;Playwright: Extract session cookies\n        BrowserAuth-&gt;&gt;SessionManager: save_session(domain, cookies)\n        SessionManager--&gt;&gt;Agent: Session saved (30 min TTL)\n        BrowserAuth-&gt;&gt;CredentialManager: save_credential(domain, username, password)\n        CredentialManager--&gt;&gt;Agent: Credentials encrypted and saved\n        Agent--&gt;&gt;User: \u2705 Login successful! Session active for 30 minutes\n    end\n\n    BrowserAuth-&gt;&gt;Playwright: Close browser</code></pre> <p>Authenticated Fetch Workflow:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant SessionManager\n    participant browser_use\n    participant Playwright\n\n    User-&gt;&gt;Agent: \"Fetch https://site.com/profile\"\n    Agent-&gt;&gt;Agent: Extract domain from URL\n    Agent-&gt;&gt;SessionManager: get_session(domain)\n\n    alt Session Exists\n        SessionManager--&gt;&gt;Agent: Return cookies\n        Agent-&gt;&gt;browser_use: fetch_website_content(url, cookies=cookies)\n        browser_use-&gt;&gt;Playwright: Launch with cookies injected\n        Playwright-&gt;&gt;browser_use: Return authenticated content\n        browser_use--&gt;&gt;Agent: Content retrieved\n        Agent--&gt;&gt;User: \ud83d\udcc4 Fetched \ud83d\udd10 (authenticated): [content]\n    else No Session\n        SessionManager--&gt;&gt;Agent: None (no session)\n        Agent-&gt;&gt;browser_use: fetch_website_content(url, cookies=None)\n        browser_use-&gt;&gt;Playwright: Launch without cookies\n        Playwright-&gt;&gt;browser_use: Return public content\n        browser_use--&gt;&gt;Agent: Content retrieved\n        Agent--&gt;&gt;User: \ud83d\udcc4 Fetched: [content]\n    end</code></pre> <p>Technical Architecture:</p> <pre><code>~/.wyn360/\n\u251c\u2500\u2500 credentials/\n\u2502   \u251c\u2500\u2500 .keyfile               # AES-256 encryption key (0600)\n\u2502   \u2514\u2500\u2500 vault.enc              # Encrypted credentials\n\u251c\u2500\u2500 sessions/\n\u2502   \u251c\u2500\u2500 example_com.session.json  # Session cookies with TTL\n\u2502   \u2514\u2500\u2500 github_com.session.json   # Domain-based sessions\n\u2514\u2500\u2500 logs/\n    \u2514\u2500\u2500 auth_audit.log         # Audit log (no sensitive data)\n</code></pre> <p>Module Architecture:</p> <pre><code>wyn360_cli/\n\u251c\u2500\u2500 credential_manager.py      # AES-256-GCM encryption, vault management\n\u251c\u2500\u2500 session_manager.py         # TTL-based session cookie storage\n\u251c\u2500\u2500 browser_auth.py            # Playwright automation, form detection\n\u251c\u2500\u2500 browser_use.py             # Website fetching with cookie support\n\u2514\u2500\u2500 agent.py                   # Tool integration and orchestration\n</code></pre> <p>Security Features: - Encryption: AES-256-GCM for all stored credentials - Key Management: Per-user encryption key from system entropy - File Permissions: 0600 (user read/write only) - Session TTL: 30-minute default with automatic expiration - Audit Trail: All access logged without sensitive data - No Plain Text: Credentials only decrypted when needed</p> <p>User Experience Examples:</p> <p>Example 1: Login and Fetch Authenticated Page <pre><code>User: Login to https://example-site.com with demo_user and SecurePass123!\n\nAgent: [Launches Playwright browser]\n       [Detects login form]\n       [Fills username: demo_user]\n       [Fills password: ********]\n       [Clicks submit]\n       [Extracts session cookies]\n       [Saves session with 30min TTL]\n       [Encrypts and saves credentials]\n\n       \u2705 Login successful to example-site.com!\n\n       Session Details:\n       - Domain: example-site.com\n       - Username: demo_user\n       - Session saved: Yes (30 minutes TTL)\n       - Credentials saved: Yes (encrypted)\n\n       Next Steps:\n       Use fetch_website() to access authenticated pages with this session.\n\nUser: Fetch my profile from https://example-site.com/profile\n\nAgent: [Checks SessionManager for example-site.com]\n       [Found valid session with cookies]\n       [Injects cookies into browser]\n       [Fetches authenticated content]\n\n       \ud83d\udcc4 Fetched \ud83d\udd10 (authenticated): https://example-site.com/profile\n\n       [Profile content with user-specific data...]\n</code></pre></p> <p>Example 2: CAPTCHA Detection <pre><code>User: Login to https://example.com with user@email.com and pass123\n\nAgent: [Launches browser]\n       [Navigates to URL]\n       [Detects CAPTCHA on page]\n\n       \u274c Login blocked by CAPTCHA\n\n       The website requires CAPTCHA completion:\n       - URL: https://example.com/login\n\n       Action Required:\n       Please login manually in a browser to complete the CAPTCHA.\n       Once logged in, you can use the browser's cookies with fetch_website().\n</code></pre></p> <p>Example 3: 2FA Required <pre><code>User: Login to https://github.com with myuser and mypassword\n\nAgent: [Launches browser]\n       [Fills credentials]\n       [Submits form]\n       [Detects 2FA prompt]\n\n       \ud83d\udd10 2FA Required\n\n       The website requires two-factor authentication:\n       - URL: https://github.com/login\n\n       Action Required:\n       Two-factor authentication must be completed manually.\n       Please login through a browser to complete 2FA verification.\n</code></pre></p> <p>Example 4: Session Auto-Detection <pre><code>User: Fetch https://example-site.com/dashboard\n\nAgent: [Checks for saved session]\n       [Found: example-site.com session (expires in 15 minutes)]\n       [Automatically injects cookies]\n\n       \ud83d\udcc4 Fetched \ud83d\udd10 (authenticated): https://example-site.com/dashboard\n\n       [Authenticated dashboard content...]\n</code></pre></p> <p>Configuration (config.yaml): <pre><code># Future enhancement - not yet implemented\nauthentication:\n  session_ttl: 1800  # 30 minutes\n  save_credentials: true\n  headless: true\n  timeout: 30000  # 30 seconds\n</code></pre></p> <p>Capabilities Matrix:</p> Feature Status Tool Notes Automated Login \u2705 <code>login_to_website</code> Form detection, CAPTCHA/2FA detection Credential Storage \u2705 <code>CredentialManager</code> AES-256-GCM encrypted Session Management \u2705 <code>SessionManager</code> 30-min TTL, auto-expiration Authenticated Fetch \u2705 <code>fetch_website</code> Auto cookie injection Form Detection \u2705 <code>BrowserAuth</code> Username, password, submit CAPTCHA Detection \u2705 <code>BrowserAuth</code> Notifies user 2FA Detection \u2705 <code>BrowserAuth</code> Notifies user Session Reuse \u2705 Automatic Domain-based matching Audit Logging \u2705 <code>CredentialManager</code> No sensitive data <p>Test Coverage: - CredentialManager: 21/21 tests passing - SessionManager: 16/16 tests passing - BrowserAuth: 11/11 tests passing - Total: 48/48 tests passing \u2705</p>"},{"location":"architecture/system/#design-principles","title":"\ud83c\udfaf Design Principles","text":"<ol> <li>Safety First: Confirmation prompts, overwrite protection, timeout limits</li> <li>User Control: Slash commands, model switching, configuration options</li> <li>Transparency: Token tracking, cost visibility, clear error messages</li> <li>Context Awareness: Conversation history, project configs, intent recognition</li> <li>Extensibility: Modular architecture, easy to add new tools</li> <li>Performance: Efficient file operations, smart caching, timeout protection</li> </ol>"},{"location":"architecture/system/#future-enhancements","title":"\ud83d\udcc8 Future Enhancements","text":"<p>See ROADMAP.md for planned features including: - Phase 6: Advanced Workflows (multi-file refactoring, test generation) - Phase 7: Integration Features (GitHub, databases) - Phase 8: Safety &amp; Quality (validation, backups, undo/rollback) - Phase 9: Monitoring &amp; Analytics (usage dashboards, performance metrics) - Phase 10: Collaboration Features (session sharing, prompt library)</p>"},{"location":"architecture/system/#related-documentation","title":"\ud83d\udcda Related Documentation","text":"<ul> <li>Getting Started - Quick start and basic usage</li> <li>USE_CASES.md - Detailed examples and use cases</li> <li>ROADMAP.md - Feature roadmap and expansion ideas</li> <li>ROADMAP_BROWSERUSE.md - Browser use implementation roadmap</li> <li>COST.md - Cost analysis and optimization strategies</li> </ul> <p>Version: 0.3.41 Last Updated: November 2025 Maintained by: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Contributions to WYN360 CLI are welcome! This guide will help you get started.</p>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python &gt;= 3.10</li> <li>Poetry (package manager)</li> <li>Git</li> </ul>"},{"location":"development/contributing/#setup-steps","title":"Setup Steps","text":"<ol> <li> <p>Fork and clone the repository: <pre><code>git clone https://github.com/your-username/wyn360-cli.git\ncd wyn360-cli\n</code></pre></p> </li> <li> <p>Install Poetry (if not already installed):    <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>poetry install\n</code></pre></p> </li> <li> <p>Set up pre-commit hooks (recommended): <pre><code>poetry run pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Create a feature branch: <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Make your changes and test: <pre><code># Run tests\nWYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v\n\n# Test your changes manually\npoetry run wyn360\n</code></pre></p> </li> <li> <p>Update documentation if needed: <pre><code># Update version in pyproject.toml, __init__.py\n# Update docs/ if adding new features\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#testing","title":"Testing","text":"<p>Run all tests: <pre><code>WYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v\n</code></pre></p> <p>Run specific test file: <pre><code>poetry run pytest tests/test_agent.py -v\n</code></pre></p> <p>Run with coverage: <pre><code>poetry run pytest tests/ --cov=wyn360_cli --cov-report=html\n</code></pre></p>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<p>We follow Python best practices:</p> <ul> <li>PEP 8 style guidelines</li> <li>Type hints for function parameters and return values</li> <li>Docstrings for public functions and classes</li> <li>Black for code formatting</li> <li>isort for import sorting</li> </ul>"},{"location":"development/contributing/#submitting-changes","title":"Submitting Changes","text":""},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li> <p>Ensure tests pass: <pre><code>WYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v\n</code></pre></p> </li> <li> <p>Update documentation:</p> </li> <li>Add/update docstrings</li> <li>Update relevant <code>.md</code> files</li> <li> <p>Update version numbers if needed</p> </li> <li> <p>Commit your changes: <pre><code>git add .\ngit commit -m \"feat: your feature description\"\n</code></pre></p> </li> <li> <p>Push and create PR: <pre><code>git push origin feature/your-feature-name\n# Create pull request on GitHub\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#commit-message-format","title":"Commit Message Format","text":"<p>Use conventional commits:</p> <ul> <li><code>feat:</code> - New features</li> <li><code>fix:</code> - Bug fixes</li> <li><code>docs:</code> - Documentation changes</li> <li><code>test:</code> - Adding/updating tests</li> <li><code>refactor:</code> - Code refactoring</li> <li><code>style:</code> - Code style changes</li> </ul> <p>Examples: <pre><code>feat: Add Google Gemini integration\nfix: Handle timeout errors in web search\ndocs: Update installation instructions\ntest: Add tests for document processing\n</code></pre></p>"},{"location":"development/contributing/#areas-for-contribution","title":"Areas for Contribution","text":""},{"location":"development/contributing/#high-priority","title":"High Priority","text":"<ul> <li>Bug fixes - Check GitHub issues</li> <li>Documentation improvements - Always welcome</li> <li>Test coverage - Increase test coverage</li> <li>Performance optimizations - Speed and efficiency</li> </ul>"},{"location":"development/contributing/#feature-development","title":"Feature Development","text":"<ul> <li>New AI providers - Additional LLM integrations</li> <li>Tool integrations - New development tools</li> <li>UI improvements - Better terminal experience</li> <li>Platform support - Windows/macOS specific features</li> </ul>"},{"location":"development/contributing/#documentation","title":"Documentation","text":"<ul> <li>Usage examples - Real-world workflows</li> <li>Tutorial content - Step-by-step guides</li> <li>API documentation - Code documentation</li> <li>Video tutorials - Screen recordings</li> </ul>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":""},{"location":"development/contributing/#resources","title":"Resources","text":"<ul> <li>GitHub Issues - Bug reports and feature requests</li> <li>Discussions - General questions and ideas</li> <li>Discord - Real-time chat (if available)</li> </ul>"},{"location":"development/contributing/#code-review-process","title":"Code Review Process","text":"<ul> <li>All changes require review</li> <li>Maintain backward compatibility</li> <li>Include tests for new features</li> <li>Update documentation</li> </ul>"},{"location":"development/contributing/#release-process","title":"Release Process","text":""},{"location":"development/contributing/#version-management","title":"Version Management","text":"<p>Update version in: - <code>pyproject.toml</code> - <code>version = \"X.Y.Z\"</code> - <code>wyn360_cli/__init__.py</code> - <code>__version__ = \"X.Y.Z\"</code> - Documentation files as needed</p>"},{"location":"development/contributing/#building-and-publishing","title":"Building and Publishing","text":"<pre><code># Build package\npoetry build\n\n# Test locally\npip install dist/wyn360_cli-X.Y.Z-py3-none-any.whl\n\n# Publish to PyPI (maintainers only)\npoetry publish\n</code></pre>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Help others learn and grow</li> <li>Focus on constructive feedback</li> <li>Maintain professional communication</li> </ul> <p>Thank you for contributing to WYN360 CLI!</p>"},{"location":"development/roadmap/","title":"WYN360 CLI - Feature Roadmap &amp; Expansion Ideas","text":"<p>This document outlines potential features and enhancements to expand WYN360 CLI's capabilities.</p>"},{"location":"development/roadmap/#current-capabilities-v0323","title":"\ud83c\udfaf Current Capabilities (v0.3.23)","text":"<p>What We Have: - \u2705 File operations (read, write, list, get project info) - \u2705 Command execution with confirmation - \u2705 Code generation from natural language - \u2705 Intent recognition (create vs update) - \u2705 Multi-line input support - \u2705 Comprehensive error handling - \u2705 Tool calling with retry logic - \u2705 Conversation history and context management (Phase 1) - \u2705 Token tracking and cost monitoring (Phase 1) - \u2705 Session save/load functionality (Phase 1) - \u2705 Slash commands for context management (Phase 1) - \u2705 Git operations (status, diff, log, branch) (Phase 2) - \u2705 Code search across files (Phase 2) - \u2705 File management (delete, move, create dirs) (Phase 2) - \u2705 Dynamic model switching (haiku/sonnet/opus) (Phase 3) - \u2705 Model information display with pricing (Phase 3) - \u2705 /model command for mid-session model changes (Phase 3) - \u2705 User configuration file (~/.wyn360/config.yaml) (Phase 4) - \u2705 Project configuration file (.wyn360.yaml) (Phase 4) - \u2705 Custom instructions and project context (Phase 4) - \u2705 /config command to view settings (Phase 4) - \u2705 Streaming responses - token-by-token output (Phase 5) - \u2705 Real-time feedback and progress visibility (Phase 5) - \u2705 HuggingFace authentication and README generation (Phase 6.1) - \u2705 HuggingFace Space creation and file upload (Phase 6.2) - \u2705 Full automatic deployment to HuggingFace Spaces (Phase 6 Complete) - \u2705 Automatic test generation for Python files (Phase 7.2) - \u2705 Performance metrics tracking - response times, tool usage, error rates (Phase 10.2) - \u2705 Enhanced CLI help with <code>-h</code> flag - comprehensive command reference (UX Improvement) - \u2705 Real-time web search - weather, URLs, current information (Phase 11.1) - Enhanced in v0.3.23 - \u2705 GitHub integration - commit, PR creation, branch management, merge (Phase 8.1)</p> <p>Recent Improvements (v0.3.23): - \u2b06\ufe0f Upgraded pydantic-ai from 0.0.19 to 1.13.0 for improved stability and features - \ud83d\udd27 Fixed web search tool integration - now properly recognizes resource/repo search queries - \ud83d\udcdd Enhanced system prompt with clearer web search intent examples - \u2705 Web search now works for queries like \"find a popular GitHub repo for X\"</p>"},{"location":"development/roadmap/#suggested-expansions","title":"\ud83d\ude80 Suggested Expansions","text":""},{"location":"development/roadmap/#phase-1-enhanced-context-management-completed-v028","title":"Phase 1: Enhanced Context Management \u2705 COMPLETED (v0.2.8)","text":""},{"location":"development/roadmap/#11-conversation-history-in-api-calls","title":"1.1 Conversation History in API Calls","text":"<p>Current: History stored locally but not sent to API Proposed: Send conversation history to maintain context across turns</p> <p>Benefits: - Agent remembers previous interactions - \"Continue from where we left off\" workflows - Better follow-up question handling</p> <p>Implementation: <pre><code># In agent.py chat() method\nmessages = [{\"role\": \"system\", \"content\": system_prompt}]\nmessages.extend(self.conversation_history)\nresult = await self.agent.run(user_message, message_history=messages)\n</code></pre></p> <p>Considerations: - Token usage increases significantly - Need context window management (max tokens) - Add option to disable for cost savings</p> <p>Priority: HIGH - Most requested feature</p>"},{"location":"development/roadmap/#12-context-management-commands","title":"1.2 Context Management Commands","text":"<p>Feature: User control over conversation context</p> <p>Commands: <pre><code>/clear      # Clear conversation history\n/history    # Show conversation history\n/save       # Save session to file\n/load       # Load previous session\n/token      # Show token usage stats\n</code></pre></p> <p>Implementation: - Add slash command parsing in CLI - Store sessions as JSON - Display token counts per message</p> <p>Priority: MEDIUM</p>"},{"location":"development/roadmap/#phase-2-additional-tools-completed-v029","title":"Phase 2: Additional Tools \u2705 COMPLETED (v0.2.9)","text":""},{"location":"development/roadmap/#21-git-operations-tool","title":"2.1 Git Operations Tool","text":"<p>Why: Most developers use git constantly</p> <p>Tool Functions: <pre><code>async def git_status(self, ctx: RunContext[None]) -&gt; str:\n    \"\"\"Get current git status\"\"\"\n\nasync def git_diff(self, ctx: RunContext[None], file_path: str = None) -&gt; str:\n    \"\"\"Show git diff for file or all changes\"\"\"\n\nasync def git_commit(self, ctx: RunContext[None], message: str) -&gt; str:\n    \"\"\"Create git commit with message\"\"\"\n\nasync def git_branch(self, ctx: RunContext[None]) -&gt; str:\n    \"\"\"List branches\"\"\"\n</code></pre></p> <p>Use Cases: - \"Show me what files changed\" - \"Commit these changes with message 'Add feature X'\" - \"What branch am I on?\"</p> <p>Priority: HIGH - Frequently needed</p>"},{"location":"development/roadmap/#22-searchgrep-tool","title":"2.2 Search/Grep Tool","text":"<p>Why: Find code patterns across files</p> <p>Tool Function: <pre><code>async def search_files(\n    self,\n    ctx: RunContext[None],\n    pattern: str,\n    file_pattern: str = \"*.py\"\n) -&gt; str:\n    \"\"\"Search for pattern in files matching file_pattern\"\"\"\n</code></pre></p> <p>Use Cases: - \"Find all functions that use 'requests' library\" - \"Where is the User class defined?\" - \"Show me all TODO comments\"</p> <p>Priority: HIGH - Essential for large codebases</p>"},{"location":"development/roadmap/#23-file-management-tools","title":"2.3 File Management Tools","text":"<p>Why: Complete file system operations</p> <p>Tool Functions: <pre><code>async def delete_file(self, ctx: RunContext[None], file_path: str) -&gt; str:\n    \"\"\"Delete a file (with confirmation)\"\"\"\n\nasync def move_file(\n    self,\n    ctx: RunContext[None],\n    source: str,\n    destination: str\n) -&gt; str:\n    \"\"\"Move or rename file\"\"\"\n\nasync def create_directory(self, ctx: RunContext[None], dir_path: str) -&gt; str:\n    \"\"\"Create directory structure\"\"\"\n</code></pre></p> <p>Priority: MEDIUM</p>"},{"location":"development/roadmap/#phase-3-model-selection-optimization-completed-v030","title":"Phase 3: Model Selection &amp; Optimization \u2705 COMPLETED (v0.3.0)","text":""},{"location":"development/roadmap/#31-dynamic-model-switching","title":"3.1 Dynamic Model Switching","text":"<p>Feature: Choose model based on task complexity</p> <p>Implementation: <pre><code># In CLI\nwyn360 --model haiku      # Fast &amp; cheap for simple tasks\nwyn360 --model sonnet     # Default - balanced\nwyn360 --model opus       # Most capable - expensive\n\n# Or dynamic in-session\n\"Use Haiku for this simple task\"\n\"Switch to Opus for complex refactoring\"\n</code></pre></p> <p>Cost Optimization: | Model | Input Cost | Output Cost | Best For | |-------|-----------|-------------|----------| | Haiku | $0.25/M | $1.25/M | Simple file ops, quick questions | | Sonnet | $3.00/M | $15.00/M | General coding, analysis | | Opus | $15.00/M | $75.00/M | Complex reasoning, architecture |</p> <p>Priority: MEDIUM - Good for power users</p>"},{"location":"development/roadmap/#32-automatic-model-selection","title":"3.2 Automatic Model Selection","text":"<p>Feature: Agent chooses appropriate model for task</p> <p>Logic: <pre><code>def suggest_model(task_description: str) -&gt; str:\n    if is_simple_task(task_description):\n        return \"haiku\"  # \"read file\", \"list files\"\n    elif is_complex_task(task_description):\n        return \"opus\"   # \"refactor architecture\", \"design system\"\n    else:\n        return \"sonnet\"  # Default\n</code></pre></p> <p>Priority: LOW - Nice to have</p>"},{"location":"development/roadmap/#phase-4-configuration-personalization-completed-v031","title":"Phase 4: Configuration &amp; Personalization \u2705 COMPLETED (v0.3.1)","text":""},{"location":"development/roadmap/#41-configuration-file","title":"4.1 Configuration File","text":"<p>Feature: Persistent user preferences</p> <p>File: <code>~/.wyn360/config.yaml</code> <pre><code># Default settings\nmodel: claude-sonnet-4-20250514\nmax_tokens: 4096\ntemperature: 0.7\n\n# Custom system prompt additions\ncustom_instructions: |\n  - Always use type hints\n  - Follow PEP 8 strictly\n  - Add docstrings to all functions\n\n# Shortcuts\naliases:\n  test: \"run pytest tests/ -v\"\n  lint: \"run ruff check .\"\n\n# Favorite directories\nworkspaces:\n  - ~/projects/app1\n  - ~/projects/ml-research\n</code></pre></p> <p>Priority: MEDIUM - Improves UX for regular users</p>"},{"location":"development/roadmap/#42-project-specific-context","title":"4.2 Project-Specific Context","text":"<p>Feature: Auto-load project context</p> <p>File: <code>.wyn360.yaml</code> in project root <pre><code># Project-specific instructions\ncontext: |\n  This is a FastAPI project with:\n  - PostgreSQL database\n  - Redis caching\n  - Celery for background tasks\n\n# Project-specific tools\ndependencies:\n  - fastapi\n  - sqlalchemy\n  - celery\n\n# Common commands\ncommands:\n  dev: \"uvicorn app.main:app --reload\"\n  test: \"pytest tests/ -v --cov\"\n</code></pre></p> <p>Priority: MEDIUM - Great for teams</p>"},{"location":"development/roadmap/#phase-5-streaming-responses-completed-v032-bugfixes-v033-034","title":"Phase 5: Streaming Responses \u2705 COMPLETED (v0.3.2, bugfixes v0.3.3-0.3.4)","text":""},{"location":"development/roadmap/#51-token-by-token-streaming","title":"5.1 Token-by-Token Streaming","text":"<p>Why: See responses as they generate (like ChatGPT)</p> <p>Current Experience: <pre><code>You: Generate a large script\n[Spinner for 10 seconds]\nWYN360: [Entire response appears at once]\n</code></pre></p> <p>Proposed Experience: <pre><code>You: Generate a large script\nWYN360: I'll create a comprehensive... [tokens appear as generated]\n</code></pre></p> <p>Implementation: <pre><code># Use async streaming API\nasync for chunk in agent.run_stream(user_message):\n    print(chunk, end='', flush=True)\n</code></pre></p> <p>Benefits: - Feels faster (immediate feedback) - Can cancel long responses - Better UX for lengthy outputs</p> <p>Priority: HIGH - Significant UX improvement</p>"},{"location":"development/roadmap/#phase-6-huggingface-integration-completed-v0316-v0317","title":"Phase 6: HuggingFace Integration \u2705 COMPLETED (v0.3.16-v0.3.17)","text":""},{"location":"development/roadmap/#61-huggingface-authentication-readme-generation-completed-v0316","title":"6.1 HuggingFace Authentication &amp; README Generation \u2705 COMPLETED (v0.3.16)","text":"<p>Feature: Enable users to deploy apps to HuggingFace Spaces through natural language</p> <p>Phase 1 Implementation:</p> <p>New Tools: <pre><code>async def check_hf_authentication(self, ctx: RunContext[None]) -&gt; str:\n    \"\"\"Check if user is authenticated with HuggingFace\"\"\"\n\nasync def authenticate_hf(self, ctx: RunContext[None], token: str) -&gt; str:\n    \"\"\"Authenticate with HuggingFace using provided token\"\"\"\n\nasync def create_hf_readme(\n    self,\n    ctx: RunContext[None],\n    title: str,\n    sdk: str = \"streamlit\",\n    sdk_version: str = \"1.34.0\",\n    app_file: str = \"app.py\",\n    emoji: str = \"\ud83d\udd25\",\n    color_from: str = \"indigo\",\n    color_to: str = \"green\",\n    license: str = \"mit\"\n) -&gt; str:\n    \"\"\"Generate README.md with HuggingFace Space frontmatter\"\"\"\n</code></pre></p> <p>Workflow: 1. User creates an app (e.g., Streamlit chatbot) using WYN360-CLI 2. User says \"push to huggingface\" 3. WYN360 checks for HF_TOKEN authentication 4. If not authenticated, asks for token and authenticates 5. Generates README.md with proper YAML frontmatter for Spaces</p> <p>Example Use Case: <pre><code>You: Create a simple Streamlit echo chatbot\n\nWYN360: [Creates app.py with Streamlit code]\n\nYou: Push this to HuggingFace\n\nWYN360: Let me check your HuggingFace authentication...\nNot authenticated. Please provide your HuggingFace token.\nGet one from: https://huggingface.co/settings/tokens\n\nYou: hf_xxxxxxxxxxxxx\n\nWYN360: \u2713 Authenticated as 'username'\nCreating README.md with Streamlit Space configuration...\n\u2713 README.md created\n\n[Phase 2 will add: Space creation and file upload]\n</code></pre></p> <p>Test Coverage: - 12 new unit tests (7 in test_agent.py, 5 in test_utils.py) - Tests for authentication checking (authenticated/not authenticated) - Tests for authentication success/failure - Tests for README creation (Streamlit, Gradio, Docker, Static) - Tests for username extraction from HF CLI output</p> <p>Priority: HIGH - Enables direct deployment to HuggingFace Spaces</p>"},{"location":"development/roadmap/#62-huggingface-space-creation-file-upload-completed-v0317","title":"6.2 HuggingFace Space Creation &amp; File Upload \u2705 COMPLETED (v0.3.17)","text":"<p>Feature: Complete the deployment workflow by creating Spaces and uploading files</p> <p>Implemented Tools: <pre><code>async def create_hf_space(\n    self,\n    ctx: RunContext[None],\n    space_name: str,\n    sdk: str = \"streamlit\",\n    private: bool = False\n) -&gt; str:\n    \"\"\"Create HuggingFace Space via CLI\"\"\"\n\nasync def push_to_hf_space(\n    self,\n    ctx: RunContext[None],\n    space_name: str,\n    files: List[str] = None\n) -&gt; str:\n    \"\"\"Upload files to HuggingFace Space\"\"\"\n</code></pre></p> <p>HuggingFace CLI Commands Used: <pre><code># Create Space\nhf repo create {space_name} --type=space --space-sdk={sdk}\n\n# Upload files\nhf upload {space_name} {file_path}\n# or upload entire directory\nhf upload {space_name} . --repo-type=space\n</code></pre></p> <p>Complete Workflow (Phase 1 + Phase 2): <pre><code>You: Create a Streamlit chatbot and deploy to HuggingFace\n\nWYN360:\n1. Creating Streamlit app...\n   \u2713 app.py created\n\n2. Checking HuggingFace authentication...\n   \u2713 Authenticated as 'username'\n\n3. Creating README.md for Space...\n   \u2713 README.md created\n\n4. Creating HuggingFace Space...\n   What should the Space be called? (format: username/repo-name)\n\nYou: username/echo-chatbot\n\nWYN360:\n   \u2713 Space created: https://huggingface.co/spaces/username/echo-chatbot\n\n5. Uploading files to Space...\n   Uploading: app.py\n   Uploading: README.md\n   Uploading: requirements.txt\n   \u2713 All files uploaded\n\n\ud83c\udf89 Your app is live at: https://huggingface.co/spaces/username/echo-chatbot\n</code></pre></p> <p>Supported SDKs: - Streamlit (most common for demos) - Gradio (ML interfaces) - Docker (custom environments) - Static (HTML/JS apps)</p> <p>Priority: HIGH - Completes the deployment workflow</p>"},{"location":"development/roadmap/#phase-7-advanced-workflows-medium-priority","title":"Phase 7: Advanced Workflows (MEDIUM PRIORITY)","text":""},{"location":"development/roadmap/#71-multi-file-refactoring","title":"7.1 Multi-File Refactoring","text":"<p>Feature: Refactor across multiple files in one operation</p> <p>Use Case: <pre><code>You: Rename the User class to Account across all files\n\nWYN360:\nFound User class in:\n- models/user.py\n- services/user_service.py\n- api/user_routes.py\n\nI'll refactor all 3 files:\n1. Read all files\n2. Update class name and imports\n3. Write back with changes\n</code></pre></p> <p>Priority: MEDIUM - Powerful for large refactors</p>"},{"location":"development/roadmap/#72-test-generation-mode-completed-v0318","title":"7.2 Test Generation Mode \u2705 COMPLETED (v0.3.18)","text":"<p>Feature: Automatically generate tests for code</p> <p>Use Case: <pre><code>You: Generate tests for calculator.py\n\nWYN360:\nReading calculator.py...\nFound functions: add(), subtract(), multiply(), divide()\n\nCreating test_calculator.py with:\n- test_add_positive_numbers\n- test_add_negative_numbers\n- test_divide_by_zero_raises_error\n[... comprehensive test suite]\n</code></pre></p> <p>Priority: MEDIUM - High value for developers</p>"},{"location":"development/roadmap/#73-documentation-generation","title":"7.3 Documentation Generation","text":"<p>Feature: Auto-generate documentation</p> <p>Use Case: <pre><code>You: Generate API documentation for my FastAPI app\n\nWYN360:\nAnalyzing routes...\nCreating API_DOCS.md with:\n- Endpoints\n- Request/Response schemas\n- Example usage\n- Authentication\n</code></pre></p> <p>Priority: LOW - Nice to have</p>"},{"location":"development/roadmap/#phase-8-integration-features","title":"Phase 8: Integration Features","text":""},{"location":"development/roadmap/#81-github-integration-completed-v0323","title":"8.1 GitHub Integration \u2705 COMPLETED (v0.3.23)","text":"<p>Feature: Complete GitHub workflow management with commit, PR creation, and branch operations</p> <p>Implemented Tools: <pre><code>async def check_gh_authentication(ctx: RunContext[None]) -&gt; str:\n    \"\"\"Check if user is authenticated with GitHub\"\"\"\n\nasync def authenticate_gh(ctx: RunContext[None], token: str) -&gt; str:\n    \"\"\"Authenticate with GitHub using access token\"\"\"\n\nasync def gh_commit_changes(\n    ctx: RunContext[None],\n    message: str,\n    push: bool = True\n) -&gt; str:\n    \"\"\"Commit changes to the current repository and push to GitHub\"\"\"\n\nasync def gh_create_pr(\n    ctx: RunContext[None],\n    title: str,\n    body: str = \"\",\n    base_branch: str = \"main\"\n) -&gt; str:\n    \"\"\"Create a pull request on GitHub\"\"\"\n\nasync def gh_create_branch(\n    ctx: RunContext[None],\n    branch_name: str,\n    checkout: bool = True\n) -&gt; str:\n    \"\"\"Create a new branch and optionally check it out\"\"\"\n\nasync def gh_checkout_branch(\n    ctx: RunContext[None],\n    branch_name: str\n) -&gt; str:\n    \"\"\"Check out an existing branch\"\"\"\n\nasync def gh_merge_branch(\n    ctx: RunContext[None],\n    source_branch: str,\n    target_branch: str\n) -&gt; str:\n    \"\"\"Merge source branch into target branch\"\"\"\n</code></pre></p> <p>Complete Workflow: <pre><code>You: Create branch feature/auth\n\nWYN360: [Creates and checks out branch]\n\u2713 Branch 'feature/auth' created\n\nYou: [Generate code]\n\nYou: Commit these changes\n\nWYN360: [Checks GitHub authentication]\n\u2713 Authenticated with GitHub as 'username'\n[Stages all changes]\n[Commits with message]\n[Pushes to origin]\n\u2713 Successfully committed and pushed changes\n\nYou: Create pull request\n\nWYN360: [Analyzes changes]\n[Generates PR description]\n[Creates PR on GitHub]\n\u2713 PR created: https://github.com/username/repo/pull/42\n\nYou: Checkout main\n\nWYN360: [Switches to main branch]\n\u2713 Checked out main\n\nYou: Merge feature/auth into main\n\nWYN360: [Merges branch]\n\u2713 Successfully merged feature/auth into main\n</code></pre></p> <p>Features: - \ud83d\udd10 GitHub authentication with GH_TOKEN/GITHUB_TOKEN - \ud83d\udcbe Commit and push changes directly from CLI - \ud83d\udd00 Create pull requests with title, body, and base branch - \ud83c\udf3f Branch management: create, checkout branches - \ud83d\udd04 Branch merging with conflict detection - \ud83d\udd12 User confirmation for all git operations - \u2705 Auto-authentication from environment variables - \ud83d\udcda Comprehensive documentation in USE_CASES.md Section 17</p> <p>Test Coverage: Unit tests to be added for all 7 GitHub tools</p> <p>Priority: COMPLETED - Full GitHub workflow management</p>"},{"location":"development/roadmap/#82-database-tools","title":"8.2 Database Tools","text":"<p>Feature: Direct database operations</p> <p>Capabilities: <pre><code>async def run_query(\n    self,\n    ctx: RunContext[None],\n    query: str,\n    connection_string: str\n) -&gt; str:\n    \"\"\"Execute SQL query and return results\"\"\"\n\nasync def describe_table(\n    self,\n    ctx: RunContext[None],\n    table_name: str\n) -&gt; str:\n    \"\"\"Show table schema\"\"\"\n</code></pre></p> <p>Priority: LOW - Niche use case</p>"},{"location":"development/roadmap/#phase-9-safety-quality-high-priority","title":"Phase 9: Safety &amp; Quality (HIGH PRIORITY)","text":""},{"location":"development/roadmap/#91-pre-execution-validation","title":"9.1 Pre-Execution Validation","text":"<p>Feature: Validate code before execution</p> <p>Checks: <pre><code># Before running command\n- Static analysis (syntax errors)\n- Security scanning (dangerous operations)\n- Dependency checking (missing imports)\n</code></pre></p> <p>Example: <pre><code>You: Run script.py\n\nWYN360:\n\u26a0\ufe0f  WARNING: Security issues detected:\n- Line 15: eval() is potentially unsafe\n- Line 23: os.system() without sanitization\n\nContinue anyway? (y/N):\n</code></pre></p> <p>Priority: HIGH - Safety first</p>"},{"location":"development/roadmap/#92-automatic-backups","title":"9.2 Automatic Backups","text":"<p>Feature: Create backups before modifications</p> <p>Implementation: <pre><code># Before write_file with overwrite=True\nbackup_path = f\".wyn360_backup/{file_path}.{timestamp}\"\nshutil.copy(file_path, backup_path)\n</code></pre></p> <p>Commands: <pre><code>/backup list     # Show all backups\n/backup restore  # Restore from backup\n/backup clean    # Clean old backups\n</code></pre></p> <p>Priority: MEDIUM - Prevents accidents</p>"},{"location":"development/roadmap/#93-undorollback","title":"9.3 Undo/Rollback","text":"<p>Feature: Undo last operation</p> <p>Implementation: <pre><code># Track all operations in session\noperations = [\n    {\"type\": \"write_file\", \"path\": \"app.py\", \"backup\": \"...\"},\n    {\"type\": \"delete_file\", \"path\": \"old.py\", \"backup\": \"...\"},\n]\n\n# Rollback command\n/undo  # Undo last operation\n/undo 3  # Undo last 3 operations\n</code></pre></p> <p>Priority: MEDIUM - Safety net</p>"},{"location":"development/roadmap/#phase-10-monitoring-analytics-completed-v0319","title":"Phase 10: Monitoring &amp; Analytics \u2705 COMPLETED (v0.3.19)","text":""},{"location":"development/roadmap/#101-token-usage-tracking-completed-phase-1","title":"10.1 Token Usage Tracking \u2705 COMPLETED (Phase 1)","text":"<p>Feature: Track and display token usage</p> <p>Dashboard: <pre><code>You: /tokens\n\nToken Usage Statistics:\n- Input tokens: 45,230 ($0.136)\n- Output tokens: 12,450 ($0.187)\n- Total cost: $0.323\n- Average/message: $0.013\n</code></pre></p> <p>Status: Already implemented in Phase 1 with /tokens command</p>"},{"location":"development/roadmap/#102-performance-metrics-completed-v0319","title":"10.2 Performance Metrics \u2705 COMPLETED (v0.3.19)","text":"<p>Feature: Track response times and success rates</p> <p>Implementation: - PerformanceMetrics class in utils.py - Tracks response times (avg, min, max) - Tracks tool usage and success rates - Tracks error frequency and types - Persisted in session save/load - Integrated into all key tools</p> <p>New Command: /stats <pre><code>You: /stats\n\nToken Usage              Performance Metrics\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nTotal Requests: 25      Session Duration: 15m 30s\nInput Tokens: 45,230    Avg Response Time: 2.3s\nOutput Tokens: 12,450   Min Response Time: 0.8s\nTotal Cost: $0.32       Max Response Time: 5.2s\n                        Error Count: 0\n\nTool Usage\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nTotal Tool Calls: 47\nSuccessful Calls: 45\nFailed Calls: 2\nSuccess Rate: 95.7%\n\nMost Used Tools\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nTool              Success  Failed  Total\nread_file         15       0       15\nwrite_file        12       1       13\nexecute_command   8        0       8\nsearch_files      5        0       5\ngit_status        5        1       6\n</code></pre></p> <p>Test Coverage: 11 comprehensive unit tests</p> <p>Priority: COMPLETED - Useful for monitoring and optimization</p>"},{"location":"development/roadmap/#phase-11-collaboration-features-low-priority","title":"Phase 11: Collaboration Features (LOW PRIORITY)","text":""},{"location":"development/roadmap/#111-session-sharing","title":"11.1 Session Sharing","text":"<p>Feature: Share WYN360 sessions with team</p> <p>Implementation: <pre><code># Export session\nwyn360 --export session.json\n\n# Import on another machine\nwyn360 --import session.json\n</code></pre></p> <p>Use Case: Share coding session with colleague for review</p> <p>Priority: LOW - Team feature</p>"},{"location":"development/roadmap/#112-prompt-library","title":"11.2 Prompt Library","text":"<p>Feature: Share and reuse prompts</p> <p>Implementation: <pre><code># prompts.yaml\nprompts:\n  refactor_for_testing:\n    text: \"Refactor this code to be more testable by extracting dependencies\"\n\n  add_logging:\n    text: \"Add comprehensive logging to this module using Python logging\"\n\n  optimize_performance:\n    text: \"Analyze and optimize this code for better performance\"\n</code></pre></p> <p>Usage: <pre><code>You: @refactor_for_testing app.py\n\nWYN360: [Applies the refactor_for_testing prompt to app.py]\n</code></pre></p> <p>Priority: LOW - Power user feature</p>"},{"location":"development/roadmap/#implementation-priority-matrix","title":"\ud83d\udcca Implementation Priority Matrix","text":""},{"location":"development/roadmap/#high-priority-implement-soon","title":"HIGH Priority (Implement Soon)","text":"<ol> <li>\u2728 Conversation History in API - Most impactful</li> <li>\u2728 Git Operations Tool - Frequently needed</li> <li>\u2728 Search/Grep Tool - Essential for large codebases</li> <li>\u2728 Streaming Responses - Major UX improvement</li> <li>\u2728 Pre-Execution Validation - Safety critical</li> </ol>"},{"location":"development/roadmap/#medium-priority-next-phase","title":"MEDIUM Priority (Next Phase)","text":"<ol> <li>\ud83d\udd27 Context Management Commands - User control</li> <li>\ud83d\udd27 Model Selection - Cost optimization</li> <li>\ud83d\udd27 Configuration File - Personalization</li> <li>\ud83d\udd27 File Management Tools - Complete file operations</li> <li>\ud83d\udd27 Multi-File Refactoring - Advanced workflow</li> <li>\ud83d\udd27 Test Generation - High value</li> <li>\ud83d\udd27 Automatic Backups - Safety</li> <li>\ud83d\udd27 Undo/Rollback - Safety net</li> </ol>"},{"location":"development/roadmap/#low-priority-future-consideration","title":"LOW Priority (Future Consideration)","text":"<ol> <li>\ud83d\udca1 GitHub Integration - Nice to have</li> <li>\ud83d\udca1 Database Tools - Niche</li> <li>\ud83d\udca1 Token Usage Dashboard - Analytics</li> <li>\ud83d\udca1 Session Sharing - Collaboration</li> <li>\ud83d\udca1 Prompt Library - Power users</li> <li>\ud83d\udca1 Documentation Generation - Automation</li> </ol>"},{"location":"development/roadmap/#recommended-development-roadmap","title":"\ud83c\udfaf Recommended Development Roadmap","text":""},{"location":"development/roadmap/#v030-context-history","title":"v0.3.0 - Context &amp; History","text":"<p>Focus: Conversation context management - Add conversation history to API calls - Implement /clear, /history commands - Add token usage tracking - Session save/load</p> <p>Timeline: 2-3 weeks</p>"},{"location":"development/roadmap/#v040-enhanced-tools","title":"v0.4.0 - Enhanced Tools","text":"<p>Focus: Additional tool capabilities - Git operations tool - Search/grep functionality - File management (delete, move, mkdir) - Pre-execution validation</p> <p>Timeline: 3-4 weeks</p>"},{"location":"development/roadmap/#v050-streaming-ux","title":"v0.5.0 - Streaming &amp; UX","text":"<p>Focus: Real-time experience - Token-by-token streaming - Better progress indicators - Configuration file support - Project-specific context</p> <p>Timeline: 2-3 weeks</p>"},{"location":"development/roadmap/#v060-advanced-workflows","title":"v0.6.0 - Advanced Workflows","text":"<p>Focus: Complex operations - Multi-file refactoring - Test generation mode - Automatic backups - Undo/rollback</p> <p>Timeline: 3-4 weeks</p>"},{"location":"development/roadmap/#v070-integrations","title":"v0.7.0+ - Integrations","text":"<p>Focus: External services - GitHub integration - Model selection - Database tools - Analytics dashboard</p> <p>Timeline: TBD</p>"},{"location":"development/roadmap/#quick-wins-easy-to-implement","title":"\ud83d\udca1 Quick Wins (Easy to Implement)","text":""},{"location":"development/roadmap/#1-add-version-command","title":"1. Add Version Command","text":"<pre><code>wyn360 --version  # Show current version\n</code></pre>"},{"location":"development/roadmap/#2-add-help-in-session","title":"2. Add Help in Session","text":"<pre><code>You: /help\nWYN360: [Shows available commands and tips]\n</code></pre>"},{"location":"development/roadmap/#3-keyboard-shortcuts-documentation","title":"3. Keyboard Shortcuts Documentation","text":"<pre><code>You: /shortcuts\nWYN360:\n- Ctrl+C: Cancel current operation\n- Ctrl+D: Exit\n- Ctrl+Enter: New line\n- Enter: Submit\n</code></pre>"},{"location":"development/roadmap/#4-exit-code-summary","title":"4. Exit Code Summary","text":"<p>After each command, show summary: <pre><code>\u2705 Command executed successfully (exit code 0)\n   Duration: 2.3s\n   Output lines: 45\n</code></pre></p>"},{"location":"development/roadmap/#5-better-error-messages","title":"5. Better Error Messages","text":"<p>Instead of: \"An error occurred: Tool 'write_file' exceeded max retries\" Show: \"I tried 3 times but couldn't write the file. This usually means...\"</p>"},{"location":"development/roadmap/#future-vision-v10","title":"\ud83d\udd2e Future Vision (v1.0+)","text":"<p>Long-term possibilities:</p>"},{"location":"development/roadmap/#1-wyn360-as-code-review-assistant","title":"1. WYN360 as Code Review Assistant","text":"<ul> <li>Automated PR reviews</li> <li>Security vulnerability detection</li> <li>Best practices suggestions</li> <li>Performance optimization recommendations</li> </ul>"},{"location":"development/roadmap/#2-wyn360-as-cicd-integration","title":"2. WYN360 as CI/CD Integration","text":"<ul> <li>Automatic test generation in CI pipeline</li> <li>Documentation generation on commit</li> <li>Code quality checks</li> <li>Deployment assistance</li> </ul>"},{"location":"development/roadmap/#3-wyn360-as-teaching-tool","title":"3. WYN360 as Teaching Tool","text":"<ul> <li>Explain code line-by-line</li> <li>Generate learning examples</li> <li>Create coding challenges</li> <li>Interactive tutorials</li> </ul>"},{"location":"development/roadmap/#4-wyn360-as-architecture-advisor","title":"4. WYN360 as Architecture Advisor","text":"<ul> <li>System design suggestions</li> <li>Refactoring recommendations</li> <li>Technology selection</li> <li>Performance optimization</li> </ul>"},{"location":"development/roadmap/#5-wyn360-ide-plugin","title":"5. WYN360 IDE Plugin","text":"<ul> <li>VSCode extension</li> <li>JetBrains plugin</li> <li>Vim integration</li> <li>Embedded in popular IDEs</li> </ul>"},{"location":"development/roadmap/#community-feature-requests","title":"\ud83d\udcdd Community Feature Requests","text":"<p>How to contribute ideas:</p> <ol> <li>Open GitHub issue with label <code>feature-request</code></li> <li>Describe use case and expected behavior</li> <li>Discuss implementation approach</li> <li>Community votes on priority</li> </ol> <p>Template: <pre><code>## Feature Request: [Name]\n\n**Use Case:**\n[Describe the problem this solves]\n\n**Proposed Solution:**\n[How it should work]\n\n**Example:**\n[Show example interaction]\n\n**Priority:** [High/Medium/Low]\n</code></pre></p>"},{"location":"development/roadmap/#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Want to help implement these features?</p> <ol> <li>Check the GitHub Issues for open feature requests</li> <li>Comment on the feature you want to work on</li> <li>Fork the repository</li> <li>Implement the feature with tests</li> <li>Submit a pull request</li> </ol> <p>Development Setup: <pre><code>git clone https://github.com/yiqiao-yin/wyn360-cli.git\ncd wyn360-cli\npoetry install\nWYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v\n</code></pre></p>"},{"location":"development/roadmap/#feedback","title":"\ud83d\udcde Feedback","text":"<p>Have suggestions not listed here?</p> <ul> <li>\ud83d\udce7 Email: yiqiao.yin@wyn-associates.com</li> <li>\ud83d\udc1b Issues: https://github.com/yiqiao-yin/wyn360-cli/issues</li> <li>\ud83d\udcac Discussions: https://github.com/yiqiao-yin/wyn360-cli/discussions</li> </ul> <p>Last Updated: November 2025 Current Version: 0.3.23 Next Planned Release: v0.3.23+ (Phase 7.1 Multi-File Refactoring or Phase 7.3 Documentation Generation)</p>"},{"location":"development/testing/","title":"Testing","text":"<p>Comprehensive guide to testing WYN360 CLI during development and contribution.</p>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 test_agent.py          # Agent and tool tests (46 tests)\n\u251c\u2500\u2500 test_cli.py            # CLI and slash command tests (33 tests)\n\u251c\u2500\u2500 test_config.py         # Configuration tests (25 tests)\n\u251c\u2500\u2500 test_utils.py          # Utility function tests (29 tests)\n\u251c\u2500\u2500 test_browser_*.py      # Browser automation tests\n\u251c\u2500\u2500 test_document_*.py     # Document processing tests\n\u2514\u2500\u2500 test_credential_*.py   # Security and credential tests\n                          # Total: 133+ tests\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#basic-test-execution","title":"Basic Test Execution","text":"<p>Run all tests: <pre><code>WYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v\n</code></pre></p> <p>Run specific test file: <pre><code>poetry run pytest tests/test_agent.py -v\n</code></pre></p> <p>Run specific test class: <pre><code>poetry run pytest tests/test_utils.py::TestExecuteCommandSafe -v\n</code></pre></p> <p>Run with short traceback: <pre><code>WYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v --tb=short\n</code></pre></p>"},{"location":"development/testing/#coverage-analysis","title":"Coverage Analysis","text":"<p>Generate coverage report: <pre><code>poetry run pytest tests/ --cov=wyn360_cli --cov-report=html\n</code></pre></p> <p>View coverage in browser: <pre><code>open htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\n</code></pre></p>"},{"location":"development/testing/#test-categories","title":"Test Categories","text":""},{"location":"development/testing/#unit-tests","title":"Unit Tests","text":"<p>Agent Tests (<code>test_agent.py</code>) - WYN360Agent initialization - Tool method functionality - Conversation history management - Token tracking - Model switching</p> <p>CLI Tests (<code>test_cli.py</code>) - Slash command parsing - Command execution - Input/output handling - Error handling</p> <p>Configuration Tests (<code>test_config.py</code>) - Config file loading - Environment variable handling - Default value setting - Hierarchical config merging</p> <p>Utility Tests (<code>test_utils.py</code>) - File operations - Command execution safety - Project analysis - Performance metrics</p>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":"<p>Browser Tests (<code>test_browser_*.py</code>) - Browser automation - Website fetching - Vision-based navigation - Authentication flows</p> <p>Document Tests (<code>test_document_*.py</code>) - Multi-format document reading - Vision mode processing - Chunking and embedding - Cost tracking</p> <p>Security Tests (<code>test_credential_*.py</code>) - Credential encryption/decryption - Session management - Audit logging - Permission handling</p>"},{"location":"development/testing/#test-environment-setup","title":"Test Environment Setup","text":""},{"location":"development/testing/#required-environment-variables","title":"Required Environment Variables","text":"<pre><code># Skip interactive confirmations during tests\nexport WYN360_SKIP_CONFIRM=1\n\n# Test API keys (use test/mock keys)\nexport ANTHROPIC_API_KEY=test_key_anthropic\nexport GEMINI_API_KEY=test_key_gemini\nexport GH_TOKEN=test_key_github\nexport HF_TOKEN=test_key_huggingface\n</code></pre>"},{"location":"development/testing/#mock-configuration","title":"Mock Configuration","text":"<p>Tests use mocking to avoid real API calls:</p> <pre><code># Example from tests\n@patch('wyn360_cli.agent.WYN360Agent')\ndef test_agent_initialization(mock_agent):\n    \"\"\"Test agent initializes with correct parameters.\"\"\"\n    mock_agent.return_value = MagicMock()\n    # Test implementation\n</code></pre>"},{"location":"development/testing/#writing-new-tests","title":"Writing New Tests","text":""},{"location":"development/testing/#test-structure-template","title":"Test Structure Template","text":"<pre><code>import pytest\nfrom unittest.mock import Mock, patch, MagicMock\nfrom wyn360_cli.your_module import YourClass\n\nclass TestYourClass:\n    \"\"\"Test suite for YourClass functionality.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Set up test fixtures before each test method.\"\"\"\n        self.instance = YourClass()\n\n    def test_basic_functionality(self):\n        \"\"\"Test basic functionality works as expected.\"\"\"\n        # Arrange\n        input_data = \"test_input\"\n        expected_output = \"expected_result\"\n\n        # Act\n        result = self.instance.method(input_data)\n\n        # Assert\n        assert result == expected_output\n\n    @patch('wyn360_cli.your_module.external_dependency')\n    def test_with_mocking(self, mock_external):\n        \"\"\"Test functionality that depends on external services.\"\"\"\n        # Arrange\n        mock_external.return_value = \"mocked_response\"\n\n        # Act\n        result = self.instance.method_with_dependency()\n\n        # Assert\n        assert result is not None\n        mock_external.assert_called_once()\n</code></pre>"},{"location":"development/testing/#async-test-template","title":"Async Test Template","text":"<pre><code>import pytest\nimport asyncio\n\nclass TestAsyncFunctionality:\n    \"\"\"Test async methods.\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_async_method(self):\n        \"\"\"Test async method functionality.\"\"\"\n        instance = AsyncClass()\n        result = await instance.async_method()\n        assert result is not None\n</code></pre>"},{"location":"development/testing/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"development/testing/#1-test-categories","title":"1. Test Categories","text":"<p>Unit Tests: Test individual functions/methods in isolation <pre><code>def test_utility_function():\n    \"\"\"Test utility function with known input/output.\"\"\"\n    result = utility_function(\"input\")\n    assert result == \"expected_output\"\n</code></pre></p> <p>Integration Tests: Test component interactions <pre><code>@pytest.mark.asyncio\nasync def test_agent_tool_integration():\n    \"\"\"Test agent and tool work together.\"\"\"\n    agent = WYN360Agent()\n    result = await agent.read_file(\"test_file.py\")\n    assert \"def \" in result  # Contains function definition\n</code></pre></p> <p>End-to-End Tests: Test complete workflows <pre><code>def test_complete_workflow():\n    \"\"\"Test entire user workflow.\"\"\"\n    # This would test CLI \u2192 Agent \u2192 Tools \u2192 Output\n    pass\n</code></pre></p>"},{"location":"development/testing/#2-mock-external-dependencies","title":"2. Mock External Dependencies","text":"<p>Always mock external services: <pre><code>@patch('requests.get')\ndef test_web_fetch(mock_get):\n    \"\"\"Test web fetching with mocked HTTP calls.\"\"\"\n    mock_get.return_value.text = \"mocked content\"\n    result = fetch_website(\"https://example.com\")\n    assert result == \"mocked content\"\n</code></pre></p>"},{"location":"development/testing/#3-test-error-conditions","title":"3. Test Error Conditions","text":"<pre><code>def test_error_handling():\n    \"\"\"Test proper error handling.\"\"\"\n    with pytest.raises(ValueError, match=\"Invalid input\"):\n        function_that_should_raise(\"invalid_input\")\n</code></pre>"},{"location":"development/testing/#4-use-fixtures-for-common-setup","title":"4. Use Fixtures for Common Setup","text":"<pre><code>@pytest.fixture\ndef sample_config():\n    \"\"\"Provide sample configuration for tests.\"\"\"\n    return {\n        \"model\": \"test-model\",\n        \"max_tokens\": 100,\n        \"custom_instructions\": \"Test instructions\"\n    }\n\ndef test_with_fixture(sample_config):\n    \"\"\"Test using the fixture.\"\"\"\n    agent = WYN360Agent(config=sample_config)\n    assert agent.config[\"model\"] == \"test-model\"\n</code></pre>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"development/testing/#github-actions","title":"GitHub Actions","text":"<p>Tests run automatically on: - Pull requests to main branch - Pushes to main branch - Release creation</p>"},{"location":"development/testing/#test-matrix","title":"Test Matrix","text":"<p>Tests run against: - Python 3.10, 3.11, 3.12 - Linux, macOS, Windows - Multiple dependency versions</p>"},{"location":"development/testing/#debugging-test-failures","title":"Debugging Test Failures","text":""},{"location":"development/testing/#common-issues","title":"Common Issues","text":"<p>Import Errors: <pre><code># Ensure package is installed in development mode\npoetry install\n\n# Check Python path\npython -c \"import sys; print('\\n'.join(sys.path))\"\n</code></pre></p> <p>API Key Errors: <pre><code># Ensure skip confirmation is set\nexport WYN360_SKIP_CONFIRM=1\n\n# Use mock API keys\nexport ANTHROPIC_API_KEY=test_key\n</code></pre></p> <p>Async Test Issues: <pre><code># Ensure proper async test marking\n@pytest.mark.asyncio\nasync def test_async_function():\n    result = await async_function()\n    assert result is not None\n</code></pre></p>"},{"location":"development/testing/#debug-output","title":"Debug Output","text":"<p>Run with debug output: <pre><code>poetry run pytest tests/ -v -s --tb=long\n</code></pre></p> <p>Run single test with debugging: <pre><code>poetry run pytest tests/test_agent.py::TestWYN360Agent::test_specific_method -v -s\n</code></pre></p>"},{"location":"development/testing/#expected-test-output","title":"Expected Test Output","text":"<p>When all tests pass:</p> <pre><code>============================= test session starts ==============================\nplatform linux -- Python 3.10.12, pytest-8.4.2, pluggy-1.6.0\ncachedir: .pytest_cache\nrootdir: /home/workbench/wyn360-cli/wyn360-cli\nconfigfile: pyproject.toml\nplugins: asyncio-1.2.0, mock-3.15.1\ncollected 133 items\n\ntests/test_agent.py::TestWYN360Agent::test_agent_initialization PASSED   [  1%]\ntests/test_agent.py::TestHistoryManagement::test_clear_history PASSED    [ 18%]\ntests/test_cli.py::TestSlashCommands::test_clear_command PASSED          [ 42%]\ntests/test_config.py::TestWYN360Config::test_default_values PASSED       [ 60%]\ntests/test_utils.py::TestExecuteCommandSafe::test_execute_command PASSED [100%]\n\n============================== 133 passed in 2.64s\n</code></pre>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"development/testing/#benchmark-tests","title":"Benchmark Tests","text":"<pre><code>import time\n\ndef test_performance_benchmark():\n    \"\"\"Test performance meets expectations.\"\"\"\n    start_time = time.time()\n\n    # Perform operation\n    result = expensive_operation()\n\n    end_time = time.time()\n    execution_time = end_time - start_time\n\n    assert execution_time &lt; 5.0  # Should complete in under 5 seconds\n    assert result is not None\n</code></pre> <p>For more testing examples, see the existing test files in the <code>tests/</code> directory.</p>"},{"location":"features/browser-use/","title":"Advanced Browser Automation &amp; Control","text":"<p>Navigate websites, extract data, and automate complex web tasks using smolagents-inspired browser automation with enhanced code generation.</p>"},{"location":"features/browser-use/#overview","title":"Overview","text":"<p>WYN360 CLI provides advanced web interaction capabilities:</p> <ol> <li>Direct Website Fetching - Read specific URLs directly</li> <li>Enhanced Code Generation - Smolagents-inspired complete automation scripts</li> <li>Secure Python Sandbox - Isolated execution environment with resource monitoring</li> <li>Intelligent Error Recovery - Adaptive code regeneration and error learning</li> <li>Pattern Caching &amp; Learning - Performance optimization through automation patterns</li> </ol>"},{"location":"features/browser-use/#direct-website-fetching","title":"Direct Website Fetching","text":""},{"location":"features/browser-use/#basic-usage","title":"Basic Usage","text":"<pre><code>You: Read https://github.com/yiqiao-yin/wyn360-cli\n\nWYN360: [Fetches the specific URL directly]\n\n\ud83d\udcc4 **Fetched:** https://github.com/yiqiao-yin/wyn360-cli\n\n# WYN360 CLI\nAn intelligent AI coding assistant CLI tool...\n\n[Full page content converted to markdown]\n</code></pre>"},{"location":"features/browser-use/#features","title":"Features","text":"<ul> <li>LLM-Optimized - Automatic conversion to clean markdown</li> <li>Smart Caching - 30-minute TTL for faster repeated access</li> <li>Smart Truncation - Preserves document structure within token limits</li> </ul>"},{"location":"features/browser-use/#advanced-browser-automation","title":"Advanced Browser Automation","text":""},{"location":"features/browser-use/#smolagents-inspired-approach","title":"Smolagents-Inspired Approach","text":"<p>The system uses code-first automation with intelligent recovery:</p> <p>\ud83d\udcdd Enhanced Code Generation \u2192 \ud83d\udd12 Secure Sandbox Execution \u2192 \ud83e\udde0 Intelligent Error Recovery</p>"},{"location":"features/browser-use/#browser-visibility-control","title":"Browser Visibility Control","text":"<p>Control browser visibility for debugging and development:</p> <pre><code># Show browser window during automation (great for debugging)\nwyn360 --show-browser\n\n# Environment variable option\nexport WYN360_BROWSER_SHOW=1\nwyn360\n\n# Default headless mode (production)\nwyn360\n</code></pre>"},{"location":"features/browser-use/#automation-capabilities","title":"Automation Capabilities","text":"<ul> <li>Performance-Optimized - 60% reduction in timeout errors, 30% fewer LLM calls</li> <li>Batch Operations - Complete automation scripts with multiple actions in single execution</li> <li>Secure Execution - Isolated Python sandbox with resource monitoring and safety controls</li> <li>Intelligent Recovery - Adaptive code regeneration based on error analysis and learning</li> <li>Pattern Caching - Automated optimization through successful automation pattern reuse</li> </ul>"},{"location":"features/browser-use/#example-e-commerce-automation","title":"Example: E-commerce Automation","text":"<pre><code>You: Browse Amazon and find the cheapest wireless mouse under $20 with good reviews\n\nWYN360: [Launches smolagents-inspired browser automation]\n\n\ud83c\udfaf **Enhanced Browser Automation Started**\n\ud83d\udcdd **Generating complete automation script...**\n\nGenerated Code:\n```python\n# Complete automation script\nawait page.goto(\"https://amazon.com\")\nsearch_box = page.locator('input[placeholder*=\"search\"]')\nawait search_box.fill(\"wireless mouse\")\nawait search_box.press(\"Enter\")\nawait page.locator('span:text(\"Under $20\")').click()\nawait page.locator('[data-cy=\"reviews-block\"] span:has-text(\"4 &amp; Up\")').click()\nproducts = await page.locator('[data-component-type=\"s-search-result\"]').all()\n# Extract and compare results...\n</code></pre> <p>\ud83d\udd12 Executing in secure sandbox... \u2713 \ud83d\udcca Monitoring execution: Memory: 45MB, Time: 6.2s \u2713</p> <p>\u2705 Task Completed Successfully! \ud83d\udca1 Approach Used: Enhanced Code Generation with Secure Sandbox \u26a1 Performance: 6 seconds, $0.03 cost</p> <p>Result: Logitech M185 Wireless Mouse - Price: $14.99 - Rating: 4.5/5 stars (15,234 reviews) - Features: 2.4GHz wireless, 12-month battery life - Link: [Product Page]</p> <p>Performance Breakdown: - Code Generation: $0.020 - Sandbox Execution: $0.005 - Resource Monitoring: $0.005 - Total Improvement vs Step-by-Step: 70% faster, 40% cheaper <pre><code>### Example: Intelligent Error Recovery\n</code></pre> You: Complete my shopping cart checkout</p> <p>WYN360: [Enhanced automation encounters execution error]</p> <p>\ud83d\udcdd Generated automation script and executing... \u274c Execution Error Detected in Secure Sandbox</p> <p>\ud83e\udde0 Intelligent Error Analysis: - Error Type: Element selector failure (confidence: 85%) - Root Cause: Checkout page layout changed since last pattern - Classification: element_not_found</p> <p>\ud83d\udd04 Automatic Code Regeneration: - Analyzing current page structure - Adapting selectors for new layout - Optimizing error handling patterns - Generating improved automation script</p> <p>Generated Improved Code: <pre><code># Regenerated automation with improved selectors\ncheckout_btn = page.locator('[data-testid=\"checkout-button\"], button:has-text(\"checkout\")')\nawait checkout_btn.wait_for(timeout=10000)\nawait checkout_btn.click()\n# Enhanced error handling and retry logic...\n</code></pre></p> <p>\ud83d\udd12 Re-executing in secure sandbox... \u2713 \u2705 Recovery Successful!</p> <p>\ud83d\udca1 Learning Applied: New checkout pattern cached for future use \u26a1 Total Recovery Time: 4 seconds \ud83d\udcb0 Total Cost (including recovery): $0.05</p> <p>\ud83c\udf89 Checkout completed successfully with intelligent recovery! <pre><code>## Automation Approaches\n\n### 1. Enhanced Code Generation (Primary)\n- **Speed:** \u26a1 4-8 seconds per complete automation\n- **Cost:** \ud83d\udcb0 ~$0.02-0.05 per generated script\n- **Best For:** Complete automation workflows, batch operations\n- **Success Rate:** ~92% with intelligent patterns\n\n### 2. Secure Sandbox Execution\n- **Speed:** \ud83d\ude80 1-3 seconds execution time\n- **Cost:** \ud83d\udcb0 ~$0.001-0.005 per execution\n- **Best For:** Safe code execution with resource monitoring\n- **Security:** Full isolation with controlled environment\n\n### 3. Intelligent Error Recovery\n- **Speed:** \ud83d\udd04 3-6 seconds for code regeneration\n- **Cost:** \ud83d\udcb0 ~$0.01-0.02 per recovery attempt\n- **Best For:** Adaptive learning and improved automation\n- **Success Rate:** ~85% recovery success on first retry\n\n## Setup Requirements\n\n### Install Browser Binaries\n```bash\n# Install Playwright browser\nplaywright install chromium\n\n# Verify installation\nplaywright --version\n</code></pre></p>"},{"location":"features/browser-use/#environment-configuration","title":"Environment Configuration","text":"<pre><code># Enhanced automation settings\nexport WYN360_BROWSER_SHOW=1                    # Show browser (0 for headless)\nexport WYN360_ENHANCED_CODE_GENERATION=true     # Enable smolagents approach\nexport WYN360_SECURE_SANDBOX=true               # Enable secure execution\nexport WYN360_ERROR_RECOVERY=true               # Enable intelligent recovery\n\n# Performance control settings\nexport WYN360_MAX_COST_PER_TASK=0.20             # Maximum cost per automation\nexport WYN360_PATTERN_CACHING=true              # Enable pattern caching\nexport WYN360_CODE_OPTIMIZATION=standard        # Code optimization level\n</code></pre>"},{"location":"features/browser-use/#authentication-setup-optional","title":"Authentication Setup (Optional)","text":"<p>For sites requiring login: <pre><code>You: Login to GitHub using my credentials\n\nWYN360: [Initiates secure authentication flow]\n\ud83d\udd10 Please enter your credentials:\nUsername: [securely prompted]\nPassword: [securely masked]\n\n\u2705 Successfully logged in to GitHub\n\ud83d\udcbe Session saved for 30 minutes\n\ud83d\udd12 Credentials securely handled (not stored)\n</code></pre></p>"},{"location":"features/browser-use/#advanced-features","title":"Advanced Features","text":""},{"location":"features/browser-use/#cost-performance-tracking","title":"Cost &amp; Performance Tracking","text":"<p>Check detailed automation analytics: <pre><code>You: /tokens\n\nWYN360: \ud83d\udcca **Token Usage &amp; Cost Breakdown**\n\n**Total Session Cost:** $0.14\n\n**Enhanced Browser Automation:**\n- Code Generation: $0.08 (70% of operations)\n- Sandbox Execution: $0.02 (20% of operations)\n- Error Recovery: $0.04 (10% of operations)\n\n**Performance Metrics:**\n- Average task completion: 7 seconds\n- Cost improvement vs step-by-step: 65%\n- Success rate: 96%\n- Timeout error reduction: 60%\n\n**Approach Distribution:**\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 Enhanced Generation (85%)\n\u2588\u2588\u2588\u2588 Error Recovery (12%)\n\u2588 Legacy Fallback (3%)\n</code></pre></p>"},{"location":"features/browser-use/#pattern-learning-caching","title":"Pattern Learning &amp; Caching","text":"<p>The system learns and caches successful automation patterns: <pre><code>\ud83d\udcda **Enhanced Pattern Cache Status**\n- Cached automation scripts: 45\n- Cache hit rate: 78%\n- Performance improvement: 3.2x faster\n- Error reduction: 65% fewer timeouts\n- Most successful: E-commerce and form automation patterns\n</code></pre></p>"},{"location":"features/browser-use/#strategy-selection","title":"Strategy Selection","text":"<p>Control which automation approach to use: <pre><code># Let system use enhanced approach (recommended)\n\"Browse Amazon for headphones\"\n# System: Uses enhanced code generation with secure execution\n\n# Force specific approach for testing\n\"Browse Amazon for headphones using legacy system\"\n# System: Uses step-by-step legacy approach\n\n# Secure-only approach\n\"Browse secure banking site for account info\"\n# System: Enhanced generation with maximum security isolation\n</code></pre></p>"},{"location":"features/browser-use/#configuration","title":"Configuration","text":""},{"location":"features/browser-use/#browser-behavior","title":"Browser Behavior","text":"<pre><code># Fine-tune smolagents automation in agent config\nautomation_config:\n  enhanced_code_generation: true    # Enable smolagents approach\n  secure_sandbox_execution: true   # Enable secure execution\n  error_recovery_enabled: true     # Enable intelligent recovery\n  max_retries_per_task: 3          # Retry attempts with regeneration\n  show_browser: false              # Default headless mode\n  code_optimization_level: standard # Code optimization setting\n</code></pre>"},{"location":"features/browser-use/#cost-controls","title":"Cost Controls","text":"<pre><code># Budget management for enhanced automation\ncost_controls:\n  max_cost_per_task: 0.20           # Stop if exceeding 20\u00a2\n  prefer_batch_operations: true    # Favor code generation over step-by-step\n  enable_pattern_caching: true     # Cache successful automation scripts\n  track_spending: true              # Real-time cost monitoring\n  daily_budget: 5.00                # Daily automation budget\n</code></pre>"},{"location":"features/browser-use/#troubleshooting","title":"Troubleshooting","text":""},{"location":"features/browser-use/#browser-not-showing","title":"Browser Not Showing","text":"<p>Problem: <code>--show-browser</code> flag not working</p> <p>Solutions: <pre><code># Check environment variable\necho $WYN360_BROWSER_SHOW\n\n# Set explicitly\nexport WYN360_BROWSER_SHOW=1\nwyn360\n\n# Or use CLI flag (overrides environment)\nwyn360 --show-browser\n</code></pre></p>"},{"location":"features/browser-use/#code-generation-issues","title":"Code Generation Issues","text":"<p>Problem: Generated automation scripts fail to execute</p> <p>Solutions: 1. Enable browser visibility: <code>wyn360 --show-browser</code> 2. Check error recovery: Review intelligent error analysis 3. Verify sandbox security: Ensure safe execution environment 4. Enable pattern caching: Reuse successful automation patterns</p>"},{"location":"features/browser-use/#high-costs","title":"High Costs","text":"<p>Problem: Automation costs more than expected</p> <p>Solutions: 1. Check approach distribution: Use <code>/tokens</code> command 2. Enable pattern caching: Set <code>WYN360_PATTERN_CACHING=true</code> 3. Monitor error recovery: Too many regeneration attempts? 4. Use batch operations: Combine multiple actions in single script</p>"},{"location":"features/browser-use/#authentication-issues","title":"Authentication Issues","text":"<p>Problem: Can't access logged-in content</p> <p>Solutions: 1. Login first: Use explicit login request 2. Check session: Sessions last 30 minutes 3. Clear cache: If cookies are corrupted 4. Manual intervention: Use show-browser for complex auth</p>"},{"location":"features/browser-use/#best-practices","title":"Best Practices","text":""},{"location":"features/browser-use/#1-optimize-for-enhanced-code-generation","title":"1. Optimize for Enhanced Code Generation","text":"<pre><code># Good: Clear, specific automation goals\n\"Find product price on Amazon product page\"\n\n# Better: Detailed task descriptions\n\"Search Amazon for wireless mouse under $20 with good reviews and extract the cheapest option\"\n\n# Best: Specific and comprehensive\n\"Browse Amazon, search for 'wireless mouse', apply price filter under $20, filter by 4+ star ratings, and return the top 3 cheapest options with details\"\n</code></pre>"},{"location":"features/browser-use/#2-use-browser-visibility-strategically","title":"2. Use Browser Visibility Strategically","text":"<pre><code># Development &amp; debugging\nwyn360 --show-browser\n\n# Production &amp; scripts with enhanced automation\nwyn360  # headless for optimal performance\n\n# Specific debugging with code generation\n\"Browse to checkout and show me the generated automation script\"\n</code></pre>"},{"location":"features/browser-use/#3-leverage-intelligent-recovery","title":"3. Leverage Intelligent Recovery","text":"<pre><code># Enhanced system automatically handles most errors:\n\"Browse complex e-commerce site for product comparison\"\n\u2192 System: Generates code, detects errors, regenerates improved code\n\u2192 Success: Automatic recovery with learning applied\n</code></pre>"},{"location":"features/browser-use/#4-monitor-performance-patterns","title":"4. Monitor Performance &amp; Patterns","text":"<pre><code># Regular performance checking\n/tokens\n\n# Enable pattern caching for better performance\nexport WYN360_PATTERN_CACHING=true\n\n# Optimize code generation level\nexport WYN360_CODE_OPTIMIZATION=advanced\n</code></pre>"},{"location":"features/browser-use/#real-world-examples","title":"Real-World Examples","text":""},{"location":"features/browser-use/#e-commerce-price-comparison","title":"E-commerce Price Comparison","text":"<pre><code>You: Compare wireless earbuds prices across Amazon, Best Buy, and Target\n\nWYN360: [Enhanced automation with batch script generation]\n\ud83d\udcdd **Generating cross-site comparison script...**\n\nGenerated Automation Code:\n```python\n# Multi-site price comparison automation\nsites = [\n    {\"name\": \"Amazon\", \"url\": \"https://amazon.com\", \"search\": \"Sony WF-1000XM4\"},\n    {\"name\": \"Best Buy\", \"url\": \"https://bestbuy.com\", \"search\": \"Sony WF-1000XM4\"},\n    {\"name\": \"Target\", \"url\": \"https://target.com\", \"search\": \"Sony WF-1000XM4\"}\n]\nresults = []\nfor site in sites:\n    # Execute search and extract pricing data\n    # Handle different site layouts automatically\n</code></pre> <p>\ud83d\udd12 Executing in secure sandbox... \u2713</p> <p>Amazon: Sony WF-1000XM4 - $199.99 (4.3\u2b50) Best Buy: Sony WF-1000XM4 - $189.99 (4.5\u2b50) \u2190 Best Deal Target: Sony WF-1000XM4 - $209.99 (4.2\u2b50)</p> <p>\ud83d\udca1 Recommendation: Best Buy offers the lowest price \u26a1 Performance: Enhanced code generation (6.8s total) \ud83d\udcb0 Cost: $0.06 total (vs $0.35 with step-by-step) <pre><code>### Research &amp; Data Extraction\n</code></pre> You: Gather the latest iPhone reviews and ratings from tech websites</p> <p>WYN360: [Enhanced automation for data extraction] \ud83d\udcdd Generating review compilation script...</p> <p>Generated Code: <pre><code># Multi-site review extraction automation\ntech_sites = [\n    {\"name\": \"TechRadar\", \"url\": \"techradar.com/reviews/iphone-15-pro\"},\n    {\"name\": \"GSMArena\", \"url\": \"gsmarena.com/iphone_15_pro_review\"},\n    {\"name\": \"The Verge\", \"url\": \"theverge.com/iphone-15-pro-review\"}\n]\nfor site in tech_sites:\n    # Extract review content, ratings, pros/cons\n    # Handle different review formats automatically\n</code></pre></p> <p>\ud83d\udd12 Executing extraction in secure sandbox... \u2713</p> <p>\ud83d\udcf1 iPhone Review Compilation</p> <p>TechRadar: iPhone 15 Pro - 4.5/5 - Pros: Excellent camera, titanium build - Cons: High price, no significant innovation</p> <p>GSMArena: iPhone 15 Pro - 8.7/10 - Battery: 89h endurance rating - Camera: 48MP main, improved night mode</p> <p>The Verge: iPhone 15 Pro - 8/10 - \"Incremental but meaningful improvements\" - USB-C transition praised</p> <p>\ud83c\udfaf Extraction Method: Enhanced code generation with batch processing \u23f1\ufe0f Time: 22 seconds across 3 sites \ud83d\udcb8 Cost: $0.08 (75% savings vs step-by-step) <pre><code>## Performance Metrics\n\n### **Benchmark Comparison**\n\n| Task Type | Step-by-Step (Old) | Smolagents (New) | Improvement |\n|-----------|-------------------|------------------|-------------|\n| **Product Search** | $0.25, 45s | $0.04, 8s | 84% cost \u2193, 82% time \u2193 |\n| **Form Submission** | $0.40, 60s | $0.06, 12s | 85% cost \u2193, 80% time \u2193 |\n| **Data Extraction** | $0.15, 30s | $0.03, 6s | 80% cost \u2193, 80% time \u2193 |\n| **Multi-Page Flow** | $0.50, 90s | $0.08, 15s | 84% cost \u2193, 83% time \u2193 |\n\n### **Success Rates by Approach**\n- **Enhanced Code Generation:** 92% success rate\n- **Secure Sandbox Execution:** 98% success rate\n- **Intelligent Error Recovery:** 85% recovery success rate\n- **Combined System:** 96% overall success rate\n\n## API Integration\n\nFor programmatic usage:\n\n```python\nfrom wyn360_cli.agent import WYN360Agent\n\n# Initialize with enhanced automation control\nagent = WYN360Agent(\n    api_key=\"your_key\",\n    show_browser=False,  # Headless by default\n    max_cost_per_task=0.20,\n    enhanced_automation=True  # Enable smolagents approach\n)\n\n# Enhanced automation with code generation\nresult = await agent.browse_page_intelligently(\n    ctx=None,\n    url=\"https://example-site.com\",\n    task=\"Find and extract pricing information\",\n    strategy=\"enhanced\"  # enhanced, legacy, secure_only\n)\n\n# Structured data extraction with secure sandbox\ndata = await agent.extract_page_data(\n    ctx=None,\n    url=\"https://product-page.com\",\n    schema={\n        \"title\": str,\n        \"price\": float,\n        \"rating\": float,\n        \"availability\": bool\n    },\n    execution_mode=\"secure_sandbox\"  # Enhanced security\n)\n</code></pre></p>"},{"location":"features/browser-use/#see-also","title":"See Also","text":"<ul> <li>Complete Technical Guide - Full architecture documentation</li> <li>Usage Examples - Real-world automation workflows</li> <li>Cost Optimization Guide - Managing automation expenses</li> <li>Troubleshooting Guide - Common issues and solutions</li> </ul> <p>Updated for WYN360-CLI v0.3.69 Smolagents-Inspired Browser Automation with Enhanced Code Generation</p>"},{"location":"features/github/","title":"GitHub Integration","text":"<p>Seamless repository management, commit operations, and pull request workflows directly from WYN360 CLI.</p>"},{"location":"features/github/#features","title":"Features","text":"<ul> <li>Authentication - Automatic login with GitHub tokens</li> <li>Commit &amp; Push - Stage, commit, and push changes</li> <li>Branch Management - Create, checkout, and merge branches</li> <li>Pull Requests - Create PRs with generated descriptions</li> <li>Repository Operations - Clone, fork, and manage repositories</li> </ul>"},{"location":"features/github/#setup","title":"Setup","text":"<p>Set your GitHub token: <pre><code>export GH_TOKEN=ghp_your_github_token\n# or\nexport GITHUB_TOKEN=ghp_your_github_token\n</code></pre></p>"},{"location":"features/github/#usage-examples","title":"Usage Examples","text":""},{"location":"features/github/#commit-changes","title":"Commit Changes","text":"<pre><code>You: Commit my changes with a good message\n\nWYN360: [Analyzes changes and creates descriptive commit]\n\u2713 Added 3 files, modified 2 files\n\u2713 Generated commit: \"feat: Add authentication middleware and user routes\"\n\u2713 Pushed to origin/main\n</code></pre>"},{"location":"features/github/#create-pull-request","title":"Create Pull Request","text":"<pre><code>You: Create a PR for this feature branch\n\nWYN360: [Creates PR with auto-generated description]\n\u2713 Pull Request created: #42\n\ud83d\udccb Title: \"Add user authentication system\"\n\ud83d\udd17 URL: https://github.com/user/repo/pull/42\n</code></pre>"},{"location":"features/github/#branch-operations","title":"Branch Operations","text":"<pre><code>You: Create a new feature branch for user profiles\n\nWYN360:\n\u2713 Created branch: feature/user-profiles\n\u2713 Switched to new branch\n\u2713 Ready for development\n</code></pre> <p>For detailed examples, see Usage Examples.</p>"},{"location":"features/huggingface/","title":"HuggingFace Integration","text":"<p>Deploy applications to HuggingFace Spaces directly from WYN360 CLI with automated setup and deployment.</p>"},{"location":"features/huggingface/#features","title":"Features","text":"<ul> <li>Space Creation - Create Streamlit/Gradio Spaces</li> <li>File Upload - Automatic code deployment</li> <li>README Generation - Professional documentation</li> <li>Authentication - Seamless HF token integration</li> </ul>"},{"location":"features/huggingface/#setup","title":"Setup","text":"<p>Set your HuggingFace token: <pre><code>export HF_TOKEN=hf_your_huggingface_token\n# or\nexport HUGGINGFACE_TOKEN=hf_your_huggingface_token\n</code></pre></p>"},{"location":"features/huggingface/#usage-examples","title":"Usage Examples","text":""},{"location":"features/huggingface/#deploy-streamlit-app","title":"Deploy Streamlit App","text":"<pre><code>You: Deploy my Streamlit app to HuggingFace\n\nWYN360:\n\u2713 Created HuggingFace Space: username/my-streamlit-app\n\u2713 Generated professional README.md\n\u2713 Uploaded application files\n\u2713 Space URL: https://huggingface.co/spaces/username/my-streamlit-app\n</code></pre>"},{"location":"features/huggingface/#create-gradio-interface","title":"Create Gradio Interface","text":"<pre><code>You: Create a Gradio space for my ML model\n\nWYN360:\n\u2713 Generated Gradio interface code\n\u2713 Created HuggingFace Space\n\u2713 Deployed model and dependencies\n\u2713 Live demo available at: [Space URL]\n</code></pre> <p>For detailed examples, see Usage Examples.</p>"},{"location":"features/overview/","title":"Features Overview","text":"<p>WYN360 CLI provides comprehensive AI-powered development assistance through a rich set of integrated features.</p>"},{"location":"features/overview/#core-ai-capabilities","title":"Core AI Capabilities","text":""},{"location":"features/overview/#interactive-ai-assistant","title":"\ud83e\udd16 Interactive AI Assistant","text":"<ul> <li>Natural Language Interface - Describe what you want in plain English</li> <li>Conversation Memory - Maintains context across multiple interactions</li> <li>Multi-Provider Support - Anthropic Claude, Google Gemini, AWS Bedrock</li> <li>Model Switching - Change AI models mid-session based on task complexity</li> </ul>"},{"location":"features/overview/#code-generation-analysis","title":"\ud83d\udcdd Code Generation &amp; Analysis","text":"<ul> <li>Production-Ready Code - Generate complete applications, not just snippets</li> <li>Smart File Operations - Context-aware file creation, reading, and updates</li> <li>Intent Recognition - Understands \"update existing\" vs \"create new\" automatically</li> <li>Self-Correcting - Smart retry mechanism with error handling</li> </ul>"},{"location":"features/overview/#advanced-features","title":"Advanced Features","text":""},{"location":"features/overview/#web-integration","title":"\ud83c\udf10 Web Integration","text":"<ul> <li>Real-Time Web Search - Access current information and resources</li> <li>Direct Website Fetching - Read specific URLs directly</li> <li>Autonomous Browsing - AI navigates websites and extracts data</li> <li>Smart Caching - Efficient content caching with TTL management</li> </ul>"},{"location":"features/overview/#document-processing","title":"\ud83d\udcc4 Document Processing","text":"<ul> <li>Multi-Format Support - Excel, Word, PDF, and more</li> <li>Vision Mode - Process images, charts, and diagrams</li> <li>Semantic Chunking - Intelligent document segmentation</li> <li>Embedding Search - Find relevant content across large documents</li> </ul>"},{"location":"features/overview/#development-tools","title":"\ud83d\udd27 Development Tools","text":"<ul> <li>GitHub Integration - Commit, push, create PRs seamlessly</li> <li>HuggingFace Deployment - Deploy to Spaces with one command</li> <li>Automatic Test Generation - Generate comprehensive pytest tests</li> <li>Command Execution - Run any CLI tool with safety confirmations</li> </ul>"},{"location":"features/overview/#feature-comparison-by-provider","title":"Feature Comparison by Provider","text":"Feature Anthropic Claude Google Gemini AWS Bedrock Code Generation \u2705 Excellent \u2705 Very Good \u2705 Excellent Web Search \u2705 Built-in \u26a0\ufe0f Custom tool \u2705 Built-in Document Processing \u2705 Full support \u2705 Full support \u2705 Full support Vision Mode \u2705 Advanced \u2705 Good \u2705 Advanced Browser Automation \u2705 Supported \u2705 Supported \u2705 Supported Context Window 200K tokens 2M tokens 200K tokens Cost per M tokens $3.00/$15.00 $0.075/$0.30 $3.00/$15.00 Best for Complex reasoning Cost efficiency Enterprise use"},{"location":"features/overview/#development-workflow-features","title":"Development Workflow Features","text":""},{"location":"features/overview/#session-management","title":"\ud83d\udcca Session Management","text":"<ul> <li>Conversation History - Review past interactions</li> <li>Token Tracking - Monitor API usage and costs in real-time</li> <li>Session Save/Load - Preserve important conversations</li> <li>Model Information - View current model, pricing, and capabilities</li> </ul>"},{"location":"features/overview/#configuration-customization","title":"\u2699\ufe0f Configuration &amp; Customization","text":"<ul> <li>Hierarchical Config - Project, user, and default settings</li> <li>Custom Instructions - Add personal coding standards to every conversation</li> <li>Project Context - Help AI understand your tech stack</li> <li>Environment Variables - Runtime configuration overrides</li> </ul>"},{"location":"features/overview/#user-experience","title":"\ud83c\udfaf User Experience","text":"<ul> <li>Multi-line Input - Shift+Enter for newlines, Enter to submit</li> <li>Streaming Responses - See results as they're generated</li> <li>Rich Terminal UI - Beautiful formatting with syntax highlighting</li> <li>Slash Commands - Quick access to features and settings</li> </ul>"},{"location":"features/overview/#security-privacy","title":"Security &amp; Privacy","text":""},{"location":"features/overview/#credential-management","title":"\ud83d\udd12 Credential Management","text":"<ul> <li>AES-256 Encryption - Secure storage of API keys and tokens</li> <li>Per-User Keys - Isolated encryption for multi-user systems</li> <li>Audit Logging - Track authentication attempts without exposing secrets</li> <li>Session Management - Secure cookie storage for web authentication</li> </ul>"},{"location":"features/overview/#safety-features","title":"\ud83d\udee1\ufe0f Safety Features","text":"<ul> <li>Command Confirmation - User approval required for system commands</li> <li>Timeout Protection - Prevents infinite loops and runaway processes</li> <li>File Permissions - Respects system security boundaries</li> <li>Error Isolation - Failed operations don't crash the session</li> </ul>"},{"location":"features/overview/#performance-optimization","title":"Performance &amp; Optimization","text":""},{"location":"features/overview/#speed-features","title":"\u26a1 Speed Features","text":"<ul> <li>Streaming Responses - Start reading while AI is generating</li> <li>Smart Caching - Website and document content caching</li> <li>Parallel Processing - Multiple operations can run concurrently</li> <li>Token Optimization - Intelligent context management</li> </ul>"},{"location":"features/overview/#cost-management","title":"\ud83d\udcb0 Cost Management","text":"<ul> <li>Multiple Models - Choose based on task complexity and budget</li> <li>Token Limits - Configurable limits to control costs</li> <li>Usage Tracking - Real-time monitoring of API consumption</li> <li>Cost Transparency - Separate tracking for different API types</li> </ul>"},{"location":"features/overview/#integration-ecosystem","title":"Integration Ecosystem","text":""},{"location":"features/overview/#platform-integrations","title":"\ud83d\udd17 Platform Integrations","text":"<ul> <li>GitHub - Repository management, PRs, issues</li> <li>HuggingFace - Space deployment, model hosting</li> <li>AWS - Bedrock integration for enterprise users</li> <li>Docker - Container management and deployment</li> </ul>"},{"location":"features/overview/#developer-tools","title":"\ud83d\udee0\ufe0f Developer Tools","text":"<ul> <li>Poetry - Python dependency management</li> <li>Pytest - Automated testing framework</li> <li>Playwright - Browser automation</li> <li>Git - Version control operations</li> </ul>"},{"location":"features/overview/#feature-roadmap","title":"Feature Roadmap","text":""},{"location":"features/overview/#current-focus-v03x","title":"Current Focus (v0.3.x)","text":"<ul> <li>\u2705 Multi-provider AI support</li> <li>\u2705 Autonomous browsing capabilities</li> <li>\u2705 Document processing with vision</li> <li>\u2705 Google Gemini integration</li> </ul>"},{"location":"features/overview/#upcoming-features","title":"Upcoming Features","text":"<ul> <li>Claude Computer Use - Direct computer interaction capabilities</li> <li>Enhanced Vision - Advanced image and diagram processing</li> <li>Team Collaboration - Shared sessions and project contexts</li> <li>Plugin System - Extensible tool architecture</li> </ul>"},{"location":"features/overview/#get-started-with-specific-features","title":"Get Started with Specific Features","text":"<ul> <li>Web Search \u2192 - Find current information and resources</li> <li>Browser Use \u2192 - Autonomous web navigation and data extraction</li> <li>Vision Mode \u2192 - Process images and visual content</li> <li>GitHub Integration \u2192 - Seamless repository management</li> <li>HuggingFace \u2192 - Deploy and share your projects</li> </ul> <p>Next: Explore specific features or check out Usage Examples \u2192</p>"},{"location":"features/vision-mode/","title":"Vision Mode","text":"<p>Process images, charts, diagrams, and visual content within documents using AI vision capabilities.</p>"},{"location":"features/vision-mode/#overview","title":"Overview","text":"<p>Vision Mode enables WYN360 CLI to understand and analyze visual content in documents, providing insights from charts, diagrams, screenshots, and other images.</p>"},{"location":"features/vision-mode/#supported-formats","title":"Supported Formats","text":"<ul> <li>Word Documents (.docx) - Images, charts, diagrams</li> <li>PDF Files (.pdf) - Scanned documents, technical diagrams</li> <li>Excel Files (.xlsx) - Embedded charts and visualizations</li> <li>Direct Images (.png, .jpg, .gif) - Screenshots, diagrams</li> </ul>"},{"location":"features/vision-mode/#processing-modes","title":"Processing Modes","text":""},{"location":"features/vision-mode/#skip-mode-default","title":"Skip Mode (Default)","text":"<pre><code>You: Read report.docx\n\nWYN360: [Processes text only, ignores images]\n# Cost: $0.00 for images\n</code></pre>"},{"location":"features/vision-mode/#describe-mode","title":"Describe Mode","text":"<pre><code>You: Read report.docx with describe mode\n\nWYN360: [Extracts alt text and captions only]\n\ud83d\udcca [Image 1]: Revenue chart showing quarterly data\n\ud83d\udcd0 [Image 2]: System architecture diagram\n# Cost: $0.00 for images (no API calls)\n</code></pre>"},{"location":"features/vision-mode/#vision-mode_1","title":"Vision Mode","text":"<pre><code>You: Read report.docx with vision mode\n\nWYN360: [Full AI analysis of images]\n\ud83d\udcca **[Image 1]:** Bar chart showing quarterly revenue growth from Q1 to Q4.\nQ4 shows the highest revenue at approximately $2.5M, representing a 23%\nincrease from Q3. All quarters show positive growth year-over-year.\n\n\ud83d\udcd0 **[Image 2]:** System architecture diagram depicting three layers:\nfrontend (React), API layer (FastAPI), and database (PostgreSQL).\nShows data flow from user requests through authentication middleware.\n\n\ud83d\udcb0 **Vision API Cost:** $0.06 (2 images processed)\n</code></pre>"},{"location":"features/vision-mode/#use-cases","title":"Use Cases","text":""},{"location":"features/vision-mode/#technical-documentation","title":"Technical Documentation","text":"<ul> <li>Architecture Diagrams - Understand system designs</li> <li>Flowcharts - Process workflow analysis</li> <li>UML Diagrams - Class and sequence diagram interpretation</li> </ul>"},{"location":"features/vision-mode/#data-analysis","title":"Data Analysis","text":"<ul> <li>Charts &amp; Graphs - Extract insights from visualizations</li> <li>Dashboards - Understand KPIs and metrics</li> <li>Infographics - Convert visual data to text insights</li> </ul>"},{"location":"features/vision-mode/#uiux-design","title":"UI/UX Design","text":"<ul> <li>Mockups - Analyze interface designs</li> <li>Wireframes - Understand user flow</li> <li>Screenshots - Capture current state for analysis</li> </ul>"},{"location":"features/vision-mode/#cost-management","title":"Cost Management","text":""},{"location":"features/vision-mode/#vision-api-pricing","title":"Vision API Pricing","text":"<ul> <li>Cost per Image: ~$0.01-0.05 depending on complexity</li> <li>Separate Tracking - Vision costs shown separately from text processing</li> <li>Token Efficiency - Smart chunking reduces processing costs</li> </ul>"},{"location":"features/vision-mode/#usage-examples","title":"Usage Examples","text":"<pre><code>Document with 5 images:\n- Text processing: 2,000 tokens = $0.006\n- Vision processing: 5 images = $0.15\n- Total cost: ~$0.156\n</code></pre>"},{"location":"features/vision-mode/#configuration","title":"Configuration","text":"<pre><code># Vision processing settings\nvision_mode: \"skip\"        # skip, describe, vision\nvision_batch_size: 5       # Process images in batches\nvision_quality: \"standard\" # standard, high\n</code></pre>"},{"location":"features/vision-mode/#examples","title":"Examples","text":"<p>See Usage Examples for detailed workflows with visual content processing.</p>"},{"location":"features/web-search/","title":"Web Search","text":"<p>Access real-time information from the web to enhance your development workflow.</p>"},{"location":"features/web-search/#overview","title":"Overview","text":"<p>WYN360 CLI integrates web search capabilities to help you find current information, libraries, documentation, and resources while coding.</p>"},{"location":"features/web-search/#basic-usage","title":"Basic Usage","text":"<pre><code>You: Find the latest Python web frameworks\n\nWYN360: [Searches the web for current information]\n\n## Popular Python Web Frameworks (2025)\n\n1. **FastAPI** \u2b50 76k stars\n   - Modern, fast, OpenAPI support\n   - Async/await native\n   - https://github.com/tiangolo/fastapi\n\n2. **Django** \u2b50 79k stars\n   - Batteries included, ORM, admin\n   - Mature ecosystem\n   - https://github.com/django/django\n\n[Sources: GitHub search results, Stack Overflow trends]\n</code></pre>"},{"location":"features/web-search/#search-types","title":"Search Types","text":""},{"location":"features/web-search/#technical-resources","title":"Technical Resources","text":"<ul> <li>Library and framework comparisons</li> <li>Documentation and tutorials</li> <li>GitHub repositories</li> <li>Package versions and compatibility</li> </ul>"},{"location":"features/web-search/#current-information","title":"Current Information","text":"<ul> <li>Weather data</li> <li>News and trends</li> <li>Stock prices</li> <li>Real-time data</li> </ul>"},{"location":"features/web-search/#problem-solving","title":"Problem Solving","text":"<ul> <li>Error messages and solutions</li> <li>Best practices</li> <li>Code examples</li> <li>Community discussions</li> </ul>"},{"location":"features/web-search/#features","title":"Features","text":"<ul> <li>Real-time Results - Always current information</li> <li>Source Attribution - Clear source links</li> <li>Cost Effective - $10 per 1000 searches</li> <li>Session Limits - Default 5 searches per session (configurable)</li> </ul>"},{"location":"features/web-search/#configuration","title":"Configuration","text":"<p>Adjust search limits in your configuration:</p> <pre><code># .env or config\nMAX_INTERNET_SEARCH_LIMIT=10\n</code></pre>"},{"location":"features/web-search/#examples","title":"Examples","text":"<p>See Usage Examples for detailed workflows.</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>WYN360 CLI uses a hierarchical configuration system that allows you to customize behavior at multiple levels.</p>"},{"location":"getting-started/configuration/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>Configuration is loaded in this priority order (highest to lowest):</p> <ol> <li>Project Configuration (<code>.wyn360.yaml</code>) - Highest priority</li> <li>User Configuration (<code>~/.wyn360/config.yaml</code>)</li> <li>Default Values - Lowest priority</li> </ol>"},{"location":"getting-started/configuration/#user-configuration","title":"User Configuration","text":""},{"location":"getting-started/configuration/#location","title":"Location","text":"<pre><code>~/.wyn360/config.yaml\n</code></pre>"},{"location":"getting-started/configuration/#creating-user-config","title":"Creating User Config","text":"<p>Create your user configuration directory and file:</p> <pre><code>mkdir -p ~/.wyn360\ntouch ~/.wyn360/config.yaml\n</code></pre>"},{"location":"getting-started/configuration/#user-config-example","title":"User Config Example","text":"<pre><code># ~/.wyn360/config.yaml\nmodel: \"claude-sonnet-4-20250514\"\nmax_tokens: 4096\ntemperature: 0.1\n\n# Custom instructions added to every conversation\ncustom_instructions: |\n  Please follow these coding standards:\n  - Use type hints for all function parameters and return values\n  - Add docstrings to all functions and classes\n  - Follow PEP 8 style guidelines\n  - Prefer pathlib over os.path for file operations\n  - Use f-strings for string formatting\n\n# Browser use settings\nbrowser_use_cache_enabled: true\nbrowser_use_cache_ttl: 1800  # 30 minutes\nbrowser_use_truncate_strategy: \"smart\"  # smart, beginning, end, middle\nbrowser_use_max_tokens: 10000\n\n# User aliases and shortcuts\naliases:\n  review: \"Review this code for potential improvements, bugs, and style issues\"\n  test: \"Generate comprehensive pytest tests for this code\"\n  doc: \"Add comprehensive documentation and docstrings to this code\"\n</code></pre>"},{"location":"getting-started/configuration/#project-configuration","title":"Project Configuration","text":""},{"location":"getting-started/configuration/#location_1","title":"Location","text":"<pre><code>.wyn360.yaml  # In your project root directory\n</code></pre>"},{"location":"getting-started/configuration/#project-config-example","title":"Project Config Example","text":"<pre><code># .wyn360.yaml - Project-specific settings\nmodel: \"gemini-2.5-flash\"  # Cost-effective for this project\nmax_tokens: 2048\n\n# Project context helps AI understand your setup\nproject_context: |\n  This is a FastAPI web application with:\n  - PostgreSQL database using SQLAlchemy ORM\n  - Redis for caching\n  - Celery for background tasks\n  - Docker for containerization\n  - pytest for testing\n\n  Code style preferences:\n  - Use async/await for all database operations\n  - Prefer Pydantic models for request/response validation\n  - Store configuration in environment variables\n  - Use dependency injection for database sessions\n\n# Project-specific custom instructions\ncustom_instructions: |\n  For this project:\n  - Always use async/await patterns\n  - Include proper error handling with custom exceptions\n  - Add logging statements for important operations\n  - Follow the established project structure in /app\n\n# Browser settings for this project's needs\nbrowser_use_cache_enabled: false  # Always fetch fresh data\nbrowser_use_max_tokens: 15000     # Need more context for documentation\n</code></pre>"},{"location":"getting-started/configuration/#configuration-options-reference","title":"Configuration Options Reference","text":""},{"location":"getting-started/configuration/#core-settings","title":"Core Settings","text":"Option Type Default Description <code>model</code> string Auto-detect AI model to use <code>max_tokens</code> integer 4096 Maximum output tokens <code>temperature</code> float 0.1 Model creativity (0.0-1.0) <code>custom_instructions</code> string \"\" Added to every conversation <code>project_context</code> string \"\" Project-specific context"},{"location":"getting-started/configuration/#browser-use-settings","title":"Browser Use Settings","text":"Option Type Default Description <code>browser_use_cache_enabled</code> boolean true Enable website caching <code>browser_use_cache_ttl</code> integer 1800 Cache TTL in seconds <code>browser_use_truncate_strategy</code> string \"smart\" How to truncate long pages <code>browser_use_max_tokens</code> integer 10000 Max tokens for fetched content"},{"location":"getting-started/configuration/#truncate-strategies","title":"Truncate Strategies","text":"<ul> <li><code>smart</code> - Preserves structure, removes less important content</li> <li><code>beginning</code> - Keep first N tokens</li> <li><code>end</code> - Keep last N tokens</li> <li><code>middle</code> - Keep first and last, remove middle</li> </ul>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"<p>Environment variables override all configuration files:</p>"},{"location":"getting-started/configuration/#core-variables","title":"Core Variables","text":"Variable Description Example <code>CHOOSE_CLIENT</code> AI provider (1=Anthropic, 2=Bedrock, 3=Gemini, 0=auto) <code>3</code> <code>MAX_TOKEN</code> Maximum output tokens <code>4096</code> <code>MAX_INTERNET_SEARCH_LIMIT</code> Web searches per session <code>5</code> <code>WYN360_SKIP_CONFIRM</code> Skip command confirmations <code>1</code>"},{"location":"getting-started/configuration/#ai-provider-credentials","title":"AI Provider Credentials","text":"Google GeminiAnthropic ClaudeAWS Bedrock <pre><code>GEMINI_API_KEY=your_key_here\nGEMINI_MODEL=gemini-2.5-flash\n</code></pre> <pre><code>ANTHROPIC_API_KEY=your_key_here\nANTHROPIC_MODEL=claude-sonnet-4-20250514\n</code></pre> <pre><code>AWS_ACCESS_KEY_ID=your_access_key\nAWS_SECRET_ACCESS_KEY=your_secret_key\nAWS_SESSION_TOKEN=your_session_token\nAWS_REGION=us-west-2\nANTHROPIC_MODEL=us.anthropic.claude-sonnet-4-20250514-v1:0\n</code></pre>"},{"location":"getting-started/configuration/#integration-tokens","title":"Integration Tokens","text":"<pre><code>GH_TOKEN=ghp_your_github_token              # GitHub features\nGITHUB_TOKEN=ghp_your_github_token          # Alternative GitHub token var\nHF_TOKEN=hf_your_huggingface_token          # HuggingFace features\nHUGGINGFACE_TOKEN=hf_your_huggingface_token # Alternative HF token var\n</code></pre>"},{"location":"getting-started/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"getting-started/configuration/#workspace-specific-settings","title":"Workspace-Specific Settings","text":"<p>Create different configurations for different types of projects:</p> <pre><code># ~/.wyn360/config.yaml\n# Default settings\nmodel: \"gemini-2.5-flash\"\nmax_tokens: 4096\n\n# Workspace-specific overrides\nworkspaces:\n  ml_projects:\n    model: \"claude-sonnet-4-20250514\"  # Better for complex ML tasks\n    max_tokens: 8192\n    custom_instructions: |\n      Focus on scientific computing best practices:\n      - Use NumPy/SciPy for numerical operations\n      - Follow scikit-learn patterns for ML models\n      - Include proper data validation and preprocessing\n      - Add visualization with matplotlib/seaborn\n\n  web_development:\n    model: \"gemini-2.5-flash\"  # Cost-effective for web dev\n    max_tokens: 4096\n    browser_use_cache_enabled: true\n    custom_instructions: |\n      Web development focus:\n      - Use modern frameworks (FastAPI, React, etc.)\n      - Include proper error handling and logging\n      - Follow REST API best practices\n      - Include basic security measures\n</code></pre>"},{"location":"getting-started/configuration/#aliases-and-shortcuts","title":"Aliases and Shortcuts","text":"<pre><code># ~/.wyn360/config.yaml\naliases:\n  # Code review shortcuts\n  review: \"Review this code for bugs, performance issues, and style problems\"\n  security: \"Analyze this code for security vulnerabilities\"\n  optimize: \"Suggest performance optimizations for this code\"\n\n  # Documentation shortcuts\n  doc: \"Add comprehensive docstrings and comments to this code\"\n  readme: \"Create a README.md file for this project\"\n\n  # Testing shortcuts\n  test: \"Generate comprehensive pytest tests for this code\"\n  integration: \"Create integration tests for this API endpoint\"\n\n  # Deployment shortcuts\n  deploy: \"Help me deploy this application to production\"\n  docker: \"Create a Dockerfile for this application\"\n</code></pre> <p>Usage: <pre><code>You: @review main.py\n# Expands to: \"Review this code for bugs, performance issues, and style problems\" + file content\n</code></pre></p>"},{"location":"getting-started/configuration/#configuration-commands","title":"Configuration Commands","text":""},{"location":"getting-started/configuration/#view-current-configuration","title":"View Current Configuration","text":"<pre><code># In WYN360 CLI session\n/config\n\n# Shows:\n# \ud83d\udccb Current Configuration\n# Model: gemini-2.5-flash\n# Max Tokens: 4096\n# Custom Instructions: [First 100 chars...]\n# Project Context: [First 100 chars...]\n# Browser Cache: Enabled (TTL: 1800s)\n</code></pre>"},{"location":"getting-started/configuration/#validate-configuration","title":"Validate Configuration","text":"<pre><code># Check config file syntax\npoetry run python -c \"\nimport yaml\nwith open('.wyn360.yaml') as f:\n    config = yaml.safe_load(f)\n    print('\u2705 Configuration is valid')\n\"\n</code></pre>"},{"location":"getting-started/configuration/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"getting-started/configuration/#1-layer-your-settings","title":"1. Layer Your Settings","text":"<ul> <li>User config: Personal preferences, API keys, general coding style</li> <li>Project config: Project-specific context, model selection, team standards</li> <li>Environment variables: Runtime overrides, CI/CD settings</li> </ul>"},{"location":"getting-started/configuration/#2-use-project-context-effectively","title":"2. Use Project Context Effectively","text":"<pre><code>project_context: |\n  Tech Stack:\n  - Backend: Django 4.2 with DRF\n  - Database: PostgreSQL 14\n  - Cache: Redis\n  - Testing: pytest + factory_boy\n  - Deployment: Docker + AWS ECS\n\n  Project Structure:\n  - /apps/core/ - Core business logic\n  - /apps/api/ - REST API endpoints\n  - /apps/users/ - User management\n  - /config/ - Settings and configuration\n\n  Coding Standards:\n  - Follow Django best practices\n  - Use class-based views for complex logic\n  - Prefer function-based views for simple endpoints\n  - All models must have proper __str__ methods\n  - Use Django's built-in User model extensions\n</code></pre>"},{"location":"getting-started/configuration/#3-cost-optimization","title":"3. Cost Optimization","text":"<pre><code># Cost-conscious configuration\nmodel: \"gemini-2.5-flash\"  # 40x cheaper than Claude\nmax_tokens: 2048           # Reduce for simpler tasks\nbrowser_use_cache_enabled: true  # Avoid re-fetching pages\nbrowser_use_cache_ttl: 3600      # Cache for 1 hour\n</code></pre>"},{"location":"getting-started/configuration/#4-team-consistency","title":"4. Team Consistency","text":"<p>Create a shared <code>.wyn360.yaml</code> in your project repository:</p> <pre><code># .wyn360.yaml - Team settings\nmodel: \"claude-sonnet-4-20250514\"  # Consistent model for team\nmax_tokens: 4096\ntemperature: 0.1  # Consistent, less random responses\n\nproject_context: |\n  Team coding standards and project setup...\n\ncustom_instructions: |\n  Team-wide instructions that everyone should follow...\n\n# Don't include API keys in project config!\n# Use environment variables or user config instead\n</code></pre> <p>Next: Features Overview \u2192</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#basic-installation","title":"Basic Installation","text":"<p>Install WYN360 CLI from PyPI using pip:</p> <pre><code>pip install wyn360-cli\n</code></pre>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: &gt;= 3.10, &lt; 4.0</li> <li>Operating System: Linux, macOS, Windows</li> <li>Memory: Minimum 512MB RAM</li> <li>Storage: ~200MB for full installation with browser capabilities</li> </ul>"},{"location":"getting-started/installation/#optional-browser-use-setup","title":"Optional: Browser Use Setup","text":"<p>If you want to use the autonomous browsing and direct website fetching features:</p> <pre><code># Install Playwright browser binaries (one-time setup, ~200MB)\nplaywright install chromium\n</code></pre> <p>When do you need browser capabilities?</p> <ul> <li>Required for: Direct URL fetching (<code>Read https://example.com</code>), autonomous browsing</li> <li>Not required for: Web search, all other features work without it</li> <li>Recommendation: Install if you plan to use web automation features</li> </ul>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Test your installation:</p> <pre><code># Check if wyn360 is installed\nwyn360 --help\n\n# Expected output:\nUsage: wyn360 [OPTIONS]\n\nAn intelligent AI coding assistant CLI tool powered by Anthropic Claude.\n\nOptions:\n  --max-token INTEGER             Maximum tokens for model output\n  --max-internet-search-limit INTEGER  Maximum internet searches per session\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>WYN360 CLI automatically installs these core dependencies:</p>"},{"location":"getting-started/installation/#core-framework","title":"Core Framework","text":"<ul> <li><code>click&gt;=8.1.0</code> - CLI framework</li> <li><code>pydantic-ai&gt;=1.13.0</code> - AI agent framework with web search support</li> <li><code>rich&gt;=13.0.0</code> - Terminal formatting and display</li> </ul>"},{"location":"getting-started/installation/#ai-provider-support","title":"AI Provider Support","text":"<ul> <li><code>anthropic[bedrock]&gt;=0.39.0</code> - Anthropic Claude API client with AWS Bedrock support</li> <li><code>google-genai&gt;=1.0.0</code> - Google Gemini API client</li> </ul>"},{"location":"getting-started/installation/#advanced-features","title":"Advanced Features","text":"<ul> <li><code>crawl4ai&gt;=0.7.6</code> - LLM-optimized web crawler for browser use</li> <li><code>playwright&gt;=1.40.0</code> - Browser automation (requires separate binary install)</li> <li><code>sentence-transformers&gt;=2.2.0</code> - Document embeddings for semantic search</li> <li><code>pytesseract&gt;=0.3.10</code> - OCR capabilities</li> <li><code>cryptography&gt;=42.0.0</code> - Secure credential management</li> </ul>"},{"location":"getting-started/installation/#configuration-utils","title":"Configuration &amp; Utils","text":"<ul> <li><code>python-dotenv&gt;=1.2.1</code> - Environment variable management</li> <li><code>prompt-toolkit&gt;=3.0.0</code> - Advanced input handling (multi-line support)</li> <li><code>pyyaml&gt;=6.0.0</code> - Configuration file support</li> <li><code>huggingface-hub&gt;=0.20.0</code> - HuggingFace integration</li> </ul>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>For contributors or advanced users who want to install from source:</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Poetry - Python dependency management</li> <li>Git - Version control</li> </ul>"},{"location":"getting-started/installation/#setup-steps","title":"Setup Steps","text":"<ol> <li> <p>Install Poetry (if not already installed):    <pre><code>curl -sSL https://install.python-poetry.org | python3 -\n</code></pre></p> </li> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/yiqiao-yin/wyn360-cli.git\ncd wyn360-cli\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>poetry install\n</code></pre></p> </li> <li> <p>Activate the environment:    <pre><code>poetry shell\n</code></pre></p> </li> <li> <p>Run from source:    <pre><code>python -m wyn360_cli.cli\n# or\npoetry run wyn360\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#running-tests","title":"Running Tests","text":"<pre><code># Skip command confirmation prompts in tests\nWYN360_SKIP_CONFIRM=1 poetry run pytest tests/ -v\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Once installed, you'll need to configure your AI provider credentials:</p> <ul> <li>Quick Start Guide \u2192 - Get up and running in 5 minutes</li> <li>Configuration \u2192 - Detailed setup and customization options</li> </ul>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":"<p>??? question \"ImportError: No module named 'wyn360_cli'\"     This usually means the package wasn't installed correctly. Try:     <pre><code>pip uninstall wyn360-cli\npip install wyn360-cli\n</code></pre></p> <p>??? question \"playwright command not found\"     Playwright binaries need to be installed separately:     <pre><code>playwright install chromium\n</code></pre>     If <code>playwright</code> command isn't found, try:     <pre><code>python -m playwright install chromium\n</code></pre></p> <p>??? question \"Permission denied errors\"     On some systems, you may need to install with user permissions:     <pre><code>pip install --user wyn360-cli\n</code></pre></p> <p>??? question \"Python version errors\"     Ensure you're using Python 3.10 or higher:     <pre><code>python --version\n# Should show Python 3.10.x or higher\n</code></pre></p>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the GitHub Issues page</li> <li>Search existing issues or create a new one</li> <li>Include your Python version, OS, and error message</li> </ol> <p>Next: Quick Start Guide \u2192</p>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>Get up and running with WYN360 CLI in under 5 minutes!</p>"},{"location":"getting-started/quickstart/#step-1-choose-your-ai-provider","title":"Step 1: Choose Your AI Provider","text":"<p>WYN360 CLI supports four AI providers. Choose the one that works best for you:</p> Anthropic ClaudeAWS BedrockGoogle Gemini (Recommended)OpenAIAuto-Detection <p>Why Claude? Most capable, excellent for complex coding tasks</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=1\nexport ANTHROPIC_API_KEY=your_key_here\nexport ANTHROPIC_MODEL=claude-sonnet-4-20250514\n</code></pre></p> <p>Get API Key: Anthropic Console</p> <p>Available Models: - <code>claude-sonnet-4-20250514</code> - Most capable (default) - <code>claude-3-5-haiku-20241022</code> - Fastest and cheapest - <code>claude-opus-4-1-20250805</code> - Most powerful</p> <p>Why Bedrock? Enterprise AWS integration, compliance features</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=2\nexport AWS_ACCESS_KEY_ID=your_access_key\nexport AWS_SECRET_ACCESS_KEY=your_secret_key\nexport AWS_SESSION_TOKEN=your_session_token\nexport AWS_REGION=us-west-2\nexport ANTHROPIC_MODEL=us.anthropic.claude-sonnet-4-20250514-v1:0\n</code></pre></p> <p>Requirements: Valid AWS account with Bedrock access</p> <p>Why Gemini? ~40x cheaper than Claude, 2M context window, fast performance</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=3\nexport GEMINI_API_KEY=your_key_here\nexport GEMINI_MODEL=gemini-2.5-flash\n</code></pre></p> <p>Get API Key: Google AI Studio</p> <p>Pricing: $0.075 per million input tokens (vs $3.00 for Claude)</p> <p>Why OpenAI? Industry-leading performance, competitive pricing, fast response times</p> <p>Setup: <pre><code>export CHOOSE_CLIENT=4\nexport OPENAI_API_KEY=your_key_here\nexport OPENAI_MODEL=gpt-4o\n</code></pre></p> <p>Get API Key: OpenAI Platform</p> <p>Available Models: - <code>gpt-4o</code> - Latest and most capable (default) - <code>gpt-4</code> - Stable and reliable - <code>gpt-3.5-turbo</code> - Fast and cost-effective</p> <p>Let WYN360 choose automatically based on available credentials:</p> <pre><code># Just set your preferred API key - no CHOOSE_CLIENT needed\nexport GEMINI_API_KEY=your_key_here\n# System automatically detects and uses Gemini\n</code></pre> <p>Priority order: 1. <code>ANTHROPIC_API_KEY</code> \u2192 Use Anthropic 2. AWS credentials \u2192 Use Bedrock 3. <code>GEMINI_API_KEY</code> \u2192 Use Gemini 4. <code>OPENAI_API_KEY</code> \u2192 Use OpenAI</p>"},{"location":"getting-started/quickstart/#step-2-set-up-environment","title":"Step 2: Set Up Environment","text":""},{"location":"getting-started/quickstart/#option-a-using-env-file-recommended","title":"Option A: Using .env File (Recommended)","text":"<p>Create a <code>.env</code> file in your project directory:</p> <pre><code># .env file - choose one provider\nCHOOSE_CLIENT=3\nGEMINI_API_KEY=your_gemini_key\nGEMINI_MODEL=gemini-2.5-flash\nMAX_TOKEN=4096\nMAX_INTERNET_SEARCH_LIMIT=5\n</code></pre>"},{"location":"getting-started/quickstart/#option-b-using-environment-variables","title":"Option B: Using Environment Variables","text":"<pre><code>export CHOOSE_CLIENT=3\nexport GEMINI_API_KEY=your_gemini_key\nexport GEMINI_MODEL=gemini-2.5-flash\n</code></pre>"},{"location":"getting-started/quickstart/#additional-configuration-optional","title":"Additional Configuration (Optional)","text":"<pre><code># Token limits\nexport MAX_TOKEN=4096\nexport MAX_INTERNET_SEARCH_LIMIT=5\n\n# Integration tokens (optional)\nexport GH_TOKEN=ghp_your_github_token        # For GitHub features\nexport HF_TOKEN=hf_your_huggingface_token    # For HuggingFace features\n\n# Skip confirmations (useful for automation)\nexport WYN360_SKIP_CONFIRM=0\n</code></pre>"},{"location":"getting-started/quickstart/#step-3-start-wyn360-cli","title":"Step 3: Start WYN360 CLI","text":"<pre><code>wyn360\n</code></pre> <p>You should see:</p> <pre><code>\ud83e\udd16 WYN360 CLI v0.3.60\n\ud83d\udd0d AI Provider: Google Gemini (gemini-2.5-flash)\n\ud83d\udca1 Model: gemini-2.5-flash | Context: 2M tokens\n\ud83d\udcb0 Cost: $0.075/$0.30 per M tokens (input/output)\n\nType your message (Shift+Enter for newline, Enter to send, 'exit' to quit):\nYou:\n</code></pre>"},{"location":"getting-started/quickstart/#step-4-try-your-first-commands","title":"Step 4: Try Your First Commands","text":""},{"location":"getting-started/quickstart/#basic-chat","title":"Basic Chat","text":"<pre><code>You: Hello! Can you help me create a Python function?\n\nWYN360: Hello! I'd be happy to help you create a Python function.\nWhat kind of function would you like me to create for you?\n</code></pre>"},{"location":"getting-started/quickstart/#code-generation","title":"Code Generation","text":"<pre><code>You: Create a function that calculates the factorial of a number\n\nWYN360: I'll create a factorial function for you.\n\n[Creates factorial.py with the function and saves it]\n\n\u2713 Created factorial.py with factorial function\n\u2713 Added error handling for negative numbers\n\u2713 Included docstring and example usage\n</code></pre>"},{"location":"getting-started/quickstart/#project-analysis","title":"Project Analysis","text":"<pre><code>You: List all Python files in this project\n\nWYN360: [Scans directory]\n\n\ud83d\udcc1 **Python Files Found:**\n- `wyn360_cli/cli.py` (840 lines)\n- `wyn360_cli/agent.py` (4,259 lines)\n- `wyn360_cli/config.py` (308 lines)\n- `tests/test_agent.py` (46 tests)\n[... complete listing]\n</code></pre>"},{"location":"getting-started/quickstart/#step-5-explore-slash-commands","title":"Step 5: Explore Slash Commands","text":"<p>WYN360 CLI includes powerful slash commands for session management:</p> Command Description Example <code>/help</code> Show all available commands <code>/help</code> <code>/model</code> Show current model or switch <code>/model haiku</code> <code>/tokens</code> Show token usage and costs <code>/tokens</code> <code>/history</code> Display conversation history <code>/history</code> <code>/save &lt;file&gt;</code> Save session to file <code>/save my_session.json</code> <code>/load &lt;file&gt;</code> Load session from file <code>/load my_session.json</code> <code>/clear</code> Clear history and reset <code>/clear</code> <code>/config</code> Show current configuration <code>/config</code>"},{"location":"getting-started/quickstart/#example-session-management","title":"Example Session Management","text":"<pre><code>You: Create a web scraper for Python packages\n\nWYN360: [Creates scraper.py with full implementation]\n\nYou: /save scraper_session.json\n\u2713 Session saved to: scraper_session.json\n\nYou: /tokens\n\ud83d\udcca **Token Usage This Session**\nInput: 1,245 tokens | Output: 892 tokens\n\ud83d\udcb0 Cost: $0.002 | Model: gemini-2.5-flash\n\nYou: /model\n\ud83e\udd16 **Current Model: gemini-2.5-flash**\n\ud83d\udcb0 Pricing: $0.075/$0.30 per M tokens (input/output)\n\ud83d\udcca Context Window: 2M tokens\n\ud83d\udd27 Max Output: 4096 tokens\n</code></pre>"},{"location":"getting-started/quickstart/#common-first-tasks","title":"Common First Tasks","text":""},{"location":"getting-started/quickstart/#file-operations","title":"File Operations","text":"<pre><code>You: Read the contents of config.py\nYou: Update main.py to add logging\nYou: Create a new FastAPI app in app.py\nYou: Delete the old backup files\n</code></pre>"},{"location":"getting-started/quickstart/#development-workflow","title":"Development Workflow","text":"<pre><code>You: Run the tests for this project\nYou: Check git status and show me what's changed\nYou: Install the requirements from requirements.txt\nYou: Create a virtual environment and activate it\n</code></pre>"},{"location":"getting-started/quickstart/#web-and-research","title":"Web and Research","text":"<pre><code>You: Search for the latest Python web frameworks\nYou: Read https://docs.python.org/3/tutorial/\nYou: Find GitHub repositories for machine learning\nYou: What's the current weather in San Francisco?\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you're set up, explore these advanced features:</p> <ul> <li>Configuration \u2192 - Customize WYN360 for your workflow</li> <li>Features Overview \u2192 - Discover all capabilities</li> <li>Usage Examples \u2192 - Real-world workflows and examples</li> <li>Cost Management \u2192 - Optimize token usage and costs</li> </ul>"},{"location":"getting-started/quickstart/#quick-tips","title":"Quick Tips","text":"<p>Multi-line Input</p> <ul> <li>Enter = Submit message</li> <li>Shift+Enter = Add new line</li> <li>Ctrl+C = Cancel current input</li> </ul> <p>Cost Optimization</p> <ul> <li>Use Gemini for cost-effective operations</li> <li>Switch to Claude for complex reasoning tasks</li> <li>Use <code>/model haiku</code> for simple tasks</li> <li>Monitor usage with <code>/tokens</code></li> </ul> <p>Session Management</p> <ul> <li>Save important conversations with <code>/save</code></li> <li>Use <code>/clear</code> to reset token counters</li> <li>Load previous sessions with <code>/load</code></li> </ul> <p>Next: Configuration Guide \u2192</p>"},{"location":"usage/commands/","title":"Commands Reference","text":"<p>Complete reference for WYN360 CLI commands and slash commands.</p>"},{"location":"usage/commands/#chat-commands","title":"Chat Commands","text":"Command Description <code>&lt;message&gt;</code> Chat with the AI assistant <code>Enter</code> Submit your message <code>Shift+Enter</code> Add a new line (multi-line input) <code>exit</code> or <code>quit</code> End the session"},{"location":"usage/commands/#slash-commands","title":"Slash Commands","text":""},{"location":"usage/commands/#session-management","title":"Session Management","text":"Command Description Example <code>/clear</code> Clear conversation history and reset token counters <code>/clear</code> <code>/history</code> Display conversation history in a table <code>/history</code> <code>/save &lt;file&gt;</code> Save current session to JSON file <code>/save analysis_session.json</code> <code>/load &lt;file&gt;</code> Load session from JSON file <code>/load analysis_session.json</code>"},{"location":"usage/commands/#model-configuration","title":"Model &amp; Configuration","text":"Command Description Example <code>/model [name]</code> Show current model info or switch models <code>/model haiku</code> <code>/tokens</code> Show detailed token usage statistics and costs <code>/tokens</code> <code>/config</code> Show current configuration <code>/config</code>"},{"location":"usage/commands/#help-information","title":"Help &amp; Information","text":"Command Description Example <code>/help</code> Display help message with all commands <code>/help</code>"},{"location":"usage/commands/#model-names","title":"Model Names","text":"<p>Use these names with the <code>/model</code> command:</p>"},{"location":"usage/commands/#anthropic-claude","title":"Anthropic Claude","text":"<ul> <li><code>sonnet</code> - Claude Sonnet 4 (most capable)</li> <li><code>haiku</code> - Claude 3.5 Haiku (fastest, cheapest)</li> <li><code>opus</code> - Claude Opus 4 (most powerful)</li> </ul>"},{"location":"usage/commands/#google-gemini","title":"Google Gemini","text":"<ul> <li><code>gemini-2.5-flash</code> - Fast and cost-effective</li> <li><code>gemini-2.5-pro</code> - More powerful</li> </ul>"},{"location":"usage/commands/#cli-arguments","title":"CLI Arguments","text":"<p>When starting WYN360:</p> <pre><code>wyn360 [OPTIONS]\n\nOptions:\n  --max-token INTEGER             Maximum tokens for model output\n  --max-internet-search-limit INTEGER  Maximum internet searches per session\n  --help                          Show help message and exit\n</code></pre>"},{"location":"usage/commands/#examples","title":"Examples","text":""},{"location":"usage/commands/#basic-usage","title":"Basic Usage","text":"<pre><code># Start with default settings\nwyn360\n\n# Start with custom token limit\nwyn360 --max-token 8192\n\n# Start with more search quota\nwyn360 --max-internet-search-limit 10\n</code></pre>"},{"location":"usage/commands/#session-management_1","title":"Session Management","text":"<pre><code>You: Write a data analysis script\nWYN360: [Creates analysis.py]\n\nYou: /save data_analysis_session.json\n\u2713 Session saved to: data_analysis_session.json\n\nYou: /tokens\n\ud83d\udcca **Token Usage This Session**\nInput: 1,500 tokens | Output: 800 tokens\n\ud83d\udcb0 Cost: $0.02 | Model: claude-sonnet-4\n\nYou: /clear\n\u2713 Conversation history cleared. Token counters reset.\n\nYou: /load data_analysis_session.json\n\u2713 Session loaded from: data_analysis_session.json\n</code></pre>"},{"location":"usage/commands/#model-switching","title":"Model Switching","text":"<pre><code>You: /model\n\ud83e\udd16 **Current Model: claude-sonnet-4-20250514**\n\ud83d\udcb0 Pricing: $3.00/$15.00 per M tokens (input/output)\n\ud83d\udcca Context Window: 200K tokens\n\nYou: /model haiku\n\u2713 Switched to Claude 3.5 Haiku (claude-3-5-haiku-20241022)\n\ud83d\udcb0 New pricing: $0.25/$1.25 per M tokens\n\nYou: /model gemini-2.5-flash\n\u2713 Switched to Google Gemini (gemini-2.5-flash)\n\ud83d\udcb0 New pricing: $0.075/$0.30 per M tokens\n\ud83d\udcca Context Window: 2M tokens\n</code></pre> <p>For more examples, see Usage Examples.</p>"},{"location":"usage/cost/","title":"WYN360 CLI - Cost Analysis &amp; Estimation","text":"<p>This document provides a detailed breakdown of the costs associated with using WYN360 CLI, which is powered by Anthropic Claude.</p>"},{"location":"usage/cost/#pricing-anthropic-claude-sonnet-4","title":"\ud83d\udcb0 Pricing (Anthropic Claude Sonnet 4)","text":"<p>As of January 2025, the default model <code>claude-sonnet-4-20250514</code> pricing:</p>"},{"location":"usage/cost/#token-costs","title":"Token Costs","text":"Token Type Cost per Million Tokens Input Tokens $3.00 Output Tokens $15.00"},{"location":"usage/cost/#web-search-costs-phase-111-v0321","title":"Web Search Costs (Phase 11.1 - v0.3.21)","text":"Feature Cost Web Search $10.00 per 1,000 searches Session Limit 5 searches (default, configurable) Per Search $0.01 <p>Important: Web search costs are in addition to token costs. Each search incurs: - Fixed search cost: $0.01 - Token costs for processing results: ~$0.001-0.015 (varies by result size) - Total per search: ~$0.011-0.025</p> <p>Formula: <pre><code>Total Cost = (Input Tokens / 1,000,000 \u00d7 $3)\n           + (Output Tokens / 1,000,000 \u00d7 $15)\n           + (Web Searches \u00d7 $0.01)\n           + (Search Result Token Processing)\n</code></pre></p>"},{"location":"usage/cost/#vision-api-costs-phase-51-v0330","title":"Vision API Costs (Phase 5.1 - v0.3.30)","text":"Feature Cost Vision API (Image Processing) Uses Sonnet pricing Input (per image + prompt) ~$0.0033 per image (~1,100 tokens) Output (description) ~$0.0015-0.0030 per image (~100-200 tokens) Total per image ~$0.01-0.05 <p>Important: Vision API costs are in addition to document processing costs. Each image processed incurs: - Input tokens: ~1,000 tokens (image encoding) + ~100 tokens (prompt) = ~1,100 tokens - Output tokens: ~100-200 tokens (description) - Total cost per image: ~$0.01-0.05</p> <p>Image Handling Modes: - <code>skip</code> (default) - No vision API calls, zero cost - <code>describe</code> - Extract alt text only, zero API cost - <code>vision</code> - Full Claude Vision API processing (costs apply)</p> <p>Example Costs: - 5-image document: ~$0.05-0.25 - 20-image presentation: ~$0.20-1.00 - 50-image technical manual: ~$0.50-2.50</p> <p>Formula: <pre><code>Vision Cost = (Vision Input Tokens / 1,000,000 \u00d7 $3)\n            + (Vision Output Tokens / 1,000,000 \u00d7 $15)\n\nwhere:\n  Vision Input Tokens = (Number of Images \u00d7 1,100)\n  Vision Output Tokens = (Number of Images \u00d7 100-200)\n</code></pre></p> <p>Combined Formula (with Vision): <pre><code>Total Cost = (Conversation Input / 1M \u00d7 $3)\n           + (Conversation Output / 1M \u00d7 $15)\n           + (Document Processing Input / 1M \u00d7 $3)\n           + (Document Processing Output / 1M \u00d7 $15)\n           + (Vision Input / 1M \u00d7 $3)\n           + (Vision Output / 1M \u00d7 $15)\n           + (Web Searches \u00d7 $0.01)\n</code></pre></p>"},{"location":"usage/cost/#autonomous-browsing-costs-phase-52-56-v0352-0356","title":"Autonomous Browsing Costs (Phase 5.2-5.6 - v0.3.52-0.3.56) \ud83c\udd95","text":"Feature Cost Per Screenshot Analysis ~$0.01-0.02 Simple Task (10-15 steps) ~$0.10-0.30 Medium Task (15-20 steps) ~$0.15-0.40 Complex Task (20-30 steps) ~$0.20-0.60 <p>Important: Autonomous browsing uses Claude Vision API to analyze screenshots and make navigation decisions.</p> <p>What happens per step: 1. Screenshot capture - 1024x768 PNG (~100-200KB) 2. Vision API call - Screenshot + analysis prompt 3. Decision making - Parse JSON response with next action</p> <p>Token breakdown per screenshot: - Input: ~1,792 tokens (screenshot encoding) + ~500-800 tokens (prompt) = ~2,300-2,600 tokens - Output: ~200-400 tokens (JSON decision + reasoning) - Cost per screenshot: ~$0.01-0.02</p> <p>Calculation: <pre><code>Input cost:  2,500 tokens \u00d7 $3.00 / 1M = $0.0075\nOutput cost: 300 tokens \u00d7 $15.00 / 1M = $0.0045\nTotal:       ~$0.012 per screenshot\n</code></pre></p> <p>Real-World Examples:</p> Task Type Steps Screenshots Estimated Cost Simple product search 8 8 $0.10 Price comparison 12 12 $0.14 Multi-filter shopping 18 18 $0.22 Complex exploration 25 25 $0.30 Multi-page analysis 30 30 $0.36 <p>Cost Optimization Tips:</p> <ol> <li> <p>Use targeted URLs: Start closer to your goal    <pre><code># \u274c Expensive: Start from homepage\nbrowse_and_find(task, url=\"https://amazon.com\")  # 20+ steps\n\n# \u2705 Cheaper: Start from relevant page\nbrowse_and_find(task, url=\"https://amazon.com/s?k=wireless+mouse\")  # 10 steps\n</code></pre></p> </li> <li> <p>Set appropriate max_steps: Don't allow unnecessary actions    <pre><code># \u2705 Good: Limit steps for simple tasks\nbrowse_and_find(task, url, max_steps=10)  # ~$0.12\n\n# \u274c Wasteful: Too many steps for simple task\nbrowse_and_find(task, url, max_steps=50)  # Could reach $0.60\n</code></pre></p> </li> <li> <p>Cache and reuse sessions: For authenticated browsing    <pre><code># Login once\nawait login_to_website(url, username, password)\n\n# Reuse session for multiple browsing tasks (no re-login cost)\nawait browse_and_find(task1, authenticated_url)\nawait browse_and_find(task2, authenticated_url)\nawait browse_and_find(task3, authenticated_url)\n</code></pre></p> </li> <li> <p>Batch similar tasks: Group related queries    <pre><code># \u274c Expensive: 3 separate browsing sessions\nbrowse_and_find(\"Find product A\", \"https://site.com\")  # 15 steps\nbrowse_and_find(\"Find product B\", \"https://site.com\")  # 15 steps\nbrowse_and_find(\"Find product C\", \"https://site.com\")  # 15 steps\n# Total: 45 steps \u00d7 $0.012 = $0.54\n\n# \u2705 Cheaper: Single task with multiple targets\nbrowse_and_find(\"Find products A, B, and C with prices\", \"https://site.com\")\n# Total: 20 steps \u00d7 $0.012 = $0.24\n</code></pre></p> </li> </ol> <p>Combined Formula (with Autonomous Browsing): <pre><code>Total Cost = (Conversation Input / 1M \u00d7 $3)\n           + (Conversation Output / 1M \u00d7 $15)\n           + (Document Processing Input / 1M \u00d7 $3)\n           + (Document Processing Output / 1M \u00d7 $15)\n           + (Autonomous Browsing Screenshots \u00d7 $0.012)\n           + (Web Searches \u00d7 $0.01)\n</code></pre></p> <p>Tracking Costs: <pre><code># Check vision API usage\nprint(f\"Vision images processed: {agent.vision_image_count}\")\nprint(f\"Vision input tokens: {agent.vision_input_tokens}\")\nprint(f\"Vision output tokens: {agent.vision_output_tokens}\")\n\n# Estimate autonomous browsing cost\nestimated_cost = agent.vision_image_count \u00d7 0.012\nprint(f\"Estimated autonomous browsing cost: ${estimated_cost:.2f}\")\n</code></pre></p>"},{"location":"usage/cost/#token-breakdown-per-request","title":"\ud83d\udcca Token Breakdown Per Request","text":"<p>Every interaction with WYN360 CLI consists of several components that contribute to token usage:</p>"},{"location":"usage/cost/#1-system-prompt-1000-tokens","title":"1. System Prompt (~1,000 tokens)","text":"<p>The system prompt is sent with every request and includes: - Role description and capabilities (~100 tokens) - File operation intelligence guidelines (~200 tokens) - Command execution guidelines (~150 tokens) - HuggingFace integration guidelines (~100 tokens) - Test generation guidelines (~100 tokens) - Web search guidelines (~100 tokens) - NEW in v0.3.21 - Best practices and examples (~250 tokens)</p> <p>Cost per request: ~$0.003 (input only)</p>"},{"location":"usage/cost/#2-tool-definitions-1800-tokens","title":"2. Tool Definitions (~1,800 tokens)","text":"<p>All 20 tools are registered with the agent and their schemas are sent with each request (19 custom + 1 builtin):</p> <p>Core Tools (Phase 1): - <code>read_file</code> - Read file contents (~100 tokens) - <code>write_file</code> - Create/update files (~120 tokens) - <code>list_files</code> - Scan directory (~80 tokens) - <code>get_project_info</code> - Project summary (~100 tokens) - <code>execute_command</code> - Run shell commands (~200 tokens)</p> <p>Extended Tools (Phase 2 - Added in v0.2.9): - <code>git_status</code> - Show git status (~80 tokens) - <code>git_diff</code> - Show git changes (~80 tokens) - <code>git_log</code> - Show commit history (~80 tokens) - <code>git_branch</code> - List branches (~80 tokens) - <code>search_files</code> - Pattern search across files (~100 tokens) - <code>delete_file</code> - Delete files safely (~80 tokens) - <code>move_file</code> - Move/rename files (~80 tokens) - <code>create_directory</code> - Create nested directories (~80 tokens)</p> <p>HuggingFace Tools (Phase 6/7 - Added in v0.3.16-v0.3.17): - <code>check_hf_authentication</code> - Check HF auth status (~80 tokens) - <code>authenticate_hf</code> - Authenticate with HF (~80 tokens) - <code>create_hf_readme</code> - Create Space README (~100 tokens) - <code>create_hf_space</code> - Create new HF Space (~100 tokens) - <code>push_to_hf_space</code> - Push files to Space (~100 tokens)</p> <p>Test Generation Tool (Phase 7.2 - Added in v0.3.18): - <code>generate_tests</code> - Auto-generate pytest test stubs (~100 tokens)</p> <p>Web Search Builtin Tool (Phase 11.1 - Added in v0.3.21): - <code>web_search</code> - Real-time internet search (~60 tokens for definition)   - Note: This is a builtin tool, not a custom @tool function   - Invoked automatically by Claude when current information is needed   - Additional cost: $0.01 per search (5 searches max per session)</p> <p>Cost per request: ~$0.0054 (input only, excluding web search usage costs)</p>"},{"location":"usage/cost/#3-user-message-50-500-tokens","title":"3. User Message (~50-500 tokens)","text":"<p>Varies based on complexity: - Simple: \"Create a hello world script\" (~10 tokens) - Medium: \"Add authentication to my FastAPI app\" (~15 tokens) - Complex: Multi-line detailed requirements (~200-500 tokens)</p> <p>Average cost: ~$0.00015 - $0.0015 (input)</p>"},{"location":"usage/cost/#4-conversation-history-new-in-v028-variable","title":"4. Conversation History (NEW in v0.2.8) (Variable)","text":"<p>Starting with v0.2.8, conversation history is maintained across interactions to provide better context:</p> <p>How it works: - Every user message and assistant response is stored - The entire conversation history is sent with each subsequent request - This allows the agent to maintain context across multiple turns - History accumulates throughout the session</p> <p>Token Impact: - Turn 1: 0 tokens (no history yet) - Turn 2: ~50-800 tokens (previous turn) - Turn 3: ~100-1,600 tokens (2 previous turns) - Turn 10: ~450-8,000 tokens (9 previous turns)</p> <p>Cost implications: <pre><code>Without history (v0.2.7 and earlier):\n  Each request: ~1,500 tokens baseline (5 tools)\n\nWith history + all tools (v0.3.21):\n  Turn 1:  ~2,850 tokens baseline (20 tools, web search capable)\n  Turn 5:  ~5,350-7,850 tokens (includes 4 previous turns)\n  Turn 10: ~9,350-13,850 tokens (includes 9 previous turns)\n\nNote: Add $0.01-0.025 per web search if used\n</code></pre></p> <p>Average conversation history cost per turn: - Turns 1-3: +$0.001 - $0.005 - Turns 4-7: +$0.005 - $0.015 - Turns 8-15: +$0.015 - $0.040 - Turns 16+: +$0.040 - $0.100</p> <p>Managing history costs: - Use <code>/clear</code> to reset conversation history when starting a new task - Use <code>/save</code> before <code>/clear</code> to preserve important conversations - Use <code>/tokens</code> to monitor cumulative costs during long sessions - Balance context quality (better with history) vs cost (increases per turn)</p>"},{"location":"usage/cost/#5-tool-call-execution-variable","title":"5. Tool Call Execution (Variable)","text":"<p>When the agent calls tools, additional tokens are used:</p>"},{"location":"usage/cost/#tool-call-request-50-100-tokens-per-call","title":"Tool Call Request (~50-100 tokens per call)","text":"<pre><code>{\n  \"tool\": \"read_file\",\n  \"parameters\": {\"file_path\": \"app.py\"}\n}\n</code></pre>"},{"location":"usage/cost/#tool-response-highly-variable","title":"Tool Response (Highly Variable)","text":"Tool Typical Response Size Token Estimate <code>read_file</code> File contents 100-5,000+ tokens <code>write_file</code> Success message 20-50 tokens <code>list_files</code> File list 50-500 tokens <code>get_project_info</code> Project summary 100-1,000 tokens <code>execute_command</code> Command output 50-2,000+ tokens <p>Average tool execution: ~$0.003 - $0.015 per tool call</p>"},{"location":"usage/cost/#6-assistant-response-200-1500-tokens","title":"6. Assistant Response (~200-1,500 tokens)","text":"<p>The final response varies by complexity: - Simple confirmation: ~50 tokens - Code generation: ~500-1,500 tokens - Explanation + code: ~800-2,000 tokens</p> <p>Average cost: ~$0.003 - $0.03 (output)</p>"},{"location":"usage/cost/#cost-estimates-for-common-use-cases","title":"\ud83d\udcc8 Cost Estimates for Common Use Cases","text":""},{"location":"usage/cost/#use-case-1-simple-code-generation-blank-project","title":"Use Case 1: Simple Code Generation (Blank Project)","text":"<p>Scenario: \"Create a Streamlit hello world app\"</p> <p>Token Breakdown: <pre><code>System Prompt:        850 tokens (input)\nTool Definitions:     600 tokens (input)\nUser Message:          15 tokens (input)\nTool Calls:             0 (no file reading needed)\nAssistant Response:   800 tokens (output, includes code)\n---------------------------------------------------\nTotal Input:        1,465 tokens\nTotal Output:         800 tokens\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  1,465 / 1,000,000 \u00d7 $3  = $0.004395\nOutput:   800 / 1,000,000 \u00d7 $15 = $0.012000\n---------------------------------------------------\nTotal Cost: $0.016395 (~$0.016 per request)\n</code></pre></p> <p>Monthly estimate (50 requests): ~$0.82</p>"},{"location":"usage/cost/#use-case-2-update-existing-file","title":"Use Case 2: Update Existing File","text":"<p>Scenario: \"Add logging to my script.py\"</p> <p>Token Breakdown: <pre><code>System Prompt:        850 tokens (input)\nTool Definitions:     600 tokens (input)\nUser Message:          20 tokens (input)\n---------------------------------------------------\nTool Call 1 - read_file:\n  Request:             50 tokens (input)\n  Response:         1,200 tokens (input, file contents)\n---------------------------------------------------\nTool Call 2 - write_file:\n  Request:            100 tokens (input)\n  Response:            30 tokens (input, success message)\n---------------------------------------------------\nAssistant Response:   600 tokens (output, explanation)\n---------------------------------------------------\nTotal Input:        3,450 tokens\nTotal Output:         600 tokens\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  3,450 / 1,000,000 \u00d7 $3  = $0.01035\nOutput:   600 / 1,000,000 \u00d7 $15 = $0.00900\n---------------------------------------------------\nTotal Cost: $0.01935 (~$0.019 per request)\n</code></pre></p> <p>Monthly estimate (30 updates): ~$0.58</p>"},{"location":"usage/cost/#use-case-3-execute-python-script","title":"Use Case 3: Execute Python Script","text":"<p>Scenario: \"Run my analysis.py script\"</p> <p>Token Breakdown: <pre><code>System Prompt:        850 tokens (input)\nTool Definitions:     600 tokens (input)\nUser Message:          12 tokens (input)\n---------------------------------------------------\nTool Call - execute_command:\n  Request:             80 tokens (input)\n  Response:         1,500 tokens (input, command output)\n---------------------------------------------------\nAssistant Response:   400 tokens (output, summary)\n---------------------------------------------------\nTotal Input:        3,042 tokens\nTotal Output:         400 tokens\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  3,042 / 1,000,000 \u00d7 $3  = $0.009126\nOutput:   400 / 1,000,000 \u00d7 $15 = $0.006000\n---------------------------------------------------\nTotal Cost: $0.015126 (~$0.015 per request)\n</code></pre></p> <p>Monthly estimate (20 executions): ~$0.30</p>"},{"location":"usage/cost/#use-case-4-complex-project-analysis","title":"Use Case 4: Complex Project Analysis","text":"<p>Scenario: \"Analyze my codebase and suggest improvements\"</p> <p>Token Breakdown: <pre><code>System Prompt:        850 tokens (input)\nTool Definitions:     600 tokens (input)\nUser Message:          25 tokens (input)\n---------------------------------------------------\nTool Call 1 - get_project_info:\n  Request:             60 tokens (input)\n  Response:           800 tokens (input, project summary)\n---------------------------------------------------\nTool Call 2 - list_files:\n  Request:             50 tokens (input)\n  Response:           300 tokens (input, file list)\n---------------------------------------------------\nTool Call 3 - read_file (main.py):\n  Request:             50 tokens (input)\n  Response:         2,500 tokens (input, file contents)\n---------------------------------------------------\nTool Call 4 - read_file (config.py):\n  Request:             50 tokens (input)\n  Response:         1,000 tokens (input, file contents)\n---------------------------------------------------\nAssistant Response: 1,800 tokens (output, detailed analysis)\n---------------------------------------------------\nTotal Input:        6,285 tokens\nTotal Output:       1,800 tokens\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  6,285 / 1,000,000 \u00d7 $3  = $0.018855\nOutput: 1,800 / 1,000,000 \u00d7 $15 = $0.027000\n---------------------------------------------------\nTotal Cost: $0.045855 (~$0.046 per request)\n</code></pre></p> <p>Monthly estimate (10 analyses): ~$0.46</p>"},{"location":"usage/cost/#use-case-5-uv-project-setup","title":"Use Case 5: UV Project Setup","text":"<p>Scenario: \"Initialize UV project and add dependencies\"</p> <p>Token Breakdown: <pre><code>System Prompt:        850 tokens (input)\nTool Definitions:     600 tokens (input)\nUser Message:          30 tokens (input)\n---------------------------------------------------\nTool Call 1 - execute_command (uv init):\n  Request:             80 tokens (input)\n  Response:           400 tokens (input, init output)\n---------------------------------------------------\nTool Call 2 - execute_command (uv add):\n  Request:             90 tokens (input)\n  Response:           600 tokens (input, package install output)\n---------------------------------------------------\nAssistant Response:   700 tokens (output, setup guide)\n---------------------------------------------------\nTotal Input:        3,350 tokens\nTotal Output:         700 tokens\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  3,350 / 1,000,000 \u00d7 $3  = $0.01005\nOutput:   700 / 1,000,000 \u00d7 $15 = $0.01050\n---------------------------------------------------\nTotal Cost: $0.02055 (~$0.021 per request)\n</code></pre></p> <p>Monthly estimate (5 setups): ~$0.11</p>"},{"location":"usage/cost/#use-case-6-web-search-weather-query-new-in-v0321","title":"Use Case 6: Web Search - Weather Query (NEW in v0.3.21)","text":"<p>Scenario: \"What's the weather in San Francisco?\"</p> <p>Token Breakdown: <pre><code>System Prompt:      1,000 tokens (input, includes web search guidelines)\nTool Definitions:   1,800 tokens (input, 20 tools)\nUser Message:          15 tokens (input)\n---------------------------------------------------\nWeb Search Call:\n  Request:             50 tokens (input)\n  Search Cost:         $0.01 (flat fee per search)\n  Response:           300 tokens (input, weather data from web)\n---------------------------------------------------\nAssistant Response:   250 tokens (output, formatted weather info)\n---------------------------------------------------\nTotal Input:        3,165 tokens\nTotal Output:         250 tokens\nWeb Search:         1 search\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  3,165 / 1,000,000 \u00d7 $3  = $0.009495\nOutput:   250 / 1,000,000 \u00d7 $15 = $0.003750\nWeb Search: 1 \u00d7 $0.01          = $0.010000\n---------------------------------------------------\nTotal Cost: $0.023245 (~$0.023 per weather query)\n</code></pre></p> <p>Monthly estimate (20 weather queries): ~$0.46</p> <p>Note: Session limit of 5 searches prevents excessive costs. Start new session if limit reached.</p>"},{"location":"usage/cost/#use-case-7-web-search-url-reading-new-in-v0321","title":"Use Case 7: Web Search - URL Reading (NEW in v0.3.21)","text":"<p>Scenario: \"Read this article: https://python.org/downloads/release/python-3130/\"</p> <p>Token Breakdown: <pre><code>System Prompt:      1,000 tokens (input)\nTool Definitions:   1,800 tokens (input)\nUser Message:          20 tokens (input)\n---------------------------------------------------\nWeb Search Call:\n  Request:             60 tokens (input)\n  Search Cost:         $0.01 (flat fee per search)\n  Response:         1,200 tokens (input, article content)\n---------------------------------------------------\nAssistant Response:   800 tokens (output, summary and analysis)\n---------------------------------------------------\nTotal Input:        4,080 tokens\nTotal Output:         800 tokens\nWeb Search:         1 search\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  4,080 / 1,000,000 \u00d7 $3  = $0.012240\nOutput:   800 / 1,000,000 \u00d7 $15 = $0.012000\nWeb Search: 1 \u00d7 $0.01          = $0.010000\n---------------------------------------------------\nTotal Cost: $0.034240 (~$0.034 per URL read)\n</code></pre></p> <p>Monthly estimate (10 URL reads): ~$0.34</p>"},{"location":"usage/cost/#use-case-8-web-search-latest-information-new-in-v0321","title":"Use Case 8: Web Search - Latest Information (NEW in v0.3.21)","text":"<p>Scenario: \"What's new in Python 3.13?\"</p> <p>Token Breakdown: <pre><code>System Prompt:      1,000 tokens (input)\nTool Definitions:   1,800 tokens (input)\nUser Message:          15 tokens (input)\n---------------------------------------------------\nWeb Search Call 1 (main query):\n  Request:             50 tokens (input)\n  Search Cost:         $0.01 (flat fee)\n  Response:           800 tokens (input, search results)\n---------------------------------------------------\nWeb Search Call 2 (follow-up for details):\n  Request:             50 tokens (input)\n  Search Cost:         $0.01 (flat fee)\n  Response:           600 tokens (input, additional details)\n---------------------------------------------------\nAssistant Response: 1,200 tokens (output, comprehensive summary)\n---------------------------------------------------\nTotal Input:        4,315 tokens\nTotal Output:       1,200 tokens\nWeb Searches:       2 searches\n</code></pre></p> <p>Cost Calculation: <pre><code>Input:  4,315 / 1,000,000 \u00d7 $3  = $0.012945\nOutput: 1,200 / 1,000,000 \u00d7 $15 = $0.018000\nWeb Searches: 2 \u00d7 $0.01        = $0.020000\n---------------------------------------------------\nTotal Cost: $0.050945 (~$0.051 per info query)\n</code></pre></p> <p>Monthly estimate (8 info queries): ~$0.41</p> <p>Note: Complex queries may use 1-2 searches. Simple queries typically use 1 search.</p>"},{"location":"usage/cost/#monthly-cost-estimates-by-usage-pattern","title":"\ud83d\udca1 Monthly Cost Estimates by Usage Pattern","text":""},{"location":"usage/cost/#light-user-10-20-requestsmonth","title":"Light User (10-20 requests/month)","text":"<p>Profile: Occasional quick scripts, simple code generation</p> <p>Estimated monthly cost: $0.20 - $0.40</p> <p>Breakdown: - 10 simple code generations: ~$0.16 - 5 file updates: ~$0.10 - 5 command executions: ~$0.08</p>"},{"location":"usage/cost/#regular-user-50-100-requestsmonth","title":"Regular User (50-100 requests/month)","text":"<p>Profile: Daily coding tasks, project maintenance</p> <p>Estimated monthly cost: $1.00 - $2.50</p> <p>Breakdown: - 30 code generations: ~$0.50 - 40 file updates: ~$0.80 - 20 command executions: ~$0.30 - 10 project analyses: ~$0.46</p>"},{"location":"usage/cost/#heavy-user-200-500-requestsmonth","title":"Heavy User (200-500 requests/month)","text":"<p>Profile: Primary coding assistant, extensive project work</p> <p>Estimated monthly cost: $5.00 - $15.00</p> <p>Breakdown: - 100 code generations: ~$1.60 - 150 file updates: ~$2.90 - 100 command executions: ~$1.50 - 50 project analyses: ~$2.30 - Complex multi-tool sessions: ~$5.00+</p>"},{"location":"usage/cost/#teamenterprise-1000-requestsmonth","title":"Team/Enterprise (1000+ requests/month)","text":"<p>Profile: Multiple developers, CI/CD integration</p> <p>Estimated monthly cost: $30.00 - $100.00+</p> <p>Considerations: - Shared API key across team - Automated workflows - Larger codebases (more tokens per file) - More complex operations</p>"},{"location":"usage/cost/#cost-optimization-strategies","title":"\ud83c\udfaf Cost Optimization Strategies","text":""},{"location":"usage/cost/#1-minimize-file-reads","title":"1. Minimize File Reads","text":"<p>Problem: Reading large files adds significant input tokens.</p> <p>Solution: <pre><code># Instead of: \"Read all my files and analyze them\"\n# Try: \"Analyze app.py only\"\n</code></pre></p> <p>Savings: Can reduce cost by 50-80% for large codebases</p>"},{"location":"usage/cost/#2-use-specific-requests","title":"2. Use Specific Requests","text":"<p>Problem: Vague requests trigger multiple tool calls.</p> <p>Before: <pre><code>\"Improve my project\"\n\u2192 Triggers: list_files, read_file (\u00d75), get_project_info\n\u2192 Cost: ~$0.06\n</code></pre></p> <p>After: <pre><code>\"Add error handling to app.py line 45\"\n\u2192 Triggers: read_file (\u00d71), write_file (\u00d71)\n\u2192 Cost: ~$0.02\n</code></pre></p> <p>Savings: ~66% cost reduction</p>"},{"location":"usage/cost/#3-batch-related-operations","title":"3. Batch Related Operations","text":"<p>Problem: Multiple separate sessions repeat system prompt/tool definitions.</p> <p>Instead of: <pre><code>Session 1: \"Create app.py\"         \u2192 $0.016\nSession 2: \"Create utils.py\"       \u2192 $0.016\nSession 3: \"Create config.py\"      \u2192 $0.016\nTotal: $0.048\n</code></pre></p> <p>Use: <pre><code>Session 1: \"Create app.py, utils.py, and config.py\"\nTotal: ~$0.025\n</code></pre></p> <p>Savings: ~48% cost reduction</p>"},{"location":"usage/cost/#4-limit-command-output","title":"4. Limit Command Output","text":"<p>Problem: Verbose command output increases tokens.</p> <p>Strategy: - Use command flags to limit output: <code>ls -1</code> instead of <code>ls -la</code> - Filter output in commands: <code>pytest -q</code> instead of <code>pytest -v</code> - Redirect stderr when not needed</p> <p>Savings: 20-40% on command execution costs</p>"},{"location":"usage/cost/#5-clear-conversation-history-periodically","title":"5. Clear Conversation History Periodically","text":"<p>Problem: Long conversation history increases context tokens (if implemented).</p> <p>Current: WYN360 stores history in memory but doesn't send full history yet.</p> <p>Future consideration: If conversation history is sent with each request, periodically restart CLI to clear history.</p>"},{"location":"usage/cost/#6-use-smaller-model-for-simple-tasks","title":"6. Use Smaller Model for Simple Tasks","text":"<p>Current: Uses <code>claude-sonnet-4-20250514</code> by default</p> <p>Alternative: Could add option for Claude Haiku for simple tasks: - Haiku pricing: ~$0.25 per million input tokens (88% cheaper) - Good for: Simple file operations, quick questions</p> <p>Command: <pre><code>wyn360 --model claude-haiku-3-5-20250304\n</code></pre></p> <p>Potential savings: 80-90% for simple operations</p>"},{"location":"usage/cost/#token-usage-tracking","title":"\ud83d\udcca Token Usage Tracking","text":""},{"location":"usage/cost/#method-1-check-anthropic-console","title":"Method 1: Check Anthropic Console","text":"<ol> <li>Visit: https://console.anthropic.com/</li> <li>Navigate to \"Usage\" tab</li> <li>View token usage by day/month</li> <li>Calculate costs using pricing table</li> </ol>"},{"location":"usage/cost/#method-2-api-response-headers-future-enhancement","title":"Method 2: API Response Headers (Future Enhancement)","text":"<p>Could add token tracking to WYN360:</p> <pre><code># Potential feature\nresult = await agent.chat(user_input)\nprint(f\"Tokens used - Input: {result.input_tokens}, Output: {result.output_tokens}\")\nprint(f\"Estimated cost: ${result.cost:.4f}\")\n</code></pre>"},{"location":"usage/cost/#method-3-estimate-from-response-length","title":"Method 3: Estimate from Response Length","text":"<p>Rough estimation: - 1 token \u2248 4 characters for English text - 1 token \u2248 0.75 words on average</p> <p>Example: <pre><code>response_length = len(response_text)\nestimated_output_tokens = response_length / 4\nestimated_cost = estimated_output_tokens / 1_000_000 * 15\n</code></pre></p>"},{"location":"usage/cost/#real-world-cost-examples","title":"\ud83d\udd0d Real-World Cost Examples","text":""},{"location":"usage/cost/#example-1-building-a-streamlit-app-full-session","title":"Example 1: Building a Streamlit App (Full Session)","text":"<p>Session transcript: <pre><code>1. \"Create a Streamlit data visualization app\"      \u2192 $0.016\n2. \"Add file upload functionality\"                   \u2192 $0.019\n3. \"Add CSV parsing with pandas\"                     \u2192 $0.018\n4. \"Add bar chart visualization\"                     \u2192 $0.020\n5. \"Run the app with streamlit run app.py\"          \u2192 $0.015\n-----------------------------------------------------------\nTotal session cost: $0.088\n</code></pre></p> <p>Result: Complete working app for less than 9 cents</p>"},{"location":"usage/cost/#example-2-debugging-session-10-interactions","title":"Example 2: Debugging Session (10 interactions)","text":"<p>Session transcript: <pre><code>1. \"Read my script.py and find the error\"           \u2192 $0.022\n2. \"The error is on line 45, fix it\"                \u2192 $0.019\n3. \"Run the script to test\"                          \u2192 $0.015\n4. \"Still getting error, read the full traceback\"   \u2192 $0.018\n5. \"Add try-except error handling\"                   \u2192 $0.021\n6. \"Run it again\"                                     \u2192 $0.015\n7. \"Add logging to debug the issue\"                  \u2192 $0.019\n8. \"Test with sample input\"                          \u2192 $0.017\n9. \"Perfect! Add unit tests\"                         \u2192 $0.023\n10. \"Run the tests\"                                   \u2192 $0.016\n-----------------------------------------------------------\nTotal session cost: $0.185\n</code></pre></p> <p>Result: Debugged and tested code for ~19 cents</p>"},{"location":"usage/cost/#example-3-monthly-developer-usage","title":"Example 3: Monthly Developer Usage","text":"<p>Typical month (60 sessions): <pre><code>Code generation:        30 sessions \u00d7 $0.016 = $0.48\nFile updates:           20 sessions \u00d7 $0.019 = $0.38\nCommand execution:      15 sessions \u00d7 $0.015 = $0.23\nProject analysis:        5 sessions \u00d7 $0.046 = $0.23\n-----------------------------------------------------------\nTotal monthly cost: $1.32\n</code></pre></p> <p>Comparison: - GitHub Copilot: $10/month (fixed) - WYN360 CLI: ~$1.32/month (usage-based) - Savings: ~$8.68/month (87% cheaper for typical usage)</p>"},{"location":"usage/cost/#cost-considerations","title":"\u26a0\ufe0f Cost Considerations","text":""},{"location":"usage/cost/#what-increases-costs","title":"What Increases Costs:","text":"<ol> <li>Large File Operations</li> <li>Reading files &gt;5,000 lines: +$0.01-0.05 per file</li> <li> <p>Reading multiple files: Multiplies costs</p> </li> <li> <p>Verbose Command Output</p> </li> <li>Long-running scripts with extensive output</li> <li> <p>Unfiltered logs and stack traces</p> </li> <li> <p>Complex Multi-Step Operations</p> </li> <li>Multiple tool calls per request</li> <li> <p>Iterative refinement (trial and error)</p> </li> <li> <p>Conversation Length</p> </li> <li>Future: If full conversation history is sent</li> <li>Currently: Minimal impact (history not sent to API)</li> </ol>"},{"location":"usage/cost/#what-keeps-costs-low","title":"What Keeps Costs Low:","text":"<ol> <li>Focused Requests</li> <li>Specific file operations</li> <li> <p>Clear, concise instructions</p> </li> <li> <p>Small Files</p> </li> <li>Scripts under 500 lines</li> <li> <p>Targeted changes</p> </li> <li> <p>Single-Shot Operations</p> </li> <li>Complete requirements in one message</li> <li>Avoid back-and-forth clarifications</li> </ol>"},{"location":"usage/cost/#controlling-response-length-max_tokens","title":"\u2699\ufe0f Controlling Response Length (max_tokens)","text":"<p>What is max_tokens?</p> <p>The <code>max_tokens</code> setting controls the maximum length of Claude's response. By default, WYN360 CLI is configured with <code>max_tokens: 4096</code>, which provides balanced responses for most use cases.</p> <p>How it Affects Cost:</p> <p>Higher <code>max_tokens</code> values allow longer responses but increase output token costs: - Output tokens cost $15 per million tokens (5\u00d7 more expensive than input tokens) - A response using 8,000 tokens costs $0.12 vs 4,000 tokens at $0.06 - Longer responses = higher costs per request</p> <p>Important: The <code>max_tokens</code> limit doesn't guarantee Claude will use all tokens\u2014it sets a ceiling. Claude typically uses only what's needed, but having a higher limit allows for longer responses when necessary.</p>"},{"location":"usage/cost/#view-current-configuration","title":"View Current Configuration","text":"<p>You can check your current <code>max_tokens</code> setting using the <code>/config</code> command:</p> <pre><code>wyn360\nYou: /config\n\n# Output shows:\nModel            claude-sonnet-4-20250514\nMax Tokens       4096  \u2190 Current limit\nTemperature      0.7\n</code></pre>"},{"location":"usage/cost/#how-to-change-max_tokens","title":"How to Change max_tokens","text":"<p>You have full control over <code>max_tokens</code> without updating the package. Choose one of these options:</p>"},{"location":"usage/cost/#option-1-globally-all-projects","title":"Option 1: Globally (All Projects)","text":"<p>Edit your user configuration file to apply the setting across all projects:</p> <pre><code># Edit user config\nnano ~/.wyn360/config.yaml\n\n# Change line:\nmax_tokens: 8192  # Or 16384, 32768, etc.\n</code></pre> <p>User Config Location: <code>~/.wyn360/config.yaml</code></p>"},{"location":"usage/cost/#option-2-per-project","title":"Option 2: Per Project","text":"<p>Override the setting for a specific project by creating/editing a project configuration:</p> <pre><code># Create/edit project config in your project root\nnano .wyn360.yaml\n\n# Add:\nmax_tokens: 16384\n</code></pre> <p>Project Config Location: <code>.wyn360.yaml</code> (in your project root directory)</p> <p>Note: Project config overrides user config, which overrides the default (4096).</p>"},{"location":"usage/cost/#recommended-values","title":"Recommended Values","text":"<p>Choose a <code>max_tokens</code> value based on your typical use case:</p> Value Use Case Cost Impact 4096 Default - balanced responses Baseline 8192 Longer explanations, more code ~2\u00d7 potential cost 16384 Very long responses, large file generation ~4\u00d7 potential cost 32768 Maximum for complex documentation ~8\u00d7 potential cost"},{"location":"usage/cost/#cost-examples","title":"Cost Examples","text":"<p>Example 1: Simple Code Generation (4096 tokens limit) <pre><code>Request: \"Create a FastAPI hello world app\"\nResponse: ~800 tokens\nCost: $0.012 (output only)\n</code></pre></p> <p>Example 2: With 8192 tokens limit <pre><code>Request: \"Create a FastAPI app with detailed explanations\"\nResponse: ~2,500 tokens\nCost: $0.0375 (output only) - 3\u00d7 more expensive\n</code></pre></p> <p>Example 3: With 16384 tokens limit <pre><code>Request: \"Generate complete FastAPI app with tests and docs\"\nResponse: ~6,000 tokens\nCost: $0.09 (output only) - 7.5\u00d7 more expensive\n</code></pre></p>"},{"location":"usage/cost/#best-practices","title":"Best Practices","text":"<ol> <li>Start with default (4096) - Suitable for 90% of use cases</li> <li>Increase for specific projects - Use project config (<code>.wyn360.yaml</code>) when you need longer responses</li> <li>Monitor with <code>/tokens</code> - Check actual usage to see if you're hitting limits</li> <li>Use <code>/clear</code> regularly - Reset conversation history to control input token costs</li> <li>Balance quality vs cost - Higher limits enable longer responses but cost more</li> </ol> <p>Note: Higher <code>max_tokens</code> values allow longer responses but cost more. Claude will use only what's needed, but setting a higher ceiling enables more comprehensive responses when required.</p>"},{"location":"usage/cost/#cost-comparison-with-alternatives","title":"\ud83d\udcb0 Cost Comparison with Alternatives","text":"Tool Pricing Model Typical Monthly Cost WYN360 CLI Pay-per-use $1-5 for regular users GitHub Copilot Fixed subscription $10/month Cursor IDE Fixed subscription $20/month ChatGPT Plus Fixed subscription $20/month Direct API Usage Pay-per-use $5-50+ (depending on usage) <p>WYN360 Advantages: - \u2705 Only pay for what you use - \u2705 No monthly commitment - \u2705 Transparent token usage - \u2705 Can be very cost-effective for light users - \u2705 Full control over model selection</p> <p>When WYN360 Might Cost More: - Heavy daily usage (200+ sessions/day) - Very large codebases (constant file reading) - Compared to flat-rate tools if you use heavily</p>"},{"location":"usage/cost/#summary","title":"\ud83d\udcdd Summary","text":""},{"location":"usage/cost/#key-takeaways","title":"Key Takeaways:","text":"<ol> <li>Average cost per request: $0.015 - $0.025</li> <li>Typical monthly cost: $1 - $5 for regular developers</li> <li>Most expensive operation: Reading large files</li> <li>Most economical: Simple code generation</li> <li>Optimization: Use specific requests, batch operations</li> </ol>"},{"location":"usage/cost/#cost-formula","title":"Cost Formula:","text":"<pre><code>Per Request Cost \u2248 Base ($0.0045) + Tool Calls ($0.003-0.015 each) + Response ($0.003-0.03)\n</code></pre>"},{"location":"usage/cost/#recommendation","title":"Recommendation:","text":"<p>For most developers, WYN360 CLI will cost $1-3 per month - significantly less than subscription-based alternatives while providing similar capabilities.</p>"},{"location":"usage/cost/#additional-resources","title":"\ud83d\udd17 Additional Resources","text":"<ul> <li>Anthropic Pricing: https://www.anthropic.com/pricing</li> <li>Usage Console: https://console.anthropic.com/</li> <li>WYN360 Documentation: USE_CASES.md</li> <li>Token Counting: https://platform.openai.com/tokenizer (similar to Claude)</li> </ul> <p>Last Updated: November 2025 Version: 0.3.23</p>"},{"location":"usage/use-cases/","title":"WYN360 CLI - Complete User Guide &amp; Use Cases","text":"<p>A comprehensive guide to WYN360 CLI - from simple to complex workflows</p> <p>Version: 0.3.23 Last Updated: November 2025 Maintained by: Yiqiao Yin (yiqiao.yin@wyn-associates.com)</p>"},{"location":"usage/use-cases/#part-1-introduction-getting-started","title":"Part 1: Introduction &amp; Getting Started","text":""},{"location":"usage/use-cases/#welcome-to-wyn360-cli","title":"Welcome to WYN360 CLI","text":"<p>WYN360 CLI is an AI-powered command-line assistant that helps you build, analyze, and manage Python projects through natural language conversations. This guide will walk you through everything from simple file operations to complex multi-turn development workflows.</p>"},{"location":"usage/use-cases/#quick-start-guide","title":"Quick Start Guide","text":"<p>Installation: <pre><code>pip install wyn360-cli\n</code></pre></p> <p>Set up your API key: <pre><code>export ANTHROPIC_API_KEY='your-key-here'\n</code></pre></p> <p>Launch WYN360: <pre><code>wyn360\n</code></pre></p> <p>Your first interaction: <pre><code>You: What files do I have?\nWYN360: [Lists all files in your directory]\n\nYou: Create a hello world Python script\nWYN360: [Generates and saves hello_world.py]\n</code></pre></p>"},{"location":"usage/use-cases/#how-to-read-this-document","title":"How to Read This Document","text":"<p>This guide is organized as a progressive learning path:</p> <ol> <li>Part 1 (This section) - Introduction and setup</li> <li>Part 2 - 18 use cases organized from simple to complex:</li> <li>Use Cases 1-9: Simple single-turn operations (file ops, git, search)</li> <li>Use Cases 10-11: Configuration and setup</li> <li>Use Cases 12-14: Deployment and integration</li> <li>Use Cases 15-16: Advanced features (performance, web search)</li> <li>Use Cases 17-18: Complex multi-turn workflows</li> <li>Part 3 - Appendices with reference materials</li> <li>Part 4 - Changelog and version history</li> </ol> <p>Reading Tips: - Beginners: Read sequentially from Use Case 1 - Intermediate users: Jump to use cases that match your needs - Advanced users: Check appendices for technical details - All users: Review \"Pro Tips\" and \"Learning Path\" sections</p>"},{"location":"usage/use-cases/#part-2-core-use-cases-1-18","title":"Part 2: Core Use Cases (1-18)","text":""},{"location":"usage/use-cases/#simple-single-turn-use-cases","title":"Simple Single-Turn Use Cases","text":""},{"location":"usage/use-cases/#use-case-1-start-new-projects-from-scratch","title":"Use Case 1: Start New Projects from Scratch","text":"<p>Complexity: Simple Type: Single-turn Best For: Rapid prototyping, learning, quick demos</p> <p>When you're in an empty directory and want to build something from scratch, WYN360 becomes your coding partner.</p> <p>How it works: - User describes what they want to build in natural language - Agent generates complete, runnable code - Automatically extracts code from responses using regex - Saves files with smart naming conventions</p> <p>Smart File Naming: - <code>app.py</code> - For Streamlit or FastAPI applications - <code>main.py</code> - For general scripts with main() functions - <code>script.py</code> - For simple utility scripts</p> <p>Example Interaction: <pre><code>You: Build a Streamlit chatbot that echoes user input\n\nWYN360:\n\u2713 Generates complete app.py with Streamlit code\n\u2713 Creates requirements.txt with dependencies\n\u2713 Provides setup and run instructions\n\u2713 Includes usage examples\n</code></pre></p> <p>Real-world scenarios: - Quick prototypes for demos - Learning new frameworks - Starting weekend projects - Creating utility scripts - Building proof-of-concepts</p>"},{"location":"usage/use-cases/#use-case-2-analyze-existing-projects","title":"Use Case 2: Analyze Existing Projects","text":"<p>Complexity: Simple Type: Single-turn Best For: Understanding codebases, code review, onboarding</p> <p>WYN360 can understand your existing codebase before making suggestions or changes.</p> <p>Analysis Capabilities: - Scans directory structure and categorizes files - Reads Python files, configs, and documentation - Understands project architecture and patterns - Identifies dependencies and relationships - Makes context-aware recommendations</p> <p>Available Analysis Tools:</p> Tool Function Use Case <code>list_files()</code> Inventory all files by category \"What files do I have?\" <code>read_file()</code> Read specific file contents \"Show me my config.py\" <code>get_project_info()</code> Generate comprehensive project summary \"Summarize my project structure\" <p>Example Interaction: <pre><code>You: What does my project do?\n\nWYN360:\n- Scans all files in the directory\n- Identifies main entry points\n- Reads configuration files\n- Analyzes dependencies\n- Provides comprehensive summary\n</code></pre></p> <p>File Categorization: - Python files (<code>.py</code>) - Source code - Text files (<code>.md</code>, <code>.txt</code>, <code>.rst</code>) - Documentation - Config files (<code>.json</code>, <code>.yaml</code>, <code>.toml</code>, <code>.ini</code>) - Configuration - Other files - Resources, data, etc.</p>"},{"location":"usage/use-cases/#use-case-3-code-generation-refactoring","title":"Use Case 3: Code Generation &amp; Refactoring","text":"<p>Complexity: Simple to Moderate Type: Single-turn Best For: Writing new code, improving existing code, documentation</p> <p>Write high-quality Python code or improve existing code.</p> <p>Code Generation Features: - Production-ready code with error handling - Comprehensive docstrings and comments - Type hints and annotations - Best practices and design patterns - Unit test suggestions</p> <p>Refactoring Capabilities: - Improve code structure - Add documentation - Optimize performance - Enhance readability - Apply design patterns</p> <p>Quality Standards: - Follows PEP 8 style guidelines - Includes proper error handling - Uses meaningful variable names - Provides clear documentation - Considers edge cases</p> <p>Example Interaction: <pre><code>You: Refactor my data processing script to use async\n\nWYN360:\n- Analyzes current synchronous code\n- Identifies I/O-bound operations\n- Converts to async/await patterns\n- Adds proper exception handling\n- Includes usage examples\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-4-execute-commands-and-scripts","title":"Use Case 4: Execute Commands and Scripts","text":"<p>Complexity: Simple Type: Single-turn Best For: Running scripts, package management, testing Version: NEW in v0.2.2</p> <p>Run any shell command, Python script, or CLI tool directly through WYN360 with built-in safety confirmations.</p> <p>Capabilities: - Execute Python scripts - Run UV commands for package management - Start Streamlit/FastAPI applications - Execute shell scripts - Run any CLI tool (npm, docker, git, etc.) - Built-in timeout protection (5 minutes default) - User confirmation before execution</p> <p>Supported Command Types:</p> Command Type Example Use Case Python Scripts <code>python run_analysis.py</code> Run data analysis scripts UV Package Manager <code>uv init project</code>, <code>uv add torch</code> Initialize projects, install packages UV Run <code>uv run streamlit run app.py</code> Run apps in UV environments Shell Scripts <code>bash setup.sh</code> Execute automation scripts Any CLI Tool <code>npm install</code>, <code>docker ps</code> Use any command-line tool <p>Safety Features: - \u26a0\ufe0f Confirmation prompt before execution - \u23f1\ufe0f Automatic timeout after 5 minutes (configurable) - \ud83d\udcdd Captures both stdout and stderr - \u2705 Shows exit codes and success status - \ud83d\udd12 Runs with user's permissions in current directory</p> <p>Example Interaction: <pre><code>You: Run the adult.py analysis script\n\nWYN360: [Prepares to execute]\n\n======================================================================\n\u26a0\ufe0f  COMMAND EXECUTION CONFIRMATION\n======================================================================\nCommand: python adult.py\nDirectory: /your/working/directory\nPermissions: Full user permissions\n======================================================================\n\n&gt;&gt;&gt; WAITING FOR YOUR RESPONSE &lt;&lt;&lt;\n\nExecute this command? (y/N): y\n\n\u2705 Command executed successfully (exit code 0)\n\nOutput:\nLoading Adult dataset...\nPreprocessing data...\nTraining model...\nAccuracy: 0.85\nResults saved to results.csv\n</code></pre></p> <p>Bypass Confirmation (For Testing): Set environment variable <code>WYN360_SKIP_CONFIRM=1</code> to skip confirmation prompts.</p>"},{"location":"usage/use-cases/#use-case-5-multi-line-input-support","title":"Use Case 5: Multi-line Input Support","text":"<p>Complexity: Simple Type: Feature Best For: Complex prompts, code pasting, detailed instructions Version: NEW in v0.2.2</p> <p>Write complex, multi-line prompts with ease using keyboard shortcuts.</p> <p>How it works: - Enter \u2192 Submit your message - Ctrl+Enter \u2192 Add a new line (continue typing)</p> <p>Example: <pre><code>You: [Ctrl+Enter for each line]\nCreate a Streamlit app that:\n1. Loads a CSV file\n2. Shows summary statistics\n3. Displays interactive charts\n4. Allows filtering by columns\n[Press Enter to submit]\n\nWYN360: [Generates complete multi-featured app]\n</code></pre></p> <p>Why it's useful: - Write detailed, structured prompts - Paste code with proper formatting - Create multi-step instructions - Format lists and requirements clearly</p>"},{"location":"usage/use-cases/#use-case-6-git-operations","title":"Use Case 6: Git Operations","text":"<p>Complexity: Simple Type: Single-turn Best For: Version control, reviewing changes Version: NEW in v0.2.9</p> <p>WYN360 can now interact with git repositories to help you manage version control.</p> <p>Example Interaction: <pre><code>You: What files have I changed?\n\nWYN360: [Calls git_status tool]\nGit Status:\n\nOn branch main\nChanges not staged for commit:\n  modified:   agent.py\n  modified:   tests/test_agent.py\n\nUntracked files:\n  new_feature.py\n</code></pre></p> <p>Available Git Operations:</p> Command Tool Use Case \"Show git status\" <code>git_status()</code> See modified and untracked files \"What changed in agent.py?\" <code>git_diff(file_path)</code> View specific file changes \"Show recent commits\" <code>git_log(max_count)</code> Review commit history \"What branch am I on?\" <code>git_branch()</code> List all branches <p>Real-world scenarios: <pre><code>You: Show me what changed in my last session\nWYN360: [Shows git diff output with line-by-line changes]\n\nYou: Show the last 5 commits\nWYN360: [Displays commit history with messages and SHAs]\n\nYou: What branch am I working on?\nWYN360: [Shows current branch marked with *]\n</code></pre></p> <p>Benefits: - \u2705 Quick status checks without leaving the CLI - \u2705 Review changes before committing - \u2705 Understand project history - \u2705 Stay oriented in your git workflow</p>"},{"location":"usage/use-cases/#use-case-7-code-search","title":"Use Case 7: Code Search","text":"<p>Complexity: Simple Type: Single-turn Best For: Finding code patterns, definitions, usage Version: NEW in v0.2.9</p> <p>Find code patterns, definitions, and usage across your entire project.</p> <p>Example Interaction: <pre><code>You: Where is the User class defined?\n\nWYN360: [Calls search_files(\"class User\", \"*.py\")]\nSearch Results for 'class User' in *.py:\n\n./models/user.py:15:class User(BaseModel):\n./tests/test_models.py:8:class UserTest(unittest.TestCase):\n</code></pre></p> <p>Search Capabilities:</p> Query Tool Call Result \"Find all TODO comments\" <code>search_files(\"TODO\", \"*.py\")</code> Lists files and line numbers \"Where do I import requests?\" <code>search_files(\"import requests\")</code> Shows all import statements \"Find database connections\" <code>search_files(\"connect\", \"*.py\")</code> Locates connection code \"Show all API endpoints\" <code>search_files(\"@app.route\")</code> Lists Flask/FastAPI routes <p>Advanced Search Examples: <pre><code>You: Find all functions that use the requests library\nWYN360: [Searches for 'requests.' across Python files]\nFound 12 matches across 4 files\n\nYou: Show me all error logging statements\nWYN360: [Searches for 'logger.error' or 'logging.error']\nLocated error handling in 8 different locations\n\nYou: Where are environment variables used?\nWYN360: [Searches for 'os.getenv' and 'os.environ']\nEnvironment variables accessed in config.py and utils.py\n</code></pre></p> <p>Search Features: - \u2705 Regex pattern support - \u2705 File type filtering (.py, .txt, etc.) - \u2705 Line numbers for easy navigation - \u2705 Smart truncation (shows first 100 matches) - \u2705 Case-insensitive searching</p>"},{"location":"usage/use-cases/#use-case-8-file-management","title":"Use Case 8: File Management","text":"<p>Complexity: Simple Type: Single-turn Best For: Project organization, cleanup, restructuring Version: NEW in v0.2.9</p> <p>Complete file system operations for organizing your project.</p> <p>Delete Files: <pre><code>You: Delete the old_script.py file\n\nWYN360: [Calls delete_file(\"old_script.py\")]\n\u2713 Successfully deleted file: old_script.py\n</code></pre></p> <p>Move/Rename Files: <pre><code>You: Rename utils.py to helpers.py\n\nWYN360: [Calls move_file(\"utils.py\", \"helpers.py\")]\n\u2713 Successfully moved 'utils.py' to 'helpers.py'\n\nYou: Move config.py to the src directory\n\nWYN360: [Calls move_file(\"config.py\", \"src/config.py\")]\n\u2713 Successfully moved 'config.py' to 'src/config.py'\n</code></pre></p> <p>Create Directories: <pre><code>You: Create a tests directory\n\nWYN360: [Calls create_directory(\"tests\")]\n\u2713 Successfully created directory: tests\n\nYou: Create nested directories src/utils/helpers\n\nWYN360: [Calls create_directory(\"src/utils/helpers\")]\n\u2713 Successfully created directory: src/utils/helpers\n</code></pre></p> <p>Project Reorganization Workflow: <pre><code>You: I want to reorganize my project. Create src, tests, and docs directories\n\nWYN360:\n[Creates src directory]\n\u2713 Successfully created directory: src\n\n[Creates tests directory]\n\u2713 Successfully created directory: tests\n\n[Creates docs directory]\n\u2713 Successfully created directory: docs\n\nYour project structure is now organized with src/, tests/, and docs/ directories.\n\nYou: Move all .py files except tests to src\n\nWYN360:\n[Moves files one by one, preserving structure]\n\u2713 Successfully moved 'app.py' to 'src/app.py'\n\u2713 Successfully moved 'utils.py' to 'src/utils.py'\n\u2713 Successfully moved 'config.py' to 'src/config.py'\n</code></pre></p> <p>Safety Features: - \u26a0\ufe0f Delete operations are irreversible - use with caution - \u2705 Move operations create parent directories automatically - \u2705 Prevents overwriting existing files - \u2705 Clear error messages for permission issues</p>"},{"location":"usage/use-cases/#use-case-9-model-selection-optimization","title":"Use Case 9: Model Selection &amp; Optimization","text":"<p>Complexity: Moderate Type: Configuration Best For: Cost optimization, performance tuning Version: NEW in v0.3.0</p> <p>Choose the right AI model for your task to optimize cost and performance.</p> <p>Available Models:</p> Model Speed Cost Best For Haiku Fastest Cheapest ($0.25/$1.25 per M) Simple file ops, quick questions Sonnet Balanced Moderate ($3/$15 per M) General coding, analysis (default) Opus Slower Premium ($15/$75 per M) Complex reasoning, architecture <p>Viewing Current Model: <pre><code>You: /model\n\n[Model Information Table]\nModel: Sonnet 4\nFull ID: claude-sonnet-4-20250514\nDescription: Balanced performance - general coding &amp; analysis\nInput Cost: $3.00/M tokens\nOutput Cost: $15.00/M tokens\n\nAvailable models: haiku, sonnet, opus\nUsage: /model &lt;name&gt;  (e.g., /model haiku)\n</code></pre></p> <p>Switching Models Mid-Session: <pre><code>You: /model haiku\n\u2713 Switched to Haiku (claude-3-5-haiku-20241022)\n\nYou: List all Python files in this directory\nWYN360: [Uses Haiku - fast and cheap for simple task]\n\nYou: /model opus\n\u2713 Switched to Opus 4 (claude-opus-4-20250514)\n\nYou: Refactor my entire application architecture\nWYN360: [Uses Opus - most capable for complex reasoning]\n</code></pre></p> <p>Cost Optimization Strategies:</p> <p>Strategy 1: Start with Haiku, upgrade as needed <pre><code>You: /model haiku\n\nYou: Show me the files in this project\nWYN360: [Haiku handles this easily - saves money]\n\nYou: Now help me redesign the database schema\nYou: /model opus\n\nWYN360: [Switches to Opus for complex architectural decision]\n</code></pre></p> <p>Strategy 2: Use Sonnet for most work, Haiku for repetitive tasks <pre><code>You: /model sonnet\n\nYou: Add error handling to api.py\nWYN360: [Sonnet provides good code quality]\n\nYou: /model haiku\n\nYou: Run git status\nYou: List files in tests directory\nYou: Show me config.json\nWYN360: [Haiku handles these simple operations cheaply]\n</code></pre></p> <p>Strategy 3: Model selection by session type</p> <p>Exploration sessions (Haiku): - Understanding new codebase - Reading files - Running git commands - Simple searches</p> <p>Development sessions (Sonnet - default): - Writing new features - Refactoring code - Debugging issues - General coding</p> <p>Architecture sessions (Opus): - System design - Complex refactoring - Performance optimization - Critical bug fixes</p> <p>Real-World Cost Comparison:</p> <pre><code>Scenario: Adding a new feature (10 interactions)\n\nWith Haiku only:\n  - 15K input tokens \u00d7 $0.25/M = $0.004\n  - 8K output tokens \u00d7 $1.25/M = $0.010\n  - Total: $0.014\n\nWith Sonnet (default):\n  - 15K input tokens \u00d7 $3.00/M = $0.045\n  - 8K output tokens \u00d7 $15.00/M = $0.120\n  - Total: $0.165\n\nWith Opus:\n  - 15K input tokens \u00d7 $15.00/M = $0.225\n  - 8K output tokens \u00d7 $75.00/M = $0.600\n  - Total: $0.825\n\nOptimized (mixed):\n  - 3 simple tasks with Haiku: $0.004\n  - 5 coding tasks with Sonnet: $0.083\n  - 2 complex tasks with Opus: $0.165\n  - Total: $0.252 (saves 69% vs all Opus, better quality than all Haiku)\n</code></pre> <p>Command-Line Model Selection:</p> <p>You can also set the model when starting WYN360: <pre><code># Start with Haiku for quick tasks\nwyn360 --model haiku\n\n# Start with Opus for complex work\nwyn360 --model opus\n\n# Use full model ID\nwyn360 --model claude-sonnet-4-20250514\n</code></pre></p> <p>Pro Tips: - \u2705 Use <code>/model</code> without arguments to check current model and costs - \u2705 Switch models freely - conversation history is preserved - \u2705 Start sessions with cheaper models, upgrade when needed - \u2705 Use Haiku for file operations and git commands - \u2705 Use Opus sparingly for genuinely complex architectural decisions - \u2705 Monitor costs with <code>/tokens</code> command - \u26a0\ufe0f Model switches only affect future requests, not past ones</p>"},{"location":"usage/use-cases/#configuration-setup","title":"Configuration &amp; Setup","text":""},{"location":"usage/use-cases/#use-case-10-configuration-personalization","title":"Use Case 10: Configuration &amp; Personalization","text":"<p>Complexity: Moderate Type: Setup/Configuration Best For: Team collaboration, personal preferences, project-specific context Version: NEW in v0.3.1</p> <p>Problem: Every developer has different preferences and every project has unique requirements. Repeating instructions manually is tedious.</p> <p>Solution: WYN360 supports two levels of configuration: 1. User Config (<code>~/.wyn360/config.yaml</code>) - Your personal preferences across all projects 2. Project Config (<code>.wyn360.yaml</code>) - Project-specific settings and context</p>"},{"location":"usage/use-cases/#configuration-levels","title":"Configuration Levels","text":""},{"location":"usage/use-cases/#user-configuration-wyn360configyaml","title":"User Configuration (~/.wyn360/config.yaml)","text":"<pre><code># Personal preferences that apply to all projects\nmodel: claude-sonnet-4-20250514\nmax_tokens: 4096\ntemperature: 0.7\n\n# Custom instructions for all your work\ncustom_instructions: |\n  - Always use type hints in Python\n  - Follow PEP 8 style guidelines\n  - Add comprehensive docstrings\n  - Include error handling\n\n# Quick command aliases\naliases:\n  test: \"run pytest tests/ -v\"\n  lint: \"run ruff check .\"\n  format: \"run ruff format .\"\n\n# Your workspace directories\nworkspaces:\n  - ~/projects\n  - ~/work\n</code></pre>"},{"location":"usage/use-cases/#project-configuration-wyn360yaml","title":"Project Configuration (.wyn360.yaml)","text":"<pre><code># Project-specific context - helps AI understand your codebase\ncontext: |\n  This is a FastAPI web application with:\n  - PostgreSQL database (SQLAlchemy ORM)\n  - Redis for caching and session management\n  - Celery for background tasks\n  - JWT authentication\n  - RESTful API design\n\n# Key dependencies\ndependencies:\n  - fastapi\n  - sqlalchemy\n  - redis\n  - celery\n  - pyjwt\n\n# Common project commands\ncommands:\n  dev: \"uvicorn app.main:app --reload\"\n  test: \"pytest tests/ -v --cov\"\n  migrate: \"alembic upgrade head\"\n\n# Override model for this project (optional)\nmodel: claude-3-5-haiku-20241022  # Use faster model for simple project\n</code></pre>"},{"location":"usage/use-cases/#configuration-priority","title":"Configuration Priority","text":"<p>Configurations merge with this precedence (highest to lowest): 1. Project config (<code>.wyn360.yaml</code> in current directory) 2. User config (<code>~/.wyn360/config.yaml</code>) 3. Default values</p>"},{"location":"usage/use-cases/#example-workflows","title":"Example Workflows","text":""},{"location":"usage/use-cases/#workflow-1-setting-up-user-preferences","title":"Workflow 1: Setting Up User Preferences","text":"<pre><code># First time setup - create default user config\n$ wyn360\n\nWYN360:\nNo user config found. Create one with:\n~/.wyn360/config.yaml\n\n# After creating config:\n$ wyn360\n\n\u2022 Loaded user config from: /home/user/.wyn360/config.yaml\n\u2022 Custom instructions loaded\n\u2713 Connected using model: claude-sonnet-4-20250514\n</code></pre>"},{"location":"usage/use-cases/#workflow-2-project-specific-context","title":"Workflow 2: Project-Specific Context","text":"<pre><code># Create .wyn360.yaml in your project root\ncontext: |\n  This is a machine learning project that:\n  - Trains sentiment analysis models\n  - Uses PyTorch and Hugging Face Transformers\n  - Processes large text datasets\n  - Requires GPU for training\n\ndependencies:\n  - pytorch\n  - transformers\n  - datasets\n  - scikit-learn\n\ncommands:\n  train: \"python train.py --config config.yaml\"\n  evaluate: \"python evaluate.py --model checkpoints/best\"\n</code></pre> <p>When you run wyn360 in this directory: <pre><code>$ wyn360\n\n\u2022 Loaded user config from: ~/.wyn360/config.yaml\n\u2022 Loaded project config from: .wyn360.yaml\n\u2022 Custom instructions loaded\n\u2022 Project context loaded\n\u2713 Connected using model: claude-sonnet-4-20250514\n\nYou: Help me implement a new transformer model\n\nWYN360: I see you're working on a sentiment analysis project with PyTorch\nand Transformers. Let me help you implement a new model that integrates with\nyour existing training pipeline...\n[AI now understands your project context automatically!]\n</code></pre></p>"},{"location":"usage/use-cases/#workflow-3-viewing-current-configuration","title":"Workflow 3: Viewing Current Configuration","text":"<pre><code>You: /config\n\nCurrent Configuration\n\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\nModel                   claude-sonnet-4-20250514\nMax Tokens              4096\nTemperature             0.7\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nUser Config             ~/.wyn360/config.yaml\nProject Config          .wyn360.yaml\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nCustom Instructions     - Always use type hints...\nProject Context         This is a FastAPI project...\nDependencies            fastapi, sqlalchemy, redis (+2 more)\nAliases                 test, lint, format\n\nTip: Create ~/.wyn360/config.yaml for user settings\nTip: Create .wyn360.yaml in project root for project settings\n</code></pre>"},{"location":"usage/use-cases/#benefits","title":"Benefits","text":"<p>1. Consistency Across Projects - Same code style and conventions everywhere - No need to repeat preferences</p> <p>2. Team Collaboration - Share <code>.wyn360.yaml</code> in git repo - Everyone gets same project context - New team members onboard faster</p> <p>3. Project-Specific Intelligence - AI understands your tech stack - More relevant code suggestions - Better architecture decisions</p> <p>4. Time Savings - No repeating \"use type hints\" every time - No explaining project structure repeatedly - Quick command aliases</p>"},{"location":"usage/use-cases/#real-world-example","title":"Real-World Example","text":"<p>Scenario: You're a Python developer who always uses type hints and works on multiple projects (FastAPI, Django, ML).</p> <p>Setup:</p> <ol> <li> <p>User Config (<code>~/.wyn360/config.yaml</code>): <pre><code>custom_instructions: |\n  - Always use type hints\n  - Add docstrings to all functions\n  - Follow PEP 8\n  - Prefer pathlib over os.path\n\naliases:\n  test: \"run pytest tests/ -v\"\n  lint: \"run ruff check .\"\n</code></pre></p> </li> <li> <p>FastAPI Project (<code>.wyn360.yaml</code>): <pre><code>context: |\n  FastAPI REST API with PostgreSQL\ndependencies: [fastapi, sqlalchemy, pydantic]\ncommands:\n  dev: \"uvicorn app:app --reload\"\n</code></pre></p> </li> <li> <p>ML Project (<code>.wyn360.yaml</code>): <pre><code>context: |\n  PyTorch deep learning project\ndependencies: [torch, transformers, scikit-learn]\ncommands:\n  train: \"python train.py\"\nmodel: claude-sonnet-4-20250514  # Use more capable model\n</code></pre></p> </li> </ol> <p>Result: When you work in the FastAPI project, the AI knows about FastAPI and REST APIs. When you switch to the ML project, it knows about PyTorch and transformers. Both use your personal preferences (type hints, docstrings, etc.).</p>"},{"location":"usage/use-cases/#tips","title":"Tips","text":"<p>Best Practices: 1. \u2705 Keep user config for personal preferences 2. \u2705 Keep project config for project-specific context 3. \u2705 Commit <code>.wyn360.yaml</code> to git (helps team) 4. \u2705 Use project config to specify tech stack 5. \u274c Don't put API keys in config files 6. \u274c Don't make configs too verbose</p> <p>Pro Tips: - Use <code>/config</code> command to verify your settings - Use project config for complex projects (5+ files) - Update project context as your project evolves - Share project config in README for team alignment</p>"},{"location":"usage/use-cases/#use-case-11-streaming-responses","title":"Use Case 11: Streaming Responses","text":"<p>Complexity: Simple Type: Feature Best For: Better UX, long responses, real-time feedback Version: NEW in v0.3.2</p> <p>Problem: Waiting for entire responses can feel slow, especially for long code generations or explanations. Users want immediate feedback.</p> <p>Solution: WYN360 now streams responses token-by-token as they're generated, providing instant visual feedback and a more responsive experience.</p>"},{"location":"usage/use-cases/#before-streaming-old-behavior","title":"Before Streaming (Old Behavior)","text":"<pre><code>You: Generate a large Python script for data analysis\n\n[Spinner animation for 10-15 seconds]\n\nWYN360: [Entire response appears at once after waiting]\n</code></pre> <p>User Experience: - \u274c Long wait with no feedback - \u274c Feels slow and unresponsive - \u274c Can't see progress - \u274c Can't start reading early parts</p>"},{"location":"usage/use-cases/#after-streaming-new-behavior","title":"After Streaming (New Behavior)","text":"<pre><code>You: Generate a large Python script for data analysis\n\nWYN360: I'll create a comprehensive data analysis script...\n\n[Text appears word-by-word as it's generated]\n</code></pre> <p>Let me build this step by step:</p> <ol> <li>First, import the necessary libraries:</li> </ol> <pre><code>import pandas as pd\n</code></pre> <p>User Experience: - \u2705 Immediate feedback - \u2705 Feels fast and responsive - \u2705 See progress in real-time - \u2705 Start reading while streaming</p>"},{"location":"usage/use-cases/#benefits_1","title":"Benefits","text":"<p>1. Faster Perceived Response Time - Even though total time is the same, streaming feels much faster - Immediate feedback creates sense of progress - Similar to ChatGPT's streaming experience</p> <p>2. Better UX for Long Responses - Start reading documentation while it generates - Review code as it appears - Understand context before completion</p> <p>3. Transparency - See exactly what the AI is generating - Can stop if going in wrong direction - Better sense of AI \"thinking\" process</p>"},{"location":"usage/use-cases/#example-workflows_1","title":"Example Workflows","text":""},{"location":"usage/use-cases/#workflow-1-long-code-generation","title":"Workflow 1: Long Code Generation","text":"<pre><code>You: Create a FastAPI application with authentication, database models,\n     and CRUD endpoints for a blog system\n\nWYN360: I'll create a complete FastAPI blog application...\n\nLet me structure this into several files:\n\n1. **app/main.py** - Main application entry point\n```python\nfrom fastapi import FastAPI, Depends\nfrom fastapi.security import OAuth2PasswordBearer\n...\n[Code streams in real-time]\n</code></pre> <ol> <li>app/models.py - Database models ... [Continues streaming] <pre><code>**Experience:** You can start reading the main.py code while models.py is still being generated.\n\n#### Workflow 2: Documentation and Explanations\n</code></pre> You: Explain how asyncio works in Python with examples</li> </ol> <p>WYN360: Asyncio is Python's library for writing concurrent code...</p> <p>[Explanation streams word-by-word]</p> <p>Here's how it works:</p> <ol> <li>Event Loop: The core of asyncio...</li> <li>Coroutines: Functions defined with async def...</li> <li>Tasks: Wrapped coroutines that run concurrently...</li> </ol> <p>[You can read section 1 while sections 2-3 are still generating] <pre><code>#### Workflow 3: Large Script Generation\n\n**Before (Non-Streaming):**\n</code></pre> You: Generate a comprehensive data pipeline script</p> <p>[Wait 15 seconds with spinner]</p> <p>WYN360: [500 lines of code appear instantly][Overwhelming - hard to parse all at once] <pre><code>**After (Streaming):**\n```bash\nYou: Generate a comprehensive data pipeline script\n\nWYN360: I'll create a data pipeline with these components:\n[Starts streaming immediately]\n\n# Step 1: Data ingestion\n[Code appears line-by-line]\n\n# Step 2: Data transformation\n[Code continues streaming]\n\n# Step 3: Data validation\n[More code streams in]\n\n[You're already reading Step 1 while Step 3 is being generated]\n</code></pre></p>"},{"location":"usage/use-cases/#technical-details","title":"Technical Details","text":"<p>How It Works: - Uses pydantic-ai's streaming API - Tokens are yielded as they're generated by Claude - Rich console displays them immediately - Full response is accumulated for history</p> <p>Performance: - No slowdown: Streaming adds no latency - Same total time: Response completes at same time - Better perception: Feels 2-3x faster due to immediate feedback</p>"},{"location":"usage/use-cases/#comparison","title":"Comparison","text":"Aspect Non-Streaming Streaming First Token 10-15s wait Instant Perceived Speed Slow Fast Reading Start After completion Immediately Progress Feedback None Real-time User Experience Waiting Engaging"},{"location":"usage/use-cases/#use-cases-where-streaming-shines","title":"Use Cases Where Streaming Shines","text":"<p>1. Documentation Generation <pre><code>You: Document this module with detailed docstrings\n\nWYN360: [Streams documentation as it writes]\n# You can read early functions while later ones generate\n</code></pre></p> <p>2. Code Refactoring <pre><code>You: Refactor this 500-line script\n\nWYN360: [Shows refactored code streaming]\n# Review changes as they happen, not all at once\n</code></pre></p> <p>3. Explanations and Tutorials <pre><code>You: Explain design patterns with examples\n\nWYN360: [Explanation streams naturally]\n# Read and understand each pattern before next one generates\n</code></pre></p> <p>4. Large File Generation <pre><code>You: Create a complete API client with all endpoints\n\nWYN360: [Streams code file by file]\n# Start planning implementation while rest generates\n</code></pre></p>"},{"location":"usage/use-cases/#tips_1","title":"Tips","text":"<p>Pro Tips: - Streaming is automatic - no configuration needed - Works for all response types (code, text, explanations) - Conversation history is preserved normally - Same quality as non-streaming responses</p>"},{"location":"usage/use-cases/#deployment-integration","title":"Deployment &amp; Integration","text":""},{"location":"usage/use-cases/#use-case-12-huggingface-deployment","title":"Use Case 12: HuggingFace Deployment","text":"<p>Complexity: Moderate Type: Deployment Best For: Sharing apps, demos, public deployment Version: v0.3.16 (Phase 1), v0.3.17 (Phase 2 - Full Deployment)</p> <p>Deploy Streamlit or Gradio applications to HuggingFace Spaces with automatic setup and authentication.</p> <p>Phase 1: Authentication (v0.3.16) - Check HuggingFace CLI authentication status - Authenticate with HuggingFace using access token - Generate README.md with Space configuration</p> <p>Phase 2: Full Deployment (v0.3.17) - Create HuggingFace Space repository via CLI - Upload files to HuggingFace Space automatically - Complete end-to-end deployment automation</p> <p>Available Tools:</p> Tool Purpose Version <code>check_hf_authentication()</code> Check authentication status v0.3.16 <code>authenticate_hf(token)</code> Authenticate with HF token v0.3.16 <code>create_hf_readme()</code> Generate Space README v0.3.16 <code>create_hf_space(name, type)</code> Create Space repository v0.3.17 <code>push_to_hf_space(space_name)</code> Upload files to Space v0.3.17 <p>Example Workflow:</p> <pre><code># Step 1: Build your app\nYou: Create a Streamlit chatbot app\n\nWYN360: [Generates app.py with chatbot code]\n\u2713 Created app.py\n\n# Step 2: Deploy to HuggingFace\nYou: Deploy this to HuggingFace\n\nWYN360: I'll help you deploy to HuggingFace Spaces.\n\n[Checks authentication]\nNot authenticated with HuggingFace. Please provide your token.\n\nYou: [Provides HF token]\n\nWYN360:\n\u2713 Authenticated with HuggingFace as 'username'\n\n[Creates Space]\n\u2713 Created Space: username/chatbot-demo\n\n[Generates README.md with Space config]\n\u2713 Created README.md with Space configuration\n\n[Pushes files to Space]\n\u2713 Uploaded app.py to Space\n\u2713 Uploaded requirements.txt to Space\n\n\ud83d\ude80 Your app is now live at:\nhttps://huggingface.co/spaces/username/chatbot-demo\n</code></pre> <p>Authentication: <pre><code># Set token in environment (recommended)\nexport HF_TOKEN=\"hf_your_token_here\"\n\n# Or provide when prompted\nYou: Authenticate with huggingface\n\nWYN360: Please provide your HuggingFace token...\nYou: hf_abc123xyz...\n\nWYN360: \u2713 Authenticated successfully\n</code></pre></p> <p>Space Configuration (README.md): <pre><code>---\ntitle: My Chatbot\nemoji: \ud83e\udd16\ncolorFrom: blue\ncolorTo: purple\nsdk: streamlit\nsdk_version: 1.28.0\napp_file: app.py\npinned: false\n---\n```yaml\n\n**Supported SDKs:**\n- Streamlit\n- Gradio\n- Static (HTML/CSS/JS)\n\n**Benefits:**\n- \u2705 One-command deployment\n- \u2705 Automatic authentication\n- \u2705 README generation\n- \u2705 Public URL instantly\n- \u2705 No manual git operations needed\n\n---\n\n### Use Case 13: Automatic Test Generation\n\n**Complexity:** Moderate\n**Type:** Testing/Quality Assurance\n**Best For:** TDD, code coverage, test scaffolding\n**Version:** NEW in v0.3.18 (Phase 7.2)\n\n**Feature:** Automatically generate pytest test stubs for Python files\n\nAutomatically generate pytest test scaffolding for your Python code using AST parsing.\n\n**How it works:**\n- Analyzes Python files using Abstract Syntax Tree (AST) parsing\n- Identifies functions and classes\n- Generates test stubs with TODO markers\n- Creates proper pytest structure\n- Safe code analysis without execution\n\n**Example Interaction:**\n</code></pre> You: Generate tests for calculator.py</p> <p>WYN360: [Analyzes calculator.py using AST]</p> <p>Found: - 4 functions: add(), subtract(), multiply(), divide() - 1 class: Calculator</p> <p>[Generates tests/test_calculator.py] \u2713 Created tests/test_calculator.py with 5 test stubs</p> <p>Generated test file structure: <pre><code>import pytest\nfrom calculator import add, subtract, multiply, divide, Calculator\n\ndef test_add():\n    # TODO: Implement test for add()\n    assert add(2, 3) == 5\n\ndef test_subtract():\n    # TODO: Implement test for subtract()\n    pass\n\ndef test_multiply():\n    # TODO: Implement test for multiply()\n    pass\n\ndef test_divide():\n    # TODO: Implement test for divide()\n    pass\n\nclass TestCalculator:\n    def test_init(self):\n        # TODO: Implement test for Calculator.__init__()\n        pass\n</code></pre></p> <p>Next steps: Complete the TODO sections with actual test logic. <pre><code>**Advanced Example:**\n</code></pre> You: Generate comprehensive tests for api.py</p> <p>WYN360: [Analyzes api.py]</p> <p>Found: - 8 API endpoints - 3 database models - 2 authentication functions - 5 helper functions</p> <p>[Generates tests/test_api.py] \u2713 Created test scaffolding with:   - 8 endpoint tests   - 3 model tests   - 2 authentication tests   - 5 helper function tests   - Fixtures for database setup   - Mock configurations</p> <p>Total: 18 test stubs generated <pre><code>**Features:**\n- \u2705 AST parsing (safe, no code execution)\n- \u2705 Generates pytest-compatible tests\n- \u2705 Includes TODO markers for easy completion\n- \u2705 Proper import statements\n- \u2705 Class and function test structure\n- \u2705 Fixture suggestions\n\n**Workflow Integration:**\n```bash\n# 1. Write your code\nYou: Create a user authentication module\n\nWYN360: [Generates auth.py]\n\n# 2. Generate tests automatically\nYou: Generate tests for auth.py\n\nWYN360: [Creates tests/test_auth.py with stubs]\n\n# 3. Complete the tests\nYou: Fill in the test logic\n\nWYN360: [Adds assertions and test data]\n\n# 4. Run tests\nYou: Run pytest\n\nWYN360: [Executes tests]\n</code></pre></p> <p>Productivity Benefits: - \u2705 Saves time on test boilerplate - \u2705 Ensures consistent test structure - \u2705 Encourages test-driven development - \u2705 Quick scaffolding for TDD - \u2705 Easy to complete TODO sections</p>"},{"location":"usage/use-cases/#use-case-14-github-integration","title":"Use Case 14: GitHub Integration","text":"<p>Complexity: Moderate to Complex Type: Version Control/CI/CD Best For: Complete git workflows, team collaboration Version: v0.3.23 (Phase 8.1)</p> <p>Feature: Complete GitHub integration with commit, PR creation, and branch management</p> <p>WYN360 provides seamless GitHub integration directly from the CLI! This feature enables complete git workflow management including committing changes, creating pull requests, managing branches, and merging code.</p>"},{"location":"usage/use-cases/#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd10 GitHub Authentication - Token-based authentication with GH_TOKEN/GITHUB_TOKEN</li> <li>\ud83d\udcbe Commit &amp; Push - Stage, commit, and push changes directly from CLI</li> <li>\ud83d\udd00 Pull Requests - Create PRs with title, body, and base branch</li> <li>\ud83c\udf3f Branch Management - Create, checkout, and list branches</li> <li>\ud83d\udd04 Branch Merging - Merge branches with conflict detection</li> <li>\ud83d\udd12 User Confirmation - All git operations require y/N approval</li> <li>\u2705 Auto-Authentication - Automatically uses environment token if found</li> <li>\ud83c\udfaf Session Persistence - Token stored in environment across session</li> </ul>"},{"location":"usage/use-cases/#use-case-141-commit-and-push-changes","title":"Use Case 14.1: Commit and Push Changes","text":"<p>Commit your changes to the current repository and push to GitHub with a single command.</p> <p>User Interaction: <pre><code>You: Commit these changes\n\nWYN360: [Checks GitHub authentication]\n\nLet me check your GitHub authentication first...\n\n\u2713 Authenticated with GitHub as 'yiqiao-yin'\n\nI'll now commit your changes. Let me check what's been modified:\n\n[Runs git status]\nChanges to be committed:\n  modified:   agent.py\n  modified:   USE_CASES.md\n  new file:   tests/test_github.py\n\n[Runs git add -A to stage all changes]\n\n======================================================================\n\u26a0\ufe0f  COMMAND EXECUTION CONFIRMATION\n======================================================================\nCommand: git commit -m \"Add GitHub integration tools\"\nDirectory: /home/workbench/wyn360-cli/wyn360-cli\nPermissions: Full user permissions\n======================================================================\n\n&gt;&gt;&gt; WAITING FOR YOUR RESPONSE &lt;&lt;&lt;\n\nExecute this command? (y/N): y\n\n\u2705 Command executed successfully (exit code 0)\n\nCommit created: a1b2c3d\nAuthor: Yiqiao Yin &lt;yiqiao.yin@wyn-associates.com&gt;\nMessage: Add GitHub integration tools\n\nNow pushing to remote...\n\n======================================================================\n\u26a0\ufe0f  COMMAND EXECUTION CONFIRMATION\n======================================================================\nCommand: git push origin main\nDirectory: /home/workbench/wyn360-cli/wyn360-cli\nPermissions: Full user permissions\n======================================================================\n\n&gt;&gt;&gt; WAITING FOR YOUR RESPONSE &lt;&lt;&lt;\n\nExecute this command? (y/N): y\n\n\u2705 Command executed successfully (exit code 0)\n\n\u2713 Successfully committed and pushed changes to GitHub!\n</code></pre></p> <p>If Not Authenticated: <pre><code>You: Commit to github\n\nWYN360: [Checks authentication]\n\nNot authenticated with GitHub. To use GitHub features, I need your access token.\n\nTo get a GitHub token:\n1. Visit: https://github.com/settings/tokens/new\n2. Generate a Personal Access Token with 'repo' and 'workflow' scopes\n3. Copy the token (format: ghp_... or github_pat_...)\n\nPlease provide your GitHub token (it will be stored in GH_TOKEN environment variable):\n\nYou: ghp_abc123xyz789...\n\nWYN360: [Authenticates]\n\n\u2713 Authenticated with GitHub (auto-authenticated using provided token)\n\nNow let me commit your changes...\n\n[Proceeds with commit workflow]\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-142-create-pull-request","title":"Use Case 14.2: Create Pull Request","text":"<p>Open a pull request from your current branch to the main branch.</p> <p>User Interaction: <pre><code>You: Create a pull request for my feature\n\nWYN360: [Checks authentication - already authenticated this session]\n\n\u2713 Authenticated with GitHub as 'yiqiao-yin'\n\nLet me gather information about your branch...\n\n[Runs git branch --show-current]\nCurrent branch: feature/github-integration\n\n[Runs git diff main...feature/github-integration]\nChanges include:\n- agent.py: +150 lines (7 new tools)\n- SYSTEM.md: +75 lines (architecture updates)\n- USE_CASES.md: +200 lines (documentation)\n\nI'll create a pull request with the following details:\n\n**Title:** Add GitHub Integration Tools (Phase 8.1)\n\n**Body:**\nThis PR implements Phase 8.1 - GitHub Integration with 7 new tools:\n\n## Changes\n- \u2705 GitHub authentication (check_gh_authentication, authenticate_gh)\n- \u2705 Commit and push (gh_commit_changes)\n- \u2705 Create PRs (gh_create_pr)\n- \u2705 Branch management (gh_create_branch, gh_checkout_branch)\n- \u2705 Branch merging (gh_merge_branch)\n\n## Documentation\n- Updated SYSTEM.md with GitHub integration layer\n- Added Section 17 to USE_CASES.md\n- Updated system prompt with GitHub workflow\n\n**Base branch:** main\n\n======================================================================\n\u26a0\ufe0f  COMMAND EXECUTION CONFIRMATION\n======================================================================\nCommand: gh pr create --title \"Add GitHub Integration Tools (Phase 8.1)\" \\\n         --base main --body \"...\"\nDirectory: /home/workbench/wyn360-cli/wyn360-cli\nPermissions: Full user permissions\n======================================================================\n\n&gt;&gt;&gt; WAITING FOR YOUR RESPONSE &lt;&lt;&lt;\n\nExecute this command? (y/N): y\n\n\u2705 Command executed successfully (exit code 0)\n\n\u2713 Successfully created pull request!\n\nPR URL: https://github.com/yiqiao-yin/wyn360-cli/pull/42\nTitle: Add GitHub Integration Tools (Phase 8.1)\nBase: main \u2190 feature/github-integration\nStatus: Open\n\nView or merge at: https://github.com/yiqiao-yin/wyn360-cli/pull/42\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-143-branch-management","title":"Use Case 14.3: Branch Management","text":"<p>Create new branches and switch between them seamlessly.</p> <p>Create New Branch: <pre><code>You: Create a new branch called feature/auth\n\nWYN360: I'll create a new branch 'feature/auth' and check it out.\n\n======================================================================\n\u26a0\ufe0f  COMMAND EXECUTION CONFIRMATION\n======================================================================\nCommand: git checkout -b feature/auth\nDirectory: /home/workbench/wyn360-cli/wyn360-cli\nPermissions: Full user permissions\n======================================================================\n\n&gt;&gt;&gt; WAITING FOR YOUR RESPONSE &lt;&lt;&lt;\n\nExecute this command? (y/N): y\n\n\u2705 Command executed successfully (exit code 0)\n\n\u2713 Successfully created and checked out branch 'feature/auth'\n\nCurrent branch: feature/auth\nBase commit: a1b2c3d (from main)\n\nYou can now make changes on this branch. When ready:\n- Commit: \"commit these changes\"\n- Push: \"push to github\"\n- PR: \"create pull request\"\n</code></pre></p> <p>Checkout Existing Branch: <pre><code>You: Switch to the develop branch\n\nWYN360: I'll check out the 'develop' branch.\n\n[First checks if branch exists with git branch]\nBranch 'develop' exists.\n\n======================================================================\n\u26a0\ufe0f  COMMAND EXECUTION CONFIRMATION\n======================================================================\nCommand: git checkout develop\nDirectory: /home/workbench/wyn360-cli/wyn360-cli\nPermissions: Full user permissions\n======================================================================\n\n&gt;&gt;&gt; WAITING FOR YOUR RESPONSE &lt;&lt;&lt;\n\nExecute this command? (y/N): y\n\n\u2705 Command executed successfully (exit code 0)\n\n\u2713 Successfully checked out branch 'develop'\n\nPrevious branch: main\nCurrent branch: develop\nLast commit: x9y8z7 \"Update documentation\"\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-144-merge-branches","title":"Use Case 14.4: Merge Branches","text":"<p>Merge feature branches into target branches with conflict detection.</p> <p>Successful Merge: <pre><code>You: Merge feature/auth into main\n\nWYN360: I'll merge 'feature/auth' into 'main'.\n\n[Checks current branch]\nCurrent branch: main \u2713\n\n[Checks if source branch exists]\nSource branch 'feature/auth' exists \u2713\n\n[Checks for uncommitted changes]\nWorking directory clean \u2713\n\n======================================================================\n\u26a0\ufe0f  COMMAND EXECUTION CONFIRMATION\n======================================================================\nCommand: git merge feature/auth\nDirectory: /home/workbench/wyn360-cli/wyn360-cli\nPermissions: Full user permissions\n======================================================================\n\n&gt;&gt;&gt; WAITING FOR YOUR RESPONSE &lt;&lt;&lt;\n\nExecute this command? (y/N): y\n\n\u2705 Command executed successfully (exit code 0)\n\n\u2713 Successfully merged 'feature/auth' into 'main'\n\nMerge type: Fast-forward\nFiles changed: 5\nInsertions: +230 lines\nDeletions: -15 lines\n\nChanges:\n  modified: agent.py (+150, -10)\n  modified: SYSTEM.md (+45, -0)\n  modified: USE_CASES.md (+30, -5)\n  new file: tests/test_auth.py (+5, -0)\n\nNext steps:\n- Push to remote: \"push to github\"\n- Create PR: \"create pull request\"\n</code></pre></p>"},{"location":"usage/use-cases/#configuration","title":"Configuration","text":"<p>Environment Variables: <pre><code># Set GitHub token for automatic authentication\nexport GH_TOKEN=\"ghp_your_token_here\"\n\n# Or use GITHUB_TOKEN (both work)\nexport GITHUB_TOKEN=\"ghp_your_token_here\"\n```yaml\n\n**Token Requirements:**\n- Format: `ghp_*` or `github_pat_*`\n- Required scopes: `repo`, `workflow`\n- Generate at: https://github.com/settings/tokens/new\n\n**.env File (Recommended):**\n```bash\n# .env file in your project root\nANTHROPIC_API_KEY=your_anthropic_key\nGH_TOKEN=ghp_your_github_token\n</code></pre></p>"},{"location":"usage/use-cases/#example-workflow-complete-feature-development","title":"Example Workflow: Complete Feature Development","text":"<p>Scenario: Building a new authentication feature</p> <pre><code># 1. Create feature branch\nYou: Create a new branch called feature/auth\n\nWYN360: [Creates and checks out branch]\n\u2713 Branch 'feature/auth' created and checked out\n\n# 2. Generate code\nYou: Create an authentication module with JWT support\n\nWYN360: [Generates auth.py with JWT implementation]\n\u2713 Created auth.py\n\n# 3. Write tests\nYou: Generate tests for the authentication module\n\nWYN360: [Generates tests/test_auth.py]\n\u2713 Created tests/test_auth.py\n\n# 4. Commit changes\nYou: Commit these changes with message \"Add JWT authentication\"\n\nWYN360: [Authentication already verified]\n[Stages all changes]\n[Commits with message]\n[Pushes to origin]\n\u2713 Successfully committed and pushed changes\n\n# 5. Create PR\nYou: Create a pull request titled \"Add JWT Authentication Feature\"\n\nWYN360: [Analyzes changes]\n[Generates PR description]\n[Creates PR on GitHub]\n\u2713 PR created: https://github.com/username/repo/pull/42\n\n# 6. After review, merge to main\nYou: Checkout main\n\nWYN360: [Switches to main branch]\n\u2713 Checked out main\n\nYou: Merge feature/auth into main\n\nWYN360: [Merges branch]\n[No conflicts]\n\u2713 Successfully merged feature/auth into main\n\nYou: Push to github\n\nWYN360: [Pushes main branch]\n\u2713 Pushed to origin/main\n\n\u2705 Complete workflow: Branch \u2192 Code \u2192 Commit \u2192 PR \u2192 Merge \u2192 Deploy\n</code></pre> <p>Time Saved: - Manual workflow: 10-15 minutes - With WYN360: 2-3 minutes - Efficiency gain: 70-80%</p>"},{"location":"usage/use-cases/#advanced-features","title":"Advanced Features","text":""},{"location":"usage/use-cases/#use-case-15-performance-monitoring-analytics","title":"Use Case 15: Performance Monitoring &amp; Analytics","text":"<p>Complexity: Advanced Type: Monitoring/Analytics Best For: Session optimization, cost tracking, performance tuning Version: v0.3.19 (Phase 10.2)</p> <p>Monitor your CLI usage, response times, tool efficiency, and identify performance bottlenecks with comprehensive metrics tracking.</p>"},{"location":"usage/use-cases/#what-is-performance-monitoring","title":"What is Performance Monitoring?","text":"<p>WYN360 automatically tracks and analyzes session performance, providing insights into: - Response Times: How fast the AI responds to your requests - Tool Usage: Which tools you use most and their success rates - Error Tracking: What errors occur and how frequently - Session Statistics: Overall session duration and activity</p>"},{"location":"usage/use-cases/#the-stats-command","title":"The /stats Command","text":"<p>View comprehensive performance metrics at any time during your session:</p> <pre><code>You: /stats\n\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513  \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503   Token Usage        \u2503  \u2503   Performance Metrics   \u2503\n\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b  \u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n\u2503 Total Requests: 25   \u2503  \u2503 Session Duration: 15m   \u2503\n\u2503 Input Tokens: 45,230 \u2503  \u2503 Avg Response: 2.3s      \u2503\n\u2503 Output Tokens: 12,450\u2503  \u2503 Min Response: 0.8s      \u2503\n\u2503 Total Cost: $0.32    \u2503  \u2503 Max Response: 5.2s      \u2503\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b  \u2503 Error Count: 0          \u2503\n                          \u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503      Tool Usage            \u2503\n\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u252b\n\u2503 Total Tool Calls: 47       \u2503\n\u2503 Successful Calls: 45       \u2503\n\u2503 Failed Calls: 2            \u2503\n\u2503 Success Rate: 95.7%        \u2503\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\n\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503      Most Used Tools           \u2503\n\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u252b\n\u2503 Tool      \u2503Success\u2503Failed\u2503Total\u2503\n\u2523\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u2501\u254b\u2501\u2501\u2501\u2501\u2501\u252b\n\u2503 read_file \u2503  15   \u2503  0   \u2503 15  \u2503\n\u2503write_file \u2503  12   \u2503  1   \u2503 13  \u2503\n\u2503execute_cmd\u2503   8   \u2503  0   \u2503  8  \u2503\n\u2503search_files\u2503  5   \u2503  0   \u2503  5  \u2503\n\u2503git_status \u2503   5   \u2503  1   \u2503  6  \u2503\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u2501\u253b\u2501\u2501\u2501\u2501\u2501\u251b\n</code></pre>"},{"location":"usage/use-cases/#use-case-151-identifying-slow-operations","title":"Use Case 15.1: Identifying Slow Operations","text":"<p>Scenario: You notice your session feels slow sometimes</p> <pre><code>You: /stats\n\nWYN360: [Shows metrics]\n- Avg Response: 4.5s\n- Max Response: 15.2s  \u2190 Outlier detected!\n\nYou: What took 15 seconds?\n\nWYN360: Looking at your session history, the slowest\noperation was \"Generate comprehensive ML pipeline\" which\ngenerated 800+ lines of code. Consider breaking large\nrequests into smaller chunks for faster responses.\n</code></pre> <p>Insight: Large code generation requests take longer. Break them into smaller, focused tasks.</p>"},{"location":"usage/use-cases/#use-case-152-tool-success-rate-analysis","title":"Use Case 15.2: Tool Success Rate Analysis","text":"<p>Scenario: Want to see which operations are failing</p> <pre><code>You: /stats\n\nWYN360: [Shows tool usage]\nTool Success Rates:\n- read_file: 100% (15/15)\n- write_file: 92.3% (12/13)  \u2190 1 failure\n- execute_command: 100% (8/8)\n- git_status: 83.3% (5/6)    \u2190 1 failure\n\nYou: Why did write_file fail once?\n\nWYN360: The write_file failure was due to attempting\nto write without overwrite=True when the file already\nexisted. This was corrected in the retry.\n</code></pre> <p>Insight: Understand which operations need error handling or user confirmation.</p>"},{"location":"usage/use-cases/#use-case-153-session-cost-monitoring","title":"Use Case 15.3: Session Cost Monitoring","text":"<p>Scenario: Track spending during a long coding session</p> <pre><code>You: I've been working for 2 hours. How much have I spent?\n\nYou: /stats\n\nWYN360: [Shows combined token + performance metrics]\nSession Duration: 2h 15m\nTotal Requests: 47\nTotal Cost: $1.23\nAverage Cost per Request: $0.026\n\nMost expensive operations:\n1. Multi-file refactoring: $0.15\n2. Test generation: $0.12\n3. Documentation creation: $0.09\n</code></pre> <p>Insight: Monitor costs in real-time, identify expensive operations, optimize usage.</p>"},{"location":"usage/use-cases/#features","title":"Features","text":"<p>Automatic Tracking: - \u2705 Response times tracked for every request - \u2705 Tool calls logged with success/failure status - \u2705 Errors captured with type and message - \u2705 Session duration calculated automatically</p> <p>Persistent Metrics: - \u2705 Metrics saved with /save command - \u2705 Loaded with /load command - \u2705 Track performance across multiple sessions</p> <p>Zero Configuration: - \u2705 Works automatically - no setup required - \u2705 Non-intrusive - runs in background - \u2705 No performance overhead - \u2705 Compatible with all existing features</p>"},{"location":"usage/use-cases/#commands","title":"Commands","text":"Command Purpose Example <code>/stats</code> Show comprehensive performance metrics <code>You: /stats</code> <code>/tokens</code> Show only token usage (legacy) <code>You: /tokens</code> <code>/clear</code> Reset all metrics and history <code>You: /clear</code>"},{"location":"usage/use-cases/#use-case-16-web-search-real-time-information-access","title":"Use Case 16: Web Search - Real-Time Information Access","text":"<p>Complexity: Advanced Type: Information Retrieval Best For: Current info, weather, documentation, finding resources Version: v0.3.21, Enhanced in v0.3.23</p> <p>Feature: Real-time web search using Claude's native web_search_20250305 tool</p>"},{"location":"usage/use-cases/#overview","title":"Overview","text":"<p>WYN360 now has access to real-time web search capabilities! This feature enables the AI assistant to fetch current information from the internet, including weather data, website content, latest documentation, and finding GitHub repositories and libraries (enhanced in v0.3.23).</p> <p>v0.3.23 Enhancements: - \u2b06\ufe0f Upgraded from pydantic-ai 0.0.19 to 1.13.0 for improved stability - \ud83d\udd27 Fixed web search tool integration with proper <code>builtin_tools</code> configuration - \ud83d\udcdd Enhanced system prompt with explicit examples for finding resources - \u2705 Now properly recognizes queries like \"find a popular GitHub repo for X\"</p>"},{"location":"usage/use-cases/#key-features_1","title":"Key Features","text":"<ul> <li>\ud83c\udf24\ufe0f Weather Queries - Get current weather for any location</li> <li>\ud83c\udf10 Website Reading - Fetch and summarize web content</li> <li>\ud83d\udcda Current Information - Access latest docs, news, and trends</li> <li>\ud83d\udd0d Resource Finding - Find GitHub repos, libraries, and tutorials (NEW in v0.3.23)</li> <li>\ud83d\udcb0 Cost Controlled - Limited to 5 searches per session by default</li> <li>\ud83d\udd17 Proper Citations - All results include source URLs</li> <li>\ud83e\udd16 Automatic Invocation - Claude decides when web search is needed</li> </ul>"},{"location":"usage/use-cases/#use-case-161-weather-queries","title":"Use Case 16.1: Weather Queries","text":"<p>Get real-time weather information for any location.</p> <p>User Interaction: <pre><code>You: What's the weather in San Francisco?\n\nWYN360: [Searches web for current San Francisco weather]\n\nCurrent Weather in San Francisco, CA:\n- Temperature: 62\u00b0F (17\u00b0C)\n- Conditions: Partly Cloudy\n- Humidity: 71%\n- Wind: 10 mph NW\n- Last Updated: 2025-01-10 14:30 PST\n\nSource: [Weather.com](https://weather.com/weather/today/l/San+Francisco+CA)\n</code></pre></p> <p>Cost: - 1 search per query ($0.01) - Plus token costs for input/output (~$0.001-0.003) - Total: ~$0.011-0.013 per weather query</p>"},{"location":"usage/use-cases/#use-case-162-website-reading-summarization","title":"Use Case 16.2: Website Reading &amp; Summarization","text":"<p>Note: As of v0.3.24, specific URL fetching uses the new <code>fetch_website</code> tool for direct DOM extraction. See Use Case 16.5 for details.</p> <p>Fetch and summarize content from any publicly accessible URL using web search.</p> <p>User Interaction: <pre><code>You: What's on the Python 3.13 release page?\n\nWYN360: [Searches for Python 3.13 release information]\n\n**Python 3.13.0 Release Summary:**\n\n**Key Highlights:**\n1. **Performance Improvements:**\n   - Free-threaded CPython (no GIL) - experimental\n   - JIT compiler - experimental\n   - 5-10% performance boost in most workloads\n\n2. **New Features:**\n   - Enhanced error messages with better tracebacks\n   - Improved type hinting capabilities\n   - New syntax for generic type parameters\n   - Enhanced asyncio performance\n\n3. **Standard Library Updates:**\n   - New modules: `dbm.sqlite3`\n   - Improved `pathlib` functionality\n   - Enhanced `argparse` features\n\n**Release Date:** October 2024\n\nSource: [Python.org](https://python.org/downloads/release/python-3130/)\n</code></pre></p> <p>Cost: - 1 search per URL ($0.01) - Token costs vary by page size (typically $0.003-0.010) - Total: ~$0.013-0.020 per URL</p>"},{"location":"usage/use-cases/#use-case-163-current-information-latest-updates","title":"Use Case 16.3: Current Information &amp; Latest Updates","text":"<p>Access the latest documentation, package versions, news, and trends.</p> <p>Example: <pre><code>You: What's new in React 19?\n\nWYN360: [Searches for React 19 release information]\n\n**React 19 - Major Updates:**\n\n**Release Date:** December 2024 (Beta available)\n\n**Key New Features:**\n\n1. **React Compiler:**\n   - Automatic optimization of React code\n   - No need for manual memoization in most cases\n   - Significant performance improvements\n\n2. **Actions:**\n   - New API for handling form submissions\n   - Built-in pending states\n   - Optimistic updates support\n\n3. **Document Metadata:**\n   - Built-in support for `&lt;title&gt;`, `&lt;meta&gt;` tags\n   - No need for react-helmet or next/head\n\nSources:\n- [React Blog - React 19 Beta](https://react.dev/blog/2024/12/05/react-19)\n- [React Docs - What's New](https://react.dev/learn/whats-new)\n</code></pre></p> <p>Cost: - 1-2 searches per query ($0.01-0.02) - Token costs for synthesis (~$0.005-0.015) - Total: ~$0.015-0.035 per information query</p>"},{"location":"usage/use-cases/#use-case-164-finding-resources-github-repositories-new-in-v0323","title":"Use Case 16.4: Finding Resources &amp; GitHub Repositories (NEW in v0.3.23)","text":"<p>Find popular GitHub repositories, libraries, tools, and learning resources based on specific topics or technologies.</p> <p>User Interaction: <pre><code>You: Find a popular GitHub repo for machine learning\n\nWYN360: [Searches web for popular ML repositories]\n\nHere are some of the most popular GitHub repositories for machine learning:\n\n1. **tensorflow/tensorflow** \u2b50 185,000+ stars\n   https://github.com/tensorflow/tensorflow\n   - End-to-end open source machine learning platform\n   - Developed and maintained by Google\n   - Comprehensive ecosystem for model development and deployment\n\n2. **pytorch/pytorch** \u2b50 82,000+ stars\n   https://github.com/pytorch/pytorch\n   - Deep learning framework by Meta AI (Facebook)\n   - Dynamic computational graphs (imperative programming)\n   - Popular in research and academic communities\n\n3. **scikit-learn/scikit-learn** \u2b50 59,000+ stars\n   https://github.com/scikit-learn/scikit-learn\n   - Classic machine learning library for Python\n   - Built on NumPy, SciPy, and matplotlib\n   - Great for traditional ML algorithms (not deep learning)\n\n**Recommendation for Beginners:** Start with scikit-learn for traditional ML, then move to TensorFlow or PyTorch for deep learning.\n\nSources:\n- [GitHub Search Results - Most Stars in ML category]\n- [GitHub Trending - Machine Learning]\n</code></pre></p> <p>Finding Libraries by Language: <pre><code>You: What are good Python libraries for data visualization?\n\nWYN360: [Searches for Python data viz libraries]\n\nTop Python libraries for data visualization:\n\n1. **Matplotlib** \u2b50 19,500+ stars\n   - Standard plotting library, similar to MATLAB\n   - Best for: Static plots, scientific visualizations\n\n2. **Plotly** \u2b50 16,000+ stars\n   - Interactive web-based visualizations\n   - Best for: Interactive charts, web apps, dashboards\n\n3. **Seaborn** \u2b50 12,000+ stars\n   - Built on matplotlib, statistical focus\n   - Best for: Statistical analysis, heatmaps, distributions\n\nSources: GitHub, Python Package Index, Stack Overflow trends\n</code></pre></p> <p>Cost: - 1-2 searches per query ($0.01-0.02) - Token costs for formatting (~$0.005-0.010) - Total: ~$0.015-0.030 per resource search</p>"},{"location":"usage/use-cases/#use-case-165-direct-website-fetching-new-in-v0324","title":"Use Case 16.5: Direct Website Fetching (NEW in v0.3.24)","text":"<p>Fetch full content from specific URLs directly using the <code>fetch_website</code> tool. Unlike web search which returns search results, this fetches the complete DOM and converts it to LLM-friendly markdown.</p> <p>Key Features: - \ud83c\udf10 Full Page Content - Complete DOM extraction, not just snippets - \ud83e\udde0 LLM-Optimized - Automatic HTML \u2192 Markdown conversion - \u26a1 Smart Caching - 30-minute TTL cache (configurable) - \ud83d\udccf Smart Truncation - Preserves structure, stays under token limits - \ud83d\udcbe Cache Management - View stats, clear cache</p> <p>User Interaction: <pre><code>You: Read https://github.com/britbrat0/cs676\n\nWYN360: [Fetches the URL directly using fetch_website tool]\n\n\ud83d\udcc4 **Fetched:** https://github.com/britbrat0/cs676\n\n# CS676 - Computer Vision Course Repository\n\n## \ud83d\udcda Course Information\n- **Institution:** [University Name]\n- **Semester:** Fall 2024\n- **Instructor:** [Instructor Name]\n\n## \ud83d\udcc2 Repository Structure\n- `/assignments` - Weekly problem sets\n- `/projects` - Major course projects\n- `/lectures` - Lecture notes and slides\n- `/resources` - Additional learning materials\n\n## \ud83c\udfaf Projects\n\n### Project 1: Image Classification\nImplementation of a CNN-based image classifier using PyTorch.\nTechnologies: Python, PyTorch, NumPy, Matplotlib\n\n### Project 2: Object Detection\nYOLO-based object detection system for real-time video analysis.\nTechnologies: YOLO, OpenCV, Python\n\n### Project 3: Semantic Segmentation\nU-Net architecture for medical image segmentation.\nTechnologies: TensorFlow, Keras, Medical Imaging\n\n[Full page content extracted - showing first 70% and last 30% of 45,000 tokens]\n\n---\n**[Content truncated - Original: 52,341 tokens, Showing: ~50,000 tokens]**\n---\n\n## \ud83d\udcd6 Additional Resources\n- [Course Website](...)\n- [Discussion Forum](...)\n- [Office Hours Schedule](...)\n</code></pre></p> <p>Cache Management: <pre><code>You: Show cache stats\n\nWYN360: \ud83d\udcca **Website Cache Statistics**\n\n**Location:** `~/.wyn360/cache/fetched_sites`\n\n**Total Entries:** 3\n**Total Size:** 2.4 MB\n**Expired Entries:** 0\n\n**Cached URLs:**\n- \u2713 2m old: https://github.com/britbrat0/cs676\n- \u2713 15m old: https://python.org/downloads\n- \u2713 28m old: https://docs.anthropic.com\n\n\ud83d\udca1 *Tip: Cache expires after 30 minutes*\n</code></pre></p> <p>Clear Cache: <pre><code>You: Clear cache for https://github.com/britbrat0/cs676\n\nWYN360: \u2713 Cleared cache for: https://github.com/britbrat0/cs676\n</code></pre></p> <p>Configuration: <pre><code># ~/.wyn360/config.yaml\nbrowser_use:\n  max_tokens: 50000  # Max tokens per fetched site\n  truncate_strategy: \"smart\"  # Options: smart, head, tail\n  cache:\n    enabled: true\n    ttl: 1800  # 30 minutes in seconds\n    max_size_mb: 100  # Maximum cache size\n</code></pre></p> <p>Cost: - No search cost (direct fetching) - Token costs only (~$0.005-0.030 depending on page size) - Cache hits: Nearly free (just retrieval) - Total: ~$0.005-0.030 per fetch (first time), ~$0.001 (cached)</p> <p>When to Use: - \u2705 fetch_website: \"Read https://example.com\" (specific URL) - \u2705 WebSearchTool: \"Find ML repos\" (search/discovery)</p>"},{"location":"usage/use-cases/#when-web-search-is-used","title":"When Web Search is Used","text":"<p>WILL Use Web Search: - \u2705 Weather queries (\"What's the weather in NYC?\") - \u2705 Finding/Searching (\"Find ML repos\", \"What are good libraries?\") - \u2705 Finding resources (\"Find a popular GitHub repo for machine learning\") (v0.3.23) - \u2705 Library recommendations (\"What are good Python data viz libraries?\") (v0.3.23) - \u2705 Tutorial finding (\"Find tutorials for FastAPI\") (v0.3.23) - \u2705 Current information (\"What's new in Python 3.13?\") - \u2705 Latest versions (\"Latest React features\")</p> <p>WILL Use fetch_website: (NEW v0.3.24) - \u2705 Specific URLs (\"Read https://github.com/user/repo\") - \u2705 Direct page fetching (\"Get content from https://example.com\") - \u2705 Full DOM extraction (\"Fetch https://docs.site.com/api\")</p> <p>WILL NOT Use Web Tools: - \u274c Code generation (\"Write a FastAPI app\") - \u274c File operations (\"Show me app.py\") - \u274c Local project queries (\"List files in this project\") - \u274c Git operations (\"Show git status\") - \u274c General programming concepts (\"What is async/await?\")</p>"},{"location":"usage/use-cases/#cost-analysis","title":"Cost Analysis","text":"<p>Pricing: - Web Search Cost: $10.00 per 1,000 searches - Token Costs: Standard model pricing ($3/$15 per M tokens for Sonnet) - Session Limit: 5 searches per session (configurable)</p> <p>Example Costs:</p> Query Type Searches Token Cost Total Cost Weather 1 $0.001-0.003 $0.011-0.013 URL Reading 1 $0.003-0.010 $0.013-0.020 Latest Info 1-2 $0.005-0.015 $0.015-0.035 Resource Search 1-2 $0.005-0.010 $0.015-0.030 <p>Session Example: <pre><code>- 2 weather queries: $0.026\n- 1 URL read: $0.015\n- 2 resource searches: $0.050\nTotal: ~$0.091 per session\n</code></pre></p>"},{"location":"usage/use-cases/#configuration_1","title":"Configuration","text":"<p>Default Settings: <pre><code># In agent.py\nbuiltin_tools=[\n    WebSearchTool(max_uses=5)  # Limit searches per session\n]\n</code></pre></p> <p>Adjustable Parameters: - <code>max_uses</code>: Maximum searches per session (default: 5) - <code>search_context_size</code>: How much context to include - <code>user_location</code>: Default location for queries - <code>blocked_domains</code>: Sites to exclude - <code>allowed_domains</code>: Sites to include only</p>"},{"location":"usage/use-cases/#complex-multi-turn-workflows","title":"Complex Multi-Turn Workflows","text":""},{"location":"usage/use-cases/#use-case-17-add-features-to-existing-code","title":"Use Case 17: Add Features to Existing Code","text":"<p>Complexity: Complex Type: Multi-turn Best For: Enhancing existing projects, iterative development</p> <p>Enhance your existing projects with new functionality while maintaining code quality and consistency.</p> <p>How it works: 1. Agent reads your current code structure 2. Understands existing patterns and conventions 3. Generates new features that integrate seamlessly 4. Can modify/enhance existing files 5. Maintains your coding style</p> <p>Example Interaction: <pre><code>You: Add authentication to my FastAPI app\n\nWYN360:\n1. Reads your existing app structure\n2. Identifies route definitions\n3. Generates authentication middleware\n4. Updates routes with auth decorators\n5. Provides implementation guide\n</code></pre></p> <p>Common Feature Additions: - Authentication and authorization - Database integration - API endpoints - Error handling and logging - Input validation - Caching mechanisms - Testing utilities</p>"},{"location":"usage/use-cases/#use-case-18-interactive-coding-assistant","title":"Use Case 18: Interactive Coding Assistant","text":"<p>Complexity: Complex Type: Multi-turn Best For: Learning, debugging, code review, ongoing development</p> <p>Get help, guidance, and answers to your Python questions through ongoing conversation.</p> <p>Capabilities: - Answer coding questions - Debug issues and errors - Explain complex concepts - Provide implementation guidance - Review code quality - Suggest improvements</p> <p>Example Interactions:</p> <p>Debugging: <pre><code>You: My script has a connection timeout error\n\nWYN360:\n1. Reads your code\n2. Identifies the issue\n3. Explains the root cause\n4. Suggests fix with retry logic\n5. Can update the file directly\n</code></pre></p> <p>Learning: <pre><code>You: How do I implement async in Python?\n\nWYN360:\n- Explains async/await concepts\n- Provides working examples\n- Shows best practices\n- Demonstrates common patterns\n- Warns about pitfalls\n</code></pre></p> <p>Code Review: <pre><code>You: Review my API implementation\n\nWYN360:\n- Analyzes code structure\n- Checks error handling\n- Reviews security considerations\n- Suggests improvements\n- Provides specific fixes\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-19-document-reading-excel-word-and-pdf","title":"Use Case 19: Document Reading - Excel, Word, and PDF","text":"<p>Complexity: Advanced Type: Document Analysis Best For: Analyzing spreadsheets, reports, papers, and large documents Version: v0.3.26 - v0.3.29</p> <p>Feature: Intelligent document reading with chunking, summarization, and semantic search</p>"},{"location":"usage/use-cases/#overview_1","title":"Overview","text":"<p>WYN360 can read and analyze structured documents (Excel, Word, PDF) of any size using an intelligent chunking system. Documents are automatically split into manageable pieces, summarized, and cached for fast retrieval.</p>"},{"location":"usage/use-cases/#key-features_2","title":"Key Features","text":"<ul> <li>\ud83d\udcca Excel Files - Multi-sheet support, formulas, charts, named ranges</li> <li>\ud83d\udcdd Word Documents - Structured extraction, tables, images, sections</li> <li>\ud83d\udcc4 PDF Files - Page-aware chunking, table detection, OCR for scanned PDFs</li> <li>\ud83e\udde0 Smart Chunking - Automatically splits large documents into ~1000 token chunks</li> <li>\ud83d\udcbe Intelligent Caching - Summaries cached for 1 hour, instant re-access</li> <li>\ud83d\udd0d Query-Based Retrieval - Ask questions, get relevant sections</li> <li>\u26a1 Performance - 3-5x faster with parallel processing (v0.3.36)</li> <li>\ud83d\udddc\ufe0f Compression - 50-70% storage reduction (v0.3.36)</li> </ul>"},{"location":"usage/use-cases/#use-case-191-expense-report-analysis-excel","title":"Use Case 19.1: Expense Report Analysis (Excel)","text":"<p>Analyze multi-sheet expense tracking spreadsheets.</p> <pre><code>You: Read my expenses.xlsx file\n\nWYN360: [Processes Excel file]\n\ud83d\udcca Excel File: expenses.xlsx (3 sheets, 8,450 tokens)\n\u2713 Cache generated with 9 chunks\n\nSummary:\n- Q1_Expenses: $5,240 total, January highest at $2,100\n- Q2_Expenses: $6,180 total, April spike at $2,400\n- Summary: YTD $11,420, 8% over budget\n\nYou: What were my April gas expenses?\n\nWYN360: [Retrieves relevant chunk]\nApril gas expenses: $590\nThis represents a 15% increase from March ($512).\nBreakdown:\n- Week 1: $140\n- Week 2: $155\n- Week 3: $145\n- Week 4: $150\n</code></pre>"},{"location":"usage/use-cases/#use-case-192-research-paper-summarization-word","title":"Use Case 19.2: Research Paper Summarization (Word)","text":"<p>Analyze structured documents with sections, tables, and figures.</p> <pre><code>You: Summarize methodology section from research_paper.docx\n\nWYN360: [Reads Word document, extracts methodology section]\n\ud83d\udcdd Word Document: research_paper.docx (45 pages, 12,300 tokens)\n\nMethodology Section Summary:\n- Study Design: Randomized controlled trial (n=500)\n- Duration: 12 months (Jan-Dec 2024)\n- Measurements: Weekly assessments using validated scales\n- Analysis: Mixed-effects models with p&lt;0.05 significance\n- Tables: 3 demographic tables included\n- Key Innovation: Novel sampling technique reducing bias\n\nFull section: Pages 8-15 (2,100 tokens)\n</code></pre>"},{"location":"usage/use-cases/#use-case-193-textbook-navigation-pdf","title":"Use Case 19.3: Textbook Navigation (PDF)","text":"<p>Navigate and query large PDF documents efficiently.</p> <pre><code>You: What does Chapter 5 say about neural networks in textbook.pdf?\n\nWYN360: [Searches 120-page PDF, retrieves Chapter 5]\n\ud83d\udcc4 PDF Document: textbook.pdf (120 pages, 45,000 tokens)\nFound relevant content: Pages 67-82 (Chapter 5)\n\nChapter 5: Neural Networks\n- Introduction to feedforward architectures\n- Backpropagation algorithm explained with diagrams\n- Activation functions: ReLU, sigmoid, tanh comparison\n- Regularization techniques: Dropout (p=0.5 recommended)\n- Practical example: MNIST digit classification\n- 5 figures and 2 code listings\n\nWould you like me to extract specific sections or code examples?\n</code></pre>"},{"location":"usage/use-cases/#commands_1","title":"Commands","text":"Command Purpose Example <code>read_excel</code> Read Excel files Natural language: \"Read expenses.xlsx\" <code>read_word</code> Read Word documents Natural language: \"Summarize report.docx\" <code>read_pdf</code> Read PDF files Natural language: \"What's in chapter 3 of book.pdf?\" <code>/clear_doc_cache</code> Clear document cache <code>/clear_doc_cache</code> or <code>/clear_doc_cache file.xlsx</code> <code>/doc_cache_stats</code> Show cache statistics <code>/doc_cache_stats</code> <code>/set_doc_tokens</code> Set token limits <code>/set_doc_tokens pdf 30000</code>"},{"location":"usage/use-cases/#use-case-20-vision-mode-image-analysis-in-documents","title":"Use Case 20: Vision Mode - Image Analysis in Documents","text":"<p>Complexity: Advanced Type: Multimodal Document Processing Best For: Documents with charts, diagrams, screenshots, photos Version: v0.3.30</p> <p>Feature: Claude Vision API integration for analyzing images in Word and PDF documents</p>"},{"location":"usage/use-cases/#overview_2","title":"Overview","text":"<p>When documents contain important visual information (charts, diagrams, screenshots), WYN360 can use Claude's Vision API to describe and analyze these images.</p>"},{"location":"usage/use-cases/#key-features_3","title":"Key Features","text":"<ul> <li>\ud83d\uddbc\ufe0f Three Processing Modes:</li> <li><code>skip</code> - Ignore images entirely (fastest, cheapest)</li> <li><code>describe</code> - Extract captions and alt text (default)</li> <li><code>vision</code> - Full Claude Vision analysis (most accurate, costs extra)</li> <li>\ud83d\udcca Chart Recognition - Bar charts, line graphs, pie charts</li> <li>\ud83c\udfa8 Diagram Analysis - Flowcharts, architecture diagrams, UML</li> <li>\ud83d\udcf8 Screenshot Understanding - UI mockups, code screenshots</li> <li>\ud83d\udcb0 Cost Transparency - Separate tracking for vision API calls</li> <li>\u26a1 Batch Processing - Efficient bulk image analysis</li> </ul>"},{"location":"usage/use-cases/#use-case-201-sales-report-with-charts","title":"Use Case 20.1: Sales Report with Charts","text":"<p>Analyze Excel/PDF reports containing charts and graphs.</p> <pre><code>You: Analyze the Q4 sales charts in report.pdf\n\nWYN360: [Using vision mode]\n\ud83d\udcca Analyzing 3 charts from report.pdf...\n\nChart 1 (Page 5): Revenue Trend Line Chart\n- Shows steady growth from $2M (Q4 2023) to $3.2M (Q4 2024)\n- Notable spike in November 2024\n- Annotation indicates \"Holiday Season Peak\"\n\nChart 2 (Page 7): Regional Sales Pie Chart\n- West Coast: 42% ($1.34M)\n- East Coast: 31% ($0.99M)\n- Midwest: 18% ($0.58M)\n- South: 9% ($0.29M)\n\nChart 3 (Page 10): Product Category Bar Chart\n- Electronics leading at $1.8M\n- Apparel second at $0.9M\n- Home goods at $0.5M\n\nVision API tokens used: 4,200 input, 350 output\n</code></pre>"},{"location":"usage/use-cases/#use-case-202-technical-diagram-understanding","title":"Use Case 20.2: Technical Diagram Understanding","text":"<p>Understand architecture diagrams and flowcharts in documentation.</p> <pre><code>You: Explain the system architecture diagram on page 12\n\nWYN360: [Analyzes architectural diagram with vision]\n\ud83c\udfa8 System Architecture Diagram Analysis:\n\nComponents Identified:\n1. Frontend Layer (Top)\n   - React SPA\n   - Mobile App (iOS/Android)\n\n2. API Gateway (Middle)\n   - REST API\n   - GraphQL endpoint\n   - WebSocket connections\n\n3. Backend Services (Center)\n   - Auth Service\n   - User Service\n   - Payment Service\n   - Notification Service\n\n4. Data Layer (Bottom)\n   - PostgreSQL (Primary DB)\n   - Redis (Cache)\n   - S3 (File Storage)\n\nKey Connections:\n- All frontend traffic \u2192 API Gateway \u2192 Load Balancer\n- Services communicate via message queue (RabbitMQ)\n- Shared authentication via JWT tokens\n</code></pre>"},{"location":"usage/use-cases/#commands_2","title":"Commands","text":"Command Purpose Example <code>/set_image_mode skip</code> Ignore all images Process faster, lower cost <code>/set_image_mode describe</code> Extract alt text only Default behavior <code>/set_image_mode vision</code> Full Vision API analysis Highest accuracy"},{"location":"usage/use-cases/#use-case-21-ocr-scanned-document-processing","title":"Use Case 21: OCR - Scanned Document Processing","text":"<p>Complexity: Advanced Type: OCR + Vision Analysis Best For: Scanned PDFs, image-based documents, low-quality scans Version: v0.3.32</p> <p>Feature: Tesseract OCR integration for extracting text from scanned documents</p>"},{"location":"usage/use-cases/#overview_3","title":"Overview","text":"<p>Many PDFs are scanned images with no text layer. WYN360 automatically detects scanned pages and uses OCR to extract text, making these documents searchable and analyzable.</p>"},{"location":"usage/use-cases/#key-features_4","title":"Key Features","text":"<ul> <li>\ud83d\udd0d Automatic Detection - Identifies scanned vs text-based PDFs</li> <li>\ud83d\udcc4 Tesseract OCR - Industry-standard open-source OCR engine</li> <li>\ud83c\udf0d Multi-Language - Supports English, Spanish, French, German, Chinese, etc.</li> <li>\ud83d\udcca Confidence Scores - Quality assessment of OCR results</li> <li>\ud83d\uddbc\ufe0f Combined Processing - OCR text + Vision API for images</li> <li>\u26a1 Preprocessing - Deskew, denoise for better accuracy</li> </ul>"},{"location":"usage/use-cases/#use-case-211-historical-document-processing","title":"Use Case 21.1: Historical Document Processing","text":"<p>Extract text from old scanned documents.</p> <pre><code>You: Read the scanned contract from 1995_agreement.pdf\n\nWYN360: [Detecting scanned PDF, running OCR]\n\ud83d\udcc4 Scanned PDF detected: 1995_agreement.pdf (15 pages)\n\ud83d\udd0d Running Tesseract OCR...\n\nOCR Results (Confidence: 87.3%):\nPage 1-3: Contract preamble and definitions\nPage 4-7: Terms and conditions\n  - Payment schedule: Net 30 days\n  - Termination clause: 90-day notice\n  - Liability cap: $500,000\nPage 8-12: Technical specifications\nPage 13-15: Signatures and exhibits\n\nNote: Some degraded text on pages 2 and 11 (confidence &lt;70%)\nWould you like me to describe those sections using Vision API?\n</code></pre>"},{"location":"usage/use-cases/#use-case-212-receipt-processing","title":"Use Case 21.2: Receipt Processing","text":"<p>Extract data from photographed receipts.</p> <pre><code>You: Extract information from receipt_scan.pdf\n\nWYN360: [OCR + structured extraction]\n\ud83e\uddfe Receipt Analysis:\n\nMerchant: Tech Supply Co.\nDate: January 15, 2025\nTransaction ID: #TXN-98765\n\nItems:\n1. USB-C Cable (3-pack) - $24.99\n2. Wireless Mouse - $39.99\n3. Laptop Stand - $54.99\n4. HDMI Adapter - $19.99\n\nSubtotal: $139.96\nTax (8.5%): $11.90\nTotal: $151.86\n\nPayment: Visa ending in 4242\n</code></pre>"},{"location":"usage/use-cases/#features_1","title":"Features","text":"<ul> <li>\u2705 Scanned page detection (checks for text layer)</li> <li>\u2705 Language auto-detection</li> <li>\u2705 Image preprocessing (rotation correction, noise reduction)</li> <li>\u2705 Graceful fallback if Tesseract not installed</li> <li>\u2705 Combined with Vision API for maximum accuracy</li> </ul>"},{"location":"usage/use-cases/#use-case-22-semantic-search-smart-document-retrieval","title":"Use Case 22: Semantic Search - Smart Document Retrieval","text":"<p>Complexity: Advanced Type: AI-Powered Search Best For: Finding relevant content in large document collections Version: v0.3.31</p> <p>Feature: Embedding-based semantic search using sentence-transformers</p>"},{"location":"usage/use-cases/#overview_4","title":"Overview","text":"<p>Instead of keyword matching, WYN360 uses AI embeddings to understand the meaning of your query and find semantically similar content, even if exact keywords don't match.</p>"},{"location":"usage/use-cases/#key-features_5","title":"Key Features","text":"<ul> <li>\ud83e\udde0 Semantic Understanding - Finds meaning, not just keywords</li> <li>\ud83d\udcca Cosine Similarity - Ranks results by relevance score</li> <li>\u26a1 Fast Retrieval - Query latency &lt;50ms</li> <li>\ud83d\udcbe Cached Embeddings - Computed once, reused forever</li> <li>\ud83d\udd04 Fallback Support - Uses keyword matching if embeddings fail</li> <li>\ud83d\udcc8 30-50% Better - Significantly improved accuracy vs keywords</li> </ul>"},{"location":"usage/use-cases/#use-case-221-conceptual-search","title":"Use Case 22.1: Conceptual Search","text":"<p>Find content by meaning, not exact words.</p> <p>Traditional Keyword Search: <pre><code>You: Find information about \"machine learning overfitting\"\n[Searches for documents containing \"machine learning\" AND \"overfitting\"]\nResults: 3 matches\n</code></pre></p> <p>Semantic Search: <pre><code>You: Find information about \"machine learning overfitting\"\n[Computes query embedding, matches against document embeddings]\n\nResults (ranked by semantic similarity):\n1. Chapter 3: \"Regularization Techniques\" (similarity: 0.89)\n   \"Preventing models from memorizing training data...\"\n\n2. Section 5.2: \"Cross-Validation Strategies\" (similarity: 0.84)\n   \"Detecting when your model fits noise rather than signal...\"\n\n3. Appendix B: \"Dropout and Early Stopping\" (similarity: 0.81)\n   \"Combat excessive model complexity and poor generalization...\"\n</code></pre></p> <p>Why Better? - Found \"regularization\" (related concept) without keyword match - Understood \"memorizing\" = \"overfitting\" - Ranked by actual relevance, not just keyword frequency</p>"},{"location":"usage/use-cases/#use-case-222-multi-language-search","title":"Use Case 22.2: Multi-Language Search","text":"<p>Search across languages conceptually.</p> <pre><code>You: Find content about \"client authentication mechanisms\"\n\nResults:\n1. Section 4: \"OAuth 2.0 Authorization Flow\" (English)\n2. Chapter 7: \"Autenticaci\u00f3n de Usuarios\" (Spanish)\n3. Appendix: \"JWT Token Validation\" (English)\n\nNote: Found Spanish section because embedding understands\n\"autenticaci\u00f3n\" is semantically similar to \"authentication\"\n</code></pre>"},{"location":"usage/use-cases/#performance","title":"Performance","text":"<ul> <li>Retrieval Quality: +40% accuracy improvement</li> <li>Query Speed: &lt;50ms (cached embeddings)</li> <li>Memory: ~200MB for 10,000 chunks</li> <li>Model: all-MiniLM-L6-v2 (384-dim embeddings)</li> </ul>"},{"location":"usage/use-cases/#use-case-23-multi-document-analysis","title":"Use Case 23: Multi-Document Analysis","text":"<p>Complexity: Advanced Type: Cross-Document Intelligence Best For: Comparing reports, tracking changes, aggregating insights Version: v0.3.34</p> <p>Feature: Query and analyze multiple cached documents simultaneously</p>"},{"location":"usage/use-cases/#overview_5","title":"Overview","text":"<p>Work with multiple documents at once - compare spreadsheets, find information across reports, track changes between versions.</p>"},{"location":"usage/use-cases/#key-features_6","title":"Key Features","text":"<ul> <li>\ud83d\udd0d Unified Search - Search across all cached documents</li> <li>\ud83d\udcca Document Comparison - Side-by-side analysis</li> <li>\ud83d\udd17 Cross-References - Find mentions across documents</li> <li>\ud83d\udce6 Aggregated Summaries - Combined insights from multiple sources</li> <li>\ud83c\udfaf Smart Selection - Auto-select relevant documents</li> </ul>"},{"location":"usage/use-cases/#use-case-231-budget-vs-actual-comparison","title":"Use Case 23.1: Budget vs Actual Comparison","text":"<p>Compare budget projections with actual expenses.</p> <pre><code>You: Compare budget_2024.xlsx and actual_expenses_2024.xlsx\n\nWYN360: [Analyzing both documents]\n\ud83d\udcca Budget vs Actual Comparison (2024):\n\nCategories with Variance:\n1. Marketing\n   - Budgeted: $50,000\n   - Actual: $62,500\n   - Variance: +25% ($12,500 over)\n   - Reason: Additional Q4 campaign\n\n2. Engineering\n   - Budgeted: $200,000\n   - Actual: $185,000\n   - Variance: -7.5% ($15,000 under)\n   - Reason: Delayed hiring in Q3\n\n3. Operations\n   - Budgeted: $80,000\n   - Actual: $81,200\n   - Variance: +1.5% (within tolerance)\n\nOverall: 3% over budget ($153,200 vs $150,000 planned)\n</code></pre>"},{"location":"usage/use-cases/#use-case-232-multi-report-insights","title":"Use Case 23.2: Multi-Report Insights","text":"<p>Find patterns across quarterly reports.</p> <pre><code>You: Find all mentions of \"supply chain issues\" across my Q1-Q4 reports\n\nWYN360: [Searching 4 documents]\n\ud83d\udd17 Cross-Document Search Results:\n\nQ1_Report.docx (3 mentions):\n- Page 5: \"Chip shortage impacting production\"\n- Page 12: \"3-week delay on component delivery\"\n- Page 18: \"Alternative suppliers being evaluated\"\n\nQ2_Report.docx (5 mentions):\n- Page 3: \"Supply chain stabilizing\"\n- Page 9: \"New supplier agreements signed\"\n- ...\n\nQ3_Report.docx (1 mention):\n- Page 15: \"Supply chain fully resolved\"\n\nQ4_Report.docx (0 mentions):\n- No supply chain issues reported\n\nTrend: Issue peaked in Q2, resolved by Q3\n</code></pre>"},{"location":"usage/use-cases/#use-case-233-document-change-tracking","title":"Use Case 23.3: Document Change Tracking","text":"<p>Track what changed between document versions.</p> <pre><code>You: What changed between draft_v1.docx and draft_v2.docx?\n\nWYN360: [Comparing documents]\n\ud83d\udcdd Document Comparison:\n\nSections Added in v2:\n- \"Implementation Timeline\" (pages 8-10)\n- \"Risk Mitigation Strategies\" (pages 15-17)\n\nSections Modified:\n- \"Budget Allocation\": Increased from $100K to $125K\n- \"Team Structure\": Added 2 junior developers\n- \"Success Metrics\": Changed KPIs from 3 to 5\n\nSections Removed:\n- \"Alternative Approaches\" (was pages 12-14 in v1)\n\nOverall: 23% content change, 2,300 words added\n</code></pre>"},{"location":"usage/use-cases/#use-case-24-high-performance-document-processing","title":"Use Case 24: High-Performance Document Processing","text":"<p>Complexity: Advanced Type: Optimization &amp; Efficiency Best For: Large documents, batch processing, production use Version: v0.3.36</p> <p>Feature: Parallel processing, compression, and LRU caching for maximum speed and efficiency</p>"},{"location":"usage/use-cases/#overview_6","title":"Overview","text":"<p>Phase 5.6 performance optimizations make document processing 3-5x faster with 50-70% less storage.</p>"},{"location":"usage/use-cases/#key-features-delivered","title":"Key Features Delivered","text":"<ul> <li>\u26a1 Parallel Chunk Summarization - Process multiple chunks concurrently</li> <li>\ud83d\udddc\ufe0f Gzip Compression - 50-70% storage reduction for cache</li> <li>\ud83d\udd04 LRU Cache Eviction - Keep frequently accessed documents hot</li> <li>\ud83d\udcca Batch Processing - Efficient bulk document analysis</li> <li>\ud83d\ude80 3-5x Speedup - Dramatically faster processing</li> </ul>"},{"location":"usage/use-cases/#use-case-241-bulk-document-processing","title":"Use Case 24.1: Bulk Document Processing","text":"<p>Process multiple large documents efficiently.</p> <p>Before (v0.3.35): <pre><code>You: Process all 10 quarterly reports\n\nWYN360: [Sequential processing]\nProcessing Q1_2024.pdf... (45 seconds)\nProcessing Q2_2024.pdf... (52 seconds)\nProcessing Q3_2024.pdf... (48 seconds)\n...\nTotal time: 8 minutes 15 seconds\n</code></pre></p> <p>After (v0.3.36): <pre><code>You: Process all 10 quarterly reports\n\nWYN360: [Parallel processing with batch_size=10]\nProcessing batch 1 (10 documents)...\n\u2713 All documents processed\n\nTotal time: 2 minutes 30 seconds\nSpeedup: 3.3x faster\nCache size: 45 MB (compressed from 156 MB)\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-242-frequent-access-patterns","title":"Use Case 24.2: Frequent Access Patterns","text":"<p>Optimized caching keeps hot documents instantly available.</p> <pre><code>You: What were my April expenses?\n[First access - processes document]\nResponse time: 8 seconds\n\nYou: How about May expenses?\n[Cache hit - instant retrieval]\nResponse time: 0.3 seconds\n\nYou: Compare April and May\n[Both cached - instant]\nResponse time: 0.4 seconds\n\nCache Stats:\n- Hit rate: 95%\n- Storage: 85 MB (compressed from 298 MB)\n- LRU eviction: Keeping 50 most recent documents\n- Oldest entry: 45 minutes ago\n</code></pre>"},{"location":"usage/use-cases/#performance-metrics","title":"Performance Metrics","text":"Metric Before v0.3.36 After v0.3.36 Improvement Processing Speed Sequential Parallel (batch=10) 3-5x faster Cache Storage Uncompressed JSON Gzip compressed 50-70% smaller Cache Strategy Oldest-first LRU eviction Better hit rate 100-page PDF ~30 seconds ~8 seconds 3.75x faster Cache for 100 docs ~500 MB ~180 MB 64% reduction"},{"location":"usage/use-cases/#commands_3","title":"Commands","text":"Command Purpose Performance Impact <code>/doc_cache_stats</code> View cache statistics See compression savings <code>/clear_doc_cache</code> Clear all or specific cache Free up space <code>regenerate_cache=True</code> Force reprocessing Bypass cache for fresh analysis"},{"location":"usage/use-cases/#use-case-25-authenticated-browsing-automated-login-and-session-management","title":"Use Case 25: Authenticated Browsing - Automated Login and Session Management","text":"<p>Phase: 4 (v0.3.40-v0.3.41) Tools: <code>login_to_website</code>, <code>fetch_website</code>, CredentialManager, SessionManager, BrowserAuth Status: \u2705 Ready to use</p>"},{"location":"usage/use-cases/#overview_7","title":"Overview","text":"<p>WYN360 now supports automated login to websites with secure credential storage and session management. After logging in once, all subsequent requests to that domain are automatically authenticated for 30 minutes.</p> <p>Key Features: - \ud83e\udd16 Automated browser login with form detection - \ud83d\udd10 AES-256-GCM encrypted credential storage - \u23f0 Session cookies with 30-minute TTL - \ud83c\udfaf Automatic session detection and cookie injection - \ud83d\udee1\ufe0f CAPTCHA and 2FA detection - \ud83d\udcca 48/48 tests passing</p>"},{"location":"usage/use-cases/#use-case-251-basic-login-and-authenticated-access","title":"Use Case 25.1: Basic Login and Authenticated Access","text":"<p>Scenario: You want to login to a website and access authenticated content.</p> <p>Steps:</p> <pre><code>You: Login to https://example-site.com with demo_user and SecurePass123!\n\nWYN360: [Launches headless Playwright browser]\n        [Navigates to https://example-site.com]\n        [Detects login form fields]\n        [Fills username: demo_user]\n        [Fills password: ********]\n        [Clicks submit button]\n        [Waits for navigation]\n        [Extracts session cookies]\n        [Saves session with 30-minute TTL]\n        [Encrypts and saves credentials]\n\n        \u2705 Login successful to example-site.com!\n\n        **Session Details:**\n        - Domain: example-site.com\n        - Username: demo_user\n        - Session saved: Yes (30 minutes TTL)\n        - Credentials saved: Yes (encrypted)\n\n        **Next Steps:**\n        Use fetch_website() to access authenticated pages with this session.\n\nYou: Fetch my profile from https://example-site.com/profile\n\nWYN360: [Checks SessionManager for example-site.com]\n        [Found valid session with cookies]\n        [Injects cookies into browser automatically]\n        [Fetches authenticated content]\n\n        \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://example-site.com/profile\n\n        [Your profile content with user-specific data...]\n\nYou: Fetch https://example-site.com/dashboard\n\nWYN360: [Session still valid - auto-injecting cookies]\n\n        \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://example-site.com/dashboard\n\n        [Your dashboard with personalized content...]\n</code></pre> <p>What Happened: 1. \u2705 Automated login with Playwright browser automation 2. \u2705 Form fields detected automatically (username, password, submit) 3. \u2705 Session cookies extracted and saved (30-min TTL) 4. \u2705 Credentials encrypted with AES-256-GCM and stored 5. \u2705 All subsequent fetches to same domain automatically authenticated 6. \u2705 Visual indicator (\ud83d\udd10) shows authenticated requests</p>"},{"location":"usage/use-cases/#use-case-252-session-auto-detection-zero-friction","title":"Use Case 25.2: Session Auto-Detection (Zero Friction)","text":"<p>Scenario: After logging in once, you want to access multiple authenticated pages without re-authenticating.</p> <p>Steps:</p> <pre><code>You: Login to https://example.com with myuser and mypass123\n\nWYN360: \u2705 Login successful to example.com!\n        Session saved: Yes (30 minutes TTL)\n\n[30 seconds later...]\n\nYou: Fetch https://example.com/api/user/settings\n\nWYN360: [Automatically detects saved session for example.com]\n        [Injects cookies without asking]\n\n        \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://example.com/api/user/settings\n\n        [Settings data...]\n\n[5 minutes later...]\n\nYou: Get my notifications from https://example.com/notifications\n\nWYN360: [Session still valid - 25 minutes remaining]\n\n        \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://example.com/notifications\n\n        [Notification data...]\n\n[35 minutes later...]\n\nYou: Fetch https://example.com/profile\n\nWYN360: [Session expired - no saved cookies found]\n\n        \ud83d\udcc4 **Fetched:** https://example.com/profile\n\n        [Public profile or login page - not authenticated]\n\n        \ud83d\udca1 Session has expired. Login again to access authenticated content.\n</code></pre> <p>What Happened: 1. \u2705 Login once, credentials saved for 30 minutes 2. \u2705 All fetches within 30 minutes automatically authenticated 3. \u2705 No need to manually pass cookies or tokens 4. \u2705 Session expires after 30 minutes for security 5. \u2705 Clear visual feedback (\ud83d\udd10 indicator when authenticated)</p>"},{"location":"usage/use-cases/#use-case-253-captcha-detection","title":"Use Case 25.3: CAPTCHA Detection","text":"<p>Scenario: Website has CAPTCHA protection that requires manual completion.</p> <p>Steps:</p> <pre><code>You: Login to https://example.com with user@email.com and password123\n\nWYN360: [Launches browser]\n        [Navigates to URL]\n        [Detects CAPTCHA iframe on page]\n\n        \u274c Login blocked by CAPTCHA\n\n        The website requires CAPTCHA completion:\n        - URL: https://example.com/login\n\n        **Action Required:**\n        Please login manually in a browser to complete the CAPTCHA.\n        Once logged in, you can use the browser's cookies with fetch_website().\n\n        **Alternative:**\n        Some websites allow API keys or tokens instead of browser login.\n        Check the website's developer documentation.\n</code></pre> <p>What Happened: 1. \u2705 Browser detected CAPTCHA on login page 2. \u2705 User notified with clear instructions 3. \u2705 No failed login attempts (CAPTCHA detected before submission) 4. \u274c Manual intervention required for CAPTCHA 5. \ud83d\udca1 Suggestion provided for alternative authentication methods</p>"},{"location":"usage/use-cases/#use-case-254-two-factor-authentication-2fa","title":"Use Case 25.4: Two-Factor Authentication (2FA)","text":"<p>Scenario: Website requires 2FA verification code.</p> <p>Steps:</p> <pre><code>You: Login to https://github.com with myusername and mypassword\n\nWYN360: [Launches browser]\n        [Fills credentials]\n        [Submits login form]\n        [Detects 2FA verification code input]\n\n        \ud83d\udd10 2FA Required\n\n        The website requires two-factor authentication:\n        - URL: https://github.com/login\n\n        **Action Required:**\n        Two-factor authentication must be completed manually.\n        Please login through a browser to complete 2FA verification.\n\n        **After Manual Login:**\n        You can export cookies from your browser and use them with fetch_website().\n</code></pre> <p>What Happened: 1. \u2705 Initial login succeeded (username/password accepted) 2. \u2705 2FA prompt detected automatically 3. \u2705 User notified with clear instructions 4. \u274c Automated 2FA not supported (requires manual verification) 5. \ud83d\udca1 Alternative approach suggested (export browser cookies)</p>"},{"location":"usage/use-cases/#use-case-255-multi-site-session-management","title":"Use Case 25.5: Multi-Site Session Management","text":"<p>Scenario: You're working with multiple websites and want to manage sessions for each.</p> <p>Steps:</p> <pre><code>You: Login to https://siteA.com with userA and passA\n\nWYN360: \u2705 Login successful to siteA.com!\n        Session saved: Yes (30 minutes TTL)\n\nYou: Login to https://siteB.com with userB and passB\n\nWYN360: \u2705 Login successful to siteB.com!\n        Session saved: Yes (30 minutes TTL)\n\nYou: Login to https://siteC.com with userC and passC\n\nWYN360: \u2705 Login successful to siteC.com!\n        Session saved: Yes (30 minutes TTL)\n\nYou: Fetch https://siteA.com/dashboard\n\nWYN360: \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://siteA.com/dashboard\n        [SiteA dashboard content...]\n\nYou: Fetch https://siteB.com/api/data\n\nWYN360: \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://siteB.com/api/data\n        [SiteB API data...]\n\nYou: Fetch https://siteC.com/profile\n\nWYN360: \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://siteC.com/profile\n        [SiteC profile content...]\n</code></pre> <p>What Happened: 1. \u2705 Three separate logins to three different domains 2. \u2705 Each session stored independently with 30-min TTL 3. \u2705 Domain-based session matching (siteA.com \u2260 siteB.com) 4. \u2705 All fetches automatically use correct session 5. \u2705 Sessions expire independently (30 min per domain)</p>"},{"location":"usage/use-cases/#use-case-256-testing-and-debugging-authentication","title":"Use Case 25.6: Testing and Debugging Authentication","text":"<p>Scenario: You want to test login functionality and see detailed feedback.</p> <p>Steps:</p> <pre><code>You: Login to https://example.com with testuser and wrongpassword\n\nWYN360: [Launches browser]\n        [Fills credentials]\n        [Submits form]\n        [Checks for error messages on page]\n\n        \u274c Login failed\n\n        **Details:** Incorrect username or password.\n\n        **Possible Reasons:**\n        - Incorrect username or password\n        - Website structure not recognized\n        - Login form not detected\n\n        Please verify credentials and try again.\n\nYou: Login to https://example.com with testuser and correctpassword\n\nWYN360: \u2705 Login successful to example.com!\n\nYou: Fetch https://example.com/api/test\n\nWYN360: \ud83d\udcc4 **Fetched \ud83d\udd10 (authenticated):** https://example.com/api/test\n\n        {\"authenticated\": true, \"user\": \"testuser\", \"token\": \"...\"}\n\nYou: Fetch https://differentsite.com/public\n\nWYN360: [No session for differentsite.com - fetching without auth]\n\n        \ud83d\udcc4 **Fetched:** https://differentsite.com/public\n\n        [Public content - not authenticated]\n</code></pre> <p>What Happened: 1. \u2705 First login attempt failed - clear error message 2. \u2705 Second login attempt succeeded 3. \u2705 Authenticated fetch shows \ud83d\udd10 indicator 4. \u2705 Fetch to different domain correctly shows no authentication 5. \ud83d\udca1 Clear feedback for debugging authentication issues</p>"},{"location":"usage/use-cases/#storage-and-security","title":"Storage and Security","text":"<p>Where are credentials stored? <pre><code>~/.wyn360/\n\u251c\u2500\u2500 credentials/\n\u2502   \u251c\u2500\u2500 .keyfile          # AES-256 encryption key (0600)\n\u2502   \u2514\u2500\u2500 vault.enc         # Encrypted credentials\n\u251c\u2500\u2500 sessions/\n\u2502   \u251c\u2500\u2500 example_com.session.json     # 30-min TTL\n\u2502   \u251c\u2500\u2500 testsite_com.session.json\n\u2502   \u2514\u2500\u2500 github_com.session.json\n\u2514\u2500\u2500 logs/\n    \u2514\u2500\u2500 auth_audit.log    # Audit log (no sensitive data)\n</code></pre></p> <p>Security Features: - \ud83d\udd10 AES-256-GCM encryption for credentials - \ud83d\udd11 Per-user encryption key from system entropy - \ud83d\udd12 File permissions: 0600 (user read/write only) - \u23f0 Session TTL: 30 minutes (automatic expiration) - \ud83d\udcdd Audit logging (no sensitive data logged) - \ud83d\udeab No plain text passwords ever stored</p> <p>Check what's saved: <pre><code># Credentials are encrypted in vault.enc (cannot be read directly)\nls ~/.wyn360/credentials/\n\n# Sessions are JSON but contain cookies (should not be shared)\nls ~/.wyn360/sessions/\n\n# Audit log shows access without sensitive data\ncat ~/.wyn360/logs/auth_audit.log\n</code></pre></p>"},{"location":"usage/use-cases/#troubleshooting","title":"Troubleshooting","text":"<p>Issue: \"Could not detect login form\" <pre><code>Cause: Website has non-standard login form\nSolution:\n  - Check if login URL is correct\n  - Try accessing login page directly (not homepage)\n  - Some sites use JavaScript-heavy login (may not work)\n</code></pre></p> <p>Issue: \"Login failed (incorrect credentials)\" <pre><code>Cause: Wrong username/password or form not detected correctly\nSolution:\n  - Verify credentials are correct\n  - Try logging in manually in browser first\n  - Check if website uses email vs username\n</code></pre></p> <p>Issue: \"CAPTCHA detected\" <pre><code>Cause: Website uses CAPTCHA for bot protection\nSolution:\n  - Login manually in browser\n  - Export browser cookies and use them\n  - Check if website offers API keys\n</code></pre></p> <p>Issue: \"Session expired\" <pre><code>Cause: 30-minute TTL has passed\nSolution:\n  - Simply login again\n  - Sessions auto-expire for security\n  - Credentials are saved, so re-login is quick\n</code></pre></p> <p>Issue: \"Already authenticated to domain\" <pre><code>Cause: Valid session already exists\nSolution:\n  - This is actually success! Just use fetch_website\n  - To force re-login, clear the session first:\n    \"Clear cache for https://example.com\"\n</code></pre></p>"},{"location":"usage/use-cases/#technical-details_1","title":"Technical Details","text":"<p>Form Detection Selectors: - Username: <code>input[type=\"email\"]</code>, <code>input[name*=\"user\"]</code>, <code>input[id*=\"user\"]</code> - Password: <code>input[type=\"password\"]</code>, <code>input[name=\"password\"]</code> - Submit: <code>button[type=\"submit\"]</code>, <code>button:has-text(\"login\")</code></p> <p>CAPTCHA Detection: - Checks for: <code>div[class*=\"captcha\"]</code>, <code>iframe[src*=\"recaptcha\"]</code> - Notifies user if found before attempting login</p> <p>2FA Detection: - Checks for: <code>input[name*=\"code\"]</code>, <code>input[name*=\"otp\"]</code>, <code>text=\"verification code\"</code> - Notifies user if found after initial login</p> <p>Session Format: <pre><code>{\n  \"domain\": \"example.com\",\n  \"cookies\": [\n    {\"name\": \"session_id\", \"value\": \"...\", \"domain\": \"example.com\"},\n    {\"name\": \"auth_token\", \"value\": \"...\", \"domain\": \"example.com\"}\n  ],\n  \"created_at\": 1700000000.0,\n  \"expires_at\": 1700001800.0,\n  \"ttl\": 1800\n}\n</code></pre></p>"},{"location":"usage/use-cases/#best-practices","title":"Best Practices","text":"<p>1. Use Specific Login URLs: <pre><code>\u2705 Good: \"Login to https://site.com/login with user and pass\"\n\u274c Bad:  \"Login to https://site.com with user and pass\" (homepage, not login page)\n</code></pre></p> <p>2. Test Authentication: <pre><code>\u2705 After login, try fetching authenticated content to verify\n\u2705 Check for \ud83d\udd10 indicator in fetch response\n</code></pre></p> <p>3. Handle Errors Gracefully: <pre><code>\u2705 If CAPTCHA detected, acknowledge and use alternative methods\n\u2705 If 2FA required, complete manually then continue\n</code></pre></p> <p>4. Session Management: <pre><code>\u2705 Sessions auto-expire after 30 minutes (security)\n\u2705 Credentials are saved, so re-login is quick\n\u2705 Each domain has independent session\n</code></pre></p> <p>5. Security: <pre><code>\u2705 Never share ~/.wyn360/credentials/ or ~/.wyn360/sessions/ directories\n\u2705 Credentials are encrypted with AES-256-GCM\n\u2705 File permissions are 0600 (user read/write only)\n</code></pre></p>"},{"location":"usage/use-cases/#limitations","title":"Limitations","text":"<p>What Works: - \u2705 Standard username/password forms - \u2705 Email + password forms - \u2705 Session cookie extraction - \u2705 Multiple domain sessions - \u2705 Automatic session reuse</p> <p>What Doesn't Work (Yet): - \u274c CAPTCHA completion (requires manual) - \u274c 2FA/MFA completion (requires manual) - \u274c OAuth flows (Google/Facebook login) - \u274c SAML/SSO authentication - \u274c JavaScript-heavy custom login widgets</p> <p>Workarounds: - For CAPTCHA/2FA: Login manually, export browser cookies - For OAuth: Use API keys/tokens instead - For complex flows: Use direct API authentication</p>"},{"location":"usage/use-cases/#use-case-26-enhanced-browser-authentication-debug-mode-and-troubleshooting-phase-44","title":"Use Case 26: Enhanced Browser Authentication - Debug Mode and Troubleshooting (Phase 4.4)","text":"<p>Phase: 4.4 - Enhanced Form Detection Features: Debug mode, intelligent URL discovery, fuzzy matching, manual selectors Version: v0.3.43</p>"},{"location":"usage/use-cases/#overview_8","title":"Overview","text":"<p>Phase 4.4 dramatically improves browser authentication success rates with enhanced form detection, debug mode, and fallback strategies. This use case shows you how to use these powerful troubleshooting tools.</p> <p>Test Coverage: Phase 4.4 enhanced capabilities (automatic login improvements)</p>"},{"location":"usage/use-cases/#use-case-261-debug-mode-see-whats-happening","title":"Use Case 26.1: Debug Mode - See What's Happening","text":"<p>Scenario: Login fails and you want to see exactly what went wrong.</p> <p>Steps:</p> <p>Enable debug mode before logging in: <pre><code>export WYN360_BROWSER_DEBUG=true\nwyn360 \"login to http://wyn360search.com with your_username/your_password\"\n</code></pre></p> <p>What Happens:</p> <pre><code>You: login to http://wyn360search.com with your_username/your_password\n\nWYN360: [DEBUG] Trying login URL discovery...\n        [DEBUG] Testing: http://wyn360search.com/login\n        [DEBUG] Testing: http://wyn360search.com/signin\n        [DEBUG] Testing: http://wyn360search.com/auth\n        [DEBUG] Found login page at: http://wyn360search.com/login\n\n        [Launches Playwright browser]\n        [Navigates to login page]\n        [Saves screenshot: 1_initial_page.png]\n\n        [DEBUG] Waiting for form elements to load...\n        [DEBUG] Form elements became visible\n        [Saves screenshot: 2_after_wait.png]\n        [Saves HTML: page_content.html]\n\n        [DEBUG] Enhanced form detection starting...\n        [DEBUG] Analyzing ALL input elements...\n        [DEBUG] Found 5 input fields on page\n        [DEBUG] Username candidates: 2 (best score: 3)\n        [DEBUG] Password field: found\n        [Saves JSON: form_detection.json]\n\n        [DEBUG] Form detected - username: #login_email, password: #login_password, submit: #login_submit\n\n        [Fills username field]\n        [Saves screenshot: 3_username_filled.png]\n\n        [Fills password field]\n        [Saves screenshot: 4_password_filled.png]\n\n        [Clicks submit button]\n        [Saves screenshot: 5_form_submitted.png]\n\n        \u2705 Login successful to wyn360search.com!\n\n        Session Details:\n        - Domain: wyn360search.com\n        - Username: your_username\n        - Session saved: Yes (30 minutes TTL)\n        - Credentials saved: Yes (encrypted)\n</code></pre> <p>Debug Files Created: <pre><code>~/.wyn360/debug/browser_auth/\n\u251c\u2500\u2500 1699900000_1_initial_page.png\n\u251c\u2500\u2500 1699900000_2_after_wait.png\n\u251c\u2500\u2500 1699900000_3_username_filled.png\n\u251c\u2500\u2500 1699900000_4_password_filled.png\n\u251c\u2500\u2500 1699900000_5_form_submitted.png\n\u251c\u2500\u2500 1699900000_page_content.html\n\u2514\u2500\u2500 1699900000_form_detection.json\n</code></pre></p> <p>Check Debug Output: <pre><code>ls -la ~/.wyn360/debug/browser_auth/\n\n# View screenshots\nopen ~/.wyn360/debug/browser_auth/1699900000_1_initial_page.png\n\n# View HTML\ncat ~/.wyn360/debug/browser_auth/1699900000_page_content.html\n\n# View form detection results\ncat ~/.wyn360/debug/browser_auth/1699900000_form_detection.json\n</code></pre></p> <p>form_detection.json Contents: <pre><code>{\n  \"username_selector\": \"#login_email\",\n  \"password_selector\": \"#login_password\",\n  \"submit_selector\": \"#login_submit\",\n  \"username_candidates_count\": 2,\n  \"password_found\": true\n}\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-262-intelligent-url-discovery","title":"Use Case 26.2: Intelligent URL Discovery","text":"<p>Scenario: You provide just the domain, and the system finds the login page automatically.</p> <p>Steps:</p> <pre><code>You: login to http://example.com with myuser/mypass\n\nWYN360: [Tries 12 common login URLs automatically]\n\n        \ud83d\udd0d Trying URL discovery:\n        - http://example.com/login \u274c (404)\n        - http://example.com/signin \u274c (404)\n        - http://example.com/auth \u2705 (login form found!)\n\n        [Navigates to: http://example.com/auth]\n        [Detects login form]\n        [Fills credentials]\n        [Submits form]\n\n        \u2705 Login successful to example.com!\n\n        Note: Automatically discovered login page at /auth\n</code></pre> <p>URLs Tried (in order): 1. <code>/login</code> 2. <code>/signin</code> 3. <code>/sign-in</code> 4. <code>/auth</code> 5. <code>/authenticate</code> 6. <code>/account/login</code> 7. <code>/user/login</code> 8. <code>/accounts/signin</code> 9. <code>/login.php</code> 10. <code>/signin.php</code> 11. <code>/login.html</code> 12. <code>/signin.html</code></p> <p>Fallback Strategy: If no common URL works, the system: 1. Searches homepage for \"Login\" links 2. Follows the link 3. Validates it has a login form 4. Uses that page</p>"},{"location":"usage/use-cases/#use-case-263-enhanced-form-detection-with-fuzzy-matching","title":"Use Case 26.3: Enhanced Form Detection with Fuzzy Matching","text":"<p>Scenario: Website uses non-standard field names that traditional detection misses.</p> <p>Example Website HTML: <pre><code>&lt;form&gt;\n  &lt;input type=\"text\" name=\"user_identifier\" id=\"account_email\" placeholder=\"Your Email\" /&gt;\n  &lt;input type=\"password\" name=\"secret_key\" id=\"account_pwd\" /&gt;\n  &lt;button class=\"submit-login-btn\"&gt;Enter&lt;/button&gt;\n&lt;/form&gt;\n</code></pre></p> <p>Traditional Detection: \u274c FAILS - Looks for <code>input[name=\"username\"]</code> \u2192 not found - Looks for <code>input[name=\"email\"]</code> \u2192 not found - Looks for <code>input[id=\"username\"]</code> \u2192 not found</p> <p>Enhanced Detection (Phase 4.4): \u2705 SUCCEEDS <pre><code>Analyzing ALL inputs:\n\nInput 1:\n  type=\"text\"\n  name=\"user_identifier\"  \u2190 keyword: \"user\" \u2713\n  id=\"account_email\"      \u2190 keyword: \"email\" \u2713\n  placeholder=\"Your Email\" \u2190 keyword: \"email\" \u2713\n  \u2192 Confidence score: 3\n  \u2192 Selected as USERNAME field\n\nInput 2:\n  type=\"password\"         \u2190 exact match \u2713\n  name=\"secret_key\"\n  id=\"account_pwd\"\n  \u2192 Selected as PASSWORD field\n\nButton:\n  class=\"submit-login-btn\" \u2190 keyword: \"login\" \u2713, \"submit\" \u2713\n  \u2192 Selected as SUBMIT button\n</code></pre></p> <p>Result: <pre><code>You: login to http://non-standard-site.com with user/pass\n\nWYN360: [Enhanced form detection activated]\n        [Analyzing all 15 input elements...]\n        [Found username field: #account_email (confidence: 3)]\n        [Found password field: #account_pwd]\n        [Found submit button: .submit-login-btn]\n\n        \u2705 Login successful!\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-264-manual-selector-override-when-all-else-fails","title":"Use Case 26.4: Manual Selector Override (When All Else Fails)","text":"<p>Scenario: Automatic detection fails even with enhancements. You need manual control.</p> <p>Step 1: Inspect the Page</p> <ol> <li>Visit the login page in Chrome/Firefox</li> <li>Press F12 \u2192 Elements tab</li> <li>Find the username field and note its selector:</li> <li>Right-click on the input \u2192 Copy \u2192 Copy selector</li> <li> <p>Example: <code>#user_login</code></p> </li> <li> <p>Find the password field selector:</p> </li> <li> <p>Example: <code>#user_pass</code></p> </li> <li> <p>Find the submit button selector:</p> </li> <li>Example: <code>#wp-submit</code></li> </ol> <p>Step 2: Login with Manual Selectors</p> <pre><code>You: login to http://difficult-site.com with admin/password123 using selectors #user_login, #user_pass, #wp-submit\n\nWYN360: [Bypassing automatic form detection]\n        [Using manual selectors provided]\n\n        Selectors:\n        - Username: #user_login\n        - Password: #user_pass\n        - Submit: #wp-submit\n\n        [Navigates to page]\n        [Fills #user_login with \"admin\"]\n        [Fills #user_pass with \"********\"]\n        [Clicks #wp-submit]\n\n        \u2705 Login successful to difficult-site.com! (manual selectors)\n\n        Session Details:\n        - Domain: difficult-site.com\n        - Username: admin\n        - Selectors used:\n          - Username: #user_login\n          - Password: #user_pass\n          - Submit: #wp-submit\n        - Session saved: Yes (30 minutes TTL)\n\n        Next Steps:\n        Use fetch_website() to access authenticated pages.\n</code></pre> <p>Alternative Selector Formats:</p> <pre><code># Using CSS selectors with classes\n\"using selectors .username-input, .password-input, .login-button\"\n\n# Using attribute selectors\n\"using selectors input[name='user'], input[name='pass'], button[type='submit']\"\n\n# Without submit button (will press Enter)\n\"using selectors #email, #pwd\"\n\n# Complex selectors\n\"using selectors form#login input[type='email'], form#login input[type='password'], form#login button\"\n</code></pre>"},{"location":"usage/use-cases/#use-case-265-debugging-a-failed-login","title":"Use Case 26.5: Debugging a Failed Login","text":"<p>Scenario: Login keeps failing and you want to understand why.</p> <p>Enable debug mode and analyze:</p> <pre><code>export WYN360_BROWSER_DEBUG=true\nwyn360 \"login to http://problematic-site.com with user/pass\"\n</code></pre> <p>Failure Output:</p> <pre><code>WYN360: [DEBUG] Testing login URLs...\n        [DEBUG] No common login URL found\n        [DEBUG] Searching homepage for login links...\n        [DEBUG] Found link: /members/signin\n        [DEBUG] Testing: http://problematic-site.com/members/signin\n        [DEBUG] Login form detected!\n\n        [Navigates to: http://problematic-site.com/members/signin]\n        [Saves screenshot: 1_initial_page.png]\n\n        [DEBUG] Waiting for form elements (10s timeout)...\n        [DEBUG] Form elements became visible\n        [Saves screenshot: 2_after_wait.png]\n\n        [DEBUG] Enhanced form detection starting...\n        [DEBUG] Found 12 input elements\n        [DEBUG] Username candidates: 0 \u2190 PROBLEM!\n        [DEBUG] Password field: found\n        [Saves JSON: form_detection.json]\n\n        \u274c Could not detect login form.\n\n        Possible reasons:\n        - Form uses non-standard elements\n        - JavaScript hasn't finished loading\n        - Login requires interaction (e.g., clicking a button to show form)\n\n        Solutions:\n        1. Try specifying the exact login URL (e.g., /login, /signin)\n        2. Use manual selector override: login_with_selectors()\n        3. Inspect the page and provide CSS selectors\n\n        Debug files saved to:\n        ~/.wyn360/debug/browser_auth/\n        - Screenshots: 1699900000_*.png\n        - HTML: 1699900000_page_content.html\n        - Form detection: 1699900000_form_detection.json\n</code></pre> <p>Analyze Debug Files:</p> <pre><code># Check what the page looked like\nopen ~/.wyn360/debug/browser_auth/1699900000_1_initial_page.png\n\n# Check HTML structure\ncat ~/.wyn360/debug/browser_auth/1699900000_page_content.html | grep -i \"input\"\n\n# Check what was detected\ncat ~/.wyn360/debug/browser_auth/1699900000_form_detection.json\n</code></pre> <p>form_detection.json shows the problem: <pre><code>{\n  \"username_selector\": null,          \u2190 No username field found!\n  \"password_selector\": \"#pass\",\n  \"submit_selector\": \"#login-btn\",\n  \"username_candidates_count\": 0,     \u2190 Zero candidates\n  \"password_found\": true\n}\n</code></pre></p> <p>Solution: Check HTML and find that username field is hidden in a modal: <pre><code>&lt;!-- Username field is in a modal dialog --&gt;\n&lt;div id=\"login-modal\" style=\"display:none\"&gt;\n  &lt;input id=\"username-field\" type=\"text\" /&gt;\n  &lt;input id=\"password-field\" type=\"password\" /&gt;\n&lt;/div&gt;\n</code></pre></p> <p>Fix: Use manual selectors after clicking the modal: <pre><code># First, you'd need to manually open the modal, or\n# Use manual selectors once modal is visible\nwyn360 \"login using selectors #username-field, #password-field\"\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-266-testing-different-websites","title":"Use Case 26.6: Testing Different Websites","text":"<p>Common Website Types and Success Rates:</p> Website Type Phase 4.3 Phase 4.4 Improvement Standard Forms 90% 98% +8% React/Vue/Angular 40% 90% +50% Custom Forms 50% 85% +35% WordPress 95% 99% +4% Django 85% 95% +10% Non-Standard 30% 75% +45% <p>Test Examples:</p> <p>GitHub (Standard Form): <pre><code>wyn360 \"login to https://github.com/login with myuser/mypass\"\n# \u2705 Works perfectly (standard form)\n</code></pre></p> <p>React SPA: <pre><code>wyn360 \"login to https://example-react-app.com with user/pass\"\n# \u2705 Now works with dynamic content waiting (Phase 4.4.2)\n</code></pre></p> <p>Custom WordPress: <pre><code>wyn360 \"login to https://myblog.wordpress.com/wp-login.php with admin/pass\"\n# \u2705 Detects WordPress form patterns\n</code></pre></p> <p>Complex Custom Site: <pre><code>export WYN360_BROWSER_DEBUG=true\nwyn360 \"login to https://custom-site.com with user/pass\"\n# May need manual selectors, but debug mode shows you what to use\n</code></pre></p>"},{"location":"usage/use-cases/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"usage/use-cases/#problem-1-could-not-detect-login-form","title":"Problem 1: \"Could not detect login form\"","text":"<p>Cause: Form uses non-standard elements or hidden fields</p> <p>Solution 1: Enable debug mode and inspect screenshots <pre><code>export WYN360_BROWSER_DEBUG=true\nwyn360 \"login to http://site.com with user/pass\"\nls ~/.wyn360/debug/browser_auth/\n</code></pre></p> <p>Solution 2: Try specifying exact login URL <pre><code>wyn360 \"login to http://site.com/signin with user/pass\"\n</code></pre></p> <p>Solution 3: Use manual selectors <pre><code># Inspect page first, then:\nwyn360 \"login using selectors #user, #pass, #submit\"\n</code></pre></p>"},{"location":"usage/use-cases/#problem-2-timeout-loading-page","title":"Problem 2: \"Timeout loading page\"","text":"<p>Cause: Slow website or network issues</p> <p>Solution: The default timeout is 30 seconds. The site might be down or very slow.</p>"},{"location":"usage/use-cases/#problem-3-captcha-detected","title":"Problem 3: \"CAPTCHA detected\"","text":"<p>Cause: Website requires CAPTCHA completion</p> <p>Solution: Currently unsupported. Use interactive browser mode (Phase 4.6, coming soon) or login manually and export cookies.</p>"},{"location":"usage/use-cases/#problem-4-2fa-required","title":"Problem 4: \"2FA required\"","text":"<p>Cause: Website requires two-factor authentication</p> <p>Solution: Phase 4.4 detects this. Complete 2FA manually in a browser, then export session cookies.</p>"},{"location":"usage/use-cases/#problem-5-debug-mode-creates-too-many-files","title":"Problem 5: Debug mode creates too many files","text":"<p>Solution: Clear debug directory periodically <pre><code>rm -rf ~/.wyn360/debug/browser_auth/*\n</code></pre></p> <p>Or disable debug mode: <pre><code>unset WYN360_BROWSER_DEBUG\n</code></pre></p>"},{"location":"usage/use-cases/#advanced-debug-mode-usage","title":"Advanced Debug Mode Usage","text":"<p>Custom Debug Workflow:</p> <pre><code># 1. Enable debug mode\nexport WYN360_BROWSER_DEBUG=true\n\n# 2. Attempt login\nwyn360 \"login to http://site.com with user/pass\"\n\n# 3. Check what happened\ncd ~/.wyn360/debug/browser_auth/\n\n# 4. View initial page\nopen 1699900000_1_initial_page.png\n\n# 5. Check HTML structure\ncat 1699900000_page_content.html | grep -A5 \"input\"\n\n# 6. See what was detected\ncat 1699900000_form_detection.json | jq .\n\n# 7. Find correct selectors manually\ngrep -i \"username\\|email\\|user\" 1699900000_page_content.html\ngrep -i \"password\\|pass\" 1699900000_page_content.html\n\n# 8. Try again with manual selectors\nwyn360 \"login using selectors #found-user-id, #found-pass-id\"\n\n# 9. Disable debug mode when done\nunset WYN360_BROWSER_DEBUG\n</code></pre> <p>Debug Output Interpretation:</p> <p>Screenshot Sequence: 1. <code>1_initial_page.png</code> - Page right after navigation 2. <code>2_after_wait.png</code> - After waiting for JavaScript 3. <code>3_username_filled.png</code> - After filling username 4. <code>4_password_filled.png</code> - After filling password 5. <code>5_form_submitted.png</code> - After clicking submit</p> <p>If form detection fails: - <code>form_detection_failed.png</code> - Shows the problematic page - <code>page_content.html</code> - Full HTML for manual inspection - <code>form_detection.json</code> - What the system tried to detect</p>"},{"location":"usage/use-cases/#best-practices-for-phase-44","title":"Best Practices for Phase 4.4","text":"<ol> <li>Always try automatic detection first</li> <li>Phase 4.4 improvements handle 90%+ of websites</li> <li> <p>Only use manual selectors as a last resort</p> </li> <li> <p>Use debug mode for troubleshooting</p> </li> <li>Enable it when login fails</li> <li>Inspect screenshots to understand what happened</li> <li> <p>Check JSON to see what was detected</p> </li> <li> <p>Provide specific login URLs when possible</p> </li> <li><code>https://site.com/login</code> is better than <code>https://site.com</code></li> <li> <p>Helps skip the discovery phase</p> </li> <li> <p>Keep debug files for learning</p> </li> <li>Review successful login screenshots</li> <li>Understand form detection patterns</li> <li> <p>Build a mental model of how detection works</p> </li> <li> <p>Report issues with debug output</p> </li> <li>If a site consistently fails, share debug files</li> <li>Helps improve future detection algorithms</li> </ol>"},{"location":"usage/use-cases/#whats-new-in-phase-44","title":"What's New in Phase 4.4","text":"Feature Before After Benefit URL Discovery Manual URL required 12 common paths tried Auto-finds login pages Dynamic Content Static detection only 10s wait + settle Handles React/Vue/Angular Form Detection 11 selectors Fuzzy match ALL inputs 95%+ detection rate Debug Mode No visibility 8 screenshots + HTML + JSON Easy troubleshooting Manual Override Not available Custom selectors Ultimate fallback"},{"location":"usage/use-cases/#summary","title":"Summary","text":"<p>Phase 4.4 gives you: - \u2705 90%+ login success rate (up from 60%) - \u2705 Complete visibility with debug mode - \u2705 Automatic login page discovery - \u2705 Dynamic content support - \u2705 Manual control when needed</p> <p>When to use what:</p> Situation Solution First attempt Just try normal login Login fails Enable debug mode Need to understand why Check debug screenshots/HTML Non-standard form Use manual selectors Testing new site Use debug mode from start <p>If you run into issues or have questions:</p> <ol> <li>Ask the agent: WYN360 can explain its own capabilities</li> <li>Check GitHub: https://github.com/yiqiao-yin/wyn360-cli</li> <li>Read the README: Basic setup and usage</li> <li>Report issues: GitHub Issues page</li> </ol>"},{"location":"usage/use-cases/#use-case-27-aws-bedrock-authentication-using-aws-credentials-v0345","title":"Use Case 27: AWS Bedrock Authentication - Using AWS Credentials (v0.3.45)","text":"<p>What's New: WYN360 now supports AWS Bedrock as an alternative to direct Anthropic API authentication. This allows you to use AWS credentials and billing instead of Anthropic API keys.</p>"},{"location":"usage/use-cases/#authentication-methods","title":"Authentication Methods","text":"<p>WYN360 supports two authentication methods - you can choose whichever fits your needs:</p>"},{"location":"usage/use-cases/#method-1-anthropic-api-default","title":"Method 1: Anthropic API (Default)","text":"<pre><code>export ANTHROPIC_API_KEY=\"sk-ant-xxxxx\"\nwyn360 \"write a script to analyze data\"\n</code></pre> <p>When to use: - You have an Anthropic API account - You want direct Anthropic billing - Simple setup with just one environment variable</p>"},{"location":"usage/use-cases/#method-2-aws-bedrock","title":"Method 2: AWS Bedrock","text":"<pre><code># Set AWS credentials\nexport AWS_ACCESS_KEY_ID=\"AKIA...\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx...\"\nexport AWS_SESSION_TOKEN=\"xxx...\"  # Optional - for temporary credentials\n\n# Enable Bedrock mode\nexport CLAUDE_CODE_USE_BEDROCK=1\n\n# Optional: Customize region and model\nexport AWS_REGION=\"us-west-2\"  # Default: us-east-1\nexport ANTHROPIC_MODEL=\"us.anthropic.claude-sonnet-4-20250514-v1:0\"\n\n# Use WYN360\nwyn360 \"write a script to analyze data\"\n</code></pre> <p>Output: <pre><code>\ud83c\udf29\ufe0f  AWS Bedrock mode enabled\n\ud83d\udce1 Region: us-west-2\n\ud83e\udd16 Model: us.anthropic.claude-sonnet-4-20250514-v1:0\n\nWYN360: I'll create a Python script to analyze data.csv...\n</code></pre></p> <p>When to use: - You have AWS Bedrock access - You want AWS billing instead of Anthropic - You're using AWS IAM roles/policies - You have temporary AWS credentials (STS) - You want to use AWS region-specific deployments</p>"},{"location":"usage/use-cases/#use-case-271-basic-aws-bedrock-setup","title":"Use Case 27.1: Basic AWS Bedrock Setup","text":"<p>Scenario: You have an AWS account with Bedrock access and want to use WYN360 with AWS credentials.</p> <p>Step 1: Get AWS Credentials</p> <pre><code># Option A: Use permanent credentials\nexport AWS_ACCESS_KEY_ID=\"your_aws_access_key_id\"\nexport AWS_SECRET_ACCESS_KEY=\"your_aws_secret_access_key\"\n\n# Option B: Use temporary credentials (STS)\nexport AWS_ACCESS_KEY_ID=\"your_temp_aws_access_key_id\"\nexport AWS_SECRET_ACCESS_KEY=\"your_aws_secret_access_key\"\nexport AWS_SESSION_TOKEN=\"your_aws_session_token\"\n</code></pre> <p>Step 2: Enable Bedrock Mode</p> <pre><code>export CLAUDE_CODE_USE_BEDROCK=1\n</code></pre> <p>Step 3: Use WYN360</p> <pre><code>wyn360 \"create a data processing pipeline\"\n</code></pre> <p>Result: WYN360 uses AWS Bedrock for all API calls, billed to your AWS account.</p>"},{"location":"usage/use-cases/#use-case-272-using-aws-iam-roles-ec2ecslambda","title":"Use Case 27.2: Using AWS IAM Roles (EC2/ECS/Lambda)","text":"<p>Scenario: You're running WYN360 on AWS infrastructure with IAM roles.</p> <p>Required IAM Policy: <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"bedrock:InvokeModel\",\n        \"bedrock:InvokeModelWithResponseStream\"\n      ],\n      \"Resource\": \"arn:aws:bedrock:*::foundation-model/anthropic.claude-*\"\n    }\n  ]\n}\n</code></pre></p> <p>Setup: <pre><code># No need to set AWS_ACCESS_KEY_ID or AWS_SECRET_ACCESS_KEY\n# boto3 automatically uses the instance IAM role\n\n# Just enable Bedrock mode\nexport CLAUDE_CODE_USE_BEDROCK=1\n\nwyn360 \"analyze system logs\"\n</code></pre></p> <p>Supported AWS Services: - EC2 instances with IAM instance profiles - ECS tasks with task roles - Lambda functions with execution roles - CodeBuild projects - SageMaker notebooks</p>"},{"location":"usage/use-cases/#use-case-273-custom-aws-region","title":"Use Case 27.3: Custom AWS Region","text":"<p>Scenario: You want to use a specific AWS region for lower latency or compliance.</p> <p>Available Regions: - <code>us-east-1</code> (Default - US East, Virginia) - <code>us-west-2</code> (US West, Oregon) - <code>ap-southeast-1</code> (Asia Pacific, Singapore) - <code>ap-northeast-1</code> (Asia Pacific, Tokyo) - <code>eu-central-1</code> (Europe, Frankfurt)</p> <p>Check AWS Bedrock regions for the latest availability.</p> <p>Setup: <pre><code>export AWS_ACCESS_KEY_ID=\"xxx\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\nexport CLAUDE_CODE_USE_BEDROCK=1\nexport AWS_REGION=\"eu-central-1\"  # Europe region\n\nwyn360 \"process EU customer data\"\n</code></pre></p> <p>Output: <pre><code>\ud83c\udf29\ufe0f  AWS Bedrock mode enabled\n\ud83d\udce1 Region: eu-central-1\n\ud83e\udd16 Model: us.anthropic.claude-sonnet-4-20250514-v1:0\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-274-custom-model-selection","title":"Use Case 27.4: Custom Model Selection","text":"<p>Scenario: You want to use a specific Claude model available in AWS Bedrock.</p> <p>Available Bedrock Models: - <code>us.anthropic.claude-sonnet-4-20250514-v1:0</code> - Latest Sonnet - <code>anthropic.claude-3-5-sonnet-20241022-v2:0</code> - Sonnet 3.5 - <code>anthropic.claude-3-opus-20240229-v1:0</code> - Opus (most capable) - <code>anthropic.claude-3-haiku-20240307-v1:0</code> - Haiku (fastest, cheapest)</p> <p>Setup: <pre><code>export AWS_ACCESS_KEY_ID=\"xxx\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\nexport CLAUDE_CODE_USE_BEDROCK=1\nexport ANTHROPIC_MODEL=\"anthropic.claude-3-opus-20240229-v1:0\"\n\nwyn360 \"write complex machine learning code\"\n</code></pre></p> <p>Output: <pre><code>\ud83c\udf29\ufe0f  AWS Bedrock mode enabled\n\ud83d\udce1 Region: us-east-1\n\ud83e\udd16 Model: anthropic.claude-3-opus-20240229-v1:0\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-275-switching-between-anthropic-and-bedrock","title":"Use Case 27.5: Switching Between Anthropic and Bedrock","text":"<p>Scenario: You want to switch between Anthropic API and AWS Bedrock easily.</p> <p>Option 1: Use Bedrock <pre><code>export CLAUDE_CODE_USE_BEDROCK=1\nexport AWS_ACCESS_KEY_ID=\"xxx\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\nwyn360 \"task 1\"  # Uses AWS Bedrock\n</code></pre></p> <p>Option 2: Switch to Anthropic API <pre><code>unset CLAUDE_CODE_USE_BEDROCK  # Or: export CLAUDE_CODE_USE_BEDROCK=0\nexport ANTHROPIC_API_KEY=\"sk-ant-xxx\"\nwyn360 \"task 2\"  # Uses Anthropic API\n</code></pre></p> <p>Pro Tip: Use shell aliases for quick switching: <pre><code># Add to ~/.bashrc or ~/.zshrc\nalias wyn-bedrock='export CLAUDE_CODE_USE_BEDROCK=1; unset ANTHROPIC_API_KEY'\nalias wyn-anthropic='unset CLAUDE_CODE_USE_BEDROCK; export ANTHROPIC_API_KEY=sk-ant-xxx'\n</code></pre></p> <p>Usage: <pre><code>wyn-bedrock &amp;&amp; wyn360 \"task using AWS\"\nwyn-anthropic &amp;&amp; wyn360 \"task using Anthropic\"\n</code></pre></p>"},{"location":"usage/use-cases/#use-case-276-temporary-aws-credentials-with-sts","title":"Use Case 27.6: Temporary AWS Credentials with STS","text":"<p>Scenario: You're using temporary AWS credentials from <code>aws sts assume-role</code>.</p> <p>Step 1: Get Temporary Credentials <pre><code>aws sts assume-role \\\n  --role-arn arn:aws:iam::123456789012:role/WYN360Role \\\n  --role-session-name wyn360-session \\\n  --output json &gt; /tmp/aws-creds.json\n</code></pre></p> <p>Step 2: Extract Credentials <pre><code>export AWS_ACCESS_KEY_ID=$(jq -r '.Credentials.AccessKeyId' /tmp/aws-creds.json)\nexport AWS_SECRET_ACCESS_KEY=$(jq -r '.Credentials.SecretAccessKey' /tmp/aws-creds.json)\nexport AWS_SESSION_TOKEN=$(jq -r '.Credentials.SessionToken' /tmp/aws-creds.json)\n</code></pre></p> <p>Step 3: Enable Bedrock <pre><code>export CLAUDE_CODE_USE_BEDROCK=1\nwyn360 \"analyze data with temporary permissions\"\n</code></pre></p> <p>Security Note: Temporary credentials expire after a set duration (typically 1-12 hours). You'll need to refresh them when they expire.</p>"},{"location":"usage/use-cases/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"usage/use-cases/#error-aws-bedrock-mode-enabled-but-credentials-not-found","title":"Error: \"AWS Bedrock mode enabled but credentials not found\"","text":"<p>Cause: Missing AWS credentials</p> <p>Solution: <pre><code># Check if credentials are set\necho $AWS_ACCESS_KEY_ID\necho $AWS_SECRET_ACCESS_KEY\n\n# If empty, set them:\nexport AWS_ACCESS_KEY_ID=\"xxx\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\n</code></pre></p>"},{"location":"usage/use-cases/#error-anthropic_api_key-is-required","title":"Error: \"ANTHROPIC_API_KEY is required\"","text":"<p>Cause: Bedrock mode not enabled, but no Anthropic API key</p> <p>Solution: <pre><code># Option 1: Use Bedrock\nexport CLAUDE_CODE_USE_BEDROCK=1\nexport AWS_ACCESS_KEY_ID=\"xxx\"\nexport AWS_SECRET_ACCESS_KEY=\"xxx\"\n\n# Option 2: Use Anthropic API\nexport ANTHROPIC_API_KEY=\"sk-ant-xxx\"\n</code></pre></p>"},{"location":"usage/use-cases/#both-credentials-set-which-takes-priority","title":"Both Credentials Set - Which Takes Priority?","text":"<p>When both <code>ANTHROPIC_API_KEY</code> and AWS credentials are set:</p> <pre><code>export ANTHROPIC_API_KEY=\"sk-ant-xxx\"  # Set\nexport AWS_ACCESS_KEY_ID=\"AKIA...\"     # Also set\nexport AWS_SECRET_ACCESS_KEY=\"xxx...\"  # Also set\n</code></pre> <p>Behavior: - If <code>CLAUDE_CODE_USE_BEDROCK=1</code>: Uses AWS Bedrock (ignores ANTHROPIC_API_KEY) - If <code>CLAUDE_CODE_USE_BEDROCK</code> not set: Uses Anthropic API (ignores AWS credentials)</p> <p>The <code>CLAUDE_CODE_USE_BEDROCK</code> flag determines the authentication method.</p>"},{"location":"usage/use-cases/#key-differences-anthropic-api-vs-aws-bedrock","title":"Key Differences: Anthropic API vs AWS Bedrock","text":"Feature Anthropic API AWS Bedrock Billing Anthropic account AWS account Setup 1 env var 3+ env vars IAM Support \u274c No \u2705 Yes Temporary Creds \u274c No \u2705 Yes (STS) Regional \u274c No \u2705 Yes Model Selection Standard names Bedrock ARNs Latest Models \u2705 Immediate \u23f3 May lag"},{"location":"usage/use-cases/#environment-variables-reference","title":"Environment Variables Reference","text":"<p>Required for AWS Bedrock: - <code>CLAUDE_CODE_USE_BEDROCK=1</code> - Enable Bedrock mode - <code>AWS_ACCESS_KEY_ID</code> - AWS access key - <code>AWS_SECRET_ACCESS_KEY</code> - AWS secret key</p> <p>Optional for AWS Bedrock: - <code>AWS_SESSION_TOKEN</code> - For temporary credentials (STS) - <code>AWS_REGION</code> - AWS region (default: us-east-1) - <code>ANTHROPIC_MODEL</code> - Bedrock model ARN (default: latest Sonnet)</p> <p>Required for Anthropic API: - <code>ANTHROPIC_API_KEY</code> - Anthropic API key</p> <p>Not required when using Bedrock: - <code>ANTHROPIC_API_KEY</code> - Ignored when <code>CLAUDE_CODE_USE_BEDROCK=1</code></p>"},{"location":"usage/use-cases/#best-practices_1","title":"Best Practices","text":"<ol> <li>Security:</li> <li>Never commit AWS credentials to version control</li> <li>Use IAM roles when running on AWS infrastructure</li> <li>Rotate temporary credentials regularly</li> <li> <p>Use least-privilege IAM policies</p> </li> <li> <p>Cost Management:</p> </li> <li>Monitor AWS Bedrock costs in AWS Cost Explorer</li> <li>Set billing alerts in AWS</li> <li> <p>Use appropriate models (Haiku for simple tasks, Opus for complex)</p> </li> <li> <p>Performance:</p> </li> <li>Choose AWS region closest to your location</li> <li>Use temporary credentials for time-limited tasks</li> <li> <p>Cache credentials in environment, not in scripts</p> </li> <li> <p>Troubleshooting:</p> </li> <li>Test with <code>aws bedrock list-foundation-models</code> to verify access</li> <li>Check credentials with <code>aws sts get-caller-identity</code></li> <li>Verify region supports Bedrock models</li> </ol> <p>Summary:</p> <p>AWS Bedrock integration gives you flexibility in how you authenticate and bill WYN360 usage:</p> <ul> <li>\u2705 Two authentication methods: Anthropic API or AWS Bedrock</li> <li>\u2705 Full AWS integration: IAM roles, STS, regions</li> <li>\u2705 Easy switching: Toggle with <code>CLAUDE_CODE_USE_BEDROCK</code> flag</li> <li>\u2705 Backward compatible: Existing Anthropic API users unaffected</li> <li>\u2705 Enterprise-ready: Supports AWS governance and compliance</li> </ul> <p>Choose the method that best fits your infrastructure and billing preferences!</p>"},{"location":"usage/use-cases/#part-3-appendices","title":"Part 3: Appendices","text":""},{"location":"usage/use-cases/#appendix-a-available-tools","title":"Appendix A: Available Tools","text":"<p>WYN360 has access to these specialized tools for file and project operations:</p>"},{"location":"usage/use-cases/#read_filefile_path-str","title":"<code>read_file(file_path: str)</code>","text":"<p>Purpose: Read the contents of any file in your project</p> <p>Parameters: - <code>file_path</code> - Path to the file to read</p> <p>Use cases: - \"What's in my config.py?\" - \"Show me the main.py file\" - \"Read my requirements.txt\"</p> <p>Safety features: - File size limits (1MB default) - UTF-8 encoding - Error handling for missing files</p>"},{"location":"usage/use-cases/#write_filefile_path-str-content-str-overwrite-bool","title":"<code>write_file(file_path: str, content: str, overwrite: bool)</code>","text":"<p>Purpose: Create new files or update existing ones</p> <p>Parameters: - <code>file_path</code> - Where to write the file - <code>content</code> - What to write - <code>overwrite</code> - Whether to replace existing files (default: False)</p> <p>Use cases: - \"Create a utils.py with helper functions\" - \"Update my config.json\" - \"Save this code as script.py\"</p> <p>Safety features: - Prevents accidental overwrites - Creates parent directories automatically - Validates file paths</p>"},{"location":"usage/use-cases/#list_filesdirectory-str","title":"<code>list_files(directory: str)</code>","text":"<p>Purpose: Show all files in a directory, organized by category</p> <p>Parameters: - <code>directory</code> - Directory to scan (default: current directory)</p> <p>Returns: - Python files - Text/documentation files - Configuration files - Other files</p> <p>Use cases: - \"What files do I have?\" - \"Show me all Python files\" - \"List the project structure\"</p> <p>Features: - Ignores common patterns (<code>__pycache__</code>, <code>.git</code>, <code>node_modules</code>, etc.) - Categorizes by file type - Recursive directory scanning</p>"},{"location":"usage/use-cases/#get_project_info","title":"<code>get_project_info()</code>","text":"<p>Purpose: Generate a comprehensive project summary</p> <p>Returns: - Total file count - Files by category - Project structure overview - Blank vs existing project status</p> <p>Use cases: - \"Summarize my project\" - \"What kind of project is this?\" - \"Give me an overview\"</p> <p>Analysis includes: - File counts and distribution - Directory structure - Main components - Technology stack indicators</p>"},{"location":"usage/use-cases/#appendix-b-smart-file-handling","title":"Appendix B: Smart File Handling","text":""},{"location":"usage/use-cases/#automatic-code-saving","title":"Automatic Code Saving","text":"<p>When you're in a blank project (no Python or text files), WYN360 automatically saves generated code:</p> <p>Process: 1. Detects Python code blocks in responses (using <code>`` regex) 2. Extracts the code 3. Suggests appropriate filename based on content 4. Saves automatically 5. Confirms with message:</code>\u2713 Code saved to: filename.py`</p> <p>Filename Detection Logic: <pre><code>if 'streamlit' in code:\n    filename = 'app.py'\nelif 'fastapi' in code or 'FastAPI' in code:\n    filename = 'app.py'\nelif 'def main' in code:\n    filename = 'main.py'\nelif 'class ' in code:\n    filename = 'main.py'\nelse:\n    filename = 'script.py'\n</code></pre></p>"},{"location":"usage/use-cases/#file-type-recognition","title":"File Type Recognition","text":"<p>WYN360 categorizes files to understand your project:</p> Category Extensions Purpose Python <code>.py</code> Source code Text <code>.md</code>, <code>.txt</code>, <code>.rst</code> Documentation Config <code>.json</code>, <code>.yaml</code>, <code>.toml</code>, <code>.ini</code>, <code>.cfg</code> Configuration Other All others Resources, data, etc."},{"location":"usage/use-cases/#appendix-c-intelligent-file-operation-handling","title":"Appendix C: Intelligent File Operation Handling","text":"<p>Version: NEW in v0.2.1</p> <p>WYN360 includes advanced intelligence for understanding user intent when working with files, automatically determining whether to create new files or update existing ones.</p>"},{"location":"usage/use-cases/#intent-recognition","title":"Intent Recognition","text":"<p>The agent analyzes your natural language to understand what you want:</p> <p>Update Existing Files - When you say: - \"Add feature to my app\" - \"Update the chatbot\" - \"Improve my script\" - \"Modify the config\" - \"Change the API endpoint\"</p> <p>Action taken: 1. Agent reads the existing file first to understand current state 2. Makes the requested modifications 3. Writes back with <code>overwrite=True</code> 4. Shows you what changed</p> <p>Create New Files - When you say: - \"Create a new script called utils.py\" - \"Make another chatbot\" - \"Build a separate module\" - \"Generate a helper file\"</p> <p>Action taken: 1. Agent creates the new file 2. Uses <code>overwrite=False</code> to prevent accidents 3. Leaves existing files untouched</p>"},{"location":"usage/use-cases/#context-aware-updates","title":"Context-Aware Updates","text":"<p>Before updating any file, the agent: 1. \u2713 Reads the current file contents 2. \u2713 Understands the existing structure 3. \u2713 Makes intelligent modifications 4. \u2713 Preserves what shouldn't change 5. \u2713 Explains what was updated</p> <p>Example: <pre><code>You: Add a feature to run hello_world.py when user asks\n\nWYN360:\n1. Reading your current app.py...\n2. Creating hello_world.py...\n3. Updating app.py with new functionality...\n\u2713 Created: hello_world.py\n\u2713 Updated: app.py (added script execution feature)\n</code></pre></p>"},{"location":"usage/use-cases/#self-correcting-behavior","title":"Self-Correcting Behavior","text":"<p>If the agent makes a wrong choice, it can self-correct:</p> <p>Scenario: - Agent tries to create file but it already exists - Gets clear error: \"File exists. Use overwrite=True to update\" - Automatically retries with correct settings (up to 3 retries) - Succeeds on retry</p> <p>Benefits: - No more \"max retries exceeded\" errors - Agent learns from mistakes - Seamless user experience - Natural language understanding</p>"},{"location":"usage/use-cases/#smart-retry-mechanism","title":"Smart Retry Mechanism","text":"<p>Configuration: 3 retries for tool operations</p> <p>How it works: 1. First attempt based on intent recognition 2. If error occurs, analyzes the error message 3. Adjusts parameters (e.g., sets overwrite=True) 4. Retries with corrected parameters 5. Repeats up to 3 times</p> <p>This handles: - File existence conflicts - Permission issues - Temporary failures - Ambiguous user requests</p>"},{"location":"usage/use-cases/#appendix-d-example-workflows","title":"Appendix D: Example Workflows","text":""},{"location":"usage/use-cases/#workflow-1-brand-new-project","title":"Workflow 1: Brand New Project","text":"<pre><code>Step 1: Navigate to empty directory\n$ cd my-new-project\n\nStep 2: Start WYN360\n$ wyn360\n\nStep 3: Describe what you want\nYou: Build a CLI tool that converts CSV to JSON\n\nStep 4: Agent generates and saves code\nWYN360:\n- Generates complete script with argparse\n- Includes CSV parsing logic\n- Adds JSON output formatting\n- \u2713 Code saved to: main.py\n\nStep 5: Review and run\nYou: How do I use it?\n\nWYN360:\n- Provides usage instructions\n- Shows example commands\n- Explains options\n</code></pre>"},{"location":"usage/use-cases/#workflow-2-enhance-existing-project","title":"Workflow 2: Enhance Existing Project","text":"<pre><code>Step 1: Navigate to your project\n$ cd my-existing-project\n\nStep 2: Start WYN360\n$ wyn360\n\nStep 3: Request enhancement\nYou: Add logging to my data pipeline\n\nStep 4: Agent analyzes and modifies\nWYN360:\n- Reads existing pipeline.py\n- Understands current structure\n- Generates logging configuration\n- Shows you the changes\n- Explains the additions\n\nStep 5: Review and accept\nYou: Apply these changes\n\nWYN360:\n- Updates the file\n- Confirms changes made\n- Provides testing guidance\n</code></pre>"},{"location":"usage/use-cases/#workflow-3-debug-fix","title":"Workflow 3: Debug &amp; Fix","text":"<pre><code>Step 1: Encounter an error\n$ python script.py\nError: Connection timeout\n\nStep 2: Ask WYN360 for help\nYou: My script has a connection timeout error\n\nStep 3: Agent diagnoses\nWYN360:\n- Reads your script\n- Identifies the problematic code\n- Explains the root cause\n- Shows the exact issue\n\nStep 4: Get the fix\nYou: How do I fix it?\n\nWYN360:\n- Suggests retry logic\n- Provides complete code\n- Explains the solution\n- Offers to update the file\n\nStep 5: Apply fix\nYou: Update my script\n\nWYN360:\n- Modifies the file\n- Confirms the change\n- \u2713 Code updated successfully\n</code></pre>"},{"location":"usage/use-cases/#workflow-4-learning-guidance","title":"Workflow 4: Learning &amp; Guidance","text":"<pre><code>You: How do I implement async in Python?\n\nWYN360:\n\ud83d\udcda Explanation:\n- What async/await does\n- When to use it\n- How it works\n\n\ud83d\udcbb Working Examples:\n- Simple async function\n- Using asyncio.gather()\n- Error handling in async\n\n\u2728 Best Practices:\n- When NOT to use async\n- Common pitfalls\n- Performance tips\n\n\ud83c\udfaf Real-world Example:\n- Complete async HTTP client\n- Concurrent API requests\n- Proper exception handling\n</code></pre>"},{"location":"usage/use-cases/#appendix-e-key-strengths","title":"Appendix E: Key Strengths","text":""},{"location":"usage/use-cases/#1-context-aware-development","title":"1. Context-Aware Development","text":"<ul> <li>Reads and understands your project structure before making changes</li> <li>Maintains consistency with your existing code style</li> <li>Suggests changes that integrate seamlessly</li> </ul>"},{"location":"usage/use-cases/#2-production-ready-code","title":"2. Production-Ready Code","text":"<ul> <li>Proper error handling and edge cases</li> <li>Comprehensive docstrings</li> <li>Type hints where appropriate</li> <li>Follows best practices</li> </ul>"},{"location":"usage/use-cases/#3-interactive-iterative","title":"3. Interactive &amp; Iterative","text":"<ul> <li>Chat-based interface for natural interaction</li> <li>Ask follow-up questions</li> <li>Refine solutions iteratively</li> <li>Get explanations anytime</li> </ul>"},{"location":"usage/use-cases/#4-automatic-file-management","title":"4. Automatic File Management","text":"<ul> <li>Saves generated code automatically (in blank projects)</li> <li>Smart file naming based on content</li> <li>Creates directory structures as needed</li> </ul>"},{"location":"usage/use-cases/#5-intelligent-code-analysis","title":"5. Intelligent Code Analysis","text":"<ul> <li>Detects code patterns (Streamlit, FastAPI, etc.)</li> <li>Suggests appropriate file names</li> <li>Understands project structure</li> </ul>"},{"location":"usage/use-cases/#appendix-f-current-limitations","title":"Appendix F: Current Limitations","text":""},{"location":"usage/use-cases/#1-python-focused","title":"1. Python-Focused","text":"<ul> <li>Optimized for: Python projects and development</li> <li>Can discuss: Other languages, but tooling is Python-centric</li> <li>Best for: Python developers and learners</li> </ul>"},{"location":"usage/use-cases/#2-local-files-only","title":"2. Local Files Only","text":"<ul> <li>Works with: Files in current directory and subdirectories</li> <li>Cannot access: Remote repositories, databases, external APIs</li> <li>Scope: Local file system only</li> </ul>"},{"location":"usage/use-cases/#3-session-based-memory","title":"3. Session-Based Memory","text":"<ul> <li>No persistent memory between CLI sessions</li> <li>Each session starts fresh</li> <li>Workaround: Provide context in each session or use /save and /load</li> </ul>"},{"location":"usage/use-cases/#4-file-size-limits","title":"4. File Size Limits","text":"<ul> <li>Maximum file size: 1MB per file</li> <li>Prevents reading very large files</li> <li>Workaround: Process large files in chunks</li> </ul>"},{"location":"usage/use-cases/#appendix-g-best-use-cases-summary","title":"Appendix G: Best Use Cases Summary","text":""},{"location":"usage/use-cases/#excellent-for","title":"\u2705 Excellent For:","text":"<p>Rapid Prototyping - Build MVPs quickly - Test ideas fast - Create proof-of-concepts - Generate starter templates</p> <p>Learning Python - Get explanations for concepts - See working examples - Understand best practices - Debug learning projects</p> <p>Starting New Projects - Generate project structure - Create boilerplate code - Set up configurations - Initialize common patterns</p> <p>Adding Features - Extend existing code - Integrate new functionality - Refactor safely - Improve code quality</p> <p>Code Review &amp; Suggestions - Get improvement ideas - Identify potential issues - Learn better patterns - Optimize performance</p>"},{"location":"usage/use-cases/#not-ideal-for","title":"\u274c Not Ideal For:","text":"<p>Non-Python Projects - JavaScript/TypeScript (can advise, but limited tooling) - Java, C++, Go (conceptual help only) - Mobile development (limited support)</p> <p>Large-Scale Refactoring - Entire codebase restructuring (better in IDE) - Renaming across many files (use IDE refactoring tools) - Complex merge operations</p> <p>Production Deployments - CI/CD pipeline execution - Server deployments - Container orchestration - Infrastructure as code</p> <p>Database Operations - Direct database queries - Schema migrations - Data manipulation - Backup/restore operations</p>"},{"location":"usage/use-cases/#appendix-h-pro-tips","title":"Appendix H: Pro Tips","text":""},{"location":"usage/use-cases/#1-be-specific","title":"1. Be Specific","text":"<p>Instead of: \"Make my code better\" Try: \"Add error handling to my API endpoints\"</p>"},{"location":"usage/use-cases/#2-provide-context","title":"2. Provide Context","text":"<p>Instead of: \"This doesn't work\" Try: \"My FastAPI app returns 500 errors when the database is down\"</p>"},{"location":"usage/use-cases/#3-iterate","title":"3. Iterate","text":"<ul> <li>Start with basic version</li> <li>Ask for improvements</li> <li>Refine step by step</li> <li>Build incrementally</li> </ul>"},{"location":"usage/use-cases/#4-use-in-combination-with-ide","title":"4. Use in Combination with IDE","text":"<ul> <li>Generate code with WYN360</li> <li>Refine in your IDE</li> <li>Use IDE for complex refactoring</li> <li>Use WYN360 for quick generation</li> </ul>"},{"location":"usage/use-cases/#5-review-generated-code","title":"5. Review Generated Code","text":"<ul> <li>Always read generated code</li> <li>Understand what it does</li> <li>Test before deploying</li> <li>Customize as needed</li> </ul>"},{"location":"usage/use-cases/#6-use-clear-intent-language","title":"6. Use Clear Intent Language","text":"<ul> <li>Say \"add feature\" or \"update\" when modifying existing files</li> <li>Say \"create new\" or \"make another\" for new files</li> <li>Be explicit about what you want to change</li> <li>The agent understands natural language intent</li> </ul> <p>Examples: - \u2705 \"Add authentication to my app\" (updates existing) - \u2705 \"Create a new helper module\" (creates new) - \u2705 \"Improve error handling\" (updates existing) - \u2705 \"Build a separate API client\" (creates new)</p>"},{"location":"usage/use-cases/#7-manage-context-with-slash-commands","title":"7. Manage Context with Slash Commands","text":"<ul> <li>Use <code>/tokens</code> to monitor API costs during long sessions</li> <li>Use <code>/save</code> to preserve important conversations for later</li> <li>Use <code>/load</code> to continue previous work sessions</li> <li>Use <code>/clear</code> when starting fresh to reduce token usage</li> <li>Use <code>/history</code> to review what you've discussed</li> </ul> <p>Example Workflow: <pre><code>You: Build a data analysis pipeline\nWYN360: [Creates initial pipeline]\n\nYou: Add visualization features\nWYN360: [Enhances the pipeline]\n\nYou: /tokens\n[Token Usage Statistics]\nTotal Cost: $0.03\n\nYou: /save my_pipeline_session.json\n\u2713 Session saved\n\n[Later...]\nYou: /load my_pipeline_session.json\n\u2713 Session loaded (conversation history restored)\n\nYou: Add export to Excel feature\nWYN360: [Continues from where you left off with full context]\n</code></pre></p> <p>Cost Management Tips: - Check <code>/tokens</code> regularly to track spending - Use <code>/clear</code> after completing a major feature to reset context - Save sessions before clearing to preserve your work - Long conversations cost more due to conversation history in each API call - Balance between context (better results) and cost (fewer tokens)</p>"},{"location":"usage/use-cases/#appendix-i-learning-path","title":"Appendix I: Learning Path","text":""},{"location":"usage/use-cases/#beginner","title":"Beginner","text":"<ol> <li>Start in blank directory</li> <li>Ask to build simple scripts</li> <li>Learn from generated code</li> <li>Ask \"why\" and \"how\" questions</li> </ol>"},{"location":"usage/use-cases/#intermediate","title":"Intermediate","text":"<ol> <li>Bring existing projects</li> <li>Ask for feature additions</li> <li>Request refactoring help</li> <li>Learn best practices</li> </ol>"},{"location":"usage/use-cases/#advanced","title":"Advanced","text":"<ol> <li>Use for rapid prototyping</li> <li>Generate complex architectures</li> <li>Get design pattern suggestions</li> <li>Review and optimize code</li> </ol>"},{"location":"usage/use-cases/#part-4-reference","title":"Part 4: Reference","text":""},{"location":"usage/use-cases/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"usage/use-cases/#example-1-build-a-web-scraper","title":"Example 1: Build a Web Scraper","text":"<pre><code>You: Create a web scraper that extracts article titles from a news site\n\nWYN360: [Generates complete script with requests, BeautifulSoup, error handling]\n\u2713 Code saved to: scraper.py\n</code></pre>"},{"location":"usage/use-cases/#example-2-data-processing-pipeline","title":"Example 2: Data Processing Pipeline","text":"<pre><code>You: Build a script that reads CSV, cleans data, and outputs to JSON\n\nWYN360: [Creates comprehensive data pipeline with pandas]\n\u2713 Code saved to: process_data.py\n</code></pre>"},{"location":"usage/use-cases/#example-3-api-client","title":"Example 3: API Client","text":"<pre><code>You: Create an async HTTP client for a REST API\n\nWYN360: [Generates async client with aiohttp, retry logic, error handling]\n\u2713 Code saved to: api_client.py\n</code></pre>"},{"location":"usage/use-cases/#need-help","title":"Need Help?","text":""},{"location":"usage/use-cases/#changelog","title":"Changelog","text":""},{"location":"usage/use-cases/#v0323","title":"v0.3.23","text":"<ul> <li>\ud83d\ude80 NEW FEATURE: Phase 8.1 - Complete GitHub Integration</li> <li>\u2705 TOOLS: 7 new GitHub tools (authentication, commit, PR, branches, merge)</li> <li>\ud83d\udd10 AUTHENTICATION: Token-based authentication with GH_TOKEN/GITHUB_TOKEN</li> <li>\ud83d\udcbe COMMIT &amp; PUSH: Stage, commit, and push changes directly from CLI</li> <li>\ud83d\udd00 PULL REQUESTS: Create PRs with title, body, and base branch</li> <li>\ud83c\udf3f BRANCH MANAGEMENT: Create, checkout, and list branches</li> <li>\ud83d\udd04 BRANCH MERGING: Merge branches with conflict detection</li> <li>\ud83d\udd12 USER CONFIRMATION: All git operations require y/N approval</li> <li>\u2b06\ufe0f WEB SEARCH FIX: Upgraded pydantic-ai to v1.13.0</li> <li>\ud83d\udd27 WEB SEARCH FIX: Fixed web search tool integration with builtin_tools</li> <li>\ud83d\udcdd WEB SEARCH ENHANCEMENT: Enhanced system prompt for finding GitHub repos and resources</li> <li>\ud83e\uddea TESTS: Added comprehensive tests for GitHub integration tools</li> <li>\ud83d\udcda DOCUMENTATION: Added Use Case 14 (GitHub Integration) and Use Case 17 expansion</li> </ul>"},{"location":"usage/use-cases/#v0321","title":"v0.3.21","text":"<ul> <li>\ud83c\udf10 NEW FEATURE: Phase 11.1 - Real-Time Web Search</li> <li>\u2705 BUILTIN TOOL: WebSearchTool integrated via pydantic-ai framework</li> <li>\ud83c\udf24\ufe0f WEATHER QUERIES: Ask for weather in any location with automatic search</li> <li>\ud83d\udcd6 WEBSITE READING: Fetch and summarize content from any public URL</li> <li>\ud83d\udcda CURRENT INFO: Access latest docs, package updates, news, and trends</li> <li>\ud83d\udcb0 COST CONTROLLED: Limited to 5 searches per session ($10 per 1K searches)</li> <li>\ud83d\udd17 PROPER CITATIONS: All results include source URLs and dates</li> <li>\ud83d\udcca USE CASES: Added Section 16 to USE_CASES.md with 3 detailed examples</li> <li>\ud83c\udfaf SMART INVOCATION: Claude automatically decides when web search is needed</li> <li>\u26a1 INTEGRATION: Works alongside 19 existing custom tools without conflicts</li> <li>\ud83d\udcda DOCUMENTATION: Updated SYSTEM.md, COST.md, README.md, agent.py system prompt</li> <li>\ud83e\uddea NO BREAKING CHANGES: Purely additive feature</li> </ul>"},{"location":"usage/use-cases/#v0320","title":"v0.3.20","text":"<ul> <li>\ud83c\udfa8 UX IMPROVEMENT: Enhanced CLI help output with comprehensive documentation</li> <li>\u2705 NEW FLAG: Added <code>-h</code> shorthand for <code>--help</code></li> <li>\ud83d\udcda DOCUMENTATION: Help now shows all slash commands, available tools, examples</li> <li>\ud83d\udca1 QUICK REFERENCE: Users can run <code>wyn360 -h</code> to see complete command reference</li> <li>\ud83d\udd27 ORGANIZED: Help structured into sections: Quick Start, Slash Commands, Available Tools, Examples, Documentation</li> </ul>"},{"location":"usage/use-cases/#v0319","title":"v0.3.19","text":"<ul> <li>\ud83d\ude80 NEW FEATURE: Phase 10.2 - Performance Metrics &amp; Analytics</li> <li>\u2705 CLASS: PerformanceMetrics - Comprehensive session metrics tracking</li> <li>\ud83d\udcca TRACKING: Response times (avg, min, max), tool usage, error frequency</li> <li>\ud83d\udcbb COMMAND: /stats - Display comprehensive performance dashboard</li> <li>\ud83d\udcc8 ANALYTICS: Most used tools, success rates, session duration</li> <li>\ud83d\udd04 PERSISTENCE: Metrics saved/loaded with sessions</li> <li>\ud83e\uddea TESTS: Added 11 comprehensive unit tests (169 total tests)</li> <li>\ud83d\udcda DOCUMENTATION: Added USE_CASES.md section 15 - Performance Monitoring</li> <li>\u26a1 INTEGRATION: Automatic tracking in read_file, write_file, execute_command, git_status, search_files, list_files</li> <li>\ud83c\udfaf NON-INTRUSIVE: Runs transparently in background with zero configuration</li> </ul>"},{"location":"usage/use-cases/#v0318","title":"v0.3.18","text":"<ul> <li>\ud83d\ude80 NEW FEATURE: Phase 7.2 - Automatic Test Generation</li> <li>\u2705 TOOL: generate_tests - Automatically generate pytest test stubs for Python files</li> <li>\ud83e\uddea AST PARSING: Safe code analysis without execution</li> <li>\ud83d\udcdd TEMPLATES: Generates test scaffolding with TODO markers for easy completion</li> <li>\ud83e\uddea TESTS: Added 6 new unit tests for test generation (158 total tests)</li> <li>\ud83d\udcda DOCUMENTATION: Updated system prompt with test generation workflow</li> <li>\ud83d\udca1 PRODUCTIVITY: Saves time by auto-generating test structure</li> <li>\u26a1 WORKFLOW: \"generate tests for calculator.py\" \u2192 instant pytest template</li> </ul>"},{"location":"usage/use-cases/#v0317","title":"v0.3.17","text":"<ul> <li>\ud83d\ude80 NEW FEATURE: HuggingFace integration Phase 2 - Full Deployment</li> <li>\u2705 TOOL: create_hf_space - Create HuggingFace Space repository via CLI</li> <li>\u2705 TOOL: push_to_hf_space - Upload files to HuggingFace Space automatically</li> <li>\ud83e\udd16 AUTOMATION: Complete end-to-end deployment to HuggingFace Spaces</li> <li>\ud83e\uddea TESTS: Added 6 new unit tests for Phase 2 tools (152 total tests)</li> <li>\ud83d\udcda DOCUMENTATION: Updated ROADMAP.md with Phase 6 complete</li> <li>\ud83d\udca1 SYSTEM PROMPT: Updated workflow with automatic deployment instructions</li> <li>\ud83d\udd27 BUG FIX: Fixed authentication loop when HF_TOKEN is set in environment</li> <li>\u26a1 WORKFLOW: Users can now deploy apps with one command: \"push to huggingface\"</li> </ul>"},{"location":"usage/use-cases/#v0316","title":"v0.3.16","text":"<ul> <li>\ud83d\ude80 NEW FEATURE: HuggingFace integration Phase 1</li> <li>\u2705 TOOL: check_hf_authentication - Check HuggingFace CLI authentication status</li> <li>\u2705 TOOL: authenticate_hf - Authenticate with HuggingFace using access token</li> <li>\u2705 TOOL: create_hf_readme - Generate README.md with Space configuration</li> <li>\ud83d\udce6 DEPENDENCY: Added huggingface-hub&gt;=0.20.0</li> <li>\ud83e\uddea TESTS: Added 12 new unit tests for HuggingFace tools</li> <li>\ud83d\udcda DOCUMENTATION: Updated ROADMAP.md with Phase 6 HuggingFace Integration</li> <li>\ud83d\udee0\ufe0f UTILS: Added extract_username_from_hf_whoami() helper function</li> <li>\ud83d\udca1 SYSTEM PROMPT: Added HuggingFace workflow instructions</li> </ul>"},{"location":"usage/use-cases/#v0315","title":"v0.3.15","text":"<ul> <li>\ud83d\udcda DOCUMENTATION: Created comprehensive SYSTEM.md with updated architecture</li> <li>\ud83d\udcca DOCUMENTATION: Updated mermaid diagram to include all Phase 1-5 features</li> <li>\ud83d\udcdd DOCUMENTATION: Updated COST.md with Phase 2 tools (13 tools total)</li> <li>\ud83c\udfd7\ufe0f DOCUMENTATION: Cleaned up README.md, moved architecture to SYSTEM.md</li> <li>\ud83d\udd27 FIX: Fixed mermaid syntax error for GitHub rendering</li> </ul>"},{"location":"usage/use-cases/#v0314","title":"v0.3.14","text":"<ul> <li>\ud83c\udfa8 UX IMPROVEMENT: Added confirmation feedback after command execution prompt</li> <li>\u2713 When pressing 'y': Shows \"\u2713 Confirmed. Executing command...\" before spinner</li> <li>\u2717 When pressing 'N': Shows \"\u2717 Cancelled (pressed 'N').\" with clear feedback</li> <li>\ud83d\udcfa User now sees immediate visual confirmation that their keypress was registered</li> <li>\ud83d\udd27 Added sys.stdout.flush() to ensure messages appear immediately</li> </ul>"},{"location":"usage/use-cases/#v0313","title":"v0.3.13","text":"<ul> <li>\ud83d\udc1b CRITICAL FIX: Removed streaming API entirely to fix persistent duplication</li> <li>\u2705 Now uses agent.run() to get complete response (not run_stream())</li> <li>\ud83c\udfa8 Simulates streaming by splitting response by spaces and printing word-by-word</li> <li>\u26a1 Small 0.01s delay between words creates smooth streaming effect</li> <li>\ud83d\udd27 Tools execute reliably with non-streaming approach</li> <li>\ud83d\udcfa Visual streaming effect maintained without API complexity</li> <li>\ud83c\udfaf Simple, reliable solution: get complete response \u2192 split \u2192 print word-by-word</li> </ul>"},{"location":"usage/use-cases/#v0312","title":"v0.3.12","text":"<ul> <li>\ud83d\udc1b CRITICAL FIX: Eliminated streaming text duplication</li> <li>\u26a1 Fixed: Agent now yields deltas (new text only), not accumulated text</li> <li>\ud83c\udfaf Simplified CLI: Direct delta display without complex extraction logic</li> <li>\u2705 Cleaner, more efficient streaming implementation</li> <li>\ud83d\udd27 Updated tests to expect delta chunks instead of accumulated chunks</li> <li>\ud83d\udcfa True real-time streaming with correct tool execution</li> </ul>"},{"location":"usage/use-cases/#v0311","title":"v0.3.11","text":"<ul> <li>\u26a1 CRITICAL FIX: Restored REAL streaming using run_stream()</li> <li>\ud83d\udd27 Fixed: Was using run() and waiting for full response, then simulating chunks</li> <li>\ud83c\udfaf Now uses pydantic-ai's run_stream() for true token-by-token streaming</li> <li>\ud83d\udcfa Immediate visual feedback - see text appear as model generates it</li> <li>\u2705 Tools still execute properly with streaming enabled</li> <li>\ud83d\udca1 No more long waits - responses appear instantly as they're generated</li> </ul>"},{"location":"usage/use-cases/#v0310","title":"v0.3.10","text":"<ul> <li>\ud83d\udc1b FIX: Console width detection causing narrow text wrapping</li> <li>\ud83d\udcd0 Set minimum console width of 80 characters</li> <li>\ud83c\udfa8 Maximum width of 200 for readability</li> <li>\ud83d\udcbb Uses shutil.get_terminal_size() with fallback to 120</li> <li>\u2705 Prevents text from wrapping every 10-15 characters in some environments</li> </ul>"},{"location":"usage/use-cases/#v039","title":"v0.3.9","text":"<ul> <li>\ud83d\udc1b FIX: Stricter early size validation (100KB limit, down from 1MB)</li> <li>\ud83d\udd0d Enhanced type checking with automatic string conversion attempts</li> <li>\ud83d\udccf More explicit ML script guidance: ONE model, NO extensive hyperparameter tuning</li> <li>\ud83d\udcca Better error messages with content preview when size exceeded</li> <li>\u26a0\ufe0f Clear warning: \"Your code is too long! Reduce to under 1000 lines\"</li> </ul>"},{"location":"usage/use-cases/#v038","title":"v0.3.8","text":"<ul> <li>\ud83d\udc1b CRITICAL FIX: Removed type hints from write_file to bypass pydantic validation</li> <li>\ud83d\udccf Added 50KB size guidance - model now generates concise code</li> <li>\ud83c\udfaf Updated system prompt: \"Keep code under 500-800 lines\"</li> <li>\ud83d\udca1 EDA scripts now include only essential visualizations (3-5 plots)</li> <li>\u2705 Prevents framework-level validation errors that caused \"exceeded max retries\"</li> </ul>"},{"location":"usage/use-cases/#v037","title":"v0.3.7","text":"<ul> <li>\ud83d\udc1b CRITICAL FIX: Set retries=0 to completely disable retries</li> <li>\ud83d\udcca Added comprehensive debug logging to write_file tool</li> <li>\ud83d\udd0d Input validation with detailed type checking</li> <li>\ud83d\udcdd Full error tracebacks for debugging issues</li> <li>\ud83d\udca1 Clear error messages showing exactly what went wrong</li> </ul>"},{"location":"usage/use-cases/#v036","title":"v0.3.6","text":"<ul> <li>\ud83d\udc1b FIX: Reduced retry count from 3 to 1 to prevent \"exceeded max retries\" errors</li> <li>\ud83d\udd27 Added file size validation (1MB limit) to write_file tool</li> <li>\ud83d\udcdd Improved error messages with clearer guidance for tool failures</li> <li>\ud83d\udca1 Updated system prompt to clarify retry behavior</li> <li>\u2705 Better handling of tool validation errors</li> </ul>"},{"location":"usage/use-cases/#v035","title":"v0.3.5","text":"<ul> <li>\u2728 NEW: Added back \"thinking\" spinner while agent processes</li> <li>\ud83c\udfa8 Better UX - shows \"WYN360 is thinking...\" with animated dots</li> <li>\u23f3 Spinner appears before first response chunk is ready</li> <li>\ud83d\udd27 Improved visual feedback during processing time</li> </ul>"},{"location":"usage/use-cases/#v034","title":"v0.3.4","text":"<ul> <li>\ud83d\udc1b CRITICAL FIX: Tool execution bug - tools weren't being called in streaming mode</li> <li>\ud83d\udd27 Switched to non-streaming backend with simulated chunking for reliability</li> <li>\u2705 All tools now work correctly (list_files, write_file, read_file, etc.)</li> <li>\ud83d\udcdd Updated tests to reflect new implementation</li> <li>\ud83d\udca1 Better user experience - tools execute properly with streaming-like display</li> </ul>"},{"location":"usage/use-cases/#v033","title":"v0.3.3","text":"<ul> <li>\ud83d\udc1b FIX: Streaming duplication bug - fixed text appearing multiple times</li> <li>\ud83d\udd27 Implemented delta tracking to show only new text portions</li> <li>\u2705 All 133 tests passing with streaming fix</li> </ul>"},{"location":"usage/use-cases/#v032","title":"v0.3.2","text":"<ul> <li>\u2728 NEW: Streaming Responses - token-by-token real-time output</li> <li>\u2728 NEW: <code>chat_stream()</code> method for streaming responses</li> <li>\u26a1 Immediate feedback - see responses as they're generated</li> <li>\ud83c\udfaf Better perceived performance - feels 2-3x faster</li> <li>\ud83d\udcfa Real-time progress visibility like ChatGPT</li> <li>\ud83e\uddea Added 3 new unit tests for streaming (133 total tests)</li> <li>\ud83d\udca1 No configuration needed - streaming is automatic</li> <li>\ud83d\udcda Comprehensive streaming documentation with comparisons</li> </ul>"},{"location":"usage/use-cases/#v031","title":"v0.3.1","text":"<ul> <li>\u2728 NEW: Configuration &amp; Personalization - user and project-specific settings</li> <li>\u2728 NEW: User config file (<code>~/.wyn360/config.yaml</code>) for personal preferences</li> <li>\u2728 NEW: Project config file (<code>.wyn360.yaml</code>) for project-specific context</li> <li>\u2728 NEW: <code>/config</code> slash command to view current configuration</li> <li>\ud83d\udd27 Custom instructions automatically added to system prompt</li> <li>\ud83d\udd27 Project context helps AI understand your codebase</li> <li>\ud83d\udd27 Configuration merging with precedence (project &gt; user &gt; defaults)</li> <li>\ud83e\uddea Added 27 new unit tests for configuration system (130 total tests)</li> <li>\ud83d\udce6 Added PyYAML dependency for configuration file parsing</li> <li>\ud83d\udcda Comprehensive configuration documentation and examples</li> <li>\ud83d\udca1 Support for aliases, workspaces, dependencies, and commands</li> </ul>"},{"location":"usage/use-cases/#v030","title":"v0.3.0","text":"<ul> <li>\u2728 NEW: Model selection and switching - choose Haiku, Sonnet, or Opus</li> <li>\u2728 NEW: <code>/model</code> slash command to view and switch models mid-session</li> <li>\u2728 NEW: Real-time model information with pricing and descriptions</li> <li>\ud83d\udcb0 Cost optimization - use cheaper models for simple tasks</li> <li>\ud83d\udd27 Conversation history preserved when switching models</li> <li>\ud83e\uddea Added 10 new unit tests for model switching (103 total tests)</li> <li>\ud83d\udcca Model comparison guide with cost analysis</li> <li>\ud83d\udca1 Three cost optimization strategies documented</li> <li>\ud83d\udcda Updated documentation with comprehensive model examples</li> </ul>"},{"location":"usage/use-cases/#v029","title":"v0.2.9","text":"<ul> <li>\u2728 NEW: Git operation tools - status, diff, log, branch</li> <li>\u2728 NEW: Code search across files with pattern matching</li> <li>\u2728 NEW: File management tools - delete, move/rename, create directories</li> <li>\ud83d\udd27 Added 8 new tools for enhanced project management</li> <li>\ud83e\uddea Added 17 new unit tests for Phase 2 tools (93 total tests)</li> <li>\ud83d\udcca Git integration for version control operations</li> <li>\ud83d\udd0d Search capabilities with regex support and file type filtering</li> <li>\ud83d\udcc1 Complete file system operations with safety features</li> <li>\ud83d\udcda Updated documentation with comprehensive Phase 2 examples</li> </ul>"},{"location":"usage/use-cases/#v028","title":"v0.2.8","text":"<ul> <li>\u2728 NEW: Conversation history management - context persists across multiple interactions</li> <li>\u2728 NEW: Token usage tracking and cost estimation</li> <li>\u2728 NEW: Slash commands for quick access to context management features</li> <li><code>/clear</code> - Clear conversation history and reset token counters</li> <li><code>/history</code> - Display conversation history in a formatted table</li> <li><code>/save &lt;file&gt;</code> - Save current session to JSON file</li> <li><code>/load &lt;file&gt;</code> - Load session from JSON file</li> <li><code>/tokens</code> - Show detailed token usage statistics and costs</li> <li><code>/help</code> - Display help message with all commands</li> <li>\u2728 NEW: Session save/load functionality - preserve conversations for later</li> <li>\ud83e\uddea Added 31 new unit tests for history management and slash commands (76 total tests)</li> <li>\ud83d\udcca Real-time cost tracking: input tokens ($3/M), output tokens ($15/M)</li> <li>\ud83d\udcbe JSON session export with full conversation state and token statistics</li> <li>\ud83d\udcda Updated documentation with slash command examples and usage patterns</li> </ul>"},{"location":"usage/use-cases/#v027","title":"v0.2.7","text":"<ul> <li>\ud83d\udc1b BUGFIX: Ensured command execution status always displayed</li> <li>\ud83d\udd27 Added CRITICAL instruction to agent: preserve \"\u2705 Command executed successfully\" indicator</li> <li>\ud83d\udd27 Agent now required to start responses with status indicator</li> <li>\ud83d\udcda User reported not always seeing success message - now guaranteed</li> <li>\ud83d\udca1 Consistent feedback for all command executions</li> </ul>"},{"location":"usage/use-cases/#v026","title":"v0.2.6","text":"<ul> <li>\ud83c\udfa8 UX IMPROVEMENT: Enhanced command execution confirmation prompt</li> <li>\ud83d\udd27 Made confirmation much more visible with banner and clear messaging</li> <li>\ud83d\udd27 Added \"WAITING FOR YOUR RESPONSE\" indicator</li> <li>\ud83d\udd27 Shows command, directory, and permissions clearly</li> <li>\ud83d\udd27 Added sys.stdout.flush() to ensure prompt appears immediately</li> <li>\ud83d\udcda Updated documentation to explain spinner behavior during confirmation</li> <li>\ud83d\udca1 Improves user experience - no more confusion about whether to wait or respond</li> </ul>"},{"location":"usage/use-cases/#v025","title":"v0.2.5","text":"<ul> <li>\ud83d\udc1b BUGFIX: Fixed \"write_file exceeded max retries\" error for script generation</li> <li>\ud83d\udd27 Enhanced intent recognition for \"write/generate script\" patterns</li> <li>\ud83d\udd27 Added automatic retry with overwrite=True if file exists</li> <li>\ud83d\udd27 Clear instructions: Don't read_file for NEW file creation</li> <li>\ud83d\udcda Better handling of data analysis script generation workflows</li> </ul>"},{"location":"usage/use-cases/#v024","title":"v0.2.4","text":"<ul> <li>\ud83d\udc1b BUGFIX: Fixed key binding error - Changed to Ctrl+Enter for newlines</li> <li>\ud83d\udd27 Updated key bindings: Enter submits, Ctrl+Enter adds newline</li> <li>\ud83d\udd27 Fixed ValueError: Invalid key 's-enter' issue from v0.2.3</li> </ul>"},{"location":"usage/use-cases/#v023","title":"v0.2.3","text":"<ul> <li>\ud83d\udc1b BUGFIX: Fixed multi-line input behavior - Enter now properly submits</li> <li>\ud83d\udd27 Corrected key bindings: Enter submits, Shift+Enter adds newline</li> <li>\ud83d\udd27 Changed from <code>multiline=True</code> to custom key binding approach</li> </ul>"},{"location":"usage/use-cases/#v022","title":"v0.2.2","text":"<ul> <li>\u2728 NEW: Command execution capability - run Python scripts, UV commands, shell scripts, any CLI tool</li> <li>\u2728 NEW: Multi-line input support with Shift+Enter for newline</li> <li>\u2728 NEW: User confirmation prompts before executing commands</li> <li>\u2728 NEW: Timeout protection for long-running commands (5 min default)</li> <li>\u2728 NEW: Comprehensive stdout/stderr capture with exit codes</li> <li>\ud83d\udd27 Added prompt-toolkit dependency for advanced input handling</li> <li>\ud83e\uddea Added 8 new unit tests for command execution (45 total tests)</li> <li>\ud83d\udcda Updated documentation with command execution examples</li> </ul>"},{"location":"usage/use-cases/#v021","title":"v0.2.1","text":"<ul> <li>\u2728 NEW: Intelligent file operation handling with intent recognition</li> <li>\u2728 NEW: Context-aware updates (reads before modifying)</li> <li>\u2728 NEW: Self-correcting behavior with smart retry mechanism (3 retries)</li> <li>\ud83d\udd27 Improved error messages for better agent understanding</li> <li>\ud83d\udd27 Enhanced system prompt with file operation guidelines</li> </ul>"},{"location":"usage/use-cases/#v020","title":"v0.2.0","text":"<ul> <li>\u2728 Added progress indicator with animated spinner</li> <li>\ud83d\udc1b Fixed duplicate output in CLI display</li> <li>\ud83d\udd27 Improved user experience during long operations</li> </ul>"},{"location":"usage/use-cases/#v013","title":"v0.1.3","text":"<ul> <li>\ud83d\udc1b Fixed result attribute compatibility across pydantic-ai versions</li> <li>\ud83d\udd27 Support for both .data and .output attributes</li> </ul>"},{"location":"usage/use-cases/#v012","title":"v0.1.2","text":"<ul> <li>\ud83c\udfa8 Fixed ASCII banner to correctly display \"WYN360\"</li> <li>\ud83d\udce7 Updated email to yiqiao.yin@wyn-associates.com</li> </ul>"},{"location":"usage/use-cases/#v011","title":"v0.1.1","text":"<ul> <li>\ud83d\udc1b Fixed AnthropicModel initialization error</li> <li>\ud83d\udd27 Updated to use environment variables for API key</li> </ul>"},{"location":"usage/use-cases/#v010","title":"v0.1.0","text":"<ul> <li>\ud83c\udf89 Initial release</li> </ul> <p>End of WYN360 CLI Complete User Guide</p> <p>This comprehensive guide covered all 18 use cases from simple to complex, with detailed appendices for reference. For the latest updates and version history, see the Changelog section above.</p>"}]}